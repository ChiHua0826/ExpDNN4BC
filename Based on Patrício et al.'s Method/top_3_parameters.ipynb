{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,2:3] #Glucose\n",
    "X2 = dataset[:,7:8] #Resistin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 3)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            36          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 226\n",
      "Trainable params: 226\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.7058 - acc: 0.5217 - auc_1: 0.4886 - val_loss: 0.6747 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6831 - acc: 0.5870 - auc_1: 0.5952 - val_loss: 0.6432 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6708 - acc: 0.5978 - auc_1: 0.6264 - val_loss: 0.6196 - val_acc: 0.7500 - val_auc_1: 0.7429\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6503 - acc: 0.6196 - auc_1: 0.6795 - val_loss: 0.5956 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6272 - acc: 0.6196 - auc_1: 0.7126 - val_loss: 0.5664 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6127 - acc: 0.6739 - auc_1: 0.7338 - val_loss: 0.5765 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5944 - acc: 0.6739 - auc_1: 0.7314 - val_loss: 0.5381 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5860 - acc: 0.6957 - auc_1: 0.7557 - val_loss: 0.5733 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5772 - acc: 0.6739 - auc_1: 0.7583 - val_loss: 0.5338 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5723 - acc: 0.7283 - auc_1: 0.7679 - val_loss: 0.5786 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5722 - acc: 0.6522 - auc_1: 0.7533 - val_loss: 0.5344 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5630 - acc: 0.6957 - auc_1: 0.7733 - val_loss: 0.5305 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5613 - acc: 0.7065 - auc_1: 0.7767 - val_loss: 0.5318 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5533 - acc: 0.7174 - auc_1: 0.7874 - val_loss: 0.6126 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5622 - acc: 0.7065 - auc_1: 0.7731 - val_loss: 0.5066 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5585 - acc: 0.7391 - auc_1: 0.7819 - val_loss: 0.5477 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5529 - acc: 0.7065 - auc_1: 0.7907 - val_loss: 0.5057 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5548 - acc: 0.6848 - auc_1: 0.7945 - val_loss: 0.5031 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5509 - acc: 0.7500 - auc_1: 0.7993 - val_loss: 0.5973 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5619 - acc: 0.7283 - auc_1: 0.7814 - val_loss: 0.5352 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5555 - acc: 0.6848 - auc_1: 0.7795 - val_loss: 0.5504 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5563 - acc: 0.7500 - auc_1: 0.7843 - val_loss: 0.5267 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5536 - acc: 0.7283 - auc_1: 0.7883 - val_loss: 0.5033 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5588 - acc: 0.7717 - auc_1: 0.7821 - val_loss: 0.5360 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5528 - acc: 0.7065 - auc_1: 0.7864 - val_loss: 0.5332 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5497 - acc: 0.7065 - auc_1: 0.7929 - val_loss: 0.5076 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5561 - acc: 0.7283 - auc_1: 0.7898 - val_loss: 0.5197 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5541 - acc: 0.7283 - auc_1: 0.7850 - val_loss: 0.5307 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5475 - acc: 0.7283 - auc_1: 0.7929 - val_loss: 0.5655 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5587 - acc: 0.7065 - auc_1: 0.7869 - val_loss: 0.5524 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5455 - acc: 0.7717 - auc_1: 0.7971 - val_loss: 0.5545 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5495 - acc: 0.7065 - auc_1: 0.7945 - val_loss: 0.5020 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5529 - acc: 0.7391 - auc_1: 0.7876 - val_loss: 0.5197 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5518 - acc: 0.6848 - auc_1: 0.7952 - val_loss: 0.5136 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5535 - acc: 0.7283 - auc_1: 0.7895 - val_loss: 0.5202 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5645 - acc: 0.7174 - auc_1: 0.7743 - val_loss: 0.4910 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5504 - acc: 0.7283 - auc_1: 0.7871 - val_loss: 0.5354 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5475 - acc: 0.7174 - auc_1: 0.7852 - val_loss: 0.5578 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5536 - acc: 0.7174 - auc_1: 0.7919 - val_loss: 0.5045 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5507 - acc: 0.7717 - auc_1: 0.7912 - val_loss: 0.5207 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5480 - acc: 0.7283 - auc_1: 0.7864 - val_loss: 0.5417 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5419 - acc: 0.6957 - auc_1: 0.8079 - val_loss: 0.4926 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5521 - acc: 0.6957 - auc_1: 0.7840 - val_loss: 0.5023 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5547 - acc: 0.7609 - auc_1: 0.7869 - val_loss: 0.5736 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5607 - acc: 0.7391 - auc_1: 0.7810 - val_loss: 0.5222 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5508 - acc: 0.7174 - auc_1: 0.7912 - val_loss: 0.4968 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5458 - acc: 0.6957 - auc_1: 0.7986 - val_loss: 0.5074 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5524 - acc: 0.7283 - auc_1: 0.7924 - val_loss: 0.5105 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5489 - acc: 0.7065 - auc_1: 0.7919 - val_loss: 0.5329 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5397 - acc: 0.7174 - auc_1: 0.8050 - val_loss: 0.4897 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5576 - acc: 0.7174 - auc_1: 0.7836 - val_loss: 0.5151 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5514 - acc: 0.7174 - auc_1: 0.7826 - val_loss: 0.5689 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5541 - acc: 0.6848 - auc_1: 0.7890 - val_loss: 0.5266 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5518 - acc: 0.7391 - auc_1: 0.7933 - val_loss: 0.5177 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5477 - acc: 0.6848 - auc_1: 0.7926 - val_loss: 0.5023 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5420 - acc: 0.7609 - auc_1: 0.7962 - val_loss: 0.5451 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5604 - acc: 0.7174 - auc_1: 0.7840 - val_loss: 0.5269 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5482 - acc: 0.7391 - auc_1: 0.7864 - val_loss: 0.5461 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5471 - acc: 0.6957 - auc_1: 0.7867 - val_loss: 0.4960 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5592 - acc: 0.7065 - auc_1: 0.7802 - val_loss: 0.5363 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5517 - acc: 0.7065 - auc_1: 0.7931 - val_loss: 0.5012 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5496 - acc: 0.7174 - auc_1: 0.7910 - val_loss: 0.5019 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5434 - acc: 0.7609 - auc_1: 0.7983 - val_loss: 0.5507 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5499 - acc: 0.6957 - auc_1: 0.7921 - val_loss: 0.5045 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5506 - acc: 0.7065 - auc_1: 0.7864 - val_loss: 0.5159 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5477 - acc: 0.7174 - auc_1: 0.7879 - val_loss: 0.5450 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5548 - acc: 0.7159 - auc_1: 0.787 - 0s 4ms/step - loss: 0.5542 - acc: 0.7174 - auc_1: 0.7895 - val_loss: 0.5387 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5465 - acc: 0.7283 - auc_1: 0.7979 - val_loss: 0.4883 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5545 - acc: 0.7065 - auc_1: 0.7762 - val_loss: 0.5085 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5488 - acc: 0.7283 - auc_1: 0.7979 - val_loss: 0.5006 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5489 - acc: 0.7065 - auc_1: 0.7862 - val_loss: 0.5049 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5472 - acc: 0.7065 - auc_1: 0.7895 - val_loss: 0.5056 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5530 - acc: 0.6957 - auc_1: 0.7907 - val_loss: 0.5064 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5461 - acc: 0.7174 - auc_1: 0.7955 - val_loss: 0.4990 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5480 - acc: 0.7283 - auc_1: 0.7902 - val_loss: 0.5116 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5553 - acc: 0.7174 - auc_1: 0.7921 - val_loss: 0.5247 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5492 - acc: 0.7391 - auc_1: 0.7907 - val_loss: 0.5278 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5506 - acc: 0.6848 - auc_1: 0.7910 - val_loss: 0.5162 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5516 - acc: 0.6739 - auc_1: 0.7898 - val_loss: 0.5002 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5441 - acc: 0.7500 - auc_1: 0.7983 - val_loss: 0.5224 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5493 - acc: 0.7283 - auc_1: 0.7900 - val_loss: 0.5035 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5477 - acc: 0.7391 - auc_1: 0.7900 - val_loss: 0.5328 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5501 - acc: 0.7065 - auc_1: 0.7905 - val_loss: 0.5161 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5425 - acc: 0.7174 - auc_1: 0.7988 - val_loss: 0.4871 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5470 - acc: 0.7065 - auc_1: 0.7912 - val_loss: 0.4858 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5473 - acc: 0.7500 - auc_1: 0.7948 - val_loss: 0.5282 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5476 - acc: 0.7174 - auc_1: 0.7981 - val_loss: 0.4909 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.5509 - acc: 0.7500 - auc_1: 0.7879 - val_loss: 0.5056 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5500 - acc: 0.6957 - auc_1: 0.7919 - val_loss: 0.5117 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5470 - acc: 0.7391 - auc_1: 0.7898 - val_loss: 0.5557 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5467 - acc: 0.6957 - auc_1: 0.7914 - val_loss: 0.5070 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5482 - acc: 0.7065 - auc_1: 0.7983 - val_loss: 0.5092 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.5456 - acc: 0.7283 - auc_1: 0.7945 - val_loss: 0.4975 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5478 - acc: 0.7500 - auc_1: 0.7926 - val_loss: 0.5261 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5448 - acc: 0.7283 - auc_1: 0.7964 - val_loss: 0.5066 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5543 - acc: 0.7391 - auc_1: 0.7876 - val_loss: 0.4968 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 97/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5487 - acc: 0.7174 - auc_1: 0.7912 - val_loss: 0.4950 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5504 - acc: 0.7391 - auc_1: 0.7876 - val_loss: 0.4989 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5470 - acc: 0.7174 - auc_1: 0.7910 - val_loss: 0.5180 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5449 - acc: 0.7283 - auc_1: 0.7938 - val_loss: 0.5158 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5463 - acc: 0.7174 - auc_1: 0.7943 - val_loss: 0.5077 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5500 - acc: 0.7174 - auc_1: 0.7871 - val_loss: 0.5628 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5448 - acc: 0.7391 - auc_1: 0.7957 - val_loss: 0.5365 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5518 - acc: 0.7283 - auc_1: 0.7867 - val_loss: 0.5272 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5455 - acc: 0.6957 - auc_1: 0.7943 - val_loss: 0.4861 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5507 - acc: 0.7717 - auc_1: 0.7883 - val_loss: 0.4920 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5347 - acc: 0.7609 - auc_1: 0.8074 - val_loss: 0.5836 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5529 - acc: 0.6848 - auc_1: 0.7929 - val_loss: 0.4897 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5454 - acc: 0.7065 - auc_1: 0.7983 - val_loss: 0.4834 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5469 - acc: 0.7283 - auc_1: 0.7962 - val_loss: 0.5216 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5532 - acc: 0.7065 - auc_1: 0.7900 - val_loss: 0.4934 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5476 - acc: 0.7500 - auc_1: 0.7876 - val_loss: 0.5160 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5465 - acc: 0.7283 - auc_1: 0.7860 - val_loss: 0.4941 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5456 - acc: 0.7065 - auc_1: 0.7969 - val_loss: 0.5041 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5429 - acc: 0.7391 - auc_1: 0.7990 - val_loss: 0.5561 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5470 - acc: 0.7174 - auc_1: 0.7940 - val_loss: 0.4924 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5495 - acc: 0.7283 - auc_1: 0.7888 - val_loss: 0.4850 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5497 - acc: 0.6957 - auc_1: 0.7950 - val_loss: 0.4975 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5385 - acc: 0.7065 - auc_1: 0.8005 - val_loss: 0.4754 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5526 - acc: 0.7283 - auc_1: 0.7790 - val_loss: 0.4842 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5513 - acc: 0.7174 - auc_1: 0.7895 - val_loss: 0.4789 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5469 - acc: 0.7500 - auc_1: 0.8031 - val_loss: 0.5067 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5473 - acc: 0.6957 - auc_1: 0.7919 - val_loss: 0.4739 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5444 - acc: 0.7391 - auc_1: 0.7969 - val_loss: 0.4919 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5519 - acc: 0.7391 - auc_1: 0.7907 - val_loss: 0.5024 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5472 - acc: 0.7174 - auc_1: 0.7931 - val_loss: 0.4858 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5400 - acc: 0.7609 - auc_1: 0.7976 - val_loss: 0.5321 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5479 - acc: 0.6957 - auc_1: 0.7981 - val_loss: 0.4854 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5467 - acc: 0.7065 - auc_1: 0.7960 - val_loss: 0.4754 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5383 - acc: 0.7500 - auc_1: 0.8029 - val_loss: 0.5171 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5486 - acc: 0.6739 - auc_1: 0.8060 - val_loss: 0.4655 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5458 - acc: 0.7174 - auc_1: 0.7879 - val_loss: 0.4799 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5480 - acc: 0.7283 - auc_1: 0.7943 - val_loss: 0.4837 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5358 - acc: 0.7283 - auc_1: 0.8043 - val_loss: 0.4577 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5487 - acc: 0.7391 - auc_1: 0.7905 - val_loss: 0.4742 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5452 - acc: 0.7391 - auc_1: 0.7957 - val_loss: 0.4778 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5443 - acc: 0.7174 - auc_1: 0.7945 - val_loss: 0.4850 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5458 - acc: 0.7500 - auc_1: 0.7907 - val_loss: 0.4769 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5449 - acc: 0.7609 - auc_1: 0.7888 - val_loss: 0.5200 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5456 - acc: 0.7391 - auc_1: 0.7962 - val_loss: 0.4879 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5446 - acc: 0.7283 - auc_1: 0.7969 - val_loss: 0.4760 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5438 - acc: 0.7609 - auc_1: 0.7940 - val_loss: 0.4899 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5425 - acc: 0.7500 - auc_1: 0.8010 - val_loss: 0.4924 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5452 - acc: 0.7500 - auc_1: 0.8012 - val_loss: 0.4776 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 145/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5478 - acc: 0.7174 - auc_1: 0.7902 - val_loss: 0.4970 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 146/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5424 - acc: 0.7283 - auc_1: 0.7964 - val_loss: 0.4546 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5402 - acc: 0.7500 - auc_1: 0.8048 - val_loss: 0.4832 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5439 - acc: 0.7174 - auc_1: 0.7955 - val_loss: 0.4621 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5447 - acc: 0.7283 - auc_1: 0.7888 - val_loss: 0.4416 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5454 - acc: 0.7283 - auc_1: 0.7910 - val_loss: 0.4571 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5426 - acc: 0.7391 - auc_1: 0.7933 - val_loss: 0.4621 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5396 - acc: 0.7609 - auc_1: 0.7964 - val_loss: 0.4595 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5456 - acc: 0.7174 - auc_1: 0.7931 - val_loss: 0.4931 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5395 - acc: 0.7391 - auc_1: 0.8014 - val_loss: 0.4502 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5421 - acc: 0.7609 - auc_1: 0.8007 - val_loss: 0.4570 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5570 - acc: 0.6988 - auc_1: 0.7813    - 0s 4ms/step - loss: 0.5475 - acc: 0.7174 - auc_1: 0.7919 - val_loss: 0.4460 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5408 - acc: 0.7283 - auc_1: 0.7990 - val_loss: 0.5085 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5400 - acc: 0.7391 - auc_1: 0.7955 - val_loss: 0.4461 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5463 - acc: 0.7500 - auc_1: 0.7943 - val_loss: 0.4791 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5458 - acc: 0.7391 - auc_1: 0.7898 - val_loss: 0.4748 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.5410 - acc: 0.7283 - auc_1: 0.7964 - val_loss: 0.4543 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.5366 - acc: 0.6848 - auc_1: 0.7981 - val_loss: 0.4374 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.5375 - acc: 0.7391 - auc_1: 0.7979 - val_loss: 0.4384 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5395 - acc: 0.7609 - auc_1: 0.7886 - val_loss: 0.4470 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5462 - acc: 0.7500 - auc_1: 0.7940 - val_loss: 0.4511 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5359 - acc: 0.7283 - auc_1: 0.8036 - val_loss: 0.4404 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5407 - acc: 0.7174 - auc_1: 0.7952 - val_loss: 0.4422 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5373 - acc: 0.7500 - auc_1: 0.7983 - val_loss: 0.4630 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5329 - acc: 0.7174 - auc_1: 0.8060 - val_loss: 0.4180 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5403 - acc: 0.7283 - auc_1: 0.8002 - val_loss: 0.4253 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5372 - acc: 0.7609 - auc_1: 0.7962 - val_loss: 0.4275 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5321 - acc: 0.7391 - auc_1: 0.7986 - val_loss: 0.4543 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5309 - acc: 0.7283 - auc_1: 0.8071 - val_loss: 0.4098 - val_acc: 0.8750 - val_auc_1: 0.9179\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5366 - acc: 0.7391 - auc_1: 0.7950 - val_loss: 0.4306 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5342 - acc: 0.7500 - auc_1: 0.8017 - val_loss: 0.4139 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5352 - acc: 0.7609 - auc_1: 0.7988 - val_loss: 0.4633 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5344 - acc: 0.7363 - auc_1: 0.794 - 0s 5ms/step - loss: 0.5356 - acc: 0.7391 - auc_1: 0.7948 - val_loss: 0.4050 - val_acc: 0.8750 - val_auc_1: 0.9250\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5281 - acc: 0.7717 - auc_1: 0.8043 - val_loss: 0.4431 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5322 - acc: 0.7391 - auc_1: 0.8040 - val_loss: 0.4408 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5372 - acc: 0.7174 - auc_1: 0.7931 - val_loss: 0.4168 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5318 - acc: 0.7391 - auc_1: 0.8012 - val_loss: 0.4394 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5350 - acc: 0.7717 - auc_1: 0.7943 - val_loss: 0.4388 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5324 - acc: 0.7391 - auc_1: 0.8038 - val_loss: 0.4156 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5384 - acc: 0.7500 - auc_1: 0.7969 - val_loss: 0.4158 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5286 - acc: 0.7174 - auc_1: 0.8014 - val_loss: 0.3984 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5349 - acc: 0.7174 - auc_1: 0.7990 - val_loss: 0.4340 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5307 - acc: 0.7283 - auc_1: 0.8050 - val_loss: 0.4329 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5309 - acc: 0.7500 - auc_1: 0.8002 - val_loss: 0.4227 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5239 - acc: 0.7717 - auc_1: 0.8067 - val_loss: 0.4253 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5240 - acc: 0.7500 - auc_1: 0.8076 - val_loss: 0.4025 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5268 - acc: 0.7283 - auc_1: 0.8060 - val_loss: 0.4151 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5271 - acc: 0.7717 - auc_1: 0.8052 - val_loss: 0.4030 - val_acc: 0.8750 - val_auc_1: 0.9071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5264 - acc: 0.7174 - auc_1: 0.8083 - val_loss: 0.3947 - val_acc: 0.8750 - val_auc_1: 0.9214\n",
      "Epoch 194/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5209 - acc: 0.7500 - auc_1: 0.8160 - val_loss: 0.4837 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5272 - acc: 0.7283 - auc_1: 0.8124 - val_loss: 0.4072 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5329 - acc: 0.7283 - auc_1: 0.8026 - val_loss: 0.4343 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5313 - acc: 0.7717 - auc_1: 0.8031 - val_loss: 0.3974 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5250 - acc: 0.7826 - auc_1: 0.8083 - val_loss: 0.3995 - val_acc: 0.8750 - val_auc_1: 0.9214\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5195 - acc: 0.7717 - auc_1: 0.8174 - val_loss: 0.4458 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5239 - acc: 0.7174 - auc_1: 0.8140 - val_loss: 0.4121 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5374 - acc: 0.7500 - auc_1: 0.7924 - val_loss: 0.4000 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5215 - acc: 0.7391 - auc_1: 0.8179 - val_loss: 0.4343 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.4927 - acc: 0.7500 - auc_1: 0.8295 - 0s 3ms/step - loss: 0.5335 - acc: 0.7283 - auc_1: 0.8038 - val_loss: 0.4052 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5219 - acc: 0.7609 - auc_1: 0.8107 - val_loss: 0.4320 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5127 - acc: 0.7717 - auc_1: 0.8240 - val_loss: 0.3850 - val_acc: 0.9167 - val_auc_1: 0.9286\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5295 - acc: 0.7500 - auc_1: 0.8102 - val_loss: 0.4190 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5136 - acc: 0.7609 - auc_1: 0.8200 - val_loss: 0.4009 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5222 - acc: 0.7391 - auc_1: 0.8095 - val_loss: 0.4046 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5205 - acc: 0.7717 - auc_1: 0.8110 - val_loss: 0.4891 - val_acc: 0.7500 - val_auc_1: 0.88576  \n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5246 - acc: 0.7500 - auc_1: 0.8071 - val_loss: 0.4107 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5177 - acc: 0.7717 - auc_1: 0.8162 - val_loss: 0.3976 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5240 - acc: 0.7826 - auc_1: 0.8010 - val_loss: 0.3946 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.5170 - acc: 0.7500 - auc_1: 0.8157 - val_loss: 0.3900 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5211 - acc: 0.7283 - auc_1: 0.8231 - val_loss: 0.4499 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5119 - acc: 0.7391 - auc_1: 0.8164 - val_loss: 0.4097 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5139 - acc: 0.7826 - auc_1: 0.8174 - val_loss: 0.3858 - val_acc: 0.8750 - val_auc_1: 0.9250\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5148 - acc: 0.7826 - auc_1: 0.8255 - val_loss: 0.4337 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5297 - acc: 0.7717 - auc_1: 0.8105 - val_loss: 0.4032 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5178 - acc: 0.7717 - auc_1: 0.8121 - val_loss: 0.4012 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5070 - acc: 0.7717 - auc_1: 0.8305 - val_loss: 0.3928 - val_acc: 0.8750 - val_auc_1: 0.9179\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5084 - acc: 0.7717 - auc_1: 0.8250 - val_loss: 0.4400 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5061 - acc: 0.7391 - auc_1: 0.8305 - val_loss: 0.4423 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5092 - acc: 0.7717 - auc_1: 0.8255 - val_loss: 0.4336 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5084 - acc: 0.7391 - auc_1: 0.8302 - val_loss: 0.4366 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.5075 - acc: 0.7609 - auc_1: 0.8326 - val_loss: 0.4535 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5085 - acc: 0.7826 - auc_1: 0.8226 - val_loss: 0.4024 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4984 - acc: 0.7609 - auc_1: 0.8417 - val_loss: 0.4922 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5161 - acc: 0.7500 - auc_1: 0.8186 - val_loss: 0.4286 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5087 - acc: 0.7500 - auc_1: 0.8202 - val_loss: 0.4367 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5067 - acc: 0.7717 - auc_1: 0.8271 - val_loss: 0.4314 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5070 - acc: 0.7609 - auc_1: 0.8276 - val_loss: 0.4253 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.5030 - acc: 0.7500 - auc_1: 0.8295 - val_loss: 0.4443 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5051 - acc: 0.7826 - auc_1: 0.8293 - val_loss: 0.3868 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5068 - acc: 0.7500 - auc_1: 0.8274 - val_loss: 0.3902 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5054 - acc: 0.7717 - auc_1: 0.8226 - val_loss: 0.3957 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4994 - acc: 0.7717 - auc_1: 0.8393 - val_loss: 0.4547 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5007 - acc: 0.7283 - auc_1: 0.8288 - val_loss: 0.4459 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5011 - acc: 0.7826 - auc_1: 0.8338 - val_loss: 0.3927 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5080 - acc: 0.7500 - auc_1: 0.8283 - val_loss: 0.3910 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4962 - acc: 0.7391 - auc_1: 0.8386 - val_loss: 0.3768 - val_acc: 0.9167 - val_auc_1: 0.9071\n",
      "Epoch 241/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: 0.4996 - acc: 0.7609 - auc_1: 0.8376 - val_loss: 0.4159 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 242/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5060 - acc: 0.7283 - auc_1: 0.8212 - val_loss: 0.3867 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5007 - acc: 0.7717 - auc_1: 0.8267 - val_loss: 0.3882 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4940 - acc: 0.7717 - auc_1: 0.8452 - val_loss: 0.4012 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4953 - acc: 0.7826 - auc_1: 0.8305 - val_loss: 0.3868 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5029 - acc: 0.7609 - auc_1: 0.8350 - val_loss: 0.4061 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4888 - acc: 0.7717 - auc_1: 0.8457 - val_loss: 0.4671 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4946 - acc: 0.7717 - auc_1: 0.8355 - val_loss: 0.4169 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4981 - acc: 0.7283 - auc_1: 0.8293 - val_loss: 0.4316 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4933 - acc: 0.7717 - auc_1: 0.8355 - val_loss: 0.4583 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4917 - acc: 0.7609 - auc_1: 0.8455 - val_loss: 0.4144 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4901 - acc: 0.7609 - auc_1: 0.8369 - val_loss: 0.4498 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4835 - acc: 0.7935 - auc_1: 0.8464 - val_loss: 0.4037 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5020 - acc: 0.7717 - auc_1: 0.8379 - val_loss: 0.3716 - val_acc: 0.9167 - val_auc_1: 0.9143\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4959 - acc: 0.7717 - auc_1: 0.8267 - val_loss: 0.4438 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4845 - acc: 0.7935 - auc_1: 0.8300 - val_loss: 0.3905 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4892 - acc: 0.7717 - auc_1: 0.8471 - val_loss: 0.3896 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4860 - acc: 0.8152 - auc_1: 0.8436 - val_loss: 0.4447 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4906 - acc: 0.7826 - auc_1: 0.8379 - val_loss: 0.3724 - val_acc: 0.9167 - val_auc_1: 0.9143\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4846 - acc: 0.7826 - auc_1: 0.8460 - val_loss: 0.4125 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4874 - acc: 0.7391 - auc_1: 0.8443 - val_loss: 0.4711 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4823 - acc: 0.7500 - auc_1: 0.8410 - val_loss: 0.4209 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.4763 - acc: 0.8043 - auc_1: 0.8502 - val_loss: 0.3764 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4838 - acc: 0.7717 - auc_1: 0.8436 - val_loss: 0.5226 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4838 - acc: 0.7826 - auc_1: 0.8479 - val_loss: 0.4028 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4892 - acc: 0.7500 - auc_1: 0.8388 - val_loss: 0.3565 - val_acc: 0.9583 - val_auc_1: 0.9214\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4803 - acc: 0.7935 - auc_1: 0.8464 - val_loss: 0.4150 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4736 - acc: 0.7826 - auc_1: 0.8538 - val_loss: 0.3703 - val_acc: 0.9167 - val_auc_1: 0.9143\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4749 - acc: 0.7717 - auc_1: 0.8483 - val_loss: 0.4059 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4668 - acc: 0.7826 - auc_1: 0.8574 - val_loss: 0.4578 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4769 - acc: 0.7391 - auc_1: 0.8469 - val_loss: 0.3654 - val_acc: 0.9167 - val_auc_1: 0.9179\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4738 - acc: 0.7717 - auc_1: 0.8521 - val_loss: 0.3629 - val_acc: 0.9167 - val_auc_1: 0.9143\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4729 - acc: 0.7935 - auc_1: 0.8474 - val_loss: 0.4070 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4631 - acc: 0.8043 - auc_1: 0.8517 - val_loss: 0.3732 - val_acc: 0.9167 - val_auc_1: 0.9071\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4692 - acc: 0.7717 - auc_1: 0.8526 - val_loss: 0.4408 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4671 - acc: 0.7826 - auc_1: 0.8529 - val_loss: 0.3607 - val_acc: 0.9167 - val_auc_1: 0.9143\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4661 - acc: 0.7826 - auc_1: 0.8540 - val_loss: 0.4339 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4610 - acc: 0.7935 - auc_1: 0.8562 - val_loss: 0.3970 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4517 - acc: 0.8043 - auc_1: 0.8607 - val_loss: 0.3615 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4569 - acc: 0.7717 - auc_1: 0.8507 - val_loss: 0.3667 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4595 - acc: 0.7935 - auc_1: 0.8526 - val_loss: 0.3892 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4543 - acc: 0.8152 - auc_1: 0.8562 - val_loss: 0.3808 - val_acc: 0.9167 - val_auc_1: 0.9000\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4560 - acc: 0.8043 - auc_1: 0.8614 - val_loss: 0.3644 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4485 - acc: 0.7826 - auc_1: 0.8667 - val_loss: 0.4125 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4444 - acc: 0.8043 - auc_1: 0.8702 - val_loss: 0.4109 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4444 - acc: 0.7935 - auc_1: 0.8643 - val_loss: 0.3586 - val_acc: 0.9167 - val_auc_1: 0.9107\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4437 - acc: 0.8152 - auc_1: 0.8669 - val_loss: 0.3843 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4358 - acc: 0.8261 - auc_1: 0.8664 - val_loss: 0.3578 - val_acc: 0.9167 - val_auc_1: 0.9071\n",
      "Epoch 289/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4346 - acc: 0.8370 - auc_1: 0.8643 - val_loss: 0.3552 - val_acc: 0.9167 - val_auc_1: 0.9143\n",
      "Epoch 290/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4430 - acc: 0.8043 - auc_1: 0.8619 - val_loss: 0.3989 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4288 - acc: 0.8478 - auc_1: 0.8640 - val_loss: 0.3570 - val_acc: 0.9167 - val_auc_1: 0.9143\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4331 - acc: 0.8478 - auc_1: 0.8626 - val_loss: 0.3781 - val_acc: 0.9167 - val_auc_1: 0.9036\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4243 - acc: 0.8370 - auc_1: 0.8733 - val_loss: 0.4053 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4320 - acc: 0.8261 - auc_1: 0.8650 - val_loss: 0.3759 - val_acc: 0.9167 - val_auc_1: 0.9071\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4187 - acc: 0.8043 - auc_1: 0.8769 - val_loss: 0.3083 - val_acc: 0.9583 - val_auc_1: 0.9214\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4386 - acc: 0.8152 - auc_1: 0.8683 - val_loss: 0.3163 - val_acc: 0.9167 - val_auc_1: 0.9214\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4229 - acc: 0.8261 - auc_1: 0.8702 - val_loss: 0.3110 - val_acc: 0.9583 - val_auc_1: 0.9214\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4201 - acc: 0.8478 - auc_1: 0.8698 - val_loss: 0.3717 - val_acc: 0.9167 - val_auc_1: 0.9107\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4095 - acc: 0.8587 - auc_1: 0.8800 - val_loss: 0.3309 - val_acc: 0.9167 - val_auc_1: 0.9179\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4139 - acc: 0.8261 - auc_1: 0.8798 - val_loss: 0.3620 - val_acc: 0.9167 - val_auc_1: 0.9071\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4172 - acc: 0.8587 - auc_1: 0.8707 - val_loss: 0.3443 - val_acc: 0.9167 - val_auc_1: 0.9179\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4112 - acc: 0.8370 - auc_1: 0.8790 - val_loss: 0.3598 - val_acc: 0.9167 - val_auc_1: 0.9214\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4049 - acc: 0.8370 - auc_1: 0.8840 - val_loss: 0.3480 - val_acc: 0.9167 - val_auc_1: 0.9179\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3973 - acc: 0.8261 - auc_1: 0.8900 - val_loss: 0.3272 - val_acc: 0.9167 - val_auc_1: 0.9250\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4191 - acc: 0.8261 - auc_1: 0.8776 - val_loss: 0.3421 - val_acc: 0.9167 - val_auc_1: 0.9143\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.4448 - acc: 0.8158 - auc_1: 0.8603 - 0s 3ms/step - loss: 0.4071 - acc: 0.8370 - auc_1: 0.8821 - val_loss: 0.3589 - val_acc: 0.9167 - val_auc_1: 0.9214\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4032 - acc: 0.8370 - auc_1: 0.8824 - val_loss: 0.3665 - val_acc: 0.9167 - val_auc_1: 0.9179\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4000 - acc: 0.8587 - auc_1: 0.8786 - val_loss: 0.3597 - val_acc: 0.9167 - val_auc_1: 0.9179\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3877 - acc: 0.8261 - auc_1: 0.8962 - val_loss: 0.5454 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3911 - acc: 0.8478 - auc_1: 0.8962 - val_loss: 0.3994 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4018 - acc: 0.8478 - auc_1: 0.8821 - val_loss: 0.3642 - val_acc: 0.9167 - val_auc_1: 0.9214\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4172 - acc: 0.8261 - auc_1: 0.8795 - val_loss: 0.3655 - val_acc: 0.9167 - val_auc_1: 0.9214\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3987 - acc: 0.8478 - auc_1: 0.8836 - val_loss: 0.4390 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3992 - acc: 0.8370 - auc_1: 0.8867 - val_loss: 0.3978 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3998 - acc: 0.8478 - auc_1: 0.8848 - val_loss: 0.4383 - val_acc: 0.8750 - val_auc_1: 0.8857\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4004 - acc: 0.8587 - auc_1: 0.8810 - val_loss: 0.3734 - val_acc: 0.9167 - val_auc_1: 0.9143\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3999 - acc: 0.8261 - auc_1: 0.8805 - val_loss: 0.3081 - val_acc: 0.9167 - val_auc_1: 0.9357\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3982 - acc: 0.8478 - auc_1: 0.8774 - val_loss: 0.3921 - val_acc: 0.9167 - val_auc_1: 0.9000\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3896 - acc: 0.8478 - auc_1: 0.8857 - val_loss: 0.3955 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3870 - acc: 0.8261 - auc_1: 0.8855 - val_loss: 0.4225 - val_acc: 0.8750 - val_auc_1: 0.8893\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3994 - acc: 0.8370 - auc_1: 0.8850 - val_loss: 0.3836 - val_acc: 0.9167 - val_auc_1: 0.8964\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3877 - acc: 0.8478 - auc_1: 0.8907 - val_loss: 0.3791 - val_acc: 0.9167 - val_auc_1: 0.9036\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3846 - acc: 0.8587 - auc_1: 0.8905 - val_loss: 0.4532 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3771 - acc: 0.8370 - auc_1: 0.8988 - val_loss: 0.3281 - val_acc: 0.8750 - val_auc_1: 0.9250\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4053 - acc: 0.7935 - auc_1: 0.8929 - val_loss: 0.3333 - val_acc: 0.9167 - val_auc_1: 0.9179\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3858 - acc: 0.8370 - auc_1: 0.8848 - val_loss: 0.3836 - val_acc: 0.9167 - val_auc_1: 0.8929\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3801 - acc: 0.8370 - auc_1: 0.8945 - val_loss: 0.3979 - val_acc: 0.9167 - val_auc_1: 0.8929\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3831 - acc: 0.8478 - auc_1: 0.8933 - val_loss: 0.4263 - val_acc: 0.8750 - val_auc_1: 0.8857\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3769 - acc: 0.8478 - auc_1: 0.8955 - val_loss: 0.4237 - val_acc: 0.8750 - val_auc_1: 0.8857\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3829 - acc: 0.8370 - auc_1: 0.8969 - val_loss: 0.3875 - val_acc: 0.9167 - val_auc_1: 0.8929\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3821 - acc: 0.8587 - auc_1: 0.8919 - val_loss: 0.3909 - val_acc: 0.9167 - val_auc_1: 0.8964\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3752 - acc: 0.8478 - auc_1: 0.8940 - val_loss: 0.4123 - val_acc: 0.9167 - val_auc_1: 0.8857\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3747 - acc: 0.8478 - auc_1: 0.8964 - val_loss: 0.4611 - val_acc: 0.8750 - val_auc_1: 0.8821\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3756 - acc: 0.8587 - auc_1: 0.8957 - val_loss: 0.4554 - val_acc: 0.8750 - val_auc_1: 0.8786\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3853 - acc: 0.8370 - auc_1: 0.8905 - val_loss: 0.3960 - val_acc: 0.9167 - val_auc_1: 0.8893\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3702 - acc: 0.8587 - auc_1: 0.9000 - val_loss: 0.4045 - val_acc: 0.9167 - val_auc_1: 0.8893\n",
      "Epoch 337/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3795 - acc: 0.8478 - auc_1: 0.8981 - val_loss: 0.4118 - val_acc: 0.9167 - val_auc_1: 0.8857\n",
      "Epoch 338/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3836 - acc: 0.8261 - auc_1: 0.8900 - val_loss: 0.3658 - val_acc: 0.9167 - val_auc_1: 0.9071\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3715 - acc: 0.8370 - auc_1: 0.8936 - val_loss: 0.3955 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3789 - acc: 0.8261 - auc_1: 0.8988 - val_loss: 0.4149 - val_acc: 0.9167 - val_auc_1: 0.8857\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3648 - acc: 0.8370 - auc_1: 0.9033 - val_loss: 0.4693 - val_acc: 0.8750 - val_auc_1: 0.8786\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3804 - acc: 0.8370 - auc_1: 0.9010 - val_loss: 0.4348 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3709 - acc: 0.8261 - auc_1: 0.9007 - val_loss: 0.4052 - val_acc: 0.9167 - val_auc_1: 0.8893\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3781 - acc: 0.8478 - auc_1: 0.8936 - val_loss: 0.4299 - val_acc: 0.9167 - val_auc_1: 0.8857\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3663 - acc: 0.8587 - auc_1: 0.9069 - val_loss: 0.4331 - val_acc: 0.9167 - val_auc_1: 0.8786\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3619 - acc: 0.8478 - auc_1: 0.9040 - val_loss: 0.5042 - val_acc: 0.8750 - val_auc_1: 0.8679\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3744 - acc: 0.8261 - auc_1: 0.9067 - val_loss: 0.4079 - val_acc: 0.9167 - val_auc_1: 0.8857\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3636 - acc: 0.8587 - auc_1: 0.9017 - val_loss: 0.5229 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3680 - acc: 0.8478 - auc_1: 0.9060 - val_loss: 0.4622 - val_acc: 0.8750 - val_auc_1: 0.8821\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3752 - acc: 0.8043 - auc_1: 0.9038 - val_loss: 0.3278 - val_acc: 0.9583 - val_auc_1: 0.9250\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3777 - acc: 0.8478 - auc_1: 0.8950 - val_loss: 0.4212 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3633 - acc: 0.8261 - auc_1: 0.9100 - val_loss: 0.4982 - val_acc: 0.8750 - val_auc_1: 0.8714\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3655 - acc: 0.8152 - auc_1: 0.9071 - val_loss: 0.4109 - val_acc: 0.9167 - val_auc_1: 0.8857\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3589 - acc: 0.8370 - auc_1: 0.9088 - val_loss: 0.4981 - val_acc: 0.8750 - val_auc_1: 0.8750\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3773 - acc: 0.8152 - auc_1: 0.8950 - val_loss: 0.4542 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3685 - acc: 0.8478 - auc_1: 0.8881 - val_loss: 0.3804 - val_acc: 0.8750 - val_auc_1: 0.9000\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3631 - acc: 0.8261 - auc_1: 0.9183 - val_loss: 0.4833 - val_acc: 0.8750 - val_auc_1: 0.8786\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3873 - acc: 0.8152 - auc_1: 0.9029 - val_loss: 0.4101 - val_acc: 0.9167 - val_auc_1: 0.8857\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3706 - acc: 0.8261 - auc_1: 0.9112 - val_loss: 0.3869 - val_acc: 0.9167 - val_auc_1: 0.9036\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3585 - acc: 0.8478 - auc_1: 0.9081 - val_loss: 0.4403 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3669 - acc: 0.8370 - auc_1: 0.9005 - val_loss: 0.3750 - val_acc: 0.9167 - val_auc_1: 0.9036\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3610 - acc: 0.8370 - auc_1: 0.9143 - val_loss: 0.5062 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3547 - acc: 0.8370 - auc_1: 0.9174 - val_loss: 0.4201 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3571 - acc: 0.8478 - auc_1: 0.9124 - val_loss: 0.4570 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.3441 - acc: 0.8370 - auc_1: 0.9279 - val_loss: 0.5449 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3730 - acc: 0.8261 - auc_1: 0.9110 - val_loss: 0.5228 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3660 - acc: 0.8261 - auc_1: 0.9124 - val_loss: 0.4271 - val_acc: 0.9167 - val_auc_1: 0.8893\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3559 - acc: 0.8370 - auc_1: 0.9131 - val_loss: 0.4499 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3522 - acc: 0.8261 - auc_1: 0.9105 - val_loss: 0.4757 - val_acc: 0.9167 - val_auc_1: 0.8786\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3550 - acc: 0.8370 - auc_1: 0.9110 - val_loss: 0.4689 - val_acc: 0.9167 - val_auc_1: 0.8750\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3464 - acc: 0.8587 - auc_1: 0.9119 - val_loss: 0.4481 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3454 - acc: 0.8370 - auc_1: 0.9217 - val_loss: 0.4995 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3603 - acc: 0.8370 - auc_1: 0.9083 - val_loss: 0.4687 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3490 - acc: 0.8478 - auc_1: 0.9167 - val_loss: 0.4644 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3520 - acc: 0.8478 - auc_1: 0.9150 - val_loss: 0.4716 - val_acc: 0.9167 - val_auc_1: 0.8786\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3630 - acc: 0.8261 - auc_1: 0.9148 - val_loss: 0.4393 - val_acc: 0.8750 - val_auc_1: 0.8821\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3614 - acc: 0.8261 - auc_1: 0.9093 - val_loss: 0.4864 - val_acc: 0.9167 - val_auc_1: 0.8750\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3525 - acc: 0.8261 - auc_1: 0.9145 - val_loss: 0.5453 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3505 - acc: 0.8261 - auc_1: 0.9110 - val_loss: 0.4729 - val_acc: 0.8750 - val_auc_1: 0.8821\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3530 - acc: 0.8370 - auc_1: 0.9226 - val_loss: 0.4287 - val_acc: 0.9167 - val_auc_1: 0.8857\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3489 - acc: 0.8478 - auc_1: 0.9229 - val_loss: 0.4647 - val_acc: 0.9167 - val_auc_1: 0.8714\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3516 - acc: 0.8370 - auc_1: 0.9167 - val_loss: 0.5025 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3373 - acc: 0.8478 - auc_1: 0.9248 - val_loss: 0.4455 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3460 - acc: 0.8370 - auc_1: 0.9214 - val_loss: 0.6264 - val_acc: 0.8333 - val_auc_1: 0.8071\n",
      "Epoch 385/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3447 - acc: 0.8261 - auc_1: 0.9231 - val_loss: 0.4419 - val_acc: 0.9167 - val_auc_1: 0.8750\n",
      "Epoch 386/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3460 - acc: 0.8370 - auc_1: 0.9198 - val_loss: 0.5548 - val_acc: 0.8750 - val_auc_1: 0.8464\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3487 - acc: 0.8261 - auc_1: 0.9190 - val_loss: 0.4945 - val_acc: 0.9167 - val_auc_1: 0.8714\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3363 - acc: 0.8370 - auc_1: 0.9248 - val_loss: 0.4746 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3391 - acc: 0.8370 - auc_1: 0.9226 - val_loss: 0.4221 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3404 - acc: 0.8370 - auc_1: 0.9250 - val_loss: 0.5314 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3529 - acc: 0.8370 - auc_1: 0.9179 - val_loss: 0.3948 - val_acc: 0.9167 - val_auc_1: 0.9000\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3400 - acc: 0.8370 - auc_1: 0.9217 - val_loss: 0.5531 - val_acc: 0.8750 - val_auc_1: 0.8393\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3474 - acc: 0.8152 - auc_1: 0.9238 - val_loss: 0.5100 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3352 - acc: 0.8478 - auc_1: 0.9252 - val_loss: 0.4812 - val_acc: 0.8750 - val_auc_1: 0.8750\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3423 - acc: 0.8370 - auc_1: 0.9212 - val_loss: 0.4631 - val_acc: 0.9167 - val_auc_1: 0.8786\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3439 - acc: 0.8261 - auc_1: 0.9276 - val_loss: 0.6086 - val_acc: 0.8333 - val_auc_1: 0.8321\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3365 - acc: 0.8370 - auc_1: 0.9212 - val_loss: 0.5168 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3355 - acc: 0.8370 - auc_1: 0.9195 - val_loss: 0.5289 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3419 - acc: 0.8261 - auc_1: 0.9207 - val_loss: 0.5042 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3391 - acc: 0.8261 - auc_1: 0.9236 - val_loss: 0.4685 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3340 - acc: 0.8261 - auc_1: 0.9231 - val_loss: 0.5280 - val_acc: 0.8750 - val_auc_1: 0.8786\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3335 - acc: 0.8478 - auc_1: 0.9262 - val_loss: 0.5489 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3393 - acc: 0.8152 - auc_1: 0.9233 - val_loss: 0.5156 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3333 - acc: 0.8261 - auc_1: 0.9281 - val_loss: 0.5291 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3435 - acc: 0.8152 - auc_1: 0.9179 - val_loss: 0.5075 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3379 - acc: 0.8370 - auc_1: 0.9260 - val_loss: 0.5095 - val_acc: 0.9167 - val_auc_1: 0.8821\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3441 - acc: 0.8261 - auc_1: 0.9224 - val_loss: 0.6041 - val_acc: 0.8333 - val_auc_1: 0.8357\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3473 - acc: 0.8043 - auc_1: 0.9229 - val_loss: 0.5330 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3301 - acc: 0.8261 - auc_1: 0.9224 - val_loss: 0.5421 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3323 - acc: 0.8478 - auc_1: 0.9262 - val_loss: 0.5230 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3242 - acc: 0.8478 - auc_1: 0.9293 - val_loss: 0.5791 - val_acc: 0.8750 - val_auc_1: 0.8429\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3316 - acc: 0.8370 - auc_1: 0.9255 - val_loss: 0.5205 - val_acc: 0.9167 - val_auc_1: 0.8714\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3295 - acc: 0.8478 - auc_1: 0.9188 - val_loss: 0.5086 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3287 - acc: 0.8478 - auc_1: 0.9250 - val_loss: 0.5879 - val_acc: 0.8750 - val_auc_1: 0.8321\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3391 - acc: 0.8261 - auc_1: 0.9195 - val_loss: 0.5673 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3360 - acc: 0.8152 - auc_1: 0.9238 - val_loss: 0.5258 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3323 - acc: 0.8261 - auc_1: 0.9279 - val_loss: 0.5522 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3371 - acc: 0.8478 - auc_1: 0.9238 - val_loss: 0.4804 - val_acc: 0.8750 - val_auc_1: 0.8786\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3296 - acc: 0.8370 - auc_1: 0.9264 - val_loss: 0.5522 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3322 - acc: 0.8261 - auc_1: 0.9195 - val_loss: 0.5557 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3363 - acc: 0.8478 - auc_1: 0.9176 - val_loss: 0.6014 - val_acc: 0.8750 - val_auc_1: 0.8321\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3300 - acc: 0.8478 - auc_1: 0.9226 - val_loss: 0.5151 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3319 - acc: 0.8261 - auc_1: 0.9217 - val_loss: 0.4708 - val_acc: 0.9167 - val_auc_1: 0.8786\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3248 - acc: 0.8370 - auc_1: 0.9229 - val_loss: 0.5758 - val_acc: 0.8750 - val_auc_1: 0.8464\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3243 - acc: 0.8478 - auc_1: 0.9248 - val_loss: 0.6464 - val_acc: 0.8750 - val_auc_1: 0.8179\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3315 - acc: 0.8043 - auc_1: 0.9302 - val_loss: 0.5194 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3169 - acc: 0.8370 - auc_1: 0.9269 - val_loss: 0.6394 - val_acc: 0.8750 - val_auc_1: 0.8250\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3371 - acc: 0.8478 - auc_1: 0.9248 - val_loss: 0.5072 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3230 - acc: 0.8370 - auc_1: 0.9250 - val_loss: 0.4806 - val_acc: 0.8750 - val_auc_1: 0.8679\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3198 - acc: 0.8478 - auc_1: 0.9295 - val_loss: 0.6089 - val_acc: 0.8750 - val_auc_1: 0.8321\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3309 - acc: 0.8261 - auc_1: 0.9257 - val_loss: 0.5241 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3142 - acc: 0.8370 - auc_1: 0.9288 - val_loss: 0.6557 - val_acc: 0.8750 - val_auc_1: 0.8214\n",
      "Epoch 433/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3308 - acc: 0.8043 - auc_1: 0.9240 - val_loss: 0.6263 - val_acc: 0.8750 - val_auc_1: 0.8321\n",
      "Epoch 434/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3112 - acc: 0.8478 - auc_1: 0.9350 - val_loss: 0.6508 - val_acc: 0.8750 - val_auc_1: 0.8214\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.3177 - acc: 0.8370 - auc_1: 0.9326 - val_loss: 0.5374 - val_acc: 0.8750 - val_auc_1: 0.8679\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3249 - acc: 0.8370 - auc_1: 0.9248 - val_loss: 0.4911 - val_acc: 0.8750 - val_auc_1: 0.8750\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3294 - acc: 0.8261 - auc_1: 0.9250 - val_loss: 0.4383 - val_acc: 0.8750 - val_auc_1: 0.8821\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3184 - acc: 0.8370 - auc_1: 0.9298 - val_loss: 0.5832 - val_acc: 0.8750 - val_auc_1: 0.8393\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3200 - acc: 0.8261 - auc_1: 0.9190 - val_loss: 0.4957 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3136 - acc: 0.8478 - auc_1: 0.9269 - val_loss: 0.6097 - val_acc: 0.8750 - val_auc_1: 0.8286\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3111 - acc: 0.8152 - auc_1: 0.9319 - val_loss: 0.5526 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3144 - acc: 0.8478 - auc_1: 0.9281 - val_loss: 0.5676 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3048 - acc: 0.8370 - auc_1: 0.9310 - val_loss: 0.6941 - val_acc: 0.8333 - val_auc_1: 0.8071\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3252 - acc: 0.8478 - auc_1: 0.9248 - val_loss: 0.5950 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3079 - acc: 0.8478 - auc_1: 0.9350 - val_loss: 0.5230 - val_acc: 0.9167 - val_auc_1: 0.8714\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3051 - acc: 0.8152 - auc_1: 0.9317 - val_loss: 0.5856 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3057 - acc: 0.8587 - auc_1: 0.9310 - val_loss: 0.6216 - val_acc: 0.8750 - val_auc_1: 0.8286\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3092 - acc: 0.8152 - auc_1: 0.9255 - val_loss: 0.5872 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3056 - acc: 0.8261 - auc_1: 0.9388 - val_loss: 0.6934 - val_acc: 0.8333 - val_auc_1: 0.8143\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3111 - acc: 0.8478 - auc_1: 0.9310 - val_loss: 0.7144 - val_acc: 0.8333 - val_auc_1: 0.8071\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3344 - acc: 0.8261 - auc_1: 0.9217 - val_loss: 0.6120 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3012 - acc: 0.8370 - auc_1: 0.9295 - val_loss: 0.5665 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3151 - acc: 0.8587 - auc_1: 0.9336 - val_loss: 0.5663 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3174 - acc: 0.8478 - auc_1: 0.9233 - val_loss: 0.5909 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3088 - acc: 0.8370 - auc_1: 0.9293 - val_loss: 0.6678 - val_acc: 0.8750 - val_auc_1: 0.8286\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3168 - acc: 0.8261 - auc_1: 0.9245 - val_loss: 0.5963 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3095 - acc: 0.8370 - auc_1: 0.9283 - val_loss: 0.5249 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3081 - acc: 0.8370 - auc_1: 0.9264 - val_loss: 0.5648 - val_acc: 0.9167 - val_auc_1: 0.8714\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3211 - acc: 0.8261 - auc_1: 0.9348 - val_loss: 0.5156 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3085 - acc: 0.8370 - auc_1: 0.9305 - val_loss: 0.6028 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3018 - acc: 0.8587 - auc_1: 0.9324 - val_loss: 0.5937 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.3046 - acc: 0.8261 - auc_1: 0.9343 - val_loss: 0.6996 - val_acc: 0.8750 - val_auc_1: 0.8143\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3069 - acc: 0.8370 - auc_1: 0.9307 - val_loss: 0.6260 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.3066 - acc: 0.8370 - auc_1: 0.9300 - val_loss: 0.5632 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2989 - acc: 0.8587 - auc_1: 0.9331 - val_loss: 0.6133 - val_acc: 0.8750 - val_auc_1: 0.8429\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2988 - acc: 0.8478 - auc_1: 0.9290 - val_loss: 0.4982 - val_acc: 0.9167 - val_auc_1: 0.8714\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3000 - acc: 0.8478 - auc_1: 0.9274 - val_loss: 0.5925 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.2982 - acc: 0.8587 - auc_1: 0.9314 - val_loss: 0.6183 - val_acc: 0.8333 - val_auc_1: 0.8321\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2974 - acc: 0.8478 - auc_1: 0.9367 - val_loss: 0.5559 - val_acc: 0.8750 - val_auc_1: 0.8714\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.3047 - acc: 0.8261 - auc_1: 0.9210 - val_loss: 0.5446 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3000 - acc: 0.8478 - auc_1: 0.9302 - val_loss: 0.6520 - val_acc: 0.8750 - val_auc_1: 0.8286\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2932 - acc: 0.8370 - auc_1: 0.9340 - val_loss: 0.6353 - val_acc: 0.8750 - val_auc_1: 0.8393\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2947 - acc: 0.8261 - auc_1: 0.9369 - val_loss: 0.5645 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2984 - acc: 0.8261 - auc_1: 0.9329 - val_loss: 0.5626 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2933 - acc: 0.8587 - auc_1: 0.9348 - val_loss: 0.6618 - val_acc: 0.8750 - val_auc_1: 0.8250\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2978 - acc: 0.8478 - auc_1: 0.9388 - val_loss: 0.6024 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3065 - acc: 0.8261 - auc_1: 0.9212 - val_loss: 0.6265 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3006 - acc: 0.8370 - auc_1: 0.9357 - val_loss: 0.5172 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2986 - acc: 0.8261 - auc_1: 0.9338 - val_loss: 0.6036 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3071 - acc: 0.8370 - auc_1: 0.9286 - val_loss: 0.6159 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 481/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2881 - acc: 0.8478 - auc_1: 0.9355 - val_loss: 0.5946 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 482/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2965 - acc: 0.8478 - auc_1: 0.9336 - val_loss: 0.6261 - val_acc: 0.8750 - val_auc_1: 0.8464\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2889 - acc: 0.8370 - auc_1: 0.9329 - val_loss: 0.6188 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2901 - acc: 0.8587 - auc_1: 0.9314 - val_loss: 0.5992 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2839 - acc: 0.8587 - auc_1: 0.9371 - val_loss: 0.5961 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2905 - acc: 0.8587 - auc_1: 0.9345 - val_loss: 0.5355 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2942 - acc: 0.8370 - auc_1: 0.9319 - val_loss: 0.5757 - val_acc: 0.8750 - val_auc_1: 0.8679\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2843 - acc: 0.8587 - auc_1: 0.9388 - val_loss: 0.6042 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2817 - acc: 0.8478 - auc_1: 0.9312 - val_loss: 0.6058 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2940 - acc: 0.8478 - auc_1: 0.9367 - val_loss: 0.5832 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2975 - acc: 0.8370 - auc_1: 0.9345 - val_loss: 0.4733 - val_acc: 0.9167 - val_auc_1: 0.8893\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2905 - acc: 0.8478 - auc_1: 0.9362 - val_loss: 0.6213 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.2792 - acc: 0.8587 - auc_1: 0.9369 - val_loss: 0.7037 - val_acc: 0.8750 - val_auc_1: 0.8214\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2871 - acc: 0.8478 - auc_1: 0.9355 - val_loss: 0.5753 - val_acc: 0.8750 - val_auc_1: 0.8679\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2848 - acc: 0.8587 - auc_1: 0.9381 - val_loss: 0.6488 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2867 - acc: 0.8478 - auc_1: 0.9345 - val_loss: 0.6850 - val_acc: 0.8750 - val_auc_1: 0.8250\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2794 - acc: 0.8587 - auc_1: 0.9371 - val_loss: 0.6110 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2780 - acc: 0.8696 - auc_1: 0.9381 - val_loss: 0.6413 - val_acc: 0.8333 - val_auc_1: 0.8250\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2779 - acc: 0.8587 - auc_1: 0.9398 - val_loss: 0.6240 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2744 - acc: 0.8587 - auc_1: 0.9360 - val_loss: 0.5838 - val_acc: 0.8750 - val_auc_1: 0.8714\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2833 - acc: 0.8587 - auc_1: 0.9271 - val_loss: 0.6130 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2731 - acc: 0.8696 - auc_1: 0.9390 - val_loss: 0.6432 - val_acc: 0.8750 - val_auc_1: 0.8464\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2682 - acc: 0.8587 - auc_1: 0.9407 - val_loss: 0.5692 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2750 - acc: 0.8696 - auc_1: 0.9390 - val_loss: 0.6157 - val_acc: 0.8750 - val_auc_1: 0.8464\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2789 - acc: 0.8478 - auc_1: 0.9429 - val_loss: 0.7078 - val_acc: 0.8750 - val_auc_1: 0.8214\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2745 - acc: 0.8587 - auc_1: 0.9479 - val_loss: 0.5892 - val_acc: 0.8750 - val_auc_1: 0.8679\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2808 - acc: 0.8478 - auc_1: 0.9381 - val_loss: 0.6129 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2696 - acc: 0.8696 - auc_1: 0.9376 - val_loss: 0.6349 - val_acc: 0.8750 - val_auc_1: 0.8429\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2809 - acc: 0.8696 - auc_1: 0.9429 - val_loss: 0.6215 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2766 - acc: 0.8587 - auc_1: 0.9379 - val_loss: 0.5989 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2777 - acc: 0.8696 - auc_1: 0.9393 - val_loss: 0.5714 - val_acc: 0.8750 - val_auc_1: 0.8714\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2801 - acc: 0.8478 - auc_1: 0.9448 - val_loss: 0.5386 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2716 - acc: 0.8587 - auc_1: 0.9462 - val_loss: 0.6361 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2652 - acc: 0.8804 - auc_1: 0.9379 - val_loss: 0.6396 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2620 - acc: 0.8804 - auc_1: 0.9412 - val_loss: 0.6441 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2621 - acc: 0.8587 - auc_1: 0.9405 - val_loss: 0.5973 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2606 - acc: 0.8804 - auc_1: 0.9460 - val_loss: 0.5979 - val_acc: 0.9167 - val_auc_1: 0.8536\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2637 - acc: 0.8696 - auc_1: 0.9417 - val_loss: 0.6014 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2727 - acc: 0.8587 - auc_1: 0.9314 - val_loss: 0.6264 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2576 - acc: 0.8804 - auc_1: 0.9455 - val_loss: 0.6218 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2642 - acc: 0.8804 - auc_1: 0.9433 - val_loss: 0.6140 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2552 - acc: 0.8804 - auc_1: 0.9469 - val_loss: 0.6652 - val_acc: 0.8750 - val_auc_1: 0.8286\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2658 - acc: 0.8804 - auc_1: 0.9381 - val_loss: 0.6139 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2648 - acc: 0.8804 - auc_1: 0.9471 - val_loss: 0.5977 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2606 - acc: 0.8804 - auc_1: 0.9414 - val_loss: 0.6206 - val_acc: 0.8750 - val_auc_1: 0.8500\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2569 - acc: 0.8804 - auc_1: 0.9476 - val_loss: 0.6958 - val_acc: 0.8750 - val_auc_1: 0.8214\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2600 - acc: 0.8696 - auc_1: 0.9457 - val_loss: 0.6316 - val_acc: 0.8333 - val_auc_1: 0.8464\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2587 - acc: 0.8804 - auc_1: 0.9462 - val_loss: 0.6941 - val_acc: 0.8750 - val_auc_1: 0.8286\n",
      "Epoch 529/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2511 - acc: 0.8804 - auc_1: 0.9429 - val_loss: 0.6289 - val_acc: 0.8750 - val_auc_1: 0.8429\n",
      "Epoch 530/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2555 - acc: 0.8913 - auc_1: 0.9405 - val_loss: 0.6074 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2509 - acc: 0.8804 - auc_1: 0.9450 - val_loss: 0.5806 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2532 - acc: 0.8804 - auc_1: 0.9407 - val_loss: 0.5908 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2478 - acc: 0.8913 - auc_1: 0.9426 - val_loss: 0.5992 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2444 - acc: 0.8804 - auc_1: 0.9433 - val_loss: 0.6582 - val_acc: 0.8750 - val_auc_1: 0.8286\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2615 - acc: 0.8804 - auc_1: 0.9398 - val_loss: 0.6440 - val_acc: 0.8750 - val_auc_1: 0.8429\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2506 - acc: 0.8804 - auc_1: 0.9424 - val_loss: 0.6369 - val_acc: 0.8750 - val_auc_1: 0.8357\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2593 - acc: 0.8804 - auc_1: 0.9414 - val_loss: 0.6197 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2455 - acc: 0.8696 - auc_1: 0.9455 - val_loss: 0.7141 - val_acc: 0.8750 - val_auc_1: 0.8214\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2475 - acc: 0.8913 - auc_1: 0.9448 - val_loss: 0.6005 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2500 - acc: 0.8913 - auc_1: 0.9462 - val_loss: 0.6245 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.2434 - acc: 0.8804 - auc_1: 0.9438 - val_loss: 0.6277 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2533 - acc: 0.8696 - auc_1: 0.9495 - val_loss: 0.5974 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2443 - acc: 0.8913 - auc_1: 0.9531 - val_loss: 0.6032 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.2414 - acc: 0.8913 - auc_1: 0.9448 - val_loss: 0.6007 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2458 - acc: 0.8696 - auc_1: 0.9429 - val_loss: 0.5755 - val_acc: 0.9167 - val_auc_1: 0.8714\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2491 - acc: 0.8804 - auc_1: 0.9433 - val_loss: 0.6236 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2429 - acc: 0.9022 - auc_1: 0.9526 - val_loss: 0.6128 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2512 - acc: 0.8804 - auc_1: 0.9483 - val_loss: 0.5994 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2383 - acc: 0.8804 - auc_1: 0.9414 - val_loss: 0.6159 - val_acc: 0.8750 - val_auc_1: 0.8357\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2438 - acc: 0.8804 - auc_1: 0.9502 - val_loss: 0.6247 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2380 - acc: 0.9022 - auc_1: 0.9455 - val_loss: 0.5886 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2340 - acc: 0.8913 - auc_1: 0.9540 - val_loss: 0.5942 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2436 - acc: 0.8804 - auc_1: 0.9381 - val_loss: 0.5967 - val_acc: 0.8750 - val_auc_1: 0.8393\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2401 - acc: 0.9022 - auc_1: 0.9476 - val_loss: 0.6176 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2358 - acc: 0.9022 - auc_1: 0.9443 - val_loss: 0.6107 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2349 - acc: 0.9022 - auc_1: 0.9431 - val_loss: 0.5999 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2291 - acc: 0.9022 - auc_1: 0.9533 - val_loss: 0.5936 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2359 - acc: 0.8804 - auc_1: 0.9493 - val_loss: 0.5831 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2335 - acc: 0.9022 - auc_1: 0.9602 - val_loss: 0.6109 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2292 - acc: 0.9022 - auc_1: 0.9507 - val_loss: 0.6014 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2362 - acc: 0.8913 - auc_1: 0.9464 - val_loss: 0.6322 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2459 - acc: 0.8913 - auc_1: 0.9540 - val_loss: 0.6091 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2435 - acc: 0.8696 - auc_1: 0.9510 - val_loss: 0.6031 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2290 - acc: 0.9022 - auc_1: 0.9545 - val_loss: 0.6236 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.2364 - acc: 0.9022 - auc_1: 0.9464 - val_loss: 0.6094 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2243 - acc: 0.9022 - auc_1: 0.9531 - val_loss: 0.7794 - val_acc: 0.8750 - val_auc_1: 0.8214\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2647 - acc: 0.8696 - auc_1: 0.9502 - val_loss: 0.6467 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2444 - acc: 0.8804 - auc_1: 0.9486 - val_loss: 0.6367 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2224 - acc: 0.9022 - auc_1: 0.9538 - val_loss: 0.6484 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.2277 - acc: 0.9130 - auc_1: 0.9495 - val_loss: 0.6266 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2243 - acc: 0.9130 - auc_1: 0.9510 - val_loss: 0.6799 - val_acc: 0.8750 - val_auc_1: 0.8357\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2311 - acc: 0.9022 - auc_1: 0.9462 - val_loss: 0.6521 - val_acc: 0.8750 - val_auc_1: 0.8429\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2228 - acc: 0.8913 - auc_1: 0.9529 - val_loss: 0.6269 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.2349 - acc: 0.8977 - auc_1: 0.953 - 1s 8ms/step - loss: 0.2259 - acc: 0.9022 - auc_1: 0.9571 - val_loss: 0.6225 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2317 - acc: 0.9022 - auc_1: 0.9538 - val_loss: 0.6155 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2242 - acc: 0.9022 - auc_1: 0.9524 - val_loss: 0.6225 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 577/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2198 - acc: 0.9022 - auc_1: 0.9564 - val_loss: 0.6046 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 578/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2353 - acc: 0.8913 - auc_1: 0.9471 - val_loss: 0.6755 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2250 - acc: 0.8913 - auc_1: 0.9529 - val_loss: 0.6007 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.2226 - acc: 0.8913 - auc_1: 0.9500 - val_loss: 0.5996 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2214 - acc: 0.9022 - auc_1: 0.9521 - val_loss: 0.6089 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2237 - acc: 0.9022 - auc_1: 0.9560 - val_loss: 0.6131 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2256 - acc: 0.9022 - auc_1: 0.9493 - val_loss: 0.7676 - val_acc: 0.8750 - val_auc_1: 0.8143\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2408 - acc: 0.8696 - auc_1: 0.9438 - val_loss: 0.6691 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2259 - acc: 0.9022 - auc_1: 0.9474 - val_loss: 0.6248 - val_acc: 0.8750 - val_auc_1: 0.8500\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2175 - acc: 0.9022 - auc_1: 0.9560 - val_loss: 0.5987 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2223 - acc: 0.8913 - auc_1: 0.9564 - val_loss: 0.6370 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2137 - acc: 0.9022 - auc_1: 0.9567 - val_loss: 0.6122 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2176 - acc: 0.9130 - auc_1: 0.9526 - val_loss: 0.6063 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2123 - acc: 0.9022 - auc_1: 0.9557 - val_loss: 0.6070 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2172 - acc: 0.9130 - auc_1: 0.9602 - val_loss: 0.5806 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2169 - acc: 0.9022 - auc_1: 0.9536 - val_loss: 0.6010 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2139 - acc: 0.9022 - auc_1: 0.9536 - val_loss: 0.6277 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2381 - acc: 0.8913 - auc_1: 0.9431 - val_loss: 0.5443 - val_acc: 0.8750 - val_auc_1: 0.8429\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2505 - acc: 0.8804 - auc_1: 0.9429 - val_loss: 0.5846 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2247 - acc: 0.8913 - auc_1: 0.9588 - val_loss: 0.5913 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2272 - acc: 0.9022 - auc_1: 0.9574 - val_loss: 0.6243 - val_acc: 0.8750 - val_auc_1: 0.8321\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.2124 - acc: 0.9130 - auc_1: 0.9610 - val_loss: 0.6500 - val_acc: 0.8750 - val_auc_1: 0.8357\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2214 - acc: 0.9022 - auc_1: 0.9600 - val_loss: 0.6128 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2137 - acc: 0.9022 - auc_1: 0.9502 - val_loss: 0.6055 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2131 - acc: 0.9022 - auc_1: 0.9576 - val_loss: 0.6556 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2125 - acc: 0.9022 - auc_1: 0.9555 - val_loss: 0.6413 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2104 - acc: 0.9130 - auc_1: 0.9617 - val_loss: 0.7382 - val_acc: 0.8750 - val_auc_1: 0.8214\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2480 - acc: 0.8587 - auc_1: 0.9393 - val_loss: 0.6461 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2251 - acc: 0.9022 - auc_1: 0.9562 - val_loss: 0.6743 - val_acc: 0.8333 - val_auc_1: 0.8214\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2150 - acc: 0.9022 - auc_1: 0.9538 - val_loss: 0.6463 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2081 - acc: 0.9130 - auc_1: 0.9543 - val_loss: 0.6456 - val_acc: 0.8750 - val_auc_1: 0.8500\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2079 - acc: 0.9130 - auc_1: 0.9605 - val_loss: 0.6016 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2108 - acc: 0.9022 - auc_1: 0.9581 - val_loss: 0.6208 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2126 - acc: 0.9022 - auc_1: 0.9571 - val_loss: 0.6220 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2097 - acc: 0.9022 - auc_1: 0.9586 - val_loss: 0.6274 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2087 - acc: 0.9130 - auc_1: 0.9533 - val_loss: 0.6203 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2048 - acc: 0.9130 - auc_1: 0.9540 - val_loss: 0.6072 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2038 - acc: 0.9130 - auc_1: 0.9564 - val_loss: 0.6006 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2122 - acc: 0.9130 - auc_1: 0.9562 - val_loss: 0.6093 - val_acc: 0.8750 - val_auc_1: 0.8321\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.2454 - acc: 0.8804 - auc_1: 0.9402 - val_loss: 0.6174 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2034 - acc: 0.9130 - auc_1: 0.9581 - val_loss: 0.6576 - val_acc: 0.8333 - val_auc_1: 0.8464\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2024 - acc: 0.9130 - auc_1: 0.9500 - val_loss: 0.6220 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2062 - acc: 0.9130 - auc_1: 0.9552 - val_loss: 0.6300 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2054 - acc: 0.9022 - auc_1: 0.9557 - val_loss: 0.6499 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2058 - acc: 0.9130 - auc_1: 0.9567 - val_loss: 0.6259 - val_acc: 0.8750 - val_auc_1: 0.8500\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2027 - acc: 0.9130 - auc_1: 0.9605 - val_loss: 0.5944 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2057 - acc: 0.9022 - auc_1: 0.9593 - val_loss: 0.6007 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2025 - acc: 0.9022 - auc_1: 0.9552 - val_loss: 0.6099 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 625/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2051 - acc: 0.9130 - auc_1: 0.9619 - val_loss: 0.5935 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 626/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1992 - acc: 0.9130 - auc_1: 0.9607 - val_loss: 0.6089 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2018 - acc: 0.9130 - auc_1: 0.9605 - val_loss: 0.6163 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1997 - acc: 0.9130 - auc_1: 0.9612 - val_loss: 0.5982 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2070 - acc: 0.9022 - auc_1: 0.9550 - val_loss: 0.6362 - val_acc: 0.8750 - val_auc_1: 0.8500\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2033 - acc: 0.9022 - auc_1: 0.9602 - val_loss: 0.6397 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2057 - acc: 0.9130 - auc_1: 0.9567 - val_loss: 0.6827 - val_acc: 0.8333 - val_auc_1: 0.8143\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2079 - acc: 0.8804 - auc_1: 0.9521 - val_loss: 0.7217 - val_acc: 0.8333 - val_auc_1: 0.8179\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2100 - acc: 0.9130 - auc_1: 0.9579 - val_loss: 0.6730 - val_acc: 0.8333 - val_auc_1: 0.8357\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2010 - acc: 0.9130 - auc_1: 0.9605 - val_loss: 0.6064 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2073 - acc: 0.9022 - auc_1: 0.9560 - val_loss: 0.5714 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1991 - acc: 0.9130 - auc_1: 0.9576 - val_loss: 0.6332 - val_acc: 0.8750 - val_auc_1: 0.8500\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1961 - acc: 0.9130 - auc_1: 0.9621 - val_loss: 0.6071 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2163 - acc: 0.8913 - auc_1: 0.9543 - val_loss: 0.7330 - val_acc: 0.8333 - val_auc_1: 0.8000\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2049 - acc: 0.9130 - auc_1: 0.9564 - val_loss: 0.6510 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1972 - acc: 0.9130 - auc_1: 0.9574 - val_loss: 0.6845 - val_acc: 0.8333 - val_auc_1: 0.8357\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1986 - acc: 0.9022 - auc_1: 0.9581 - val_loss: 0.6431 - val_acc: 0.8750 - val_auc_1: 0.8357\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1977 - acc: 0.9130 - auc_1: 0.9610 - val_loss: 0.6156 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2064 - acc: 0.9022 - auc_1: 0.9574 - val_loss: 0.6149 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1942 - acc: 0.9130 - auc_1: 0.9605 - val_loss: 0.6350 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1986 - acc: 0.9130 - auc_1: 0.9557 - val_loss: 0.6166 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1926 - acc: 0.9130 - auc_1: 0.9614 - val_loss: 0.6238 - val_acc: 0.9167 - val_auc_1: 0.8714\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2068 - acc: 0.9130 - auc_1: 0.9579 - val_loss: 0.6313 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1981 - acc: 0.9130 - auc_1: 0.9507 - val_loss: 0.6151 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1946 - acc: 0.9130 - auc_1: 0.9657 - val_loss: 0.6053 - val_acc: 0.9167 - val_auc_1: 0.8714\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2390 - acc: 0.8913 - auc_1: 0.9531 - val_loss: 0.5783 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2895 - acc: 0.8587 - auc_1: 0.9331 - val_loss: 0.9228 - val_acc: 0.7917 - val_auc_1: 0.7857\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2313 - acc: 0.8804 - auc_1: 0.9457 - val_loss: 0.7034 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2022 - acc: 0.9130 - auc_1: 0.9662 - val_loss: 0.7118 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1898 - acc: 0.9130 - auc_1: 0.9688 - val_loss: 0.7066 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1926 - acc: 0.9130 - auc_1: 0.9626 - val_loss: 0.7119 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1910 - acc: 0.9130 - auc_1: 0.9633 - val_loss: 0.7132 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1908 - acc: 0.9130 - auc_1: 0.9605 - val_loss: 0.6820 - val_acc: 0.9167 - val_auc_1: 0.8679\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1913 - acc: 0.9130 - auc_1: 0.9619 - val_loss: 0.6875 - val_acc: 0.8750 - val_auc_1: 0.8679\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1881 - acc: 0.9130 - auc_1: 0.9624 - val_loss: 0.6718 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1913 - acc: 0.9130 - auc_1: 0.9576 - val_loss: 0.6960 - val_acc: 0.8750 - val_auc_1: 0.8214\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1910 - acc: 0.9130 - auc_1: 0.9643 - val_loss: 0.6749 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1898 - acc: 0.9130 - auc_1: 0.9536 - val_loss: 0.6642 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.1917 - acc: 0.9130 - auc_1: 0.9536 - val_loss: 0.6854 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1928 - acc: 0.9022 - auc_1: 0.9545 - val_loss: 0.7435 - val_acc: 0.8333 - val_auc_1: 0.8071\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1939 - acc: 0.9130 - auc_1: 0.9600 - val_loss: 0.6636 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1915 - acc: 0.9130 - auc_1: 0.9581 - val_loss: 0.6706 - val_acc: 0.8750 - val_auc_1: 0.8250\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1960 - acc: 0.9130 - auc_1: 0.9545 - val_loss: 0.6777 - val_acc: 0.8750 - val_auc_1: 0.8250\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1938 - acc: 0.9130 - auc_1: 0.9581 - val_loss: 0.6556 - val_acc: 0.8333 - val_auc_1: 0.8286\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1880 - acc: 0.9130 - auc_1: 0.9621 - val_loss: 0.7609 - val_acc: 0.8750 - val_auc_1: 0.8500\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2685 - acc: 0.8478 - auc_1: 0.9293 - val_loss: 0.8462 - val_acc: 0.8333 - val_auc_1: 0.8143\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2218 - acc: 0.9022 - auc_1: 0.9574 - val_loss: 0.6923 - val_acc: 0.8750 - val_auc_1: 0.8679\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1998 - acc: 0.9130 - auc_1: 0.9576 - val_loss: 0.6938 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 673/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1894 - acc: 0.9130 - auc_1: 0.9657 - val_loss: 0.6636 - val_acc: 0.9167 - val_auc_1: 0.8607\n",
      "Epoch 674/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1925 - acc: 0.9022 - auc_1: 0.9574 - val_loss: 0.6913 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1892 - acc: 0.9130 - auc_1: 0.9648 - val_loss: 0.6812 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1884 - acc: 0.9130 - auc_1: 0.9600 - val_loss: 0.6860 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1866 - acc: 0.9130 - auc_1: 0.9614 - val_loss: 0.6896 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1883 - acc: 0.9130 - auc_1: 0.9645 - val_loss: 0.6458 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1877 - acc: 0.9130 - auc_1: 0.9583 - val_loss: 0.6635 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1906 - acc: 0.9022 - auc_1: 0.9612 - val_loss: 0.7034 - val_acc: 0.8333 - val_auc_1: 0.8179\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1892 - acc: 0.9130 - auc_1: 0.9631 - val_loss: 0.6626 - val_acc: 0.9167 - val_auc_1: 0.8643\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1877 - acc: 0.9130 - auc_1: 0.9593 - val_loss: 0.6901 - val_acc: 0.8333 - val_auc_1: 0.8179\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1938 - acc: 0.9130 - auc_1: 0.9633 - val_loss: 0.6707 - val_acc: 0.8750 - val_auc_1: 0.8286\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1873 - acc: 0.9130 - auc_1: 0.9636 - val_loss: 0.7139 - val_acc: 0.8333 - val_auc_1: 0.8250\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1880 - acc: 0.9130 - auc_1: 0.9626 - val_loss: 0.6696 - val_acc: 0.8750 - val_auc_1: 0.8500\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1869 - acc: 0.9130 - auc_1: 0.9612 - val_loss: 0.6572 - val_acc: 0.8750 - val_auc_1: 0.8643\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1840 - acc: 0.9130 - auc_1: 0.9595 - val_loss: 0.6636 - val_acc: 0.8333 - val_auc_1: 0.8286\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1849 - acc: 0.9130 - auc_1: 0.9617 - val_loss: 0.6370 - val_acc: 0.9167 - val_auc_1: 0.8571\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1842 - acc: 0.9130 - auc_1: 0.9595 - val_loss: 0.6647 - val_acc: 0.8750 - val_auc_1: 0.8571\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1889 - acc: 0.9130 - auc_1: 0.9638 - val_loss: 0.6423 - val_acc: 0.8750 - val_auc_1: 0.8250\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1831 - acc: 0.9130 - auc_1: 0.9633 - val_loss: 0.6416 - val_acc: 0.9167 - val_auc_1: 0.8714\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1909 - acc: 0.9130 - auc_1: 0.9564 - val_loss: 0.6458 - val_acc: 0.8750 - val_auc_1: 0.8679\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1919 - acc: 0.9022 - auc_1: 0.9564 - val_loss: 0.6713 - val_acc: 0.8333 - val_auc_1: 0.8143\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1976 - acc: 0.8913 - auc_1: 0.9600 - val_loss: 0.6637 - val_acc: 0.8333 - val_auc_1: 0.8250\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3076 - acc: 0.8804 - auc_1: 0.9438 - val_loss: 0.7031 - val_acc: 0.8333 - val_auc_1: 0.8071\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2240 - acc: 0.8913 - auc_1: 0.9517 - val_loss: 0.7518 - val_acc: 0.8750 - val_auc_1: 0.8393\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1925 - acc: 0.9130 - auc_1: 0.9583 - val_loss: 0.7039 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1849 - acc: 0.9130 - auc_1: 0.9640 - val_loss: 0.7277 - val_acc: 0.8750 - val_auc_1: 0.8429\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1847 - acc: 0.9130 - auc_1: 0.9602 - val_loss: 0.7190 - val_acc: 0.8750 - val_auc_1: 0.8607\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1840 - acc: 0.9130 - auc_1: 0.9581 - val_loss: 0.7185 - val_acc: 0.8750 - val_auc_1: 0.8607\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.7665543 ,  1.6949565 , -0.9752218 , -1.6656597 ,  0.41694558,\n",
      "         0.66652155, -1.4355901 , -0.12813197, -1.3062295 ],\n",
      "       [-2.0534494 , -0.06800532, -1.7611593 , -0.9239358 ,  3.2253935 ,\n",
      "        -2.0234015 ,  0.33841687, -3.1555262 , -0.61679125],\n",
      "       [ 0.3687241 ,  1.0285455 ,  1.0352566 ,  0.31617144, -0.1405706 ,\n",
      "        -0.32448107,  1.205295  ,  0.5782798 , -0.96537113]],\n",
      "      dtype=float32), array([ 0.23719083, -0.35164428, -0.0525511 ,  0.28587195, -0.06951464,\n",
      "       -0.5411495 , -0.20297909, -0.01505815,  0.66327643], dtype=float32), array([[-2.4537961 , -0.3796367 ,  1.236367  ,  0.12472475,  1.3667927 ,\n",
      "         1.3031837 , -1.0583955 ,  0.2948564 , -1.1717007 ],\n",
      "       [ 0.75524545,  1.2201914 , -0.48518303,  3.1346774 ,  0.22735052,\n",
      "        -0.15211938, -1.8272002 ,  1.118461  , -0.4520294 ],\n",
      "       [-1.7014352 , -0.38263187,  1.8581884 ,  1.0345777 , -0.5297864 ,\n",
      "         0.37611777, -3.562799  ,  0.6093481 , -0.8137099 ],\n",
      "       [-3.114182  , -1.6500318 ,  2.968498  , -0.59535295, -0.7982505 ,\n",
      "         1.8457001 , -0.08353124, -0.4659767 , -0.32758245],\n",
      "       [ 2.0821896 , -0.07249242, -1.0827116 ,  0.17390175, -1.6694866 ,\n",
      "        -0.24560158,  0.6354937 , -1.9984422 ,  3.4754014 ],\n",
      "       [ 0.02016885,  0.86989176,  0.24726655, -0.5362672 ,  0.2480813 ,\n",
      "        -1.1091691 ,  0.40974045,  0.9959088 , -1.2511152 ],\n",
      "       [ 0.09619568, -0.5830951 ,  2.0604124 ,  1.3898098 , -2.2745838 ,\n",
      "         0.07942712, -3.7285316 , -0.99436235,  1.0245341 ],\n",
      "       [-1.9613732 ,  0.8013002 ,  1.041182  ,  0.7020764 ,  0.6397839 ,\n",
      "         1.0077637 , -1.6891562 ,  1.9498066 , -2.1522713 ],\n",
      "       [-2.3693972 , -1.9267007 , -0.3322299 , -2.8616452 , -0.09001771,\n",
      "         1.8045559 ,  3.6173346 , -0.8656882 , -0.6892667 ]],\n",
      "      dtype=float32), array([-0.42813367, -0.6703101 , -0.3405123 ,  0.04027244,  0.23270224,\n",
      "        0.94230795,  0.40976456, -0.39230552,  0.45271462], dtype=float32), array([[ 0.4639935 , -0.85055417,  2.524721  ,  0.9189949 , -1.8054285 ,\n",
      "        -3.8500574 ,  1.340298  ,  0.79797643,  0.9231012 ],\n",
      "       [-1.680941  , -0.5238482 ,  1.0199838 ,  2.4561749 , -1.0469933 ,\n",
      "        -2.4222517 ,  1.231826  , -1.2989798 ,  0.65445143],\n",
      "       [-0.47583544,  0.42746496, -1.0232278 , -0.0771718 ,  0.38094446,\n",
      "         2.0670927 , -0.73779327, -9.351679  , -0.7117431 ],\n",
      "       [-0.4274823 ,  0.13382733, -0.5749956 , -0.5009536 , -3.536359  ,\n",
      "        -1.6191647 ,  1.9271083 , -0.72377425,  4.259596  ],\n",
      "       [-1.6918646 , -1.3988732 , -1.1755191 , -0.31193203, -1.6082548 ,\n",
      "        -1.2458887 , -1.1384052 ,  1.0977392 ,  2.1424253 ],\n",
      "       [ 6.8017273 , -0.21916567,  0.14507587,  0.25198594, -1.7446594 ,\n",
      "         1.293909  , -0.05081173,  0.24332774,  1.9264156 ],\n",
      "       [-2.966301  , -0.24623552,  1.2127763 , -2.8146117 ,  0.4224164 ,\n",
      "         2.2493842 , -0.72689706,  2.0953689 , -0.7127898 ],\n",
      "       [-1.2271737 , -3.0317352 , -0.6122578 , -0.8309162 , -0.2469872 ,\n",
      "         0.75248784,  0.8003051 , -1.7980611 , -0.32666042],\n",
      "       [ 1.4182082 ,  3.042785  ,  1.7627416 ,  1.0287712 , -0.158898  ,\n",
      "        -0.27331957, -0.71541506,  2.2816193 ,  0.14070834]],\n",
      "      dtype=float32), array([ 1.2140718 , -0.10050295,  0.4240899 , -0.13616368, -0.12931494,\n",
      "        0.1419731 ,  0.01358965,  0.52608913,  0.4824455 ], dtype=float32), array([[-2.1173615],\n",
      "       [-1.3987472],\n",
      "       [-2.1739483],\n",
      "       [-2.1724074],\n",
      "       [-1.2511412],\n",
      "       [-2.4118986],\n",
      "       [ 1.2033137],\n",
      "       [ 2.5938668],\n",
      "       [ 1.4982873]], dtype=float32), array([-0.5589338], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.18502032e-04]\n",
      " [8.03850532e-01]\n",
      " [6.18842423e-01]\n",
      " [4.44622507e-04]\n",
      " [1.68911740e-01]\n",
      " [9.95315313e-01]\n",
      " [9.89920735e-01]\n",
      " [9.93735135e-01]\n",
      " [9.39953685e-01]\n",
      " [9.89432454e-01]\n",
      " [6.31002665e-01]\n",
      " [3.11504561e-03]\n",
      " [9.92452562e-01]\n",
      " [1.42658537e-03]\n",
      " [2.20090654e-02]\n",
      " [9.99606907e-01]\n",
      " [6.27306759e-01]\n",
      " [8.94591033e-01]\n",
      " [9.77248132e-01]\n",
      " [9.89022613e-01]\n",
      " [4.29200828e-02]\n",
      " [1.64881884e-03]\n",
      " [6.32839978e-01]\n",
      " [9.84705508e-01]\n",
      " [9.71577287e-01]\n",
      " [9.99732077e-01]\n",
      " [9.82678115e-01]\n",
      " [6.28857017e-01]\n",
      " [1.07109193e-02]\n",
      " [9.99474466e-01]\n",
      " [1.41196311e-01]\n",
      " [4.05778410e-03]\n",
      " [5.74579928e-04]\n",
      " [5.35215661e-02]\n",
      " [1.68727583e-03]\n",
      " [9.90169466e-01]\n",
      " [9.92224097e-01]\n",
      " [9.83190179e-01]\n",
      " [6.30373299e-01]\n",
      " [9.94540751e-01]\n",
      " [6.31082654e-01]\n",
      " [6.31120145e-01]\n",
      " [6.30987346e-01]\n",
      " [4.52008471e-02]\n",
      " [1.18671462e-03]\n",
      " [6.29100561e-01]\n",
      " [9.86630619e-01]\n",
      " [6.31161630e-01]\n",
      " [9.49412048e-01]\n",
      " [2.09295209e-02]\n",
      " [1.23290464e-01]\n",
      " [6.30632699e-01]\n",
      " [4.31839144e-03]\n",
      " [4.99752583e-03]\n",
      " [2.31494009e-03]\n",
      " [1.22712202e-01]\n",
      " [6.28509462e-01]\n",
      " [9.99186814e-01]\n",
      " [3.67236440e-03]\n",
      " [6.31011605e-01]\n",
      " [6.61211371e-01]\n",
      " [9.67363775e-01]\n",
      " [9.89257038e-01]\n",
      " [9.96543229e-01]\n",
      " [1.47641113e-03]\n",
      " [5.59097342e-02]\n",
      " [5.77355586e-02]\n",
      " [8.63296032e-01]\n",
      " [1.29769534e-01]\n",
      " [1.04023479e-02]\n",
      " [6.30846739e-01]\n",
      " [9.84864414e-01]\n",
      " [6.31126463e-01]\n",
      " [9.91890669e-01]\n",
      " [6.31124496e-01]\n",
      " [1.67283614e-03]\n",
      " [9.92471099e-01]\n",
      " [6.15945726e-04]\n",
      " [6.30852103e-01]\n",
      " [3.74864228e-03]\n",
      " [3.54183023e-03]\n",
      " [1.03616416e-02]\n",
      " [6.71952307e-01]\n",
      " [6.27959430e-01]\n",
      " [7.33986080e-01]\n",
      " [9.99319434e-01]\n",
      " [9.81521547e-01]\n",
      " [9.71369028e-01]\n",
      " [6.30701855e-02]\n",
      " [9.99387383e-01]\n",
      " [9.99389768e-01]\n",
      " [9.99777853e-01]\n",
      " [1.07484996e-01]\n",
      " [9.99765694e-01]\n",
      " [6.31299198e-01]\n",
      " [6.31029487e-01]\n",
      " [7.66496286e-02]\n",
      " [9.99309540e-01]\n",
      " [5.00012282e-03]\n",
      " [9.77127790e-01]\n",
      " [9.70978200e-01]\n",
      " [6.90641522e-04]\n",
      " [9.65339601e-01]\n",
      " [9.92197692e-01]\n",
      " [9.54332530e-01]\n",
      " [9.91235614e-01]\n",
      " [5.98966837e-01]\n",
      " [8.85318965e-03]\n",
      " [9.88627374e-01]\n",
      " [5.56186447e-03]\n",
      " [8.57990701e-03]\n",
      " [6.16523504e-01]\n",
      " [6.31037235e-01]\n",
      " [6.38865292e-01]\n",
      " [1.59079105e-01]\n",
      " [2.95107603e-01]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
