{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,2:3] #Glucose\n",
    "X2 = dataset[:,7:8] #Resistin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,1:2] #BMI\n",
    "X5 = dataset[:,4:5] #HOMA\n",
    "X6 = dataset[:,5:6] #Leptin\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "X6 = normalization(X6)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X6 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 6)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "                                                                 input_layer_X6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            63          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 253\n",
      "Trainable params: 253\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "input_layer_X6 = keras.layers.Input(shape=(1, ), name='input_layer_X6')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.7012 - acc: 0.5217 - auc_1: 0.5371 - val_loss: 0.6679 - val_acc: 0.6667 - val_auc_1: 0.6857\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6725 - acc: 0.5978 - auc_1: 0.6167 - val_loss: 0.6336 - val_acc: 0.7083 - val_auc_1: 0.6964\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6517 - acc: 0.6304 - auc_1: 0.6848 - val_loss: 0.6037 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6196 - acc: 0.6087 - auc_1: 0.7267 - val_loss: 0.5773 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5869 - acc: 0.6739 - auc_1: 0.7721 - val_loss: 0.5362 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5659 - acc: 0.6739 - auc_1: 0.7769 - val_loss: 0.5658 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5503 - acc: 0.6957 - auc_1: 0.7874 - val_loss: 0.5189 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5370 - acc: 0.6522 - auc_1: 0.7929 - val_loss: 0.5789 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5310 - acc: 0.7065 - auc_1: 0.7983 - val_loss: 0.5266 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5269 - acc: 0.7065 - auc_1: 0.7943 - val_loss: 0.6008 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5195 - acc: 0.7391 - auc_1: 0.8181 - val_loss: 0.5012 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5157 - acc: 0.7283 - auc_1: 0.8076 - val_loss: 0.5411 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5130 - acc: 0.7500 - auc_1: 0.8102 - val_loss: 0.5431 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5097 - acc: 0.7391 - auc_1: 0.8169 - val_loss: 0.6168 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5079 - acc: 0.7391 - auc_1: 0.8200 - val_loss: 0.4794 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5100 - acc: 0.7283 - auc_1: 0.8198 - val_loss: 0.5373 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5020 - acc: 0.7609 - auc_1: 0.8255 - val_loss: 0.4907 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4996 - acc: 0.7500 - auc_1: 0.8283 - val_loss: 0.4639 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5021 - acc: 0.7609 - auc_1: 0.8355 - val_loss: 0.5922 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5062 - acc: 0.7391 - auc_1: 0.8205 - val_loss: 0.5387 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4962 - acc: 0.7283 - auc_1: 0.8300 - val_loss: 0.6025 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5080 - acc: 0.7609 - auc_1: 0.8131 - val_loss: 0.5239 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4971 - acc: 0.7500 - auc_1: 0.8317 - val_loss: 0.4724 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5036 - acc: 0.7717 - auc_1: 0.8274 - val_loss: 0.5408 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4972 - acc: 0.7391 - auc_1: 0.8236 - val_loss: 0.5343 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4946 - acc: 0.7283 - auc_1: 0.8279 - val_loss: 0.4975 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5008 - acc: 0.7391 - auc_1: 0.8288 - val_loss: 0.5015 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4963 - acc: 0.7391 - auc_1: 0.8305 - val_loss: 0.5433 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4903 - acc: 0.7391 - auc_1: 0.8336 - val_loss: 0.5825 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5013 - acc: 0.7609 - auc_1: 0.8207 - val_loss: 0.5490 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4846 - acc: 0.7935 - auc_1: 0.8390 - val_loss: 0.5797 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4928 - acc: 0.7609 - auc_1: 0.8350 - val_loss: 0.5013 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4909 - acc: 0.7500 - auc_1: 0.8352 - val_loss: 0.5343 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4880 - acc: 0.7500 - auc_1: 0.8345 - val_loss: 0.4877 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4875 - acc: 0.7500 - auc_1: 0.8493 - val_loss: 0.5554 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5025 - acc: 0.7500 - auc_1: 0.8321 - val_loss: 0.4686 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4860 - acc: 0.7609 - auc_1: 0.8431 - val_loss: 0.5440 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4800 - acc: 0.7609 - auc_1: 0.8436 - val_loss: 0.5812 - val_acc: 0.6667 - val_auc_1: 0.9143\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4862 - acc: 0.7500 - auc_1: 0.8393 - val_loss: 0.5143 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4822 - acc: 0.7500 - auc_1: 0.8424 - val_loss: 0.5179 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4750 - acc: 0.7500 - auc_1: 0.8486 - val_loss: 0.6043 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4728 - acc: 0.7609 - auc_1: 0.8529 - val_loss: 0.4880 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4797 - acc: 0.7717 - auc_1: 0.8379 - val_loss: 0.5051 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4839 - acc: 0.7717 - auc_1: 0.8462 - val_loss: 0.6236 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4863 - acc: 0.7609 - auc_1: 0.8393 - val_loss: 0.5744 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4800 - acc: 0.7391 - auc_1: 0.8493 - val_loss: 0.5368 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4676 - acc: 0.7935 - auc_1: 0.8571 - val_loss: 0.5129 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4750 - acc: 0.7609 - auc_1: 0.8493 - val_loss: 0.5246 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4750 - acc: 0.7717 - auc_1: 0.8474 - val_loss: 0.6011 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4645 - acc: 0.7826 - auc_1: 0.8626 - val_loss: 0.5065 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4817 - acc: 0.7609 - auc_1: 0.8488 - val_loss: 0.5619 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4734 - acc: 0.8043 - auc_1: 0.8533 - val_loss: 0.6576 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4750 - acc: 0.7717 - auc_1: 0.8529 - val_loss: 0.5728 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4704 - acc: 0.7609 - auc_1: 0.8533 - val_loss: 0.5557 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4659 - acc: 0.7500 - auc_1: 0.8605 - val_loss: 0.5377 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4554 - acc: 0.7717 - auc_1: 0.8612 - val_loss: 0.6249 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4681 - acc: 0.7717 - auc_1: 0.8579 - val_loss: 0.6118 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4693 - acc: 0.7500 - auc_1: 0.8538 - val_loss: 0.6044 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4588 - acc: 0.7717 - auc_1: 0.8574 - val_loss: 0.5347 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4751 - acc: 0.7500 - auc_1: 0.8452 - val_loss: 0.5949 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4584 - acc: 0.7500 - auc_1: 0.8657 - val_loss: 0.5486 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4605 - acc: 0.7717 - auc_1: 0.8579 - val_loss: 0.5167 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4491 - acc: 0.7826 - auc_1: 0.8638 - val_loss: 0.6702 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4607 - acc: 0.7826 - auc_1: 0.8605 - val_loss: 0.5920 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4590 - acc: 0.7826 - auc_1: 0.8664 - val_loss: 0.5941 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4470 - acc: 0.8261 - auc_1: 0.8836 - val_loss: 0.6743 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4635 - acc: 0.7826 - auc_1: 0.8560 - val_loss: 0.6418 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4443 - acc: 0.8043 - auc_1: 0.8745 - val_loss: 0.5324 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4565 - acc: 0.7826 - auc_1: 0.8629 - val_loss: 0.5790 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4470 - acc: 0.7609 - auc_1: 0.8740 - val_loss: 0.5654 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4456 - acc: 0.7717 - auc_1: 0.8721 - val_loss: 0.6289 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4448 - acc: 0.7826 - auc_1: 0.8748 - val_loss: 0.6037 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4448 - acc: 0.7609 - auc_1: 0.8786 - val_loss: 0.5498 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4465 - acc: 0.7935 - auc_1: 0.8714 - val_loss: 0.5870 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4375 - acc: 0.7826 - auc_1: 0.8779 - val_loss: 0.6210 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4493 - acc: 0.7717 - auc_1: 0.8688 - val_loss: 0.6101 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4382 - acc: 0.7935 - auc_1: 0.8819 - val_loss: 0.6027 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4433 - acc: 0.7717 - auc_1: 0.8762 - val_loss: 0.6289 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4353 - acc: 0.8152 - auc_1: 0.8812 - val_loss: 0.5831 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4276 - acc: 0.7826 - auc_1: 0.8838 - val_loss: 0.6715 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4406 - acc: 0.8043 - auc_1: 0.8710 - val_loss: 0.5996 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4373 - acc: 0.7826 - auc_1: 0.8779 - val_loss: 0.6118 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4348 - acc: 0.8152 - auc_1: 0.8838 - val_loss: 0.5964 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4302 - acc: 0.7935 - auc_1: 0.8802 - val_loss: 0.5567 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4263 - acc: 0.7826 - auc_1: 0.8874 - val_loss: 0.5459 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4281 - acc: 0.8043 - auc_1: 0.8931 - val_loss: 0.6348 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4230 - acc: 0.7935 - auc_1: 0.8917 - val_loss: 0.5571 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4301 - acc: 0.8152 - auc_1: 0.8800 - val_loss: 0.5938 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4290 - acc: 0.7935 - auc_1: 0.8883 - val_loss: 0.5631 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4221 - acc: 0.7826 - auc_1: 0.8888 - val_loss: 0.6153 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4151 - acc: 0.7826 - auc_1: 0.8936 - val_loss: 0.5837 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4164 - acc: 0.8261 - auc_1: 0.8919 - val_loss: 0.5500 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4166 - acc: 0.8152 - auc_1: 0.8945 - val_loss: 0.5810 - val_acc: 0.6250 - val_auc_1: 0.8250\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4170 - acc: 0.7935 - auc_1: 0.8940 - val_loss: 0.5610 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4148 - acc: 0.7935 - auc_1: 0.8924 - val_loss: 0.5668 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4215 - acc: 0.8478 - auc_1: 0.8876 - val_loss: 0.5924 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 97/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4087 - acc: 0.8261 - auc_1: 0.9002 - val_loss: 0.5423 - val_acc: 0.7083 - val_auc_1: 0.8393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4195 - acc: 0.7717 - auc_1: 0.8879 - val_loss: 0.5746 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4078 - acc: 0.8152 - auc_1: 0.9000 - val_loss: 0.5714 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4036 - acc: 0.8152 - auc_1: 0.8998 - val_loss: 0.5604 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4073 - acc: 0.8043 - auc_1: 0.8967 - val_loss: 0.5581 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4088 - acc: 0.8152 - auc_1: 0.8895 - val_loss: 0.6077 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3930 - acc: 0.8478 - auc_1: 0.9069 - val_loss: 0.5853 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4101 - acc: 0.8152 - auc_1: 0.8926 - val_loss: 0.5724 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3977 - acc: 0.8152 - auc_1: 0.9019 - val_loss: 0.5271 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3987 - acc: 0.8152 - auc_1: 0.9052 - val_loss: 0.5448 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3864 - acc: 0.8370 - auc_1: 0.9012 - val_loss: 0.6305 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4040 - acc: 0.8370 - auc_1: 0.8979 - val_loss: 0.5662 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3909 - acc: 0.8478 - auc_1: 0.9081 - val_loss: 0.5336 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3959 - acc: 0.8152 - auc_1: 0.9019 - val_loss: 0.5865 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4017 - acc: 0.8152 - auc_1: 0.8938 - val_loss: 0.5284 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3932 - acc: 0.8043 - auc_1: 0.9033 - val_loss: 0.5810 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3904 - acc: 0.8152 - auc_1: 0.8979 - val_loss: 0.5699 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3886 - acc: 0.8043 - auc_1: 0.9040 - val_loss: 0.5457 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3840 - acc: 0.8152 - auc_1: 0.9117 - val_loss: 0.6275 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3806 - acc: 0.8370 - auc_1: 0.9160 - val_loss: 0.5281 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3902 - acc: 0.8152 - auc_1: 0.9067 - val_loss: 0.5405 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3823 - acc: 0.8152 - auc_1: 0.9071 - val_loss: 0.5641 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3792 - acc: 0.8370 - auc_1: 0.9129 - val_loss: 0.5207 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3940 - acc: 0.8152 - auc_1: 0.9014 - val_loss: 0.5510 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3724 - acc: 0.8370 - auc_1: 0.9150 - val_loss: 0.5179 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3753 - acc: 0.8478 - auc_1: 0.9157 - val_loss: 0.5750 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3774 - acc: 0.8370 - auc_1: 0.9121 - val_loss: 0.5143 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3778 - acc: 0.8152 - auc_1: 0.9098 - val_loss: 0.5187 - val_acc: 0.6250 - val_auc_1: 0.8286\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3810 - acc: 0.8152 - auc_1: 0.9107 - val_loss: 0.5734 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3722 - acc: 0.8370 - auc_1: 0.9174 - val_loss: 0.5212 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3646 - acc: 0.8478 - auc_1: 0.9152 - val_loss: 0.5677 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3683 - acc: 0.8152 - auc_1: 0.9188 - val_loss: 0.5445 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3737 - acc: 0.8261 - auc_1: 0.9129 - val_loss: 0.5278 - val_acc: 0.6250 - val_auc_1: 0.8286\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3575 - acc: 0.8587 - auc_1: 0.9188 - val_loss: 0.5427 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3642 - acc: 0.8370 - auc_1: 0.9181 - val_loss: 0.5139 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3628 - acc: 0.8370 - auc_1: 0.9183 - val_loss: 0.5027 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3602 - acc: 0.8152 - auc_1: 0.9198 - val_loss: 0.5386 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3580 - acc: 0.8152 - auc_1: 0.9229 - val_loss: 0.5328 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3625 - acc: 0.8152 - auc_1: 0.9183 - val_loss: 0.5345 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3615 - acc: 0.8370 - auc_1: 0.9195 - val_loss: 0.5282 - val_acc: 0.6667 - val_auc_1: 0.8179\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3492 - acc: 0.8587 - auc_1: 0.9248 - val_loss: 0.5001 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3585 - acc: 0.8043 - auc_1: 0.9236 - val_loss: 0.5259 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3530 - acc: 0.8478 - auc_1: 0.9231 - val_loss: 0.5136 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3467 - acc: 0.8804 - auc_1: 0.9312 - val_loss: 0.4812 - val_acc: 0.6250 - val_auc_1: 0.8429\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3501 - acc: 0.8478 - auc_1: 0.9238 - val_loss: 0.4939 - val_acc: 0.6250 - val_auc_1: 0.8429\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3538 - acc: 0.8370 - auc_1: 0.9219 - val_loss: 0.4990 - val_acc: 0.6250 - val_auc_1: 0.8429\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3419 - acc: 0.8478 - auc_1: 0.9290 - val_loss: 0.5028 - val_acc: 0.6250 - val_auc_1: 0.8500\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3399 - acc: 0.8587 - auc_1: 0.9310 - val_loss: 0.4776 - val_acc: 0.6250 - val_auc_1: 0.8500\n",
      "Epoch 145/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3434 - acc: 0.8478 - auc_1: 0.9264 - val_loss: 0.5264 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 146/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3463 - acc: 0.8370 - auc_1: 0.9243 - val_loss: 0.4755 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3353 - acc: 0.8370 - auc_1: 0.9310 - val_loss: 0.4771 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3319 - acc: 0.8478 - auc_1: 0.9317 - val_loss: 0.4627 - val_acc: 0.6250 - val_auc_1: 0.8643\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3276 - acc: 0.8478 - auc_1: 0.9371 - val_loss: 0.4266 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3447 - acc: 0.8261 - auc_1: 0.9252 - val_loss: 0.4347 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3289 - acc: 0.8696 - auc_1: 0.9345 - val_loss: 0.4708 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3230 - acc: 0.8696 - auc_1: 0.9360 - val_loss: 0.4548 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3284 - acc: 0.8370 - auc_1: 0.9345 - val_loss: 0.5114 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3258 - acc: 0.8696 - auc_1: 0.9350 - val_loss: 0.4487 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.3123 - acc: 0.8764 - auc_1: 0.941 - 0s 4ms/step - loss: 0.3191 - acc: 0.8696 - auc_1: 0.9383 - val_loss: 0.4666 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3205 - acc: 0.8587 - auc_1: 0.9374 - val_loss: 0.4355 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3212 - acc: 0.8696 - auc_1: 0.9343 - val_loss: 0.4609 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3165 - acc: 0.8804 - auc_1: 0.9424 - val_loss: 0.4414 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3136 - acc: 0.8696 - auc_1: 0.9395 - val_loss: 0.5133 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3294 - acc: 0.8804 - auc_1: 0.9314 - val_loss: 0.4813 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3116 - acc: 0.8587 - auc_1: 0.9400 - val_loss: 0.4574 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3041 - acc: 0.8804 - auc_1: 0.9474 - val_loss: 0.4395 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3092 - acc: 0.8913 - auc_1: 0.9440 - val_loss: 0.4547 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3050 - acc: 0.8804 - auc_1: 0.9457 - val_loss: 0.4624 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3043 - acc: 0.8696 - auc_1: 0.9452 - val_loss: 0.4599 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2975 - acc: 0.8804 - auc_1: 0.9457 - val_loss: 0.4593 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3021 - acc: 0.8913 - auc_1: 0.9445 - val_loss: 0.4502 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2978 - acc: 0.8696 - auc_1: 0.9481 - val_loss: 0.5103 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2888 - acc: 0.8696 - auc_1: 0.9514 - val_loss: 0.4806 - val_acc: 0.7917 - val_auc_1: 0.8071\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2941 - acc: 0.8804 - auc_1: 0.9481 - val_loss: 0.4793 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2872 - acc: 0.8913 - auc_1: 0.9538 - val_loss: 0.5035 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2880 - acc: 0.8913 - auc_1: 0.9479 - val_loss: 0.5215 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2780 - acc: 0.9022 - auc_1: 0.9550 - val_loss: 0.5342 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2776 - acc: 0.9022 - auc_1: 0.9510 - val_loss: 0.4992 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2755 - acc: 0.8804 - auc_1: 0.9540 - val_loss: 0.5075 - val_acc: 0.8333 - val_auc_1: 0.8071\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2821 - acc: 0.8804 - auc_1: 0.9548 - val_loss: 0.5446 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2780 - acc: 0.8804 - auc_1: 0.9510 - val_loss: 0.5112 - val_acc: 0.8333 - val_auc_1: 0.8143\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2668 - acc: 0.9130 - auc_1: 0.9595 - val_loss: 0.5540 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2680 - acc: 0.8913 - auc_1: 0.9557 - val_loss: 0.5781 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2669 - acc: 0.8696 - auc_1: 0.9548 - val_loss: 0.5562 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2639 - acc: 0.8913 - auc_1: 0.9581 - val_loss: 0.5761 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2666 - acc: 0.9022 - auc_1: 0.9571 - val_loss: 0.5844 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2625 - acc: 0.8804 - auc_1: 0.9579 - val_loss: 0.5755 - val_acc: 0.8333 - val_auc_1: 0.8071\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2629 - acc: 0.9348 - auc_1: 0.9590 - val_loss: 0.5616 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2544 - acc: 0.9130 - auc_1: 0.9614 - val_loss: 0.5847 - val_acc: 0.8333 - val_auc_1: 0.7714\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2623 - acc: 0.8913 - auc_1: 0.9583 - val_loss: 0.6061 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2487 - acc: 0.9022 - auc_1: 0.9631 - val_loss: 0.6069 - val_acc: 0.7083 - val_auc_1: 0.7643\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2461 - acc: 0.9130 - auc_1: 0.9652 - val_loss: 0.5920 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2327 - acc: 0.9130 - auc_1: 0.9714 - val_loss: 0.6578 - val_acc: 0.5833 - val_auc_1: 0.7643\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2532 - acc: 0.8804 - auc_1: 0.9629 - val_loss: 0.5985 - val_acc: 0.7500 - val_auc_1: 0.7821\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2316 - acc: 0.9130 - auc_1: 0.9686 - val_loss: 0.7035 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2374 - acc: 0.9348 - auc_1: 0.9664 - val_loss: 0.6253 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2328 - acc: 0.9022 - auc_1: 0.9710 - val_loss: 0.6651 - val_acc: 0.7083 - val_auc_1: 0.7500\n",
      "Epoch 194/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2403 - acc: 0.9239 - auc_1: 0.9669 - val_loss: 0.6569 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2220 - acc: 0.9348 - auc_1: 0.9724 - val_loss: 0.6926 - val_acc: 0.5833 - val_auc_1: 0.7536\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2236 - acc: 0.9239 - auc_1: 0.9736 - val_loss: 0.6928 - val_acc: 0.6250 - val_auc_1: 0.7500\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2321 - acc: 0.9022 - auc_1: 0.9674 - val_loss: 0.6992 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2204 - acc: 0.9130 - auc_1: 0.9726 - val_loss: 0.6860 - val_acc: 0.7083 - val_auc_1: 0.7429\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2203 - acc: 0.9239 - auc_1: 0.9748 - val_loss: 0.7821 - val_acc: 0.5833 - val_auc_1: 0.7429\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2117 - acc: 0.9022 - auc_1: 0.9743 - val_loss: 0.7304 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2361 - acc: 0.9130 - auc_1: 0.9660 - val_loss: 0.7129 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2076 - acc: 0.9239 - auc_1: 0.9776 - val_loss: 0.7264 - val_acc: 0.6250 - val_auc_1: 0.7607\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2177 - acc: 0.9239 - auc_1: 0.9738 - val_loss: 0.7802 - val_acc: 0.5833 - val_auc_1: 0.7571\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2071 - acc: 0.9239 - auc_1: 0.9776 - val_loss: 0.7742 - val_acc: 0.5833 - val_auc_1: 0.7571\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2042 - acc: 0.8913 - auc_1: 0.9793 - val_loss: 0.7402 - val_acc: 0.7500 - val_auc_1: 0.7464\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2184 - acc: 0.9022 - auc_1: 0.9729 - val_loss: 0.7688 - val_acc: 0.7083 - val_auc_1: 0.7500\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2105 - acc: 0.9130 - auc_1: 0.9750 - val_loss: 0.7976 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2043 - acc: 0.9239 - auc_1: 0.9762 - val_loss: 0.8071 - val_acc: 0.6667 - val_auc_1: 0.7393\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2080 - acc: 0.9348 - auc_1: 0.9721 - val_loss: 0.8984 - val_acc: 0.5833 - val_auc_1: 0.7429\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1988 - acc: 0.9239 - auc_1: 0.9790 - val_loss: 0.8437 - val_acc: 0.5833 - val_auc_1: 0.7536\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1902 - acc: 0.9239 - auc_1: 0.9821 - val_loss: 0.8669 - val_acc: 0.5833 - val_auc_1: 0.7571\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2031 - acc: 0.9239 - auc_1: 0.9762 - val_loss: 0.8450 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1944 - acc: 0.9348 - auc_1: 0.9819 - val_loss: 0.8416 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1988 - acc: 0.9239 - auc_1: 0.9795 - val_loss: 0.8542 - val_acc: 0.6250 - val_auc_1: 0.7536\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1916 - acc: 0.9457 - auc_1: 0.9800 - val_loss: 0.8762 - val_acc: 0.5833 - val_auc_1: 0.7500\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1849 - acc: 0.9457 - auc_1: 0.9800 - val_loss: 0.9034 - val_acc: 0.5833 - val_auc_1: 0.7429\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1856 - acc: 0.9239 - auc_1: 0.9838 - val_loss: 0.8590 - val_acc: 0.6667 - val_auc_1: 0.7429\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1949 - acc: 0.9239 - auc_1: 0.9807 - val_loss: 0.8917 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1757 - acc: 0.9457 - auc_1: 0.9852 - val_loss: 0.8942 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1715 - acc: 0.9457 - auc_1: 0.9845 - val_loss: 0.8741 - val_acc: 0.7083 - val_auc_1: 0.7464\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1752 - acc: 0.9239 - auc_1: 0.9850 - val_loss: 0.9527 - val_acc: 0.5833 - val_auc_1: 0.7357\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1766 - acc: 0.9348 - auc_1: 0.9831 - val_loss: 0.9500 - val_acc: 0.5833 - val_auc_1: 0.7321\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1781 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 0.9413 - val_acc: 0.5833 - val_auc_1: 0.7393\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1679 - acc: 0.9457 - auc_1: 0.9862 - val_loss: 1.0159 - val_acc: 0.5833 - val_auc_1: 0.7357\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1765 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9643 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1677 - acc: 0.9348 - auc_1: 0.9862 - val_loss: 0.9792 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1563 - acc: 0.9457 - auc_1: 0.9864 - val_loss: 1.0863 - val_acc: 0.5833 - val_auc_1: 0.7250\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1688 - acc: 0.9348 - auc_1: 0.9862 - val_loss: 1.0064 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1600 - acc: 0.9348 - auc_1: 0.9886 - val_loss: 0.9925 - val_acc: 0.5833 - val_auc_1: 0.7214\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1723 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.9452 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1615 - acc: 0.9565 - auc_1: 0.9886 - val_loss: 0.9800 - val_acc: 0.6667 - val_auc_1: 0.7214\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1556 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 1.0356 - val_acc: 0.5833 - val_auc_1: 0.7214\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1549 - acc: 0.9348 - auc_1: 0.9886 - val_loss: 1.0381 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1588 - acc: 0.9457 - auc_1: 0.9864 - val_loss: 1.0157 - val_acc: 0.5833 - val_auc_1: 0.7286\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1557 - acc: 0.9239 - auc_1: 0.9876 - val_loss: 1.0964 - val_acc: 0.5833 - val_auc_1: 0.7429\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1495 - acc: 0.9565 - auc_1: 0.9890 - val_loss: 1.1374 - val_acc: 0.5833 - val_auc_1: 0.7286\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1635 - acc: 0.9239 - auc_1: 0.9852 - val_loss: 1.1109 - val_acc: 0.5833 - val_auc_1: 0.7107\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1543 - acc: 0.9239 - auc_1: 0.9883 - val_loss: 1.1040 - val_acc: 0.5833 - val_auc_1: 0.7214\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1639 - acc: 0.9239 - auc_1: 0.9857 - val_loss: 1.1240 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1414 - acc: 0.9565 - auc_1: 0.9910 - val_loss: 1.0751 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 241/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1452 - acc: 0.9674 - auc_1: 0.9900 - val_loss: 1.1502 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1535 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 1.1401 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1446 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 1.1481 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1395 - acc: 0.9565 - auc_1: 0.9907 - val_loss: 1.1110 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1347 - acc: 0.9457 - auc_1: 0.9910 - val_loss: 1.1787 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1428 - acc: 0.9457 - auc_1: 0.9893 - val_loss: 1.1736 - val_acc: 0.5833 - val_auc_1: 0.7036\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1392 - acc: 0.9565 - auc_1: 0.9910 - val_loss: 1.1895 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1493 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 1.1776 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1396 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 1.1679 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1431 - acc: 0.9348 - auc_1: 0.9905 - val_loss: 1.2885 - val_acc: 0.5833 - val_auc_1: 0.6893\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1317 - acc: 0.9348 - auc_1: 0.9914 - val_loss: 1.2272 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1176 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 1.2507 - val_acc: 0.5833 - val_auc_1: 0.7107\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1320 - acc: 0.9565 - auc_1: 0.9900 - val_loss: 1.2385 - val_acc: 0.5833 - val_auc_1: 0.6750\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1240 - acc: 0.9457 - auc_1: 0.9940 - val_loss: 1.2245 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1388 - acc: 0.9457 - auc_1: 0.9907 - val_loss: 1.2047 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1300 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 1.2267 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1306 - acc: 0.9565 - auc_1: 0.9907 - val_loss: 1.3164 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1326 - acc: 0.9457 - auc_1: 0.9886 - val_loss: 1.2798 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1354 - acc: 0.9457 - auc_1: 0.9907 - val_loss: 1.3765 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1143 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 1.2997 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1526 - acc: 0.9239 - auc_1: 0.9864 - val_loss: 1.3504 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1245 - acc: 0.9457 - auc_1: 0.9940 - val_loss: 1.3629 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1276 - acc: 0.9565 - auc_1: 0.9926 - val_loss: 1.3713 - val_acc: 0.5833 - val_auc_1: 0.6893\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1145 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 1.4626 - val_acc: 0.5833 - val_auc_1: 0.7107\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1182 - acc: 0.9783 - auc_1: 0.9943 - val_loss: 1.3386 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1195 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 1.2867 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1266 - acc: 0.9348 - auc_1: 0.9905 - val_loss: 1.3548 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1296 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 1.3779 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1191 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 1.4145 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1033 - acc: 0.9457 - auc_1: 0.9957 - val_loss: 1.5366 - val_acc: 0.5417 - val_auc_1: 0.7036\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1168 - acc: 0.9457 - auc_1: 0.9952 - val_loss: 1.4323 - val_acc: 0.7083 - val_auc_1: 0.6857\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1314 - acc: 0.9565 - auc_1: 0.9893 - val_loss: 1.3803 - val_acc: 0.6667 - val_auc_1: 0.6857\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1069 - acc: 0.9783 - auc_1: 0.9955 - val_loss: 1.4542 - val_acc: 0.5833 - val_auc_1: 0.7286\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1098 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 1.5383 - val_acc: 0.5833 - val_auc_1: 0.6857\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1128 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 1.4901 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0914 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 1.4601 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1073 - acc: 0.9565 - auc_1: 0.9926 - val_loss: 1.5248 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0969 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 1.4949 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1098 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 1.5541 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1006 - acc: 0.9457 - auc_1: 0.9967 - val_loss: 1.4621 - val_acc: 0.7083 - val_auc_1: 0.6643\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1166 - acc: 0.9239 - auc_1: 0.9919 - val_loss: 1.5220 - val_acc: 0.7083 - val_auc_1: 0.6393\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1247 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 1.5088 - val_acc: 0.5833 - val_auc_1: 0.7357\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0971 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.5115 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1130 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 1.6321 - val_acc: 0.5833 - val_auc_1: 0.6964\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1163 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 1.5649 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0974 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.5750 - val_acc: 0.6667 - val_auc_1: 0.6357\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0916 - acc: 0.9348 - auc_1: 0.9955 - val_loss: 1.5741 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0855 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.5795 - val_acc: 0.7083 - val_auc_1: 0.6500\n",
      "Epoch 289/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0947 - acc: 0.9457 - auc_1: 0.9962 - val_loss: 1.6131 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 290/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1003 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 1.6852 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1119 - acc: 0.9457 - auc_1: 0.9940 - val_loss: 1.6395 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1086 - acc: 0.9674 - auc_1: 0.9936 - val_loss: 1.6742 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0907 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.7327 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1079 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 1.5600 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0872 - acc: 0.9457 - auc_1: 0.9967 - val_loss: 1.5397 - val_acc: 0.7083 - val_auc_1: 0.6714\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1262 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 1.6809 - val_acc: 0.7083 - val_auc_1: 0.6429\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0888 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 1.6506 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0764 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.6549 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0812 - acc: 0.9891 - auc_1: 0.9976 - val_loss: 1.7444 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0745 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.6976 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0728 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.7008 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0939 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.8343 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0868 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 1.7316 - val_acc: 0.5833 - val_auc_1: 0.7000\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0817 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.6810 - val_acc: 0.7083 - val_auc_1: 0.6679\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0784 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.7233 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1020 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 1.8644 - val_acc: 0.5833 - val_auc_1: 0.7071\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0752 - acc: 0.9674 - auc_1: 0.9969 - val_loss: 1.7764 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0653 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.7725 - val_acc: 0.7083 - val_auc_1: 0.6571\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0582 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.8669 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0553 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8176 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0688 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.7906 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0704 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.8310 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0912 - acc: 0.9674 - auc_1: 0.9964 - val_loss: 1.8880 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0795 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 1.8660 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0754 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 1.8788 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0576 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.8662 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0607 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.9246 - val_acc: 0.7083 - val_auc_1: 0.6536\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1118 - acc: 0.9457 - auc_1: 0.9933 - val_loss: 2.0350 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0734 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 1.9897 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0593 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.9554 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0880 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.9641 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0621 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.8343 - val_acc: 0.6667 - val_auc_1: 0.6857\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0816 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 2.0361 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0377 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.9105 - val_acc: 0.7083 - val_auc_1: 0.6571\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0860 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 1.9168 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0510 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9870 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0531 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.0000 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0863 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 1.9684 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0583 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.9978 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0690 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 2.0633 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0394 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0329 - val_acc: 0.6667 - val_auc_1: 0.6929\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0465 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.0499 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1159 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 2.1905 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0498 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 2.1843 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0729 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 2.2575 - val_acc: 0.6250 - val_auc_1: 0.6071\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0535 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 2.1019 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 337/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0728 - acc: 0.9565 - auc_1: 0.9979 - val_loss: 2.2035 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 338/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0558 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.2477 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0471 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 2.2479 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0566 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 2.2168 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0421 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2523 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0351 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3236 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0354 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2482 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0442 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.2919 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0433 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2453 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0365 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.3676 - val_acc: 0.6250 - val_auc_1: 0.6179\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0358 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2011 - val_acc: 0.6667 - val_auc_1: 0.6714\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0312 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2726 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0437 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 2.3330 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0430 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 2.3380 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0779 - acc: 0.9783 - auc_1: 0.9960 - val_loss: 2.2883 - val_acc: 0.6667 - val_auc_1: 0.7036\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0619 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 2.4581 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0474 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 2.4554 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0808 - acc: 0.9674 - auc_1: 0.9964 - val_loss: 2.3943 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0475 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 2.3783 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0344 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.3918 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0381 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.4194 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0389 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 2.4625 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0442 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.5048 - val_acc: 0.6667 - val_auc_1: 0.6357\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0454 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5518 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0354 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.5699 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0384 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 2.6138 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0835 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 2.4799 - val_acc: 0.6667 - val_auc_1: 0.6464\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0294 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5159 - val_acc: 0.6667 - val_auc_1: 0.6321\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0359 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 2.5335 - val_acc: 0.5833 - val_auc_1: 0.6464\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0390 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4504 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0510 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 2.7360 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0387 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.4781 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0258 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4854 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0242 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4719 - val_acc: 0.6667 - val_auc_1: 0.6929\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0216 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5825 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0205 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.6221 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0332 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.6911 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0411 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.7062 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0308 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.5455 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0244 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.6383 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0177 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.6743 - val_acc: 0.6667 - val_auc_1: 0.6321\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0231 - acc: 1.0000 - auc_1: 1.0000 - 0s 3ms/step - loss: 0.0216 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.6802 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0170 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.7320 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0268 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.6131 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0439 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 2.7291 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0273 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.6119 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0434 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 2.7087 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1422 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 2.4333 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 385/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0678 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 2.6408 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 386/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0203 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.8381 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0311 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.8074 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0296 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.7382 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0281 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 2.5817 - val_acc: 0.6667 - val_auc_1: 0.6929\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0152 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.7749 - val_acc: 0.6667 - val_auc_1: 0.6464\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0181 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.8293 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0258 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.7399 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0308 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.8658 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0188 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.8380 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0133 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.8432 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0126 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.9517 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0157 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.7338 - val_acc: 0.7083 - val_auc_1: 0.7000\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0348 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 3.0252 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0916 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 2.6301 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0945 - acc: 0.9783 - auc_1: 0.9945 - val_loss: 3.2337 - val_acc: 0.6250 - val_auc_1: 0.6250\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0595 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 2.9638 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0146 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.9703 - val_acc: 0.6667 - val_auc_1: 0.6321\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0158 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.9662 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0146 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.9678 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0119 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.9862 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.9945 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0106 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0246 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0253 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0115 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0024 - val_acc: 0.6667 - val_auc_1: 0.6857\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0125 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0098 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0798 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0109 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0361 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0142 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.1384 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0227 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0424 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 3.1790 - val_acc: 0.5833 - val_auc_1: 0.6071\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0755 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 2.9944 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0217 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0253 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0293 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 3.2188 - val_acc: 0.5833 - val_auc_1: 0.6286\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1654 - acc: 0.9348 - auc_1: 0.9867 - val_loss: 3.0540 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0778 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 3.0268 - val_acc: 0.6667 - val_auc_1: 0.7071\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0330 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0676 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0317 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0131 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0625 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0673 - val_acc: 0.6667 - val_auc_1: 0.6714\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0565 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0815 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.0984 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.1007 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.1418 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.1191 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.1287 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 433/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.1701 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 434/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.1733 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2055 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.1476 - val_acc: 0.6667 - val_auc_1: 0.6464\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2404 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2850 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2582 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2849 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3287 - val_acc: 0.6667 - val_auc_1: 0.6464\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0125 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3322 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3816 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4068 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0125 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3486 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4771 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3335 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4421 - acc: 0.9130 - auc_1: 0.9431 - val_loss: 3.8667 - val_acc: 0.5417 - val_auc_1: 0.5750\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2139 - acc: 0.9348 - auc_1: 0.9752 - val_loss: 3.3592 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0119 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3181 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2708 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2565 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2846 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2733 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2475 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2843 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2616 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2765 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2670 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2927 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2998 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3208 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3318 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3561 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3495 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4064 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3860 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3811 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4046 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4758 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4619 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4589 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4286 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4856 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5236 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4854 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5848 - acc: 0.9239 - auc_1: 0.9357 - val_loss: 2.2515 - val_acc: 0.6667 - val_auc_1: 0.7036\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2987 - acc: 0.9239 - auc_1: 0.9712 - val_loss: 3.6140 - val_acc: 0.5833 - val_auc_1: 0.5821\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0839 - acc: 0.9783 - auc_1: 0.9924 - val_loss: 3.3883 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0412 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 3.3941 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 481/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0259 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 3.1938 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 482/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0369 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 3.3750 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3311 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3351 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3279 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3371 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3300 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3378 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3393 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3401 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3505 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3645 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3650 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3599 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3785 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3829 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3857 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4054 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4120 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4139 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4034 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4177 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4278 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4564 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4931 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4305 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4729 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4761 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5358 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4902 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5415 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5647 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6101 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1562 - acc: 0.9674 - auc_1: 0.9836 - val_loss: 3.6423 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2424 - acc: 0.9348 - auc_1: 0.9760 - val_loss: 3.9238 - val_acc: 0.5833 - val_auc_1: 0.5929\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3275 - acc: 0.8913 - auc_1: 0.9619 - val_loss: 3.9617 - val_acc: 0.5417 - val_auc_1: 0.5893\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1225 - acc: 0.9239 - auc_1: 0.9919 - val_loss: 3.3940 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0119 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3358 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0112 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.2932 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3662 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3592 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3654 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3596 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3694 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3786 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3861 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3787 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3883 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 529/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3993 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 530/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.3930 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4039 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4131 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4189 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4195 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4336 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4224 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4454 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4587 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4657 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4597 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4807 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4603 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.4997 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5363 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5122 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5238 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5778 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5594 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5631 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5664 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5872 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6297 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6512 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6444 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6347 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6075 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7187 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7274 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7232 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7037 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7201 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0211 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9959 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5924 - acc: 0.8913 - auc_1: 0.9400 - val_loss: 3.7335 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2298 - acc: 0.9348 - auc_1: 0.9829 - val_loss: 3.6227 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0126 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6132 - val_acc: 0.6667 - val_auc_1: 0.6714\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7001 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6481 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6302 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6020 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6104 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6171 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6099 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6100 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6244 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6121 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6245 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 577/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6273 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 578/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6314 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6283 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6445 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6492 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6648 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6683 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6771 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6624 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6742 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6784 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7221 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7647 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7601 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7556 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7426 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7449 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7862 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7819 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7394 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1496 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 4.0962 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2700 - acc: 0.9239 - auc_1: 0.9736 - val_loss: 3.5296 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1266 - acc: 0.9783 - auc_1: 0.9881 - val_loss: 3.9135 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1188 - acc: 0.9674 - auc_1: 0.9929 - val_loss: 3.6448 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.5872 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6091 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6581 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6612 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6674 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6745 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6856 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6804 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6951 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.6959 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7104 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7087 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7222 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7402 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7417 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7422 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7667 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7578 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7544 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7760 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7905 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.7750 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.8079 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.8214 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 625/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.8334 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 626/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.8353 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.8345 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.8594 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.8689 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.8898 - val_acc: 0.6667 - val_auc_1: 0.62860\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.8968 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.8917 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9208 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9118 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9466 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9894 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9768 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9772 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9809 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0546 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0808 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0091 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1925 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2545 - acc: 0.9348 - auc_1: 0.9795 - val_loss: 4.3452 - val_acc: 0.5833 - val_auc_1: 0.6393\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2233 - acc: 0.9565 - auc_1: 0.9729 - val_loss: 3.8893 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1941 - acc: 0.9457 - auc_1: 0.9814 - val_loss: 3.8807 - val_acc: 0.6667 - val_auc_1: 0.6214\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0727 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 3.8841 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1300 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 4.2055 - val_acc: 0.6250 - val_auc_1: 0.5714\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1274 - acc: 0.9674 - auc_1: 0.9955 - val_loss: 4.0414 - val_acc: 0.6250 - val_auc_1: 0.5857\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9586 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9638 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9661 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9644 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9696 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9697 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9652 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9667 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9614 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9649 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9752 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9705 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9725 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9752 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9738 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9796 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9744 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9810 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9857 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9822 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9820 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 3.9953 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0035 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 673/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0084 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 674/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0062 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0158 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0238 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0234 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0261 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0329 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0449 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0559 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0575 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0768 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0708 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0837 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0816 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0709 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.0823 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1160 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1241 - val_acc: 0.6250 - val_auc_1: 0.6286.000\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1109 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1500 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1453 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1545 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1516 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1859 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1914 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.2077 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.5359e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 4.1662 - val_acc: 0.6667 - val_auc_1: 0.6286\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2106 - acc: 0.9674 - auc_1: 0.9776 - val_loss: 3.5077 - val_acc: 0.5833 - val_auc_1: 0.5964\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5, X6], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.3539375 ,  1.4574825 , -1.3984326 , -1.7422614 ,  0.77525973,\n",
      "         0.32581776, -1.854485  , -0.32874966, -1.0180762 ],\n",
      "       [-2.2428496 ,  1.1981136 , -2.1536317 , -0.70439345,  2.3897583 ,\n",
      "         2.0117075 , -0.895505  , -2.84111   , -0.35768384],\n",
      "       [-0.3430082 ,  0.28651723,  0.96557826, -0.05320362, -0.42069128,\n",
      "        -1.3236469 ,  0.9421339 , -0.26070285, -1.15709   ],\n",
      "       [-0.01479406,  0.6975072 , -0.35596308,  0.5709444 ,  0.07928512,\n",
      "        -0.2081285 ,  0.5476457 , -0.27274585,  0.28548294],\n",
      "       [-1.4854932 , -0.9448329 , -0.01771419, -0.5483812 , -2.4399772 ,\n",
      "         0.14348221,  1.8360932 , -0.59490436, -0.7277425 ],\n",
      "       [ 0.07919658,  0.51057214,  0.45716843, -0.8273323 ,  1.0540177 ,\n",
      "        -1.1777974 , -0.9464421 ,  0.21303858,  0.92359364]],\n",
      "      dtype=float32), array([ 0.6552688 , -0.93210495,  0.22125748,  0.42383447, -0.34934837,\n",
      "        0.3076459 , -0.07846736,  0.6623073 ,  0.3979036 ], dtype=float32), array([[ 0.1925526 , -1.6465749 ,  1.1822869 ,  1.8064264 ,  0.5228669 ,\n",
      "         0.7700323 ,  1.1184844 , -1.4775671 ,  0.11827876],\n",
      "       [-0.1804642 ,  1.1125509 , -1.9013026 ,  1.7594346 , -0.84579   ,\n",
      "        -0.31740403, -1.8110017 , -1.5232371 , -0.5577654 ],\n",
      "       [-0.08054062, -0.5768099 ,  1.806662  ,  0.6326949 , -0.34476283,\n",
      "        -1.2134706 , -0.14552087, -0.85737395,  3.5002074 ],\n",
      "       [-0.48161697, -0.7917081 ,  1.9577446 , -0.54828966, -1.0558908 ,\n",
      "         1.2994128 ,  1.7211605 ,  1.4232926 ,  0.27329057],\n",
      "       [-1.0211811 ,  0.47592318, -2.957679  ,  0.13778168, -0.33358505,\n",
      "         1.9120052 ,  0.6161698 ,  0.13090564, -0.02961893],\n",
      "       [ 0.04256166, -0.36367515, -0.30040878, -2.432748  ,  0.4123739 ,\n",
      "         0.38160184,  2.0468721 ,  2.7392213 , -1.9706061 ],\n",
      "       [-0.54283303,  1.7786142 ,  2.1699436 , -0.44004112, -2.0648518 ,\n",
      "        -1.518481  , -1.6321027 ,  0.7855513 ,  1.826328  ],\n",
      "       [ 0.9426721 , -1.6171278 ,  1.9493989 ,  1.9042108 ,  1.1690689 ,\n",
      "         0.3625342 ,  1.8610276 , -0.9963536 ,  0.56115174],\n",
      "       [-1.6723999 , -1.2168373 , -0.22171232,  0.12716451,  0.22620118,\n",
      "         1.7906597 ,  2.161066  , -0.3831517 ,  0.33449152]],\n",
      "      dtype=float32), array([-0.09634088, -0.5937296 ,  0.22517344,  0.54400456,  0.55963725,\n",
      "        0.41593483, -0.20768237,  0.38065383,  0.10377083], dtype=float32), array([[-1.5492028 , -0.5303963 ,  0.1700912 ,  0.73311186,  0.21204264,\n",
      "        -0.36726663,  1.5832717 ,  1.1876096 ,  0.6933084 ],\n",
      "       [-1.9369277 ,  1.9419768 , -1.8663296 , -1.2218422 , -1.2158405 ,\n",
      "        -1.690206  ,  0.13875414, -1.3163702 , -1.2246224 ],\n",
      "       [ 0.6797531 ,  1.2174726 ,  3.5966756 , -1.0956146 , -1.3271166 ,\n",
      "         1.8065997 , -1.8769226 , -1.8357681 , -1.0448809 ],\n",
      "       [ 2.3007038 ,  0.40796942, -0.6758681 , -0.7651517 , -1.0185428 ,\n",
      "        -0.9849265 , -1.3123702 , -0.49035206, -0.47103652],\n",
      "       [ 0.5262922 , -1.4775281 , -0.8530993 ,  0.7394452 ,  0.2719112 ,\n",
      "         1.5645095 ,  0.0934631 ,  0.4287779 ,  0.4172012 ],\n",
      "       [ 3.5816672 , -0.6900076 ,  0.36472878,  0.24675831, -0.5353476 ,\n",
      "         1.969683  , -1.0978333 , -0.49993417, -0.08567015],\n",
      "       [-0.1793022 ,  0.62508   ,  0.23203123, -1.1989794 , -0.7271593 ,\n",
      "         3.96794   , -0.3477255 , -0.22054619, -1.0889958 ],\n",
      "       [-2.066459  , -0.2823234 ,  0.8217484 , -0.11186457,  0.11728374,\n",
      "         1.3217653 ,  1.5242112 ,  0.07544492,  0.61451215],\n",
      "       [ 1.4633225 , -1.7045665 ,  0.2643125 ,  0.4953664 ,  0.94793683,\n",
      "        -0.54109347,  0.65642524,  1.2820723 ,  0.6110252 ]],\n",
      "      dtype=float32), array([ 0.7886264 , -0.120145  , -0.14518748,  0.13750541,  0.10354137,\n",
      "       -0.63435864, -0.31257612, -0.12039136,  0.00155236], dtype=float32), array([[-2.0436404],\n",
      "       [-3.262197 ],\n",
      "       [-2.2871103],\n",
      "       [ 1.6550858],\n",
      "       [ 4.5648255],\n",
      "       [-4.0803547],\n",
      "       [ 2.340962 ],\n",
      "       [ 4.144866 ],\n",
      "       [ 3.010895 ]], dtype=float32), array([0.16163838], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.6840980e-07]\n",
      " [1.0000000e+00]\n",
      " [7.4960959e-01]\n",
      " [1.4291035e-06]\n",
      " [4.8562627e-02]\n",
      " [1.0000000e+00]\n",
      " [9.9999702e-01]\n",
      " [1.0000000e+00]\n",
      " [5.1782001e-07]\n",
      " [9.9999976e-01]\n",
      " [5.8749337e-02]\n",
      " [1.3186997e-04]\n",
      " [9.9999988e-01]\n",
      " [1.2603819e-03]\n",
      " [9.8665843e-08]\n",
      " [9.9960142e-01]\n",
      " [3.4391901e-01]\n",
      " [9.9999070e-01]\n",
      " [9.9999821e-01]\n",
      " [9.9982530e-01]\n",
      " [6.8669695e-05]\n",
      " [3.6255624e-08]\n",
      " [9.9979371e-01]\n",
      " [9.8641866e-01]\n",
      " [9.9999988e-01]\n",
      " [9.9865603e-01]\n",
      " [9.9989831e-01]\n",
      " [9.9989772e-01]\n",
      " [9.9995136e-01]\n",
      " [1.0000000e+00]\n",
      " [1.3198385e-01]\n",
      " [9.9974269e-01]\n",
      " [9.9990821e-01]\n",
      " [9.9941421e-01]\n",
      " [1.4977418e-06]\n",
      " [1.0000000e+00]\n",
      " [1.0000000e+00]\n",
      " [9.9999988e-01]\n",
      " [2.3127701e-04]\n",
      " [9.9999988e-01]\n",
      " [9.9999917e-01]\n",
      " [9.9951696e-01]\n",
      " [4.9422558e-02]\n",
      " [8.4145715e-05]\n",
      " [7.8139585e-08]\n",
      " [9.9998593e-01]\n",
      " [1.6798649e-03]\n",
      " [1.0000000e+00]\n",
      " [9.3865401e-01]\n",
      " [3.3485960e-06]\n",
      " [9.9962175e-01]\n",
      " [4.1478936e-02]\n",
      " [9.1381319e-04]\n",
      " [5.5618457e-06]\n",
      " [6.6289090e-06]\n",
      " [4.8977468e-04]\n",
      " [1.4911203e-07]\n",
      " [1.0000000e+00]\n",
      " [4.4121483e-05]\n",
      " [7.9026747e-01]\n",
      " [5.3093774e-04]\n",
      " [9.9997604e-01]\n",
      " [9.2245144e-01]\n",
      " [9.9996769e-01]\n",
      " [2.1100191e-04]\n",
      " [3.1729587e-06]\n",
      " [2.1102123e-06]\n",
      " [6.9093704e-04]\n",
      " [9.9929225e-01]\n",
      " [6.8973093e-03]\n",
      " [9.8462117e-01]\n",
      " [1.0000000e+00]\n",
      " [9.9999905e-01]\n",
      " [9.9999785e-01]\n",
      " [9.9999988e-01]\n",
      " [3.9790917e-05]\n",
      " [9.9883229e-01]\n",
      " [1.0265364e-06]\n",
      " [9.9883562e-01]\n",
      " [6.8766087e-05]\n",
      " [2.9345006e-09]\n",
      " [7.6723563e-07]\n",
      " [9.9999571e-01]\n",
      " [1.0000000e+00]\n",
      " [9.9998987e-01]\n",
      " [9.9999690e-01]\n",
      " [7.2304153e-01]\n",
      " [9.9909139e-01]\n",
      " [4.5186543e-09]\n",
      " [9.9999857e-01]\n",
      " [7.6625800e-01]\n",
      " [9.9997389e-01]\n",
      " [2.0284146e-04]\n",
      " [9.9310631e-01]\n",
      " [3.3194965e-01]\n",
      " [8.9170843e-01]\n",
      " [9.9999797e-01]\n",
      " [1.0000000e+00]\n",
      " [3.3592489e-08]\n",
      " [9.9564230e-01]\n",
      " [1.2154304e-01]\n",
      " [4.2414432e-09]\n",
      " [1.0000000e+00]\n",
      " [1.0000000e+00]\n",
      " [4.9514492e-05]\n",
      " [1.0000000e+00]\n",
      " [9.9857390e-01]\n",
      " [1.1765068e-08]\n",
      " [9.9998844e-01]\n",
      " [9.9976462e-01]\n",
      " [8.8015547e-08]\n",
      " [9.9993300e-01]\n",
      " [9.9999976e-01]\n",
      " [9.9999428e-01]\n",
      " [9.9910200e-01]\n",
      " [9.9999952e-01]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5, X6])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
