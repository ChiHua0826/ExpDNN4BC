{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,2:3] #Glucose\n",
    "X2 = dataset[:,7:8] #Resistin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,1:2] #BMI\n",
    "X5 = dataset[:,4:5] #HOMA\n",
    "X6 = dataset[:,5:6] #Leptin\n",
    "X7 = dataset[:,3:4] #Insulin\n",
    "X8 = dataset[:,6:7] #Adiponectin\n",
    "X9 = dataset[:,8:9] #MCP.1\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "X6 = normalization(X6)\n",
    "X7 = normalization(X7)\n",
    "X8 = normalization(X8)\n",
    "X9 = normalization(X9)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X6 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X7 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X8 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X9 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 9)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "                                                                 input_layer_X6[0][0]             \n",
      "                                                                 input_layer_X7[0][0]             \n",
      "                                                                 input_layer_X8[0][0]             \n",
      "                                                                 input_layer_X9[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            90          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 280\n",
      "Trainable params: 280\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "input_layer_X6 = keras.layers.Input(shape=(1, ), name='input_layer_X6')\n",
    "input_layer_X7 = keras.layers.Input(shape=(1, ), name='input_layer_X7')\n",
    "input_layer_X8 = keras.layers.Input(shape=(1, ), name='input_layer_X8')\n",
    "input_layer_X9 = keras.layers.Input(shape=(1, ), name='input_layer_X9')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7, input_layer_X8, input_layer_X9], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7, input_layer_X8, input_layer_X9], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.7022 - acc: 0.5326 - auc_1: 0.5381 - val_loss: 0.6616 - val_acc: 0.7500 - val_auc_1: 0.7036\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6690 - acc: 0.5978 - auc_1: 0.6336 - val_loss: 0.6300 - val_acc: 0.7083 - val_auc_1: 0.7536\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6513 - acc: 0.6413 - auc_1: 0.6743 - val_loss: 0.6076 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6253 - acc: 0.6522 - auc_1: 0.7100 - val_loss: 0.5820 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5966 - acc: 0.6739 - auc_1: 0.7488 - val_loss: 0.5355 - val_acc: 0.8333 - val_auc_1: 0.8143\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5809 - acc: 0.6413 - auc_1: 0.7562 - val_loss: 0.5613 - val_acc: 0.6667 - val_auc_1: 0.8179\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5607 - acc: 0.7065 - auc_1: 0.7852 - val_loss: 0.5187 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5500 - acc: 0.6413 - auc_1: 0.7729 - val_loss: 0.5695 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5438 - acc: 0.7174 - auc_1: 0.7864 - val_loss: 0.5214 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5377 - acc: 0.6848 - auc_1: 0.7776 - val_loss: 0.5904 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5290 - acc: 0.7500 - auc_1: 0.8074 - val_loss: 0.4992 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5252 - acc: 0.7391 - auc_1: 0.8005 - val_loss: 0.5205 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5209 - acc: 0.7500 - auc_1: 0.8079 - val_loss: 0.5451 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5142 - acc: 0.7174 - auc_1: 0.8095 - val_loss: 0.6175 - val_acc: 0.6250 - val_auc_1: 0.8929\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5112 - acc: 0.7391 - auc_1: 0.8188 - val_loss: 0.4715 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5164 - acc: 0.7174 - auc_1: 0.8126 - val_loss: 0.5335 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5046 - acc: 0.7609 - auc_1: 0.8202 - val_loss: 0.5077 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4976 - acc: 0.7609 - auc_1: 0.8271 - val_loss: 0.4667 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4989 - acc: 0.7391 - auc_1: 0.8310 - val_loss: 0.5862 - val_acc: 0.7083 - val_auc_1: 0.9036\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5003 - acc: 0.7609 - auc_1: 0.8164 - val_loss: 0.5363 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4898 - acc: 0.7826 - auc_1: 0.8340 - val_loss: 0.5971 - val_acc: 0.6250 - val_auc_1: 0.8929\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4961 - acc: 0.7609 - auc_1: 0.8202 - val_loss: 0.5250 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4846 - acc: 0.7717 - auc_1: 0.8412 - val_loss: 0.4801 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4881 - acc: 0.7717 - auc_1: 0.8355 - val_loss: 0.5544 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4783 - acc: 0.7609 - auc_1: 0.8338 - val_loss: 0.5431 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4758 - acc: 0.7500 - auc_1: 0.8386 - val_loss: 0.5198 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4770 - acc: 0.7717 - auc_1: 0.8364 - val_loss: 0.5184 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4706 - acc: 0.7609 - auc_1: 0.8429 - val_loss: 0.5506 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4603 - acc: 0.7609 - auc_1: 0.8493 - val_loss: 0.6201 - val_acc: 0.6250 - val_auc_1: 0.8929\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4727 - acc: 0.7717 - auc_1: 0.8419 - val_loss: 0.5737 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4467 - acc: 0.7935 - auc_1: 0.8574 - val_loss: 0.6332 - val_acc: 0.6250 - val_auc_1: 0.8964\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4628 - acc: 0.7717 - auc_1: 0.8481 - val_loss: 0.5209 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4540 - acc: 0.7500 - auc_1: 0.8548 - val_loss: 0.5402 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4515 - acc: 0.7717 - auc_1: 0.8540 - val_loss: 0.5127 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4493 - acc: 0.7391 - auc_1: 0.8621 - val_loss: 0.5789 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4591 - acc: 0.8043 - auc_1: 0.8607 - val_loss: 0.5328 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4425 - acc: 0.7717 - auc_1: 0.8681 - val_loss: 0.5651 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4316 - acc: 0.8043 - auc_1: 0.8745 - val_loss: 0.6060 - val_acc: 0.6250 - val_auc_1: 0.9000\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4414 - acc: 0.7935 - auc_1: 0.8576 - val_loss: 0.5707 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4338 - acc: 0.7935 - auc_1: 0.8621 - val_loss: 0.5440 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4186 - acc: 0.7826 - auc_1: 0.8776 - val_loss: 0.6549 - val_acc: 0.6250 - val_auc_1: 0.8964\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4268 - acc: 0.8043 - auc_1: 0.8707 - val_loss: 0.5401 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4223 - acc: 0.7935 - auc_1: 0.8698 - val_loss: 0.5297 - val_acc: 0.9167 - val_auc_1: 0.9071\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4318 - acc: 0.7935 - auc_1: 0.8700 - val_loss: 0.6640 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4311 - acc: 0.7935 - auc_1: 0.8638 - val_loss: 0.6133 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4245 - acc: 0.8043 - auc_1: 0.8693 - val_loss: 0.5694 - val_acc: 0.7083 - val_auc_1: 0.8964\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4096 - acc: 0.8043 - auc_1: 0.8745 - val_loss: 0.5447 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4159 - acc: 0.7935 - auc_1: 0.8767 - val_loss: 0.5715 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4173 - acc: 0.8152 - auc_1: 0.8705 - val_loss: 0.6227 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4035 - acc: 0.8370 - auc_1: 0.8845 - val_loss: 0.5567 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4251 - acc: 0.7826 - auc_1: 0.8760 - val_loss: 0.5974 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4189 - acc: 0.8370 - auc_1: 0.8762 - val_loss: 0.6248 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4112 - acc: 0.8152 - auc_1: 0.8793 - val_loss: 0.6041 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4074 - acc: 0.7935 - auc_1: 0.8760 - val_loss: 0.6258 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3992 - acc: 0.8152 - auc_1: 0.8843 - val_loss: 0.5565 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3967 - acc: 0.8152 - auc_1: 0.8845 - val_loss: 0.6056 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4018 - acc: 0.8043 - auc_1: 0.8855 - val_loss: 0.6037 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4002 - acc: 0.8043 - auc_1: 0.8829 - val_loss: 0.6224 - val_acc: 0.6667 - val_auc_1: 0.8929\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3871 - acc: 0.8152 - auc_1: 0.8874 - val_loss: 0.5747 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4058 - acc: 0.7935 - auc_1: 0.8893 - val_loss: 0.6619 - val_acc: 0.6667 - val_auc_1: 0.8929\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3944 - acc: 0.8261 - auc_1: 0.8840 - val_loss: 0.5863 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3904 - acc: 0.8152 - auc_1: 0.8900 - val_loss: 0.5655 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3870 - acc: 0.7935 - auc_1: 0.8907 - val_loss: 0.6602 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3933 - acc: 0.8261 - auc_1: 0.8893 - val_loss: 0.6281 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3871 - acc: 0.8043 - auc_1: 0.8967 - val_loss: 0.6375 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3819 - acc: 0.8261 - auc_1: 0.8981 - val_loss: 0.6987 - val_acc: 0.6250 - val_auc_1: 0.8857\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3952 - acc: 0.8261 - auc_1: 0.8848 - val_loss: 0.6877 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3797 - acc: 0.8370 - auc_1: 0.8960 - val_loss: 0.5906 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3888 - acc: 0.7935 - auc_1: 0.8883 - val_loss: 0.6077 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3813 - acc: 0.8261 - auc_1: 0.8969 - val_loss: 0.6154 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3837 - acc: 0.7935 - auc_1: 0.8962 - val_loss: 0.6476 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3811 - acc: 0.7935 - auc_1: 0.9005 - val_loss: 0.6484 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3798 - acc: 0.8043 - auc_1: 0.9017 - val_loss: 0.6049 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3870 - acc: 0.8043 - auc_1: 0.8871 - val_loss: 0.6076 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3778 - acc: 0.8152 - auc_1: 0.8976 - val_loss: 0.6582 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3845 - acc: 0.8043 - auc_1: 0.8902 - val_loss: 0.6628 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3729 - acc: 0.8043 - auc_1: 0.9000 - val_loss: 0.6374 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3734 - acc: 0.8370 - auc_1: 0.9026 - val_loss: 0.6736 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3793 - acc: 0.8043 - auc_1: 0.9048 - val_loss: 0.6265 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3548 - acc: 0.8261 - auc_1: 0.9112 - val_loss: 0.7415 - val_acc: 0.6250 - val_auc_1: 0.8750\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3821 - acc: 0.8370 - auc_1: 0.8974 - val_loss: 0.6753 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3679 - acc: 0.8261 - auc_1: 0.9002 - val_loss: 0.7006 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3725 - acc: 0.8043 - auc_1: 0.9029 - val_loss: 0.6730 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3642 - acc: 0.8370 - auc_1: 0.9088 - val_loss: 0.6316 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3611 - acc: 0.8478 - auc_1: 0.9033 - val_loss: 0.6488 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3583 - acc: 0.8370 - auc_1: 0.9083 - val_loss: 0.7461 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3696 - acc: 0.7935 - auc_1: 0.9093 - val_loss: 0.6531 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3674 - acc: 0.8261 - auc_1: 0.9043 - val_loss: 0.6785 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3613 - acc: 0.8152 - auc_1: 0.9105 - val_loss: 0.7287 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3701 - acc: 0.8152 - auc_1: 0.9017 - val_loss: 0.7179 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3544 - acc: 0.8261 - auc_1: 0.9160 - val_loss: 0.7151 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3591 - acc: 0.8261 - auc_1: 0.9129 - val_loss: 0.6976 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3514 - acc: 0.8152 - auc_1: 0.9152 - val_loss: 0.7104 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3476 - acc: 0.8152 - auc_1: 0.9198 - val_loss: 0.6703 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3484 - acc: 0.8261 - auc_1: 0.9210 - val_loss: 0.6731 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3688 - acc: 0.8152 - auc_1: 0.9055 - val_loss: 0.6891 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 97/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3404 - acc: 0.8152 - auc_1: 0.9233 - val_loss: 0.6776 - val_acc: 0.7500 - val_auc_1: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3454 - acc: 0.8152 - auc_1: 0.9174 - val_loss: 0.6504 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3476 - acc: 0.8152 - auc_1: 0.9238 - val_loss: 0.6839 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3337 - acc: 0.8261 - auc_1: 0.9307 - val_loss: 0.6736 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3381 - acc: 0.8261 - auc_1: 0.9243 - val_loss: 0.6833 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3294 - acc: 0.8370 - auc_1: 0.9269 - val_loss: 0.7406 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3224 - acc: 0.8370 - auc_1: 0.9314 - val_loss: 0.8123 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3340 - acc: 0.8370 - auc_1: 0.9219 - val_loss: 0.7947 - val_acc: 0.6250 - val_auc_1: 0.8893\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3261 - acc: 0.8370 - auc_1: 0.9343 - val_loss: 0.6707 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3267 - acc: 0.8261 - auc_1: 0.9338 - val_loss: 0.6513 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3060 - acc: 0.8587 - auc_1: 0.9421 - val_loss: 0.7683 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3141 - acc: 0.8370 - auc_1: 0.9369 - val_loss: 0.6992 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3089 - acc: 0.8370 - auc_1: 0.9424 - val_loss: 0.6805 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3066 - acc: 0.8696 - auc_1: 0.9438 - val_loss: 0.7670 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3201 - acc: 0.8261 - auc_1: 0.9336 - val_loss: 0.6504 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3053 - acc: 0.8152 - auc_1: 0.9407 - val_loss: 0.8060 - val_acc: 0.6250 - val_auc_1: 0.8929\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3003 - acc: 0.8261 - auc_1: 0.9393 - val_loss: 0.8168 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2994 - acc: 0.8804 - auc_1: 0.9464 - val_loss: 0.7024 - val_acc: 0.7083 - val_auc_1: 0.8893\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3005 - acc: 0.8261 - auc_1: 0.9460 - val_loss: 0.8784 - val_acc: 0.6250 - val_auc_1: 0.8750\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3044 - acc: 0.8261 - auc_1: 0.9417 - val_loss: 0.6951 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2973 - acc: 0.8478 - auc_1: 0.9471 - val_loss: 0.6953 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3002 - acc: 0.8478 - auc_1: 0.9445 - val_loss: 0.7454 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2858 - acc: 0.8587 - auc_1: 0.9512 - val_loss: 0.6735 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2936 - acc: 0.8478 - auc_1: 0.9517 - val_loss: 0.7416 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2708 - acc: 0.8478 - auc_1: 0.9588 - val_loss: 0.6377 - val_acc: 0.8750 - val_auc_1: 0.8857\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3020 - acc: 0.8261 - auc_1: 0.9352 - val_loss: 0.7546 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2750 - acc: 0.8478 - auc_1: 0.9552 - val_loss: 0.6528 - val_acc: 0.9167 - val_auc_1: 0.8750\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2829 - acc: 0.8370 - auc_1: 0.9517 - val_loss: 0.7434 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2783 - acc: 0.8043 - auc_1: 0.9481 - val_loss: 0.8333 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2886 - acc: 0.8587 - auc_1: 0.9488 - val_loss: 0.7145 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2792 - acc: 0.8478 - auc_1: 0.9538 - val_loss: 0.8107 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2788 - acc: 0.8587 - auc_1: 0.9540 - val_loss: 0.7401 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2789 - acc: 0.8696 - auc_1: 0.9540 - val_loss: 0.7761 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2738 - acc: 0.8587 - auc_1: 0.9543 - val_loss: 0.7825 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2691 - acc: 0.8913 - auc_1: 0.9569 - val_loss: 0.6836 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2681 - acc: 0.8587 - auc_1: 0.9557 - val_loss: 0.7197 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2733 - acc: 0.8587 - auc_1: 0.9543 - val_loss: 0.7688 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2655 - acc: 0.8587 - auc_1: 0.9581 - val_loss: 0.7348 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2635 - acc: 0.8478 - auc_1: 0.9562 - val_loss: 0.7495 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2758 - acc: 0.8478 - auc_1: 0.9507 - val_loss: 0.7987 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2676 - acc: 0.8804 - auc_1: 0.9543 - val_loss: 0.8108 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2646 - acc: 0.8696 - auc_1: 0.9569 - val_loss: 0.7804 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2739 - acc: 0.8696 - auc_1: 0.9521 - val_loss: 0.8097 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2602 - acc: 0.8804 - auc_1: 0.9610 - val_loss: 0.7864 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2485 - acc: 0.8696 - auc_1: 0.9633 - val_loss: 0.8767 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2699 - acc: 0.8587 - auc_1: 0.9529 - val_loss: 0.8345 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2473 - acc: 0.8804 - auc_1: 0.9621 - val_loss: 0.8513 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2653 - acc: 0.8587 - auc_1: 0.9543 - val_loss: 0.7194 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 145/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2523 - acc: 0.8696 - auc_1: 0.9605 - val_loss: 0.9273 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 146/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2511 - acc: 0.8913 - auc_1: 0.9602 - val_loss: 0.8027 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2435 - acc: 0.9022 - auc_1: 0.9655 - val_loss: 0.8283 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2458 - acc: 0.8913 - auc_1: 0.9652 - val_loss: 0.7519 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2436 - acc: 0.8804 - auc_1: 0.9624 - val_loss: 0.7424 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2469 - acc: 0.8913 - auc_1: 0.9631 - val_loss: 0.8089 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2398 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.7932 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2422 - acc: 0.8696 - auc_1: 0.9655 - val_loss: 0.8011 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2531 - acc: 0.8587 - auc_1: 0.9583 - val_loss: 0.9218 - val_acc: 0.6250 - val_auc_1: 0.8679\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2507 - acc: 0.8913 - auc_1: 0.9624 - val_loss: 0.7917 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2344 - acc: 0.8913 - auc_1: 0.9660 - val_loss: 0.8152 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2473 - acc: 0.8804 - auc_1: 0.9614 - val_loss: 0.8027 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2301 - acc: 0.8913 - auc_1: 0.9679 - val_loss: 0.8513 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2460 - acc: 0.8913 - auc_1: 0.9638 - val_loss: 0.7689 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2293 - acc: 0.8696 - auc_1: 0.9664 - val_loss: 0.8612 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2455 - acc: 0.8478 - auc_1: 0.9593 - val_loss: 0.7888 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2169 - acc: 0.9130 - auc_1: 0.9714 - val_loss: 0.8597 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2396 - acc: 0.8804 - auc_1: 0.9643 - val_loss: 0.8729 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2240 - acc: 0.8913 - auc_1: 0.9707 - val_loss: 0.7861 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2271 - acc: 0.8804 - auc_1: 0.9679 - val_loss: 0.8410 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2177 - acc: 0.9022 - auc_1: 0.9717 - val_loss: 0.7709 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2224 - acc: 0.9022 - auc_1: 0.9724 - val_loss: 0.8722 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2230 - acc: 0.9130 - auc_1: 0.9719 - val_loss: 0.7815 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2248 - acc: 0.8696 - auc_1: 0.9679 - val_loss: 0.8339 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2250 - acc: 0.9130 - auc_1: 0.9700 - val_loss: 0.8043 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2230 - acc: 0.8804 - auc_1: 0.9690 - val_loss: 0.7614 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2235 - acc: 0.9130 - auc_1: 0.9681 - val_loss: 0.8081 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2233 - acc: 0.9022 - auc_1: 0.9662 - val_loss: 0.8477 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2141 - acc: 0.9239 - auc_1: 0.9738 - val_loss: 0.7576 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2079 - acc: 0.9022 - auc_1: 0.9771 - val_loss: 0.8163 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2150 - acc: 0.8913 - auc_1: 0.9731 - val_loss: 0.7956 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2120 - acc: 0.8804 - auc_1: 0.9693 - val_loss: 0.8913 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2077 - acc: 0.9130 - auc_1: 0.9729 - val_loss: 0.7153 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2112 - acc: 0.9130 - auc_1: 0.9736 - val_loss: 0.8326 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2043 - acc: 0.9022 - auc_1: 0.9731 - val_loss: 0.8885 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1960 - acc: 0.9022 - auc_1: 0.9767 - val_loss: 0.7733 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2024 - acc: 0.9022 - auc_1: 0.9783 - val_loss: 0.9067 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2069 - acc: 0.9130 - auc_1: 0.9731 - val_loss: 0.9046 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2098 - acc: 0.8913 - auc_1: 0.9726 - val_loss: 0.7103 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2004 - acc: 0.8913 - auc_1: 0.9762 - val_loss: 0.7400 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1963 - acc: 0.9130 - auc_1: 0.9776 - val_loss: 0.7053 - val_acc: 0.8750 - val_auc_1: 0.8536\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2112 - acc: 0.8913 - auc_1: 0.9745 - val_loss: 0.7408 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2015 - acc: 0.9130 - auc_1: 0.9740 - val_loss: 0.7647 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1984 - acc: 0.8804 - auc_1: 0.9764 - val_loss: 0.7000 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1935 - acc: 0.9022 - auc_1: 0.9774 - val_loss: 0.7195 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2024 - acc: 0.8804 - auc_1: 0.9721 - val_loss: 0.6924 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1978 - acc: 0.9130 - auc_1: 0.9760 - val_loss: 0.7341 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1960 - acc: 0.9022 - auc_1: 0.9786 - val_loss: 0.6825 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1947 - acc: 0.9348 - auc_1: 0.9790 - val_loss: 0.8384 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 194/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2019 - acc: 0.9130 - auc_1: 0.9755 - val_loss: 0.7699 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1863 - acc: 0.9022 - auc_1: 0.9798 - val_loss: 0.7405 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1851 - acc: 0.9239 - auc_1: 0.9793 - val_loss: 0.7914 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2059 - acc: 0.9022 - auc_1: 0.9769 - val_loss: 0.6082 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1849 - acc: 0.9239 - auc_1: 0.9798 - val_loss: 0.6415 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1783 - acc: 0.9348 - auc_1: 0.9802 - val_loss: 0.7627 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1858 - acc: 0.8913 - auc_1: 0.9781 - val_loss: 0.6555 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2006 - acc: 0.9239 - auc_1: 0.9738 - val_loss: 0.6628 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1851 - acc: 0.9022 - auc_1: 0.9805 - val_loss: 0.6752 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1853 - acc: 0.8913 - auc_1: 0.9781 - val_loss: 0.6760 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1827 - acc: 0.9022 - auc_1: 0.9814 - val_loss: 0.7524 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1791 - acc: 0.9130 - auc_1: 0.9800 - val_loss: 0.6542 - val_acc: 0.8750 - val_auc_1: 0.8464\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1923 - acc: 0.8913 - auc_1: 0.9752 - val_loss: 0.7182 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1745 - acc: 0.9130 - auc_1: 0.9833 - val_loss: 0.6755 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1766 - acc: 0.9348 - auc_1: 0.9821 - val_loss: 0.7035 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1687 - acc: 0.9130 - auc_1: 0.9826 - val_loss: 0.7198 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1653 - acc: 0.9348 - auc_1: 0.9843 - val_loss: 0.7078 - val_acc: 0.8333 - val_auc_1: 0.8321\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1717 - acc: 0.9239 - auc_1: 0.9831 - val_loss: 0.7154 - val_acc: 0.8333 - val_auc_1: 0.8286\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1587 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 0.7195 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1601 - acc: 0.9348 - auc_1: 0.9862 - val_loss: 0.7322 - val_acc: 0.8333 - val_auc_1: 0.8393\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1556 - acc: 0.9239 - auc_1: 0.9862 - val_loss: 0.7045 - val_acc: 0.8333 - val_auc_1: 0.8321\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1615 - acc: 0.9239 - auc_1: 0.9862 - val_loss: 0.6974 - val_acc: 0.8333 - val_auc_1: 0.8250\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1768 - acc: 0.9022 - auc_1: 0.9807 - val_loss: 0.6822 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1672 - acc: 0.9239 - auc_1: 0.9840 - val_loss: 0.6581 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1477 - acc: 0.9348 - auc_1: 0.9888 - val_loss: 0.6390 - val_acc: 0.8333 - val_auc_1: 0.8321\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1393 - acc: 0.9674 - auc_1: 0.9919 - val_loss: 0.6727 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1379 - acc: 0.9239 - auc_1: 0.9900 - val_loss: 0.6322 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1543 - acc: 0.9239 - auc_1: 0.9857 - val_loss: 0.7332 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1481 - acc: 0.9565 - auc_1: 0.9879 - val_loss: 0.6343 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1328 - acc: 0.9674 - auc_1: 0.9945 - val_loss: 0.7205 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1563 - acc: 0.9348 - auc_1: 0.9867 - val_loss: 0.6979 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1449 - acc: 0.9348 - auc_1: 0.9888 - val_loss: 0.6539 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1311 - acc: 0.9565 - auc_1: 0.9940 - val_loss: 0.7145 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1399 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 0.7250 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1350 - acc: 0.9457 - auc_1: 0.9948 - val_loss: 0.7340 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1427 - acc: 0.9457 - auc_1: 0.9886 - val_loss: 0.6078 - val_acc: 0.8333 - val_auc_1: 0.8500\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1304 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 0.7249 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1244 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.7576 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1277 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 0.7566 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1412 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 0.7312 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1185 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 0.6230 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1355 - acc: 0.9457 - auc_1: 0.9910 - val_loss: 0.7748 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1103 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.7788 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1181 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.7237 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1100 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.7193 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1119 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6588 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1130 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.7554 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 241/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1325 - acc: 0.9674 - auc_1: 0.9919 - val_loss: 0.7519 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1146 - acc: 0.9674 - auc_1: 0.9936 - val_loss: 0.7368 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1089 - acc: 0.9783 - auc_1: 0.9943 - val_loss: 0.7812 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1085 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 0.7772 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0982 - acc: 0.9565 - auc_1: 0.9969 - val_loss: 0.7052 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0936 - acc: 0.9457 - auc_1: 0.9981 - val_loss: 0.7296 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0998 - acc: 0.9891 - auc_1: 0.9971 - val_loss: 0.7407 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0951 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.7889 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0872 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6803 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0928 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.7367 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0955 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6090 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1411 - acc: 0.9239 - auc_1: 0.9876 - val_loss: 0.6504 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0852 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.6806 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0749 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.7172 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0877 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.7771 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0820 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7698 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0931 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.7637 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0777 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.7313 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0842 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.7499 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0691 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7719 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0750 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.6902 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0838 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 0.7647 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0877 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.7272 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0781 - acc: 0.9565 - auc_1: 0.9986 - val_loss: 0.8414 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0704 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.7523 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0666 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7974 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0686 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.6880 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0635 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 0.7247 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0660 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6968 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0575 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8150 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0707 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.7299 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0673 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 0.7418 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0493 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7576 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0694 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.8327 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0610 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 0.8133 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0611 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 0.7954 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0752 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.7444 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0437 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7951 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0678 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.8152 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0578 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.8684 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0471 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.8142 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0515 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.8739 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0467 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8529 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0417 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8362 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0391 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8383 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0413 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8761 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0461 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8388 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0695 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8779 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 289/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0601 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 0.8561 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 290/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0716 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 0.8011 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0700 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.8530 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0450 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8356 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0409 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8591 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0531 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8778 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0338 - acc: 1.0000 - auc_1: 1.000 - 1s 6ms/step - loss: 0.0302 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9141 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0354 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9007 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0287 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9415 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0295 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9228 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0345 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9354 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0761 - acc: 0.9783 - auc_1: 0.9960 - val_loss: 0.8968 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0350 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9427 - val_acc: 0.7083 - val_auc_1: 0.8893\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0322 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9403 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0241 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9269 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0260 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9171 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0225 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9686 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0219 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9634 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0250 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9993 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0338 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0140 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0212 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9803 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0280 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9692 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0274 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0241 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0297 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9902 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0321 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0284 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0847 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 0.9415 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1114 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 1.0263 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0253 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1491 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0265 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0446 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0343 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0803 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0292 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0439 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0328 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0239 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0165 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0504 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0144 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0520 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0134 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0960 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0133 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0807 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0742 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.0248 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0207 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0243 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0182 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0650 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0169 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0519 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0137 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0614 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0132 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0596 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0120 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0905 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1033 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0140 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1096 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0115 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1131 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0102 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1352 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0105 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1395 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 337/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1595 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 338/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0165 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1087 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0501 - acc: 0.9783 - auc_1: 0.9983 - val_loss: 1.2528 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0721 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.1533 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0166 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1176 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0121 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1400 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0119 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1649 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0123 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1491 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1813 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1991 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1937 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1999 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2101 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2179 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2228 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2308 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2257 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2273 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2314 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2577 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2469 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2549 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0233 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.5045 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5015 - acc: 0.8587 - auc_1: 0.9376 - val_loss: 1.1676 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1176 - acc: 0.9457 - auc_1: 0.9926 - val_loss: 1.3834 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1100 - acc: 0.9783 - auc_1: 0.9921 - val_loss: 1.2127 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0116 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2588 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2734 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0088 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2805 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2865 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3036 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3078 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3153 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3249 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3193 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3215 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3191 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3313 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3277 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3371 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3448 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3439 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3403 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3506 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3634 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3543 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3639 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3606 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 385/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3748 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 386/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3849 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3841 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3842 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3838 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3838 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3961 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4068 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4123 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4127 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4152 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3820 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4242 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1165 - acc: 0.9565 - auc_1: 0.9945 - val_loss: 1.3237 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1977 - acc: 0.9348 - auc_1: 0.9817 - val_loss: 1.3697 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0171 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3770 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4130 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4264 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4148 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4169 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4169 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4246 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4245 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4317 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4335 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4297 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4327 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4347 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4404 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4422 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4438 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4483 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4568 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4665 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4613 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4605 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4671 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4675 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4798 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4685 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4772 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4728 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4857 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5168 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0721 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 1.2204 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4934 - acc: 0.8913 - auc_1: 0.9357 - val_loss: 1.4260 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4285 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4316 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 433/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4329 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 434/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4295 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4290 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4333 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4312 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4336 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4332 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4336 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4331 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4331 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4300 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4395 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4434 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4465 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4446 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4502 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4464 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4472 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4550 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4587 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4648 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4680 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4735 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4758 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4826 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4818 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4901 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4881 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4924 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4978 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5007 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5130 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5173 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5121 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5155 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5384 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5448 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5331 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5192 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1325 - acc: 0.9674 - auc_1: 0.9862 - val_loss: 1.2216 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1522 - acc: 0.9565 - auc_1: 0.9819 - val_loss: 1.6516 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1074 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 1.5996 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0385 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.6229 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6298 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6008 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5909 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5766 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5745 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 481/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5696 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 482/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5717 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5670 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5677 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5695 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5755 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5785 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5806 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5840 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5832 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5892 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5890 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5925 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5864 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5950 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6003 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6053 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6089 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6097 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6147 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6159 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6165 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6233 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6181 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6246 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6287 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6299 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6363 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6424 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6483 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6452 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6517 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6488 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6453 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6610 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6551 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6640 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6622 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6667 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6814 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6775 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 9.6464e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6813 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6813 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6911 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.7234e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7003 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7041 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7007 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.0545e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7267 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 529/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.5487e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7342 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 530/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 8.2244e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7369 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.1625e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7340 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7584 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4808 - acc: 0.9130 - auc_1: 0.9410 - val_loss: 1.2783 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1496 - acc: 0.9783 - auc_1: 0.9862 - val_loss: 1.5647 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0654 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 1.5903 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6112 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6203 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6257 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6291 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6354 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6366 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6419 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6459 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6486 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6539 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6574 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6599 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6614 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6661 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6715 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6718 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6763 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6753 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6803 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6867 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6905 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6916 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7000 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6958 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 9.9660e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7039 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 9.7490e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7024 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 9.6601e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7028 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.4584e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7117 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.1148e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7108 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.2303e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7167 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.3242e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7237 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 9.0512e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7251 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 8.6659e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7302 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.7550e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7353 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.1566e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7299 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 8.5554e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7359 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.1948e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7390 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.9505e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7451 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 8.5077e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7375 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.3948e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7567 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.9101e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7440 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 577/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 8.3011e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7552 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 578/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 7.4620e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7548 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.6383e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7627 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.2931e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7766 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.0225e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7873 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.5468e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7837 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.9256e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7876 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 6.5207e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7879 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.6515e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7946 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.8190e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7919 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.4594e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7959 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 6.4137e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8121 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.9587e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8118 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.7695e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8203 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.0541e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7995 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.1510e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8405 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.1347e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8398 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.1405e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8495 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.5434e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8117 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.5877e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8500 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.9968e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8494 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 5.2504e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8474 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.9723e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8598 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.4007e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8470 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.5034e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8801 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.1147e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8864 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.8433e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9034 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.6970e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8995 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.0037e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9137 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.3897e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9260 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 3.9876e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9068 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 3.9434e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8968 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 5.5339e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9873 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3454 - acc: 0.9457 - auc_1: 0.9571 - val_loss: 1.7151 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1967 - acc: 0.9565 - auc_1: 0.9712 - val_loss: 1.6823 - val_acc: 0.7917 - val_auc_1: 0.8071\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0852 - acc: 0.9674 - auc_1: 0.9960 - val_loss: 1.9352 - val_acc: 0.7500 - val_auc_1: 0.7607\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1227 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 1.7885 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0267 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.9540 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0100 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1246 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0970 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 8.8882e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0989 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 8.3431e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0991 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.0619e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1002 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 7.8362e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0983 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 7.6003e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0984 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 7.3453e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0975 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 7.1579e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0966 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 6.6301e-04 - acc: 1.0000 - auc_1: 1.000 - 0s 5ms/step - loss: 6.9152e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0964 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 625/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 6.8126e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0960 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 626/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.6197e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0929 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.5062e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0928 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 6.3208e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0943 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 6.2145e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0935 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.1169e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0932 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.0108e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0940 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 5.8463e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0916 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.7383e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0924 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.6826e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0934 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 5.6044e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0954 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.4600e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0914 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.3841e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0913 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.2991e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0938 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.1872e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0936 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 5.1700e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0932 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 5.2011e-04 - acc: 1.0000 - auc_1: 1.000 - 0s 4ms/step - loss: 5.0599e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0931 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.9615e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0942 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.9526e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0950 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.8349e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0954 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.7911e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0964 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.7605e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0977 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.6716e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0975 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.5626e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0991 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.4928e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1016 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.4319e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1011 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.4206e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1003 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.3230e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1026 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.2292e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1037 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.2136e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1032 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.1536e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1041 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.0627e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1081 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.0473e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1101 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.0028e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1121 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3.9012e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1136 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3.8376e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1119 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3.7560e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1135 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3.7138e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1173 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3.6521e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1221 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3.6576e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1224 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3.5642e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1254 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3.5464e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1290 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3.4547e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1274 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3.4295e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1314 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3.4221e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1346 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3.3057e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1358 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3.2649e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1388 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 672/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 3.2615e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1415 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 673/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3.1444e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1429 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 674/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3.0806e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1451 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3.0331e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1484 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3.0273e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1503 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.9557e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1531 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.9413e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1545 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.9455e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1532 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.9080e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1601 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.8284e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1627 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.8131e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1684 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.8120e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1745 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 2.6591e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1743 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 2.6483e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1831 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.6016e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1852 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.5772e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1900 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.5117e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1933 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.4664e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1942 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.4979e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1991 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.3590e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2077 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.3203e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2094 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.3204e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2181 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.2186e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2228 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 2.2417e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2290 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 2.2912e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2242 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 2.1867e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2294 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.0468e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2345 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.1608e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2509 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 2.0886e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2643 - val_acc: 0.7083 - val_auc_1: 0.7321\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5, X6, X7, X8, X9], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.6725496 ,  0.99691015, -1.253443  , -0.98531336,  0.12591384,\n",
      "         1.2296456 , -1.6235523 , -0.5858788 , -0.8136562 ],\n",
      "       [-1.5542159 ,  0.7359195 , -2.3101661 , -1.6941075 , -1.4366599 ,\n",
      "         1.1691829 , -0.7075912 , -0.8304946 , -1.1443902 ],\n",
      "       [ 0.10354805,  0.5337505 ,  0.70542085,  0.21318902, -0.39440325,\n",
      "        -1.506591  ,  0.7164384 ,  0.50778043, -1.0818785 ],\n",
      "       [ 0.70315146,  0.3795808 , -0.10499586,  1.4449954 , -0.27543572,\n",
      "        -0.09740153,  0.61731166,  0.15858242,  0.49265563],\n",
      "       [-0.544862  , -1.3860086 ,  0.06770246, -1.033326  , -0.38214305,\n",
      "         0.67831707, -0.22314495, -1.2680157 , -0.5279832 ],\n",
      "       [-0.22693306,  1.2975188 , -1.0079759 , -0.17767535, -0.8027256 ,\n",
      "        -0.8346353 , -0.46487373,  1.5610144 ,  0.5742916 ],\n",
      "       [ 0.19005933, -1.1259079 ,  0.9863699 , -0.70670366, -0.23546377,\n",
      "        -0.18624063, -0.06597281, -1.3763765 , -1.1027362 ],\n",
      "       [-0.5132345 ,  0.85202587,  0.15302023, -0.82062775,  2.0809119 ,\n",
      "         0.27490693, -0.82215554, -0.63056344,  0.84076005],\n",
      "       [ 0.6374744 , -1.2832607 , -0.4067995 , -0.30606347, -0.5397907 ,\n",
      "         1.017565  ,  0.46083173, -0.8161562 ,  0.23236144]],\n",
      "      dtype=float32), array([-0.15069644,  0.11896565,  0.15878935,  0.20319213,  0.64438975,\n",
      "       -0.18761894, -0.07790568,  0.18611619,  0.27733275], dtype=float32), array([[-0.42936215, -0.73676383,  0.8612915 , -1.2556677 , -0.8791905 ,\n",
      "         0.25694197,  0.3289555 ,  0.31683996,  0.46899387],\n",
      "       [ 0.66294736,  0.76185846, -0.18385781,  1.0026346 , -0.5685438 ,\n",
      "         0.75761217, -0.73121625,  0.32702696, -0.81068856],\n",
      "       [-0.05162816, -0.06733246, -0.02576993, -0.17797488, -2.479775  ,\n",
      "         0.2217275 , -0.09036875,  0.35614488,  3.2801747 ],\n",
      "       [-0.82511157, -0.61970556,  1.4682965 , -0.5969516 , -2.2834353 ,\n",
      "         1.0682639 , -0.8213887 ,  3.6810672 ,  0.53075993],\n",
      "       [-0.210496  ,  0.05563179, -2.2203789 ,  0.7774675 , -1.4827751 ,\n",
      "         1.0383503 ,  0.9996555 ,  0.43480027,  0.34330434],\n",
      "       [-1.5566962 , -1.5344704 , -0.49133852, -1.1687595 ,  1.8480495 ,\n",
      "        -1.4286671 ,  3.7305539 ,  0.63791   , -0.9543435 ],\n",
      "       [-0.6945608 , -0.05999864,  1.6602222 , -0.37583697, -0.9315023 ,\n",
      "        -0.36264557, -1.8443476 , -0.06723107,  1.3696061 ],\n",
      "       [ 0.20239817,  0.04089299,  0.74072844,  1.3233025 , -0.70888114,\n",
      "         1.0345963 , -4.056202  ,  1.6141175 , -0.27796453],\n",
      "       [-2.5888383 , -3.111445  , -0.45173416,  1.4487566 , -1.0155247 ,\n",
      "         0.84585357,  2.3977711 ,  0.71898526, -0.624049  ]],\n",
      "      dtype=float32), array([-0.03212633,  0.12830003, -0.23252319,  0.07006982, -0.3793646 ,\n",
      "        0.500038  , -0.20895761,  0.22352543, -0.05450169], dtype=float32), array([[-0.928823  , -1.1592945 , -0.09365848, -0.06436168,  1.1946592 ,\n",
      "        -1.1279213 ,  0.50025654,  1.3477919 ,  0.8067442 ],\n",
      "       [-1.1451927 , -0.530526  , -0.4885713 ,  0.18820006,  1.131346  ,\n",
      "        -1.5901527 ,  0.3079181 , -0.03570211,  0.80102414],\n",
      "       [ 0.69691455,  0.5388327 ,  0.98576903, -1.8731929 , -1.8397049 ,\n",
      "        -0.37221703, -0.8211684 , -1.4997466 , -0.25405708],\n",
      "       [ 1.7290949 ,  1.0139773 ,  0.28736103, -1.0368758 , -2.0162902 ,\n",
      "         0.11894135, -1.3420027 , -1.2681111 , -0.6514008 ],\n",
      "       [-1.8481623 , -1.4677131 , -1.2105336 , -1.6451765 ,  2.2168167 ,\n",
      "        -0.9504544 , -1.0942643 ,  2.3678062 ,  1.5503337 ],\n",
      "       [ 2.1383061 ,  0.31406283,  0.1255012 ,  0.17617519, -2.3417363 ,\n",
      "         0.7814208 , -1.1402423 , -1.7048041 , -0.5407752 ],\n",
      "       [-1.6911478 ,  1.2287984 ,  0.4367842 , -0.3464649 ,  1.1881694 ,\n",
      "         2.2060049 , -0.725603  ,  1.3728317 , -1.3529927 ],\n",
      "       [ 1.4414126 , -0.6187864 , -0.21871814, -0.2011892 , -1.4729402 ,\n",
      "         1.1129488 ,  0.9494027 , -1.6667365 ,  0.19435425],\n",
      "       [ 0.38716775,  1.9969076 ,  3.1245465 , -0.9453856 , -0.33674267,\n",
      "         0.5891415 , -1.170143  , -0.13152608, -2.2100437 ]],\n",
      "      dtype=float32), array([ 0.72190136,  0.32349423, -0.4888721 , -0.02044885, -0.5797993 ,\n",
      "       -0.16171043, -0.58270156, -0.7347809 , -0.24411292], dtype=float32), array([[-2.19537  ],\n",
      "       [-2.613428 ],\n",
      "       [-1.8579984],\n",
      "       [ 4.4020805],\n",
      "       [ 2.0696797],\n",
      "       [-2.488146 ],\n",
      "       [ 6.43064  ],\n",
      "       [ 2.3388824],\n",
      "       [ 3.070852 ]], dtype=float32), array([-0.6310384], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.43935881e-06]\n",
      " [9.99861002e-01]\n",
      " [9.99478996e-01]\n",
      " [2.06225188e-08]\n",
      " [1.21974605e-04]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [9.99530792e-01]\n",
      " [1.00000000e+00]\n",
      " [8.20939080e-04]\n",
      " [8.15853709e-04]\n",
      " [1.00000000e+00]\n",
      " [3.53545495e-08]\n",
      " [5.83732326e-04]\n",
      " [1.00000000e+00]\n",
      " [3.34649434e-04]\n",
      " [9.99992609e-01]\n",
      " [9.99996424e-01]\n",
      " [9.99995112e-01]\n",
      " [9.50863068e-06]\n",
      " [6.32074371e-05]\n",
      " [1.49305284e-04]\n",
      " [9.99997377e-01]\n",
      " [9.99949932e-01]\n",
      " [9.99978185e-01]\n",
      " [9.99998331e-01]\n",
      " [9.99115765e-01]\n",
      " [1.59834643e-04]\n",
      " [1.00000000e+00]\n",
      " [5.94048856e-07]\n",
      " [1.85370686e-06]\n",
      " [1.19892145e-04]\n",
      " [1.42550050e-06]\n",
      " [5.23289127e-05]\n",
      " [1.00000000e+00]\n",
      " [9.99777973e-01]\n",
      " [9.99840975e-01]\n",
      " [9.99419451e-01]\n",
      " [9.99999523e-01]\n",
      " [9.99959469e-01]\n",
      " [9.99725878e-01]\n",
      " [7.45615282e-04]\n",
      " [4.40475345e-09]\n",
      " [2.63942502e-06]\n",
      " [9.99685287e-01]\n",
      " [9.99710977e-01]\n",
      " [9.99945521e-01]\n",
      " [9.99973416e-01]\n",
      " [3.19022320e-06]\n",
      " [1.17492527e-09]\n",
      " [9.99614835e-01]\n",
      " [1.28293998e-09]\n",
      " [9.86573738e-08]\n",
      " [4.67884798e-09]\n",
      " [4.46241960e-04]\n",
      " [5.13891806e-04]\n",
      " [9.99996781e-01]\n",
      " [7.19316884e-10]\n",
      " [3.10795475e-03]\n",
      " [4.22485726e-04]\n",
      " [9.99992728e-01]\n",
      " [9.99548614e-01]\n",
      " [9.99997377e-01]\n",
      " [1.99822098e-04]\n",
      " [6.42230269e-04]\n",
      " [7.60353796e-05]\n",
      " [9.99971032e-01]\n",
      " [5.12425047e-10]\n",
      " [6.13613229e-05]\n",
      " [1.78854098e-04]\n",
      " [1.00000000e+00]\n",
      " [9.99935508e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99637961e-01]\n",
      " [3.20689374e-04]\n",
      " [9.99646664e-01]\n",
      " [9.84553408e-05]\n",
      " [9.99842405e-01]\n",
      " [9.15815417e-06]\n",
      " [1.89995808e-05]\n",
      " [8.10964795e-10]\n",
      " [9.99993563e-01]\n",
      " [9.99998569e-01]\n",
      " [9.99538183e-01]\n",
      " [9.99999642e-01]\n",
      " [9.99983549e-01]\n",
      " [9.99985695e-01]\n",
      " [2.23000279e-05]\n",
      " [9.99970794e-01]\n",
      " [9.99940038e-01]\n",
      " [9.99980211e-01]\n",
      " [2.16290644e-07]\n",
      " [9.95779872e-01]\n",
      " [1.25687779e-03]\n",
      " [2.77470917e-01]\n",
      " [9.97264624e-01]\n",
      " [9.99728978e-01]\n",
      " [1.78834814e-09]\n",
      " [9.99998212e-01]\n",
      " [9.99929786e-01]\n",
      " [5.29020042e-07]\n",
      " [9.99829650e-01]\n",
      " [1.00000000e+00]\n",
      " [6.64612569e-04]\n",
      " [1.00000000e+00]\n",
      " [2.51833970e-10]\n",
      " [5.65471419e-05]\n",
      " [1.00000000e+00]\n",
      " [3.19049213e-05]\n",
      " [1.76867676e-09]\n",
      " [9.99984741e-01]\n",
      " [9.97697532e-01]\n",
      " [9.99695659e-01]\n",
      " [3.62226860e-10]\n",
      " [9.99468267e-01]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5, X6, X7, X8, X9])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
