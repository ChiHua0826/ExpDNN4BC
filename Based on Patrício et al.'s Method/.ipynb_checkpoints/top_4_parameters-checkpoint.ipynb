{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 1\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,2:3] #Glucose\n",
    "X2 = dataset[:,7:8] #Resistin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,1:2] #BMI\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 4)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            45          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 235\n",
      "Trainable params: 235\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/3000\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.7116 - acc: 0.3913 - auc_1: 0.3229 - val_loss: 0.7122 - val_acc: 0.4583 - val_auc_1: 0.4444\n",
      "Epoch 2/3000\n",
      "92/92 [==============================] - 0s 54us/step - loss: 0.7064 - acc: 0.4891 - auc_1: 0.3290 - val_loss: 0.7162 - val_acc: 0.5000 - val_auc_1: 0.4444\n",
      "Epoch 3/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.7024 - acc: 0.5652 - auc_1: 0.3356 - val_loss: 0.7191 - val_acc: 0.4167 - val_auc_1: 0.4630\n",
      "Epoch 4/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.6997 - acc: 0.5978 - auc_1: 0.3391 - val_loss: 0.7221 - val_acc: 0.4167 - val_auc_1: 0.4519\n",
      "Epoch 5/3000\n",
      "92/92 [==============================] - 0s 54us/step - loss: 0.6969 - acc: 0.5978 - auc_1: 0.3396 - val_loss: 0.7249 - val_acc: 0.3750 - val_auc_1: 0.4519\n",
      "Epoch 6/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.6945 - acc: 0.6087 - auc_1: 0.3533 - val_loss: 0.7276 - val_acc: 0.3750 - val_auc_1: 0.4778\n",
      "Epoch 7/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6922 - acc: 0.6087 - auc_1: 0.3577 - val_loss: 0.7299 - val_acc: 0.3750 - val_auc_1: 0.4741\n",
      "Epoch 8/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.6903 - acc: 0.5978 - auc_1: 0.3629 - val_loss: 0.7322 - val_acc: 0.3750 - val_auc_1: 0.4815\n",
      "Epoch 9/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6883 - acc: 0.5870 - auc_1: 0.3705 - val_loss: 0.7342 - val_acc: 0.3750 - val_auc_1: 0.5074\n",
      "Epoch 10/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6866 - acc: 0.5978 - auc_1: 0.3735 - val_loss: 0.7361 - val_acc: 0.3750 - val_auc_1: 0.5000\n",
      "Epoch 11/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6849 - acc: 0.5978 - auc_1: 0.3781 - val_loss: 0.7379 - val_acc: 0.3750 - val_auc_1: 0.5037\n",
      "Epoch 12/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6833 - acc: 0.5978 - auc_1: 0.3914 - val_loss: 0.7393 - val_acc: 0.3750 - val_auc_1: 0.5148\n",
      "Epoch 13/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6818 - acc: 0.5978 - auc_1: 0.4029 - val_loss: 0.7406 - val_acc: 0.3750 - val_auc_1: 0.5370\n",
      "Epoch 14/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6804 - acc: 0.5978 - auc_1: 0.4123 - val_loss: 0.7417 - val_acc: 0.3750 - val_auc_1: 0.5370\n",
      "Epoch 15/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6790 - acc: 0.5978 - auc_1: 0.4206 - val_loss: 0.7426 - val_acc: 0.3750 - val_auc_1: 0.5444\n",
      "Epoch 16/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6777 - acc: 0.5978 - auc_1: 0.4403 - val_loss: 0.7432 - val_acc: 0.3750 - val_auc_1: 0.5667\n",
      "Epoch 17/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6763 - acc: 0.5978 - auc_1: 0.4575 - val_loss: 0.7437 - val_acc: 0.3750 - val_auc_1: 0.5556\n",
      "Epoch 18/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.6750 - acc: 0.5978 - auc_1: 0.4725 - val_loss: 0.7439 - val_acc: 0.3750 - val_auc_1: 0.5667\n",
      "Epoch 19/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6738 - acc: 0.5978 - auc_1: 0.4892 - val_loss: 0.7440 - val_acc: 0.3750 - val_auc_1: 0.5704\n",
      "Epoch 20/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6725 - acc: 0.5978 - auc_1: 0.5017 - val_loss: 0.7439 - val_acc: 0.3750 - val_auc_1: 0.5704\n",
      "Epoch 21/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.6712 - acc: 0.5978 - auc_1: 0.5096 - val_loss: 0.7436 - val_acc: 0.3750 - val_auc_1: 0.5704\n",
      "Epoch 22/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6699 - acc: 0.5978 - auc_1: 0.5342 - val_loss: 0.7432 - val_acc: 0.3750 - val_auc_1: 0.5778\n",
      "Epoch 23/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6686 - acc: 0.5978 - auc_1: 0.5622 - val_loss: 0.7427 - val_acc: 0.3750 - val_auc_1: 0.5778\n",
      "Epoch 24/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6672 - acc: 0.5978 - auc_1: 0.5816 - val_loss: 0.7421 - val_acc: 0.3750 - val_auc_1: 0.5815\n",
      "Epoch 25/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6659 - acc: 0.5978 - auc_1: 0.5897 - val_loss: 0.7414 - val_acc: 0.3750 - val_auc_1: 0.5852\n",
      "Epoch 26/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.6645 - acc: 0.5978 - auc_1: 0.6263 - val_loss: 0.7406 - val_acc: 0.3750 - val_auc_1: 0.5963\n",
      "Epoch 27/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6631 - acc: 0.5978 - auc_1: 0.6457 - val_loss: 0.7398 - val_acc: 0.3750 - val_auc_1: 0.6148\n",
      "Epoch 28/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6616 - acc: 0.5978 - auc_1: 0.6582 - val_loss: 0.7389 - val_acc: 0.3750 - val_auc_1: 0.6185\n",
      "Epoch 29/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6601 - acc: 0.5978 - auc_1: 0.6919 - val_loss: 0.7380 - val_acc: 0.3750 - val_auc_1: 0.6444\n",
      "Epoch 30/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6585 - acc: 0.5978 - auc_1: 0.7101 - val_loss: 0.7371 - val_acc: 0.3750 - val_auc_1: 0.6481\n",
      "Epoch 31/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6569 - acc: 0.5978 - auc_1: 0.7184 - val_loss: 0.7362 - val_acc: 0.3750 - val_auc_1: 0.6370\n",
      "Epoch 32/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6553 - acc: 0.5978 - auc_1: 0.7410 - val_loss: 0.7352 - val_acc: 0.3750 - val_auc_1: 0.6407\n",
      "Epoch 33/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.6536 - acc: 0.5978 - auc_1: 0.7479 - val_loss: 0.7342 - val_acc: 0.3750 - val_auc_1: 0.6556\n",
      "Epoch 34/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6518 - acc: 0.5978 - auc_1: 0.7629 - val_loss: 0.7332 - val_acc: 0.3750 - val_auc_1: 0.6556\n",
      "Epoch 35/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6500 - acc: 0.5978 - auc_1: 0.7693 - val_loss: 0.7322 - val_acc: 0.3750 - val_auc_1: 0.6889\n",
      "Epoch 36/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6481 - acc: 0.5978 - auc_1: 0.7803 - val_loss: 0.7312 - val_acc: 0.3750 - val_auc_1: 0.7111\n",
      "Epoch 37/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6462 - acc: 0.5978 - auc_1: 0.7867 - val_loss: 0.7302 - val_acc: 0.3750 - val_auc_1: 0.6852\n",
      "Epoch 38/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6441 - acc: 0.5978 - auc_1: 0.7968 - val_loss: 0.7291 - val_acc: 0.3750 - val_auc_1: 0.7000\n",
      "Epoch 39/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6421 - acc: 0.5978 - auc_1: 0.7921 - val_loss: 0.7281 - val_acc: 0.3750 - val_auc_1: 0.7111\n",
      "Epoch 40/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6399 - acc: 0.5978 - auc_1: 0.8027 - val_loss: 0.7269 - val_acc: 0.3750 - val_auc_1: 0.7111\n",
      "Epoch 41/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6377 - acc: 0.5978 - auc_1: 0.8103 - val_loss: 0.7258 - val_acc: 0.3750 - val_auc_1: 0.7370\n",
      "Epoch 42/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.6355 - acc: 0.5978 - auc_1: 0.8155 - val_loss: 0.7246 - val_acc: 0.3750 - val_auc_1: 0.7296\n",
      "Epoch 43/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6331 - acc: 0.5978 - auc_1: 0.8155 - val_loss: 0.7234 - val_acc: 0.3750 - val_auc_1: 0.7370\n",
      "Epoch 44/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6307 - acc: 0.5978 - auc_1: 0.8211 - val_loss: 0.7221 - val_acc: 0.3750 - val_auc_1: 0.7333\n",
      "Epoch 45/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6282 - acc: 0.5978 - auc_1: 0.8204 - val_loss: 0.7208 - val_acc: 0.4167 - val_auc_1: 0.7444\n",
      "Epoch 46/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6256 - acc: 0.5978 - auc_1: 0.8233 - val_loss: 0.7195 - val_acc: 0.4167 - val_auc_1: 0.7519\n",
      "Epoch 47/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.6230 - acc: 0.6087 - auc_1: 0.8226 - val_loss: 0.7181 - val_acc: 0.4167 - val_auc_1: 0.7519\n",
      "Epoch 48/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6203 - acc: 0.6087 - auc_1: 0.8246 - val_loss: 0.7167 - val_acc: 0.4167 - val_auc_1: 0.7556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.6175 - acc: 0.6087 - auc_1: 0.8251 - val_loss: 0.7152 - val_acc: 0.4583 - val_auc_1: 0.7556\n",
      "Epoch 50/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6146 - acc: 0.6196 - auc_1: 0.8285 - val_loss: 0.7137 - val_acc: 0.4583 - val_auc_1: 0.7481\n",
      "Epoch 51/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6117 - acc: 0.6196 - auc_1: 0.8278 - val_loss: 0.7122 - val_acc: 0.4583 - val_auc_1: 0.7556\n",
      "Epoch 52/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6087 - acc: 0.6522 - auc_1: 0.8302 - val_loss: 0.7107 - val_acc: 0.4583 - val_auc_1: 0.7407\n",
      "Epoch 53/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6056 - acc: 0.6630 - auc_1: 0.8290 - val_loss: 0.7091 - val_acc: 0.4583 - val_auc_1: 0.7370\n",
      "Epoch 54/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6025 - acc: 0.6522 - auc_1: 0.8339 - val_loss: 0.7076 - val_acc: 0.5000 - val_auc_1: 0.7296\n",
      "Epoch 55/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5993 - acc: 0.6522 - auc_1: 0.8322 - val_loss: 0.7061 - val_acc: 0.5000 - val_auc_1: 0.7407\n",
      "Epoch 56/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5961 - acc: 0.6630 - auc_1: 0.8332 - val_loss: 0.7045 - val_acc: 0.5000 - val_auc_1: 0.7259\n",
      "Epoch 57/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5928 - acc: 0.6957 - auc_1: 0.8339 - val_loss: 0.7031 - val_acc: 0.5000 - val_auc_1: 0.7296\n",
      "Epoch 58/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.5895 - acc: 0.6957 - auc_1: 0.8329 - val_loss: 0.7016 - val_acc: 0.4167 - val_auc_1: 0.7259\n",
      "Epoch 59/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.5861 - acc: 0.7174 - auc_1: 0.8356 - val_loss: 0.7002 - val_acc: 0.4167 - val_auc_1: 0.7296\n",
      "Epoch 60/3000\n",
      "92/92 [==============================] - 0s 54us/step - loss: 0.5827 - acc: 0.7174 - auc_1: 0.8364 - val_loss: 0.6989 - val_acc: 0.4167 - val_auc_1: 0.7296\n",
      "Epoch 61/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5793 - acc: 0.7283 - auc_1: 0.8369 - val_loss: 0.6976 - val_acc: 0.4167 - val_auc_1: 0.7259\n",
      "Epoch 62/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5758 - acc: 0.7391 - auc_1: 0.8361 - val_loss: 0.6963 - val_acc: 0.4167 - val_auc_1: 0.7185\n",
      "Epoch 63/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5724 - acc: 0.7283 - auc_1: 0.8371 - val_loss: 0.6952 - val_acc: 0.4583 - val_auc_1: 0.7185\n",
      "Epoch 64/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5689 - acc: 0.7283 - auc_1: 0.8391 - val_loss: 0.6941 - val_acc: 0.4583 - val_auc_1: 0.7222\n",
      "Epoch 65/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5654 - acc: 0.7391 - auc_1: 0.8383 - val_loss: 0.6932 - val_acc: 0.4583 - val_auc_1: 0.7222\n",
      "Epoch 66/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5619 - acc: 0.7391 - auc_1: 0.8371 - val_loss: 0.6923 - val_acc: 0.4583 - val_auc_1: 0.7185\n",
      "Epoch 67/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5584 - acc: 0.7283 - auc_1: 0.8396 - val_loss: 0.6915 - val_acc: 0.4583 - val_auc_1: 0.7185\n",
      "Epoch 68/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5550 - acc: 0.7283 - auc_1: 0.8398 - val_loss: 0.6909 - val_acc: 0.5000 - val_auc_1: 0.7148\n",
      "Epoch 69/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5515 - acc: 0.7391 - auc_1: 0.8398 - val_loss: 0.6903 - val_acc: 0.5000 - val_auc_1: 0.7185\n",
      "Epoch 70/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5481 - acc: 0.7717 - auc_1: 0.8408 - val_loss: 0.6898 - val_acc: 0.4583 - val_auc_1: 0.7148\n",
      "Epoch 71/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5447 - acc: 0.7717 - auc_1: 0.8383 - val_loss: 0.6894 - val_acc: 0.4583 - val_auc_1: 0.7148\n",
      "Epoch 72/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5413 - acc: 0.7826 - auc_1: 0.8386 - val_loss: 0.6891 - val_acc: 0.4583 - val_auc_1: 0.7185\n",
      "Epoch 73/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.5380 - acc: 0.7826 - auc_1: 0.8400 - val_loss: 0.6889 - val_acc: 0.4583 - val_auc_1: 0.7148\n",
      "Epoch 74/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.5348 - acc: 0.7826 - auc_1: 0.8405 - val_loss: 0.6888 - val_acc: 0.4583 - val_auc_1: 0.7111\n",
      "Epoch 75/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5315 - acc: 0.7935 - auc_1: 0.8408 - val_loss: 0.6887 - val_acc: 0.4583 - val_auc_1: 0.7074\n",
      "Epoch 76/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5284 - acc: 0.7935 - auc_1: 0.8428 - val_loss: 0.6886 - val_acc: 0.5000 - val_auc_1: 0.7074\n",
      "Epoch 77/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5253 - acc: 0.7935 - auc_1: 0.8430 - val_loss: 0.6887 - val_acc: 0.5000 - val_auc_1: 0.7074\n",
      "Epoch 78/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5222 - acc: 0.7935 - auc_1: 0.8435 - val_loss: 0.6887 - val_acc: 0.5000 - val_auc_1: 0.7074\n",
      "Epoch 79/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5192 - acc: 0.8043 - auc_1: 0.8457 - val_loss: 0.6887 - val_acc: 0.5000 - val_auc_1: 0.7074\n",
      "Epoch 80/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5163 - acc: 0.8043 - auc_1: 0.8459 - val_loss: 0.6888 - val_acc: 0.5000 - val_auc_1: 0.7074\n",
      "Epoch 81/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5134 - acc: 0.8043 - auc_1: 0.8447 - val_loss: 0.6888 - val_acc: 0.5000 - val_auc_1: 0.7037\n",
      "Epoch 82/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.5105 - acc: 0.8043 - auc_1: 0.8494 - val_loss: 0.6889 - val_acc: 0.5000 - val_auc_1: 0.6963\n",
      "Epoch 83/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.5078 - acc: 0.8043 - auc_1: 0.8494 - val_loss: 0.6889 - val_acc: 0.5000 - val_auc_1: 0.7000\n",
      "Epoch 84/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.5051 - acc: 0.8043 - auc_1: 0.8496 - val_loss: 0.6888 - val_acc: 0.4583 - val_auc_1: 0.7000\n",
      "Epoch 85/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5024 - acc: 0.8043 - auc_1: 0.8499 - val_loss: 0.6887 - val_acc: 0.4583 - val_auc_1: 0.7000\n",
      "Epoch 86/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4999 - acc: 0.8043 - auc_1: 0.8489 - val_loss: 0.6886 - val_acc: 0.4583 - val_auc_1: 0.7074\n",
      "Epoch 87/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4973 - acc: 0.8043 - auc_1: 0.8496 - val_loss: 0.6884 - val_acc: 0.4583 - val_auc_1: 0.7111\n",
      "Epoch 88/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4949 - acc: 0.8043 - auc_1: 0.8509 - val_loss: 0.6881 - val_acc: 0.4583 - val_auc_1: 0.7074\n",
      "Epoch 89/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4924 - acc: 0.8043 - auc_1: 0.8506 - val_loss: 0.6877 - val_acc: 0.4583 - val_auc_1: 0.7111\n",
      "Epoch 90/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4901 - acc: 0.8043 - auc_1: 0.8536 - val_loss: 0.6873 - val_acc: 0.4583 - val_auc_1: 0.7111\n",
      "Epoch 91/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4878 - acc: 0.8043 - auc_1: 0.8526 - val_loss: 0.6868 - val_acc: 0.4583 - val_auc_1: 0.7111\n",
      "Epoch 92/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4856 - acc: 0.8043 - auc_1: 0.8548 - val_loss: 0.6862 - val_acc: 0.4583 - val_auc_1: 0.7111\n",
      "Epoch 93/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4834 - acc: 0.8261 - auc_1: 0.8558 - val_loss: 0.6855 - val_acc: 0.4583 - val_auc_1: 0.7111\n",
      "Epoch 94/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4813 - acc: 0.8261 - auc_1: 0.8572 - val_loss: 0.6847 - val_acc: 0.4583 - val_auc_1: 0.7074\n",
      "Epoch 95/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4792 - acc: 0.8370 - auc_1: 0.8582 - val_loss: 0.6840 - val_acc: 0.4583 - val_auc_1: 0.7074\n",
      "Epoch 96/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4772 - acc: 0.8370 - auc_1: 0.8592 - val_loss: 0.6830 - val_acc: 0.5000 - val_auc_1: 0.7037\n",
      "Epoch 97/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4753 - acc: 0.8370 - auc_1: 0.8590 - val_loss: 0.6824 - val_acc: 0.5417 - val_auc_1: 0.7074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4734 - acc: 0.8261 - auc_1: 0.8600 - val_loss: 0.6808 - val_acc: 0.5417 - val_auc_1: 0.7111\n",
      "Epoch 99/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4716 - acc: 0.8261 - auc_1: 0.8617 - val_loss: 0.6813 - val_acc: 0.5833 - val_auc_1: 0.7074\n",
      "Epoch 100/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4698 - acc: 0.8152 - auc_1: 0.8627 - val_loss: 0.6772 - val_acc: 0.5833 - val_auc_1: 0.7074\n",
      "Epoch 101/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4682 - acc: 0.8152 - auc_1: 0.8627 - val_loss: 0.6833 - val_acc: 0.5833 - val_auc_1: 0.7074\n",
      "Epoch 102/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4666 - acc: 0.8043 - auc_1: 0.8644 - val_loss: 0.6675 - val_acc: 0.6250 - val_auc_1: 0.7074\n",
      "Epoch 103/3000\n",
      "92/92 [==============================] - 0s 54us/step - loss: 0.4655 - acc: 0.8370 - auc_1: 0.8634 - val_loss: 0.6983 - val_acc: 0.5000 - val_auc_1: 0.7111\n",
      "Epoch 104/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4654 - acc: 0.7935 - auc_1: 0.8654 - val_loss: 0.6558 - val_acc: 0.6667 - val_auc_1: 0.7074\n",
      "Epoch 105/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4650 - acc: 0.8152 - auc_1: 0.8622 - val_loss: 0.6987 - val_acc: 0.5000 - val_auc_1: 0.7185\n",
      "Epoch 106/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4630 - acc: 0.7935 - auc_1: 0.8663 - val_loss: 0.6642 - val_acc: 0.6250 - val_auc_1: 0.7074\n",
      "Epoch 107/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4606 - acc: 0.8152 - auc_1: 0.8641 - val_loss: 0.6861 - val_acc: 0.6250 - val_auc_1: 0.7185\n",
      "Epoch 108/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4588 - acc: 0.8043 - auc_1: 0.8661 - val_loss: 0.6709 - val_acc: 0.6250 - val_auc_1: 0.7111\n",
      "Epoch 109/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4574 - acc: 0.8043 - auc_1: 0.8644 - val_loss: 0.6805 - val_acc: 0.6250 - val_auc_1: 0.7185\n",
      "Epoch 110/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4562 - acc: 0.8043 - auc_1: 0.8654 - val_loss: 0.6734 - val_acc: 0.6250 - val_auc_1: 0.7185\n",
      "Epoch 111/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4551 - acc: 0.8043 - auc_1: 0.8656 - val_loss: 0.6781 - val_acc: 0.6250 - val_auc_1: 0.7185\n",
      "Epoch 112/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4541 - acc: 0.8043 - auc_1: 0.8661 - val_loss: 0.6741 - val_acc: 0.6250 - val_auc_1: 0.7185\n",
      "Epoch 113/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4531 - acc: 0.7935 - auc_1: 0.8671 - val_loss: 0.6768 - val_acc: 0.6250 - val_auc_1: 0.7222\n",
      "Epoch 114/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4522 - acc: 0.8043 - auc_1: 0.8678 - val_loss: 0.6740 - val_acc: 0.6250 - val_auc_1: 0.7259\n",
      "Epoch 115/3000\n",
      "92/92 [==============================] - 0s 54us/step - loss: 0.4513 - acc: 0.7935 - auc_1: 0.8690 - val_loss: 0.6758 - val_acc: 0.6250 - val_auc_1: 0.7259\n",
      "Epoch 116/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4504 - acc: 0.8043 - auc_1: 0.8700 - val_loss: 0.6736 - val_acc: 0.6250 - val_auc_1: 0.7259\n",
      "Epoch 117/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4496 - acc: 0.7935 - auc_1: 0.8698 - val_loss: 0.6750 - val_acc: 0.6250 - val_auc_1: 0.7296\n",
      "Epoch 118/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4489 - acc: 0.8043 - auc_1: 0.8710 - val_loss: 0.6730 - val_acc: 0.6667 - val_auc_1: 0.7333\n",
      "Epoch 119/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4481 - acc: 0.8152 - auc_1: 0.8708 - val_loss: 0.6743 - val_acc: 0.6667 - val_auc_1: 0.7370\n",
      "Epoch 120/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4474 - acc: 0.8152 - auc_1: 0.8715 - val_loss: 0.6723 - val_acc: 0.6667 - val_auc_1: 0.7370\n",
      "Epoch 121/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4468 - acc: 0.8152 - auc_1: 0.8710 - val_loss: 0.6738 - val_acc: 0.6667 - val_auc_1: 0.7370\n",
      "Epoch 122/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4462 - acc: 0.8152 - auc_1: 0.8715 - val_loss: 0.6715 - val_acc: 0.6667 - val_auc_1: 0.7407\n",
      "Epoch 123/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4456 - acc: 0.8152 - auc_1: 0.8713 - val_loss: 0.6733 - val_acc: 0.6667 - val_auc_1: 0.7370\n",
      "Epoch 124/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4450 - acc: 0.8152 - auc_1: 0.8710 - val_loss: 0.6705 - val_acc: 0.6667 - val_auc_1: 0.7407\n",
      "Epoch 125/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4445 - acc: 0.8152 - auc_1: 0.8720 - val_loss: 0.6732 - val_acc: 0.6667 - val_auc_1: 0.7407\n",
      "Epoch 126/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4439 - acc: 0.8152 - auc_1: 0.8722 - val_loss: 0.6694 - val_acc: 0.6667 - val_auc_1: 0.7407\n",
      "Epoch 127/3000\n",
      "92/92 [==============================] - 0s 54us/step - loss: 0.4435 - acc: 0.8043 - auc_1: 0.8727 - val_loss: 0.6735 - val_acc: 0.6667 - val_auc_1: 0.7444\n",
      "Epoch 128/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4430 - acc: 0.8261 - auc_1: 0.8727 - val_loss: 0.6677 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 129/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4426 - acc: 0.7935 - auc_1: 0.8715 - val_loss: 0.6747 - val_acc: 0.6667 - val_auc_1: 0.7519\n",
      "Epoch 130/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4423 - acc: 0.8261 - auc_1: 0.8717 - val_loss: 0.6653 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 131/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4420 - acc: 0.8043 - auc_1: 0.8713 - val_loss: 0.6773 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 132/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4418 - acc: 0.8152 - auc_1: 0.8735 - val_loss: 0.6618 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 133/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4417 - acc: 0.8043 - auc_1: 0.8720 - val_loss: 0.6816 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 134/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4417 - acc: 0.8152 - auc_1: 0.8732 - val_loss: 0.6585 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 135/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4418 - acc: 0.7935 - auc_1: 0.8717 - val_loss: 0.6846 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 136/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4418 - acc: 0.8152 - auc_1: 0.8725 - val_loss: 0.6581 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 137/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4414 - acc: 0.7935 - auc_1: 0.8715 - val_loss: 0.6826 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 138/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4409 - acc: 0.8152 - auc_1: 0.8722 - val_loss: 0.6607 - val_acc: 0.7083 - val_auc_1: 0.7333\n",
      "Epoch 139/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4402 - acc: 0.7935 - auc_1: 0.8722 - val_loss: 0.6783 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 140/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4397 - acc: 0.8043 - auc_1: 0.8725 - val_loss: 0.6636 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 141/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4392 - acc: 0.8043 - auc_1: 0.8730 - val_loss: 0.6752 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 142/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4388 - acc: 0.8043 - auc_1: 0.8725 - val_loss: 0.6657 - val_acc: 0.7083 - val_auc_1: 0.7333\n",
      "Epoch 143/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4385 - acc: 0.7935 - auc_1: 0.8725 - val_loss: 0.6733 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 144/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4382 - acc: 0.7935 - auc_1: 0.8720 - val_loss: 0.6670 - val_acc: 0.7083 - val_auc_1: 0.7333\n",
      "Epoch 145/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4380 - acc: 0.7935 - auc_1: 0.8727 - val_loss: 0.6722 - val_acc: 0.7083 - val_auc_1: 0.7407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4378 - acc: 0.7935 - auc_1: 0.8722 - val_loss: 0.6678 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 147/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4376 - acc: 0.7935 - auc_1: 0.8722 - val_loss: 0.6715 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 148/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4374 - acc: 0.7935 - auc_1: 0.8725 - val_loss: 0.6683 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 149/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4372 - acc: 0.7935 - auc_1: 0.8727 - val_loss: 0.6711 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 150/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4370 - acc: 0.7935 - auc_1: 0.8720 - val_loss: 0.6686 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 151/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4368 - acc: 0.7935 - auc_1: 0.8727 - val_loss: 0.6708 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 152/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4366 - acc: 0.7935 - auc_1: 0.8725 - val_loss: 0.6687 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 153/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4365 - acc: 0.7935 - auc_1: 0.8722 - val_loss: 0.6705 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 154/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4363 - acc: 0.7935 - auc_1: 0.8720 - val_loss: 0.6687 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 155/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4361 - acc: 0.7935 - auc_1: 0.8722 - val_loss: 0.6703 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 156/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4360 - acc: 0.7935 - auc_1: 0.8710 - val_loss: 0.6687 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 157/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4358 - acc: 0.7935 - auc_1: 0.8720 - val_loss: 0.6702 - val_acc: 0.7083 - val_auc_1: 0.7333\n",
      "Epoch 158/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4356 - acc: 0.7935 - auc_1: 0.8717 - val_loss: 0.6686 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 159/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4354 - acc: 0.7935 - auc_1: 0.8725 - val_loss: 0.6700 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 160/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4353 - acc: 0.7935 - auc_1: 0.8722 - val_loss: 0.6684 - val_acc: 0.7083 - val_auc_1: 0.7333\n",
      "Epoch 161/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4351 - acc: 0.7935 - auc_1: 0.8722 - val_loss: 0.6699 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 162/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4349 - acc: 0.7935 - auc_1: 0.8720 - val_loss: 0.6682 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 163/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4348 - acc: 0.7935 - auc_1: 0.8727 - val_loss: 0.6697 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 164/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4346 - acc: 0.7935 - auc_1: 0.8727 - val_loss: 0.6679 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 165/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4344 - acc: 0.7935 - auc_1: 0.8727 - val_loss: 0.6696 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 166/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4342 - acc: 0.7935 - auc_1: 0.8732 - val_loss: 0.6676 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 167/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4341 - acc: 0.7935 - auc_1: 0.8730 - val_loss: 0.6695 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 168/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4339 - acc: 0.7935 - auc_1: 0.8730 - val_loss: 0.6672 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 169/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4337 - acc: 0.7935 - auc_1: 0.8735 - val_loss: 0.6694 - val_acc: 0.7500 - val_auc_1: 0.7370\n",
      "Epoch 170/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4335 - acc: 0.7935 - auc_1: 0.8737 - val_loss: 0.6667 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 171/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4333 - acc: 0.8043 - auc_1: 0.8744 - val_loss: 0.6693 - val_acc: 0.7500 - val_auc_1: 0.7370\n",
      "Epoch 172/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4331 - acc: 0.7935 - auc_1: 0.8737 - val_loss: 0.6660 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 173/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4329 - acc: 0.8043 - auc_1: 0.8742 - val_loss: 0.6693 - val_acc: 0.7500 - val_auc_1: 0.7407\n",
      "Epoch 174/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4327 - acc: 0.7935 - auc_1: 0.8747 - val_loss: 0.6652 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 175/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4325 - acc: 0.8043 - auc_1: 0.8744 - val_loss: 0.6694 - val_acc: 0.7500 - val_auc_1: 0.7407\n",
      "Epoch 176/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4323 - acc: 0.7935 - auc_1: 0.8744 - val_loss: 0.6643 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 177/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4321 - acc: 0.8043 - auc_1: 0.8749 - val_loss: 0.6697 - val_acc: 0.7500 - val_auc_1: 0.7407\n",
      "Epoch 178/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4319 - acc: 0.7935 - auc_1: 0.8757 - val_loss: 0.6631 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 179/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4317 - acc: 0.8043 - auc_1: 0.8747 - val_loss: 0.6702 - val_acc: 0.7500 - val_auc_1: 0.7407\n",
      "Epoch 180/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4315 - acc: 0.7935 - auc_1: 0.8762 - val_loss: 0.6618 - val_acc: 0.7083 - val_auc_1: 0.7370\n",
      "Epoch 181/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4314 - acc: 0.8043 - auc_1: 0.8752 - val_loss: 0.6709 - val_acc: 0.7500 - val_auc_1: 0.7407\n",
      "Epoch 182/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4312 - acc: 0.7935 - auc_1: 0.8759 - val_loss: 0.6602 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 183/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4311 - acc: 0.8043 - auc_1: 0.8749 - val_loss: 0.6716 - val_acc: 0.7500 - val_auc_1: 0.7444\n",
      "Epoch 184/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4309 - acc: 0.8043 - auc_1: 0.8762 - val_loss: 0.6588 - val_acc: 0.7083 - val_auc_1: 0.7407\n",
      "Epoch 185/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4307 - acc: 0.8043 - auc_1: 0.8754 - val_loss: 0.6721 - val_acc: 0.7500 - val_auc_1: 0.7444\n",
      "Epoch 186/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4306 - acc: 0.8043 - auc_1: 0.8764 - val_loss: 0.6577 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 187/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4304 - acc: 0.8043 - auc_1: 0.8764 - val_loss: 0.6719 - val_acc: 0.7500 - val_auc_1: 0.7444\n",
      "Epoch 188/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4301 - acc: 0.8152 - auc_1: 0.8767 - val_loss: 0.6571 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 189/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4298 - acc: 0.8043 - auc_1: 0.8762 - val_loss: 0.6709 - val_acc: 0.7500 - val_auc_1: 0.7444\n",
      "Epoch 190/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4295 - acc: 0.8043 - auc_1: 0.8767 - val_loss: 0.6570 - val_acc: 0.7083 - val_auc_1: 0.7444\n",
      "Epoch 191/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4291 - acc: 0.8043 - auc_1: 0.8762 - val_loss: 0.6692 - val_acc: 0.7500 - val_auc_1: 0.7444\n",
      "Epoch 192/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4287 - acc: 0.8043 - auc_1: 0.8769 - val_loss: 0.6572 - val_acc: 0.7083 - val_auc_1: 0.7481\n",
      "Epoch 193/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4284 - acc: 0.8043 - auc_1: 0.8764 - val_loss: 0.6674 - val_acc: 0.7500 - val_auc_1: 0.7444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4280 - acc: 0.8152 - auc_1: 0.8776 - val_loss: 0.6574 - val_acc: 0.7083 - val_auc_1: 0.7481\n",
      "Epoch 195/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4276 - acc: 0.8043 - auc_1: 0.8776 - val_loss: 0.6656 - val_acc: 0.7500 - val_auc_1: 0.7444\n",
      "Epoch 196/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4272 - acc: 0.8152 - auc_1: 0.8771 - val_loss: 0.6575 - val_acc: 0.7083 - val_auc_1: 0.7481\n",
      "Epoch 197/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4268 - acc: 0.8043 - auc_1: 0.8771 - val_loss: 0.6639 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 198/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4265 - acc: 0.8152 - auc_1: 0.8794 - val_loss: 0.6574 - val_acc: 0.7083 - val_auc_1: 0.7481\n",
      "Epoch 199/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4261 - acc: 0.8043 - auc_1: 0.8791 - val_loss: 0.6625 - val_acc: 0.7500 - val_auc_1: 0.7444\n",
      "Epoch 200/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4257 - acc: 0.8152 - auc_1: 0.8796 - val_loss: 0.6571 - val_acc: 0.7083 - val_auc_1: 0.7519\n",
      "Epoch 201/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4254 - acc: 0.8043 - auc_1: 0.8801 - val_loss: 0.6611 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 202/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4250 - acc: 0.8152 - auc_1: 0.8799 - val_loss: 0.6566 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 203/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4246 - acc: 0.8043 - auc_1: 0.8803 - val_loss: 0.6599 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 204/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4242 - acc: 0.8152 - auc_1: 0.8803 - val_loss: 0.6560 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 205/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4238 - acc: 0.8043 - auc_1: 0.8808 - val_loss: 0.6586 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 206/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4234 - acc: 0.8152 - auc_1: 0.8803 - val_loss: 0.6553 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 207/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4230 - acc: 0.8043 - auc_1: 0.8813 - val_loss: 0.6575 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 208/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4226 - acc: 0.8152 - auc_1: 0.8801 - val_loss: 0.6544 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 209/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4222 - acc: 0.8043 - auc_1: 0.8811 - val_loss: 0.6563 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 210/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4218 - acc: 0.8152 - auc_1: 0.8811 - val_loss: 0.6535 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 211/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4213 - acc: 0.8043 - auc_1: 0.8813 - val_loss: 0.6551 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 212/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4209 - acc: 0.8152 - auc_1: 0.8821 - val_loss: 0.6524 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 213/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4204 - acc: 0.8152 - auc_1: 0.8813 - val_loss: 0.6539 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 214/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4199 - acc: 0.8152 - auc_1: 0.8823 - val_loss: 0.6513 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 215/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4194 - acc: 0.8261 - auc_1: 0.8821 - val_loss: 0.6526 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 216/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4190 - acc: 0.8152 - auc_1: 0.8830 - val_loss: 0.6501 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 217/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4185 - acc: 0.8261 - auc_1: 0.8830 - val_loss: 0.6514 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 218/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4179 - acc: 0.8261 - auc_1: 0.8833 - val_loss: 0.6488 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 219/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4174 - acc: 0.8261 - auc_1: 0.8838 - val_loss: 0.6501 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 220/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4169 - acc: 0.8261 - auc_1: 0.8843 - val_loss: 0.6474 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 221/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4163 - acc: 0.8261 - auc_1: 0.8843 - val_loss: 0.6487 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 222/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4158 - acc: 0.8261 - auc_1: 0.8853 - val_loss: 0.6459 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 223/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4152 - acc: 0.8261 - auc_1: 0.8855 - val_loss: 0.6474 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 224/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4146 - acc: 0.8261 - auc_1: 0.8862 - val_loss: 0.6444 - val_acc: 0.7500 - val_auc_1: 0.7481\n",
      "Epoch 225/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4140 - acc: 0.8261 - auc_1: 0.8862 - val_loss: 0.6459 - val_acc: 0.7500 - val_auc_1: 0.7556\n",
      "Epoch 226/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4134 - acc: 0.8261 - auc_1: 0.8865 - val_loss: 0.6427 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 227/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4128 - acc: 0.8261 - auc_1: 0.8870 - val_loss: 0.6445 - val_acc: 0.7500 - val_auc_1: 0.7556\n",
      "Epoch 228/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4122 - acc: 0.8261 - auc_1: 0.8875 - val_loss: 0.6409 - val_acc: 0.7500 - val_auc_1: 0.7556\n",
      "Epoch 229/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4115 - acc: 0.8261 - auc_1: 0.8880 - val_loss: 0.6431 - val_acc: 0.7500 - val_auc_1: 0.7556\n",
      "Epoch 230/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4109 - acc: 0.8261 - auc_1: 0.8885 - val_loss: 0.6391 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 231/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4102 - acc: 0.8261 - auc_1: 0.8889 - val_loss: 0.6417 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 232/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4096 - acc: 0.8370 - auc_1: 0.8894 - val_loss: 0.6371 - val_acc: 0.7500 - val_auc_1: 0.7519\n",
      "Epoch 233/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4089 - acc: 0.8261 - auc_1: 0.8897 - val_loss: 0.6403 - val_acc: 0.7500 - val_auc_1: 0.7630\n",
      "Epoch 234/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4082 - acc: 0.8370 - auc_1: 0.8904 - val_loss: 0.6349 - val_acc: 0.7500 - val_auc_1: 0.7556\n",
      "Epoch 235/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4075 - acc: 0.8261 - auc_1: 0.8907 - val_loss: 0.6390 - val_acc: 0.7500 - val_auc_1: 0.7630\n",
      "Epoch 236/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4068 - acc: 0.8478 - auc_1: 0.8921 - val_loss: 0.6326 - val_acc: 0.7500 - val_auc_1: 0.7630\n",
      "Epoch 237/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4061 - acc: 0.8261 - auc_1: 0.8916 - val_loss: 0.6378 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 238/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4054 - acc: 0.8478 - auc_1: 0.8926 - val_loss: 0.6302 - val_acc: 0.7917 - val_auc_1: 0.7667\n",
      "Epoch 239/3000\n",
      "92/92 [==============================] - 0s 54us/step - loss: 0.4047 - acc: 0.8261 - auc_1: 0.8924 - val_loss: 0.6366 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 240/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4040 - acc: 0.8478 - auc_1: 0.8934 - val_loss: 0.6278 - val_acc: 0.7500 - val_auc_1: 0.7667\n",
      "Epoch 241/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4033 - acc: 0.8261 - auc_1: 0.8936 - val_loss: 0.6356 - val_acc: 0.7500 - val_auc_1: 0.7741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.4026 - acc: 0.8478 - auc_1: 0.8939 - val_loss: 0.6253 - val_acc: 0.7500 - val_auc_1: 0.7667\n",
      "Epoch 243/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4020 - acc: 0.8370 - auc_1: 0.8953 - val_loss: 0.6345 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 244/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4013 - acc: 0.8478 - auc_1: 0.8939 - val_loss: 0.6229 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 245/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4006 - acc: 0.8370 - auc_1: 0.8958 - val_loss: 0.6332 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 246/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3998 - acc: 0.8478 - auc_1: 0.8958 - val_loss: 0.6207 - val_acc: 0.7500 - val_auc_1: 0.7741\n",
      "Epoch 247/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3991 - acc: 0.8370 - auc_1: 0.8963 - val_loss: 0.6313 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 248/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3983 - acc: 0.8478 - auc_1: 0.8968 - val_loss: 0.6189 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 249/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3975 - acc: 0.8370 - auc_1: 0.8983 - val_loss: 0.6290 - val_acc: 0.7917 - val_auc_1: 0.7852\n",
      "Epoch 250/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3966 - acc: 0.8478 - auc_1: 0.8980 - val_loss: 0.6173 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 251/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3957 - acc: 0.8370 - auc_1: 0.8978 - val_loss: 0.6264 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 252/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3948 - acc: 0.8478 - auc_1: 0.8985 - val_loss: 0.6159 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 253/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3939 - acc: 0.8370 - auc_1: 0.8983 - val_loss: 0.6236 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 254/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3930 - acc: 0.8478 - auc_1: 0.8995 - val_loss: 0.6146 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 255/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3921 - acc: 0.8478 - auc_1: 0.8990 - val_loss: 0.6209 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 256/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3912 - acc: 0.8478 - auc_1: 0.9000 - val_loss: 0.6132 - val_acc: 0.7917 - val_auc_1: 0.7852\n",
      "Epoch 257/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3903 - acc: 0.8587 - auc_1: 0.8998 - val_loss: 0.6183 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 258/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3895 - acc: 0.8478 - auc_1: 0.9015 - val_loss: 0.6118 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 259/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3886 - acc: 0.8587 - auc_1: 0.9012 - val_loss: 0.6159 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 260/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3877 - acc: 0.8587 - auc_1: 0.9025 - val_loss: 0.6103 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 261/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3869 - acc: 0.8587 - auc_1: 0.9025 - val_loss: 0.6137 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 262/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3860 - acc: 0.8696 - auc_1: 0.9037 - val_loss: 0.6088 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 263/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3852 - acc: 0.8587 - auc_1: 0.9029 - val_loss: 0.6115 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 264/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3844 - acc: 0.8696 - auc_1: 0.9052 - val_loss: 0.6072 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 265/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3835 - acc: 0.8696 - auc_1: 0.9054 - val_loss: 0.6095 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 266/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3827 - acc: 0.8696 - auc_1: 0.9066 - val_loss: 0.6057 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 267/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3819 - acc: 0.8696 - auc_1: 0.9061 - val_loss: 0.6075 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 268/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3811 - acc: 0.8696 - auc_1: 0.9086 - val_loss: 0.6040 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 269/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3803 - acc: 0.8696 - auc_1: 0.9084 - val_loss: 0.6057 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 270/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3795 - acc: 0.8696 - auc_1: 0.9108 - val_loss: 0.6024 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 271/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3787 - acc: 0.8696 - auc_1: 0.9113 - val_loss: 0.6039 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 272/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3779 - acc: 0.8696 - auc_1: 0.9113 - val_loss: 0.6009 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 273/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3771 - acc: 0.8696 - auc_1: 0.9123 - val_loss: 0.6022 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 274/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3763 - acc: 0.8696 - auc_1: 0.9125 - val_loss: 0.5993 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 275/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3755 - acc: 0.8696 - auc_1: 0.9135 - val_loss: 0.6006 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 276/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3748 - acc: 0.8696 - auc_1: 0.9140 - val_loss: 0.5977 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 277/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3740 - acc: 0.8696 - auc_1: 0.9135 - val_loss: 0.5990 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 278/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3733 - acc: 0.8696 - auc_1: 0.9150 - val_loss: 0.5962 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 279/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3725 - acc: 0.8696 - auc_1: 0.9155 - val_loss: 0.5975 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 280/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3718 - acc: 0.8696 - auc_1: 0.9160 - val_loss: 0.5947 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 281/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3710 - acc: 0.8696 - auc_1: 0.9155 - val_loss: 0.5961 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 282/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3703 - acc: 0.8696 - auc_1: 0.9167 - val_loss: 0.5932 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 283/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3696 - acc: 0.8696 - auc_1: 0.9160 - val_loss: 0.5948 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 284/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3689 - acc: 0.8696 - auc_1: 0.9167 - val_loss: 0.5918 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 285/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3682 - acc: 0.8696 - auc_1: 0.9160 - val_loss: 0.5936 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 286/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3675 - acc: 0.8696 - auc_1: 0.9170 - val_loss: 0.5903 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 287/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3668 - acc: 0.8696 - auc_1: 0.9165 - val_loss: 0.5924 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 288/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3662 - acc: 0.8696 - auc_1: 0.9170 - val_loss: 0.5890 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 289/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3655 - acc: 0.8696 - auc_1: 0.9165 - val_loss: 0.5914 - val_acc: 0.7917 - val_auc_1: 0.8407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3649 - acc: 0.8913 - auc_1: 0.9179 - val_loss: 0.5876 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 291/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3642 - acc: 0.8696 - auc_1: 0.9179 - val_loss: 0.5905 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 292/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3636 - acc: 0.8913 - auc_1: 0.9182 - val_loss: 0.5863 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 293/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3630 - acc: 0.8696 - auc_1: 0.9179 - val_loss: 0.5897 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 294/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3624 - acc: 0.8913 - auc_1: 0.9184 - val_loss: 0.5849 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 295/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3618 - acc: 0.8696 - auc_1: 0.9189 - val_loss: 0.5890 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 296/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3613 - acc: 0.8913 - auc_1: 0.9187 - val_loss: 0.5836 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 297/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3607 - acc: 0.8696 - auc_1: 0.9192 - val_loss: 0.5884 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 298/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3602 - acc: 0.8913 - auc_1: 0.9194 - val_loss: 0.5824 - val_acc: 0.7500 - val_auc_1: 0.8481\n",
      "Epoch 299/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3597 - acc: 0.8696 - auc_1: 0.9197 - val_loss: 0.5880 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 300/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3592 - acc: 0.8913 - auc_1: 0.9199 - val_loss: 0.5812 - val_acc: 0.7500 - val_auc_1: 0.8481\n",
      "Epoch 301/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3587 - acc: 0.8587 - auc_1: 0.9199 - val_loss: 0.5876 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 302/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3583 - acc: 0.8913 - auc_1: 0.9197 - val_loss: 0.5802 - val_acc: 0.7500 - val_auc_1: 0.8481\n",
      "Epoch 303/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3578 - acc: 0.8587 - auc_1: 0.9199 - val_loss: 0.5871 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 304/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3574 - acc: 0.8913 - auc_1: 0.9197 - val_loss: 0.5793 - val_acc: 0.7500 - val_auc_1: 0.8481\n",
      "Epoch 305/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3569 - acc: 0.8587 - auc_1: 0.9197 - val_loss: 0.5865 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 306/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3564 - acc: 0.8913 - auc_1: 0.9209 - val_loss: 0.5785 - val_acc: 0.7500 - val_auc_1: 0.8481\n",
      "Epoch 307/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3559 - acc: 0.8587 - auc_1: 0.9201 - val_loss: 0.5856 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 308/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3554 - acc: 0.8913 - auc_1: 0.9214 - val_loss: 0.5779 - val_acc: 0.7500 - val_auc_1: 0.8481\n",
      "Epoch 309/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3549 - acc: 0.8587 - auc_1: 0.9209 - val_loss: 0.5846 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 310/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3544 - acc: 0.8913 - auc_1: 0.9226 - val_loss: 0.5774 - val_acc: 0.7500 - val_auc_1: 0.8481\n",
      "Epoch 311/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3538 - acc: 0.8587 - auc_1: 0.9219 - val_loss: 0.5835 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 312/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3533 - acc: 0.8913 - auc_1: 0.9229 - val_loss: 0.5770 - val_acc: 0.7500 - val_auc_1: 0.8481\n",
      "Epoch 313/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3528 - acc: 0.8696 - auc_1: 0.9224 - val_loss: 0.5824 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 314/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3523 - acc: 0.8913 - auc_1: 0.9226 - val_loss: 0.5767 - val_acc: 0.7500 - val_auc_1: 0.8481\n",
      "Epoch 315/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3518 - acc: 0.8696 - auc_1: 0.9221 - val_loss: 0.5814 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 316/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3513 - acc: 0.8913 - auc_1: 0.9229 - val_loss: 0.5764 - val_acc: 0.7500 - val_auc_1: 0.8481\n",
      "Epoch 317/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3508 - acc: 0.8696 - auc_1: 0.9226 - val_loss: 0.5804 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 318/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3504 - acc: 0.8913 - auc_1: 0.9233 - val_loss: 0.5762 - val_acc: 0.7500 - val_auc_1: 0.8519\n",
      "Epoch 319/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3499 - acc: 0.8804 - auc_1: 0.9229 - val_loss: 0.5796 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 320/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3495 - acc: 0.8913 - auc_1: 0.9233 - val_loss: 0.5759 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 321/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3491 - acc: 0.8804 - auc_1: 0.9236 - val_loss: 0.5789 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 322/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3487 - acc: 0.9022 - auc_1: 0.9233 - val_loss: 0.5757 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 323/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3483 - acc: 0.8804 - auc_1: 0.9241 - val_loss: 0.5783 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 324/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3479 - acc: 0.9022 - auc_1: 0.9246 - val_loss: 0.5754 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 325/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3475 - acc: 0.8913 - auc_1: 0.9243 - val_loss: 0.5777 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 326/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3471 - acc: 0.9022 - auc_1: 0.9246 - val_loss: 0.5752 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 327/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3468 - acc: 0.8913 - auc_1: 0.9251 - val_loss: 0.5773 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 328/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3464 - acc: 0.9022 - auc_1: 0.9256 - val_loss: 0.5750 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 329/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3461 - acc: 0.8913 - auc_1: 0.9251 - val_loss: 0.5769 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 330/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3457 - acc: 0.8913 - auc_1: 0.9253 - val_loss: 0.5747 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 331/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3454 - acc: 0.8913 - auc_1: 0.9251 - val_loss: 0.5765 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 332/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3451 - acc: 0.8913 - auc_1: 0.9256 - val_loss: 0.5745 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 333/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3448 - acc: 0.8913 - auc_1: 0.9248 - val_loss: 0.5762 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 334/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3444 - acc: 0.8913 - auc_1: 0.9258 - val_loss: 0.5743 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 335/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3441 - acc: 0.8913 - auc_1: 0.9256 - val_loss: 0.5759 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 336/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3438 - acc: 0.8804 - auc_1: 0.9258 - val_loss: 0.5740 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 337/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3435 - acc: 0.8913 - auc_1: 0.9258 - val_loss: 0.5756 - val_acc: 0.7917 - val_auc_1: 0.8556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3432 - acc: 0.8804 - auc_1: 0.9265 - val_loss: 0.5738 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 339/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3429 - acc: 0.8913 - auc_1: 0.9260 - val_loss: 0.5754 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 340/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3427 - acc: 0.8804 - auc_1: 0.9268 - val_loss: 0.5736 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 341/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3424 - acc: 0.8913 - auc_1: 0.9270 - val_loss: 0.5752 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 342/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3421 - acc: 0.8804 - auc_1: 0.9273 - val_loss: 0.5734 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 343/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3418 - acc: 0.8913 - auc_1: 0.9270 - val_loss: 0.5750 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 344/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3416 - acc: 0.8804 - auc_1: 0.9280 - val_loss: 0.5731 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 345/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3413 - acc: 0.8913 - auc_1: 0.9283 - val_loss: 0.5749 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 346/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3411 - acc: 0.8804 - auc_1: 0.9273 - val_loss: 0.5729 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 347/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3408 - acc: 0.8913 - auc_1: 0.9285 - val_loss: 0.5748 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 348/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3406 - acc: 0.8804 - auc_1: 0.9275 - val_loss: 0.5727 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 349/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3403 - acc: 0.8913 - auc_1: 0.9285 - val_loss: 0.5747 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 350/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3401 - acc: 0.8804 - auc_1: 0.9278 - val_loss: 0.5724 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 351/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3399 - acc: 0.8913 - auc_1: 0.9285 - val_loss: 0.5747 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 352/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3396 - acc: 0.8804 - auc_1: 0.9280 - val_loss: 0.5722 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 353/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3394 - acc: 0.8804 - auc_1: 0.9285 - val_loss: 0.5747 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 354/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3392 - acc: 0.8804 - auc_1: 0.9287 - val_loss: 0.5719 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 355/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3390 - acc: 0.8804 - auc_1: 0.9287 - val_loss: 0.5747 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 356/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3388 - acc: 0.8804 - auc_1: 0.9287 - val_loss: 0.5717 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 357/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3386 - acc: 0.8913 - auc_1: 0.9283 - val_loss: 0.5747 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 358/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3384 - acc: 0.8804 - auc_1: 0.9290 - val_loss: 0.5714 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 359/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3382 - acc: 0.8913 - auc_1: 0.9287 - val_loss: 0.5748 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 360/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3381 - acc: 0.8804 - auc_1: 0.9285 - val_loss: 0.5711 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 361/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3379 - acc: 0.8913 - auc_1: 0.9280 - val_loss: 0.5749 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 362/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3377 - acc: 0.8804 - auc_1: 0.9290 - val_loss: 0.5708 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 363/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3376 - acc: 0.8804 - auc_1: 0.9280 - val_loss: 0.5751 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 364/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3374 - acc: 0.8913 - auc_1: 0.9287 - val_loss: 0.5706 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 365/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3373 - acc: 0.8804 - auc_1: 0.9283 - val_loss: 0.5752 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 366/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3371 - acc: 0.8913 - auc_1: 0.9285 - val_loss: 0.5703 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 367/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3370 - acc: 0.8804 - auc_1: 0.9290 - val_loss: 0.5753 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 368/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3368 - acc: 0.8913 - auc_1: 0.9290 - val_loss: 0.5701 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 369/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3367 - acc: 0.8804 - auc_1: 0.9287 - val_loss: 0.5753 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 370/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3365 - acc: 0.9022 - auc_1: 0.9290 - val_loss: 0.5699 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 371/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3363 - acc: 0.8804 - auc_1: 0.9287 - val_loss: 0.5751 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 372/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3362 - acc: 0.9022 - auc_1: 0.9290 - val_loss: 0.5697 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 373/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3360 - acc: 0.8804 - auc_1: 0.9292 - val_loss: 0.5749 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 374/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3358 - acc: 0.9022 - auc_1: 0.9285 - val_loss: 0.5696 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 375/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3355 - acc: 0.8804 - auc_1: 0.9287 - val_loss: 0.5746 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 376/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3353 - acc: 0.9022 - auc_1: 0.9287 - val_loss: 0.5695 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 377/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3351 - acc: 0.8696 - auc_1: 0.9290 - val_loss: 0.5742 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 378/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3349 - acc: 0.8913 - auc_1: 0.9285 - val_loss: 0.5695 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 379/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3347 - acc: 0.8696 - auc_1: 0.9290 - val_loss: 0.5737 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 380/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3344 - acc: 0.8913 - auc_1: 0.9287 - val_loss: 0.5694 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 381/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3342 - acc: 0.8804 - auc_1: 0.9290 - val_loss: 0.5733 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 382/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3340 - acc: 0.8913 - auc_1: 0.9287 - val_loss: 0.5694 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 383/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3338 - acc: 0.8804 - auc_1: 0.9292 - val_loss: 0.5729 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 384/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3336 - acc: 0.8913 - auc_1: 0.9290 - val_loss: 0.5694 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 385/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3334 - acc: 0.8804 - auc_1: 0.9292 - val_loss: 0.5725 - val_acc: 0.7917 - val_auc_1: 0.8556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3332 - acc: 0.8913 - auc_1: 0.9287 - val_loss: 0.5694 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 387/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3330 - acc: 0.8804 - auc_1: 0.9295 - val_loss: 0.5722 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 388/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3328 - acc: 0.8913 - auc_1: 0.9292 - val_loss: 0.5694 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 389/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3326 - acc: 0.8804 - auc_1: 0.9295 - val_loss: 0.5719 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 390/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3324 - acc: 0.8913 - auc_1: 0.9292 - val_loss: 0.5694 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 391/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3322 - acc: 0.8804 - auc_1: 0.9290 - val_loss: 0.5716 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 392/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3321 - acc: 0.8913 - auc_1: 0.9290 - val_loss: 0.5693 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 393/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3319 - acc: 0.8804 - auc_1: 0.9292 - val_loss: 0.5714 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 394/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3317 - acc: 0.8913 - auc_1: 0.9292 - val_loss: 0.5692 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 395/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3315 - acc: 0.8804 - auc_1: 0.9295 - val_loss: 0.5711 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 396/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3314 - acc: 0.8913 - auc_1: 0.9290 - val_loss: 0.5691 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 397/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3312 - acc: 0.8804 - auc_1: 0.9295 - val_loss: 0.5709 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 398/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3311 - acc: 0.8913 - auc_1: 0.9292 - val_loss: 0.5690 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 399/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3309 - acc: 0.8804 - auc_1: 0.9295 - val_loss: 0.5707 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 400/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3307 - acc: 0.8913 - auc_1: 0.9292 - val_loss: 0.5689 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 401/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3306 - acc: 0.8804 - auc_1: 0.9295 - val_loss: 0.5704 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 402/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3304 - acc: 0.8913 - auc_1: 0.9292 - val_loss: 0.5688 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 403/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3303 - acc: 0.8804 - auc_1: 0.9295 - val_loss: 0.5702 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 404/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3301 - acc: 0.8913 - auc_1: 0.9292 - val_loss: 0.5686 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 405/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3299 - acc: 0.8804 - auc_1: 0.9297 - val_loss: 0.5700 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 406/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3298 - acc: 0.8913 - auc_1: 0.9297 - val_loss: 0.5684 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 407/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3296 - acc: 0.8804 - auc_1: 0.9300 - val_loss: 0.5698 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 408/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3295 - acc: 0.8913 - auc_1: 0.9300 - val_loss: 0.5682 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 409/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3293 - acc: 0.8804 - auc_1: 0.9302 - val_loss: 0.5696 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 410/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3292 - acc: 0.8913 - auc_1: 0.9302 - val_loss: 0.5680 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 411/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3290 - acc: 0.8804 - auc_1: 0.9305 - val_loss: 0.5693 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 412/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3289 - acc: 0.8913 - auc_1: 0.9305 - val_loss: 0.5677 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 413/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3287 - acc: 0.8804 - auc_1: 0.9305 - val_loss: 0.5691 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 414/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3286 - acc: 0.8913 - auc_1: 0.9310 - val_loss: 0.5675 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 415/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3284 - acc: 0.8804 - auc_1: 0.9305 - val_loss: 0.5689 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 416/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3283 - acc: 0.8913 - auc_1: 0.9310 - val_loss: 0.5672 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 417/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3281 - acc: 0.8804 - auc_1: 0.9305 - val_loss: 0.5687 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 418/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3280 - acc: 0.8913 - auc_1: 0.9310 - val_loss: 0.5669 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 419/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3279 - acc: 0.8804 - auc_1: 0.9307 - val_loss: 0.5684 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 420/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3277 - acc: 0.8913 - auc_1: 0.9312 - val_loss: 0.5666 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 421/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3276 - acc: 0.8804 - auc_1: 0.9307 - val_loss: 0.5682 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 422/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3274 - acc: 0.8913 - auc_1: 0.9310 - val_loss: 0.5662 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 423/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3273 - acc: 0.8913 - auc_1: 0.9307 - val_loss: 0.5680 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 424/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3272 - acc: 0.8913 - auc_1: 0.9310 - val_loss: 0.5658 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 425/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3270 - acc: 0.8913 - auc_1: 0.9310 - val_loss: 0.5677 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 426/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3269 - acc: 0.8913 - auc_1: 0.9312 - val_loss: 0.5654 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 427/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3267 - acc: 0.8913 - auc_1: 0.9310 - val_loss: 0.5675 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 428/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3266 - acc: 0.8913 - auc_1: 0.9314 - val_loss: 0.5650 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 429/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3265 - acc: 0.8913 - auc_1: 0.9302 - val_loss: 0.5673 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 430/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3264 - acc: 0.8913 - auc_1: 0.9310 - val_loss: 0.5645 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 431/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3262 - acc: 0.8804 - auc_1: 0.9305 - val_loss: 0.5670 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 432/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3261 - acc: 0.8913 - auc_1: 0.9310 - val_loss: 0.5641 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 433/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3260 - acc: 0.8804 - auc_1: 0.9307 - val_loss: 0.5668 - val_acc: 0.7917 - val_auc_1: 0.8556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3259 - acc: 0.8913 - auc_1: 0.9312 - val_loss: 0.5636 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 435/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3258 - acc: 0.8804 - auc_1: 0.9314 - val_loss: 0.5666 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 436/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3257 - acc: 0.8913 - auc_1: 0.9310 - val_loss: 0.5631 - val_acc: 0.7500 - val_auc_1: 0.8556\n",
      "Epoch 437/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3255 - acc: 0.8804 - auc_1: 0.9312 - val_loss: 0.5663 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 438/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3254 - acc: 0.8913 - auc_1: 0.9307 - val_loss: 0.5625 - val_acc: 0.7500 - val_auc_1: 0.8593\n",
      "Epoch 439/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3253 - acc: 0.8804 - auc_1: 0.9312 - val_loss: 0.5661 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 440/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3252 - acc: 0.8913 - auc_1: 0.9317 - val_loss: 0.5620 - val_acc: 0.7500 - val_auc_1: 0.8593\n",
      "Epoch 441/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3251 - acc: 0.8804 - auc_1: 0.9314 - val_loss: 0.5658 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 442/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3250 - acc: 0.8913 - auc_1: 0.9317 - val_loss: 0.5615 - val_acc: 0.7500 - val_auc_1: 0.8593\n",
      "Epoch 443/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3249 - acc: 0.8804 - auc_1: 0.9317 - val_loss: 0.5654 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 444/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3248 - acc: 0.8913 - auc_1: 0.9314 - val_loss: 0.5609 - val_acc: 0.7500 - val_auc_1: 0.8593\n",
      "Epoch 445/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3247 - acc: 0.8804 - auc_1: 0.9317 - val_loss: 0.5650 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 446/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3245 - acc: 0.8913 - auc_1: 0.9317 - val_loss: 0.5604 - val_acc: 0.7500 - val_auc_1: 0.8593\n",
      "Epoch 447/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3244 - acc: 0.8804 - auc_1: 0.9317 - val_loss: 0.5645 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 448/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3243 - acc: 0.8913 - auc_1: 0.9322 - val_loss: 0.5598 - val_acc: 0.7500 - val_auc_1: 0.8593\n",
      "Epoch 449/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3241 - acc: 0.8804 - auc_1: 0.9322 - val_loss: 0.5639 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 450/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3240 - acc: 0.8913 - auc_1: 0.9324 - val_loss: 0.5593 - val_acc: 0.7500 - val_auc_1: 0.8593\n",
      "Epoch 451/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3238 - acc: 0.8804 - auc_1: 0.9324 - val_loss: 0.5632 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 452/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3236 - acc: 0.8913 - auc_1: 0.9324 - val_loss: 0.5588 - val_acc: 0.7500 - val_auc_1: 0.8593\n",
      "Epoch 453/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3234 - acc: 0.8913 - auc_1: 0.9327 - val_loss: 0.5625 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 454/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3233 - acc: 0.8913 - auc_1: 0.9324 - val_loss: 0.5583 - val_acc: 0.7500 - val_auc_1: 0.8593\n",
      "Epoch 455/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3231 - acc: 0.8913 - auc_1: 0.9329 - val_loss: 0.5617 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 456/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3229 - acc: 0.8913 - auc_1: 0.9324 - val_loss: 0.5578 - val_acc: 0.7500 - val_auc_1: 0.8630\n",
      "Epoch 457/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3227 - acc: 0.8913 - auc_1: 0.9329 - val_loss: 0.5610 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 458/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3225 - acc: 0.8913 - auc_1: 0.9327 - val_loss: 0.5574 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 459/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3223 - acc: 0.8913 - auc_1: 0.9332 - val_loss: 0.5602 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 460/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3221 - acc: 0.8913 - auc_1: 0.9329 - val_loss: 0.5569 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 461/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3220 - acc: 0.8913 - auc_1: 0.9339 - val_loss: 0.5595 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 462/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3218 - acc: 0.8913 - auc_1: 0.9332 - val_loss: 0.5564 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 463/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3216 - acc: 0.8913 - auc_1: 0.9339 - val_loss: 0.5587 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 464/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3214 - acc: 0.8913 - auc_1: 0.9327 - val_loss: 0.5559 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 465/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3213 - acc: 0.8913 - auc_1: 0.9339 - val_loss: 0.5580 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 466/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3211 - acc: 0.8913 - auc_1: 0.9324 - val_loss: 0.5554 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 467/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3209 - acc: 0.8913 - auc_1: 0.9342 - val_loss: 0.5573 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 468/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3208 - acc: 0.8913 - auc_1: 0.9327 - val_loss: 0.5549 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 469/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3206 - acc: 0.8913 - auc_1: 0.9342 - val_loss: 0.5566 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 470/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3204 - acc: 0.8913 - auc_1: 0.9327 - val_loss: 0.5543 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 471/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3203 - acc: 0.8913 - auc_1: 0.9339 - val_loss: 0.5559 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 472/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3201 - acc: 0.8913 - auc_1: 0.9327 - val_loss: 0.5537 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 473/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3199 - acc: 0.8913 - auc_1: 0.9339 - val_loss: 0.5552 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 474/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3198 - acc: 0.8913 - auc_1: 0.9327 - val_loss: 0.5531 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 475/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3196 - acc: 0.8913 - auc_1: 0.9332 - val_loss: 0.5545 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 476/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3195 - acc: 0.8913 - auc_1: 0.9327 - val_loss: 0.5525 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 477/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3193 - acc: 0.8913 - auc_1: 0.9332 - val_loss: 0.5538 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 478/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3192 - acc: 0.8913 - auc_1: 0.9329 - val_loss: 0.5518 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 479/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3190 - acc: 0.8913 - auc_1: 0.9332 - val_loss: 0.5530 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 480/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3188 - acc: 0.8913 - auc_1: 0.9329 - val_loss: 0.5512 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 481/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3187 - acc: 0.8913 - auc_1: 0.9334 - val_loss: 0.5523 - val_acc: 0.7917 - val_auc_1: 0.8741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3185 - acc: 0.8913 - auc_1: 0.9337 - val_loss: 0.5505 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 483/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3184 - acc: 0.8913 - auc_1: 0.9332 - val_loss: 0.5516 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 484/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3182 - acc: 0.8913 - auc_1: 0.9337 - val_loss: 0.5498 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 485/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3180 - acc: 0.8913 - auc_1: 0.9339 - val_loss: 0.5508 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 486/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3179 - acc: 0.8913 - auc_1: 0.9337 - val_loss: 0.5490 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 487/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3177 - acc: 0.8913 - auc_1: 0.9339 - val_loss: 0.5501 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 488/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3176 - acc: 0.8913 - auc_1: 0.9337 - val_loss: 0.5483 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 489/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3174 - acc: 0.8913 - auc_1: 0.9339 - val_loss: 0.5493 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 490/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3173 - acc: 0.8913 - auc_1: 0.9342 - val_loss: 0.5475 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 491/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3171 - acc: 0.8913 - auc_1: 0.9344 - val_loss: 0.5486 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 492/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3169 - acc: 0.8913 - auc_1: 0.9342 - val_loss: 0.5467 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 493/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3168 - acc: 0.8913 - auc_1: 0.9349 - val_loss: 0.5478 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 494/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3166 - acc: 0.8913 - auc_1: 0.9342 - val_loss: 0.5459 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 495/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3165 - acc: 0.8913 - auc_1: 0.9351 - val_loss: 0.5471 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 496/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3163 - acc: 0.8913 - auc_1: 0.9344 - val_loss: 0.5450 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 497/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3162 - acc: 0.8913 - auc_1: 0.9351 - val_loss: 0.5463 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 498/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3160 - acc: 0.8913 - auc_1: 0.9346 - val_loss: 0.5442 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 499/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3158 - acc: 0.8913 - auc_1: 0.9354 - val_loss: 0.5455 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 500/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3157 - acc: 0.8913 - auc_1: 0.9351 - val_loss: 0.5433 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 501/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.3155 - acc: 0.8913 - auc_1: 0.9354 - val_loss: 0.5448 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 502/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3154 - acc: 0.8913 - auc_1: 0.9351 - val_loss: 0.5424 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 503/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3152 - acc: 0.8913 - auc_1: 0.9356 - val_loss: 0.5440 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 504/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3151 - acc: 0.8913 - auc_1: 0.9349 - val_loss: 0.5415 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 505/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3149 - acc: 0.8913 - auc_1: 0.9359 - val_loss: 0.5433 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 506/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3148 - acc: 0.8913 - auc_1: 0.9351 - val_loss: 0.5406 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 507/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3146 - acc: 0.8913 - auc_1: 0.9356 - val_loss: 0.5426 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 508/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3145 - acc: 0.8913 - auc_1: 0.9356 - val_loss: 0.5397 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 509/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3143 - acc: 0.8913 - auc_1: 0.9356 - val_loss: 0.5419 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 510/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3142 - acc: 0.8804 - auc_1: 0.9356 - val_loss: 0.5388 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 511/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3140 - acc: 0.8913 - auc_1: 0.9364 - val_loss: 0.5411 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 512/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3139 - acc: 0.8804 - auc_1: 0.9356 - val_loss: 0.5379 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 513/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3137 - acc: 0.8913 - auc_1: 0.9364 - val_loss: 0.5404 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 514/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3136 - acc: 0.8804 - auc_1: 0.9356 - val_loss: 0.5369 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 515/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3135 - acc: 0.8913 - auc_1: 0.9364 - val_loss: 0.5397 - val_acc: 0.7917 - val_auc_1: 0.8778\n",
      "Epoch 516/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3133 - acc: 0.8804 - auc_1: 0.9356 - val_loss: 0.5360 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 517/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3132 - acc: 0.8913 - auc_1: 0.9364 - val_loss: 0.5390 - val_acc: 0.7917 - val_auc_1: 0.8778\n",
      "Epoch 518/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3131 - acc: 0.8804 - auc_1: 0.9359 - val_loss: 0.5351 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 519/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3129 - acc: 0.8913 - auc_1: 0.9361 - val_loss: 0.5382 - val_acc: 0.7917 - val_auc_1: 0.8778\n",
      "Epoch 520/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3128 - acc: 0.8804 - auc_1: 0.9359 - val_loss: 0.5343 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 521/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3126 - acc: 0.8913 - auc_1: 0.9364 - val_loss: 0.5375 - val_acc: 0.7917 - val_auc_1: 0.8778\n",
      "Epoch 522/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3125 - acc: 0.8804 - auc_1: 0.9359 - val_loss: 0.5334 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 523/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3123 - acc: 0.8913 - auc_1: 0.9364 - val_loss: 0.5366 - val_acc: 0.7917 - val_auc_1: 0.8815\n",
      "Epoch 524/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3121 - acc: 0.8804 - auc_1: 0.9356 - val_loss: 0.5326 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 525/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3119 - acc: 0.8913 - auc_1: 0.9371 - val_loss: 0.5358 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 526/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3117 - acc: 0.8804 - auc_1: 0.9356 - val_loss: 0.5318 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 527/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3115 - acc: 0.8913 - auc_1: 0.9371 - val_loss: 0.5349 - val_acc: 0.7917 - val_auc_1: 0.8741\n",
      "Epoch 528/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3113 - acc: 0.8804 - auc_1: 0.9356 - val_loss: 0.5310 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 529/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3111 - acc: 0.8913 - auc_1: 0.9373 - val_loss: 0.5340 - val_acc: 0.7917 - val_auc_1: 0.8741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3109 - acc: 0.8804 - auc_1: 0.9351 - val_loss: 0.5303 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 531/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3107 - acc: 0.8913 - auc_1: 0.9369 - val_loss: 0.5331 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 532/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3105 - acc: 0.8804 - auc_1: 0.9356 - val_loss: 0.5297 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 533/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3102 - acc: 0.8913 - auc_1: 0.9371 - val_loss: 0.5323 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 534/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3100 - acc: 0.8804 - auc_1: 0.9361 - val_loss: 0.5290 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 535/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3098 - acc: 0.8913 - auc_1: 0.9369 - val_loss: 0.5314 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 536/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3096 - acc: 0.8804 - auc_1: 0.9361 - val_loss: 0.5284 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 537/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3093 - acc: 0.8913 - auc_1: 0.9369 - val_loss: 0.5307 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 538/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3091 - acc: 0.8804 - auc_1: 0.9359 - val_loss: 0.5279 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 539/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3089 - acc: 0.8913 - auc_1: 0.9369 - val_loss: 0.5299 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 540/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3087 - acc: 0.8804 - auc_1: 0.9361 - val_loss: 0.5274 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 541/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3084 - acc: 0.8913 - auc_1: 0.9369 - val_loss: 0.5292 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 542/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3082 - acc: 0.8804 - auc_1: 0.9361 - val_loss: 0.5269 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 543/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3080 - acc: 0.8913 - auc_1: 0.9373 - val_loss: 0.5286 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 544/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3078 - acc: 0.8804 - auc_1: 0.9369 - val_loss: 0.5264 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 545/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3076 - acc: 0.8913 - auc_1: 0.9376 - val_loss: 0.5280 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 546/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3074 - acc: 0.8804 - auc_1: 0.9376 - val_loss: 0.5259 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 547/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.3071 - acc: 0.8913 - auc_1: 0.9381 - val_loss: 0.5274 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 548/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3069 - acc: 0.8804 - auc_1: 0.9376 - val_loss: 0.5255 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 549/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3067 - acc: 0.8913 - auc_1: 0.9386 - val_loss: 0.5269 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 550/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3065 - acc: 0.8804 - auc_1: 0.9383 - val_loss: 0.5251 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 551/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3063 - acc: 0.8913 - auc_1: 0.9383 - val_loss: 0.5264 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 552/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.3061 - acc: 0.8804 - auc_1: 0.9381 - val_loss: 0.5247 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 553/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3059 - acc: 0.8913 - auc_1: 0.9386 - val_loss: 0.5259 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 554/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3057 - acc: 0.8804 - auc_1: 0.9386 - val_loss: 0.5243 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 555/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3055 - acc: 0.8913 - auc_1: 0.9383 - val_loss: 0.5255 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 556/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.3053 - acc: 0.8804 - auc_1: 0.9383 - val_loss: 0.5240 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 557/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3051 - acc: 0.8913 - auc_1: 0.9386 - val_loss: 0.5252 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 558/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3049 - acc: 0.8804 - auc_1: 0.9381 - val_loss: 0.5237 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 559/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3046 - acc: 0.8913 - auc_1: 0.9383 - val_loss: 0.5248 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 560/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8804 - auc_1: 0.9388 - val_loss: 0.5234 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 561/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3042 - acc: 0.8913 - auc_1: 0.9386 - val_loss: 0.5246 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 562/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3040 - acc: 0.8804 - auc_1: 0.9393 - val_loss: 0.5231 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 563/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3038 - acc: 0.8913 - auc_1: 0.9388 - val_loss: 0.5243 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 564/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3036 - acc: 0.8804 - auc_1: 0.9398 - val_loss: 0.5229 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 565/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3034 - acc: 0.8913 - auc_1: 0.9391 - val_loss: 0.5241 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 566/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3032 - acc: 0.8804 - auc_1: 0.9405 - val_loss: 0.5227 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 567/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3030 - acc: 0.8913 - auc_1: 0.9396 - val_loss: 0.5240 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 568/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3028 - acc: 0.8804 - auc_1: 0.9403 - val_loss: 0.5226 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 569/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3026 - acc: 0.8913 - auc_1: 0.9396 - val_loss: 0.5239 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 570/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3024 - acc: 0.8804 - auc_1: 0.9408 - val_loss: 0.5225 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 571/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3022 - acc: 0.8913 - auc_1: 0.9396 - val_loss: 0.5239 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 572/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3020 - acc: 0.8804 - auc_1: 0.9410 - val_loss: 0.5224 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 573/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3018 - acc: 0.8913 - auc_1: 0.9403 - val_loss: 0.5239 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 574/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3016 - acc: 0.8804 - auc_1: 0.9413 - val_loss: 0.5223 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 575/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3014 - acc: 0.8913 - auc_1: 0.9403 - val_loss: 0.5239 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 576/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3012 - acc: 0.8804 - auc_1: 0.9408 - val_loss: 0.5223 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 577/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3010 - acc: 0.8913 - auc_1: 0.9403 - val_loss: 0.5240 - val_acc: 0.7917 - val_auc_1: 0.8741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3008 - acc: 0.8804 - auc_1: 0.9410 - val_loss: 0.5224 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 579/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3006 - acc: 0.8913 - auc_1: 0.9408 - val_loss: 0.5242 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 580/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3004 - acc: 0.8804 - auc_1: 0.9410 - val_loss: 0.5225 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 581/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3002 - acc: 0.8913 - auc_1: 0.9408 - val_loss: 0.5244 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 582/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3000 - acc: 0.8804 - auc_1: 0.9420 - val_loss: 0.5226 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 583/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2998 - acc: 0.8913 - auc_1: 0.9413 - val_loss: 0.5247 - val_acc: 0.7917 - val_auc_1: 0.8704\n",
      "Epoch 584/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2997 - acc: 0.8804 - auc_1: 0.9423 - val_loss: 0.5228 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 585/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2995 - acc: 0.8913 - auc_1: 0.9420 - val_loss: 0.5250 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 586/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2993 - acc: 0.8804 - auc_1: 0.9420 - val_loss: 0.5230 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 587/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2991 - acc: 0.8913 - auc_1: 0.9423 - val_loss: 0.5254 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 588/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2990 - acc: 0.8804 - auc_1: 0.9428 - val_loss: 0.5233 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 589/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2988 - acc: 0.8913 - auc_1: 0.9420 - val_loss: 0.5258 - val_acc: 0.7917 - val_auc_1: 0.8667\n",
      "Epoch 590/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2986 - acc: 0.8804 - auc_1: 0.9425 - val_loss: 0.5236 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 591/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2984 - acc: 0.8913 - auc_1: 0.9418 - val_loss: 0.5262 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 592/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2982 - acc: 0.8804 - auc_1: 0.9430 - val_loss: 0.5240 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 593/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2980 - acc: 0.8913 - auc_1: 0.9418 - val_loss: 0.5266 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 594/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2979 - acc: 0.8804 - auc_1: 0.9423 - val_loss: 0.5244 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 595/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2976 - acc: 0.8913 - auc_1: 0.9418 - val_loss: 0.5271 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 596/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2974 - acc: 0.8804 - auc_1: 0.9428 - val_loss: 0.5248 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 597/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2972 - acc: 0.8913 - auc_1: 0.9418 - val_loss: 0.5275 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 598/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2970 - acc: 0.8804 - auc_1: 0.9435 - val_loss: 0.5254 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 599/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2968 - acc: 0.8913 - auc_1: 0.9420 - val_loss: 0.5280 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 600/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2965 - acc: 0.8804 - auc_1: 0.9437 - val_loss: 0.5260 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 601/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2963 - acc: 0.8913 - auc_1: 0.9425 - val_loss: 0.5285 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 602/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2961 - acc: 0.8804 - auc_1: 0.9430 - val_loss: 0.5266 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 603/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2958 - acc: 0.8913 - auc_1: 0.9420 - val_loss: 0.5291 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 604/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2956 - acc: 0.8804 - auc_1: 0.9430 - val_loss: 0.5273 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 605/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2953 - acc: 0.8913 - auc_1: 0.9425 - val_loss: 0.5297 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 606/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2951 - acc: 0.8804 - auc_1: 0.9437 - val_loss: 0.5281 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 607/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2948 - acc: 0.8913 - auc_1: 0.9420 - val_loss: 0.5303 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 608/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2946 - acc: 0.8804 - auc_1: 0.9435 - val_loss: 0.5289 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 609/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2943 - acc: 0.8913 - auc_1: 0.9428 - val_loss: 0.5311 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 610/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2941 - acc: 0.8804 - auc_1: 0.9437 - val_loss: 0.5298 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 611/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2938 - acc: 0.8804 - auc_1: 0.9425 - val_loss: 0.5318 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 612/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2936 - acc: 0.8804 - auc_1: 0.9437 - val_loss: 0.5307 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 613/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2933 - acc: 0.8804 - auc_1: 0.9428 - val_loss: 0.5326 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 614/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2931 - acc: 0.8804 - auc_1: 0.9437 - val_loss: 0.5317 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 615/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2928 - acc: 0.8804 - auc_1: 0.9423 - val_loss: 0.5335 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 616/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2926 - acc: 0.8804 - auc_1: 0.9437 - val_loss: 0.5327 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 617/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2924 - acc: 0.8804 - auc_1: 0.9428 - val_loss: 0.5344 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 618/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2921 - acc: 0.8804 - auc_1: 0.9437 - val_loss: 0.5337 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 619/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2919 - acc: 0.8804 - auc_1: 0.9430 - val_loss: 0.5354 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 620/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2917 - acc: 0.8804 - auc_1: 0.9437 - val_loss: 0.5348 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 621/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2914 - acc: 0.8804 - auc_1: 0.9432 - val_loss: 0.5364 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 622/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2912 - acc: 0.8804 - auc_1: 0.9435 - val_loss: 0.5359 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 623/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2910 - acc: 0.8804 - auc_1: 0.9435 - val_loss: 0.5375 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 624/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2908 - acc: 0.8804 - auc_1: 0.9437 - val_loss: 0.5370 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 625/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2905 - acc: 0.8804 - auc_1: 0.9445 - val_loss: 0.5386 - val_acc: 0.7917 - val_auc_1: 0.8593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2903 - acc: 0.8804 - auc_1: 0.9440 - val_loss: 0.5382 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 627/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2901 - acc: 0.8804 - auc_1: 0.9442 - val_loss: 0.5397 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 628/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2899 - acc: 0.8804 - auc_1: 0.9440 - val_loss: 0.5393 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 629/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2896 - acc: 0.8804 - auc_1: 0.9442 - val_loss: 0.5409 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 630/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2894 - acc: 0.8804 - auc_1: 0.9440 - val_loss: 0.5406 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 631/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2892 - acc: 0.8804 - auc_1: 0.9442 - val_loss: 0.5421 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 632/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2890 - acc: 0.8804 - auc_1: 0.9442 - val_loss: 0.5418 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 633/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2887 - acc: 0.8804 - auc_1: 0.9447 - val_loss: 0.5434 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 634/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2885 - acc: 0.8804 - auc_1: 0.9442 - val_loss: 0.5431 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 635/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2883 - acc: 0.8804 - auc_1: 0.9450 - val_loss: 0.5446 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 636/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2881 - acc: 0.8804 - auc_1: 0.9447 - val_loss: 0.5444 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 637/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2879 - acc: 0.8804 - auc_1: 0.9450 - val_loss: 0.5460 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 638/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2877 - acc: 0.8804 - auc_1: 0.9450 - val_loss: 0.5457 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 639/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2874 - acc: 0.8804 - auc_1: 0.9459 - val_loss: 0.5473 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 640/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2872 - acc: 0.8804 - auc_1: 0.9450 - val_loss: 0.5470 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 641/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2870 - acc: 0.8804 - auc_1: 0.9467 - val_loss: 0.5487 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 642/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2868 - acc: 0.8804 - auc_1: 0.9457 - val_loss: 0.5484 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 643/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2866 - acc: 0.8804 - auc_1: 0.9469 - val_loss: 0.5501 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 644/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2864 - acc: 0.8804 - auc_1: 0.9459 - val_loss: 0.5498 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 645/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2862 - acc: 0.8804 - auc_1: 0.9472 - val_loss: 0.5516 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 646/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2859 - acc: 0.8804 - auc_1: 0.9455 - val_loss: 0.5513 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 647/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2857 - acc: 0.8804 - auc_1: 0.9472 - val_loss: 0.5531 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 648/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2855 - acc: 0.8804 - auc_1: 0.9467 - val_loss: 0.5527 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 649/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2853 - acc: 0.8804 - auc_1: 0.9477 - val_loss: 0.5546 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 650/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2851 - acc: 0.8804 - auc_1: 0.9467 - val_loss: 0.5542 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 651/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2849 - acc: 0.8804 - auc_1: 0.9474 - val_loss: 0.5561 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 652/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2847 - acc: 0.8804 - auc_1: 0.9467 - val_loss: 0.5557 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 653/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2845 - acc: 0.8804 - auc_1: 0.9482 - val_loss: 0.5577 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 654/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2843 - acc: 0.8804 - auc_1: 0.9469 - val_loss: 0.5572 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 655/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2841 - acc: 0.8804 - auc_1: 0.9482 - val_loss: 0.5593 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 656/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2840 - acc: 0.8696 - auc_1: 0.9477 - val_loss: 0.5588 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 657/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2837 - acc: 0.8804 - auc_1: 0.9486 - val_loss: 0.5609 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 658/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2836 - acc: 0.8696 - auc_1: 0.9477 - val_loss: 0.5603 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 659/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2833 - acc: 0.8804 - auc_1: 0.9484 - val_loss: 0.5625 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 660/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2832 - acc: 0.8696 - auc_1: 0.9474 - val_loss: 0.5619 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 661/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2829 - acc: 0.8804 - auc_1: 0.9489 - val_loss: 0.5641 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 662/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2827 - acc: 0.8696 - auc_1: 0.9474 - val_loss: 0.5635 - val_acc: 0.7917 - val_auc_1: 0.8630\n",
      "Epoch 663/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2825 - acc: 0.8804 - auc_1: 0.9484 - val_loss: 0.5657 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 664/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2823 - acc: 0.8696 - auc_1: 0.9486 - val_loss: 0.5651 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 665/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2821 - acc: 0.8804 - auc_1: 0.9484 - val_loss: 0.5673 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 666/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2819 - acc: 0.8696 - auc_1: 0.9484 - val_loss: 0.5668 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 667/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2816 - acc: 0.8804 - auc_1: 0.9484 - val_loss: 0.5689 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 668/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2814 - acc: 0.8696 - auc_1: 0.9484 - val_loss: 0.5684 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 669/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2811 - acc: 0.8804 - auc_1: 0.9489 - val_loss: 0.5705 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 670/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2809 - acc: 0.8696 - auc_1: 0.9489 - val_loss: 0.5701 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 671/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2806 - acc: 0.8804 - auc_1: 0.9491 - val_loss: 0.5722 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 672/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2803 - acc: 0.8696 - auc_1: 0.9486 - val_loss: 0.5718 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 673/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2800 - acc: 0.8804 - auc_1: 0.9494 - val_loss: 0.5738 - val_acc: 0.7917 - val_auc_1: 0.8556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 674/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2798 - acc: 0.8696 - auc_1: 0.9486 - val_loss: 0.5736 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 675/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2795 - acc: 0.8804 - auc_1: 0.9496 - val_loss: 0.5755 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 676/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2792 - acc: 0.8696 - auc_1: 0.9486 - val_loss: 0.5753 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 677/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2790 - acc: 0.8804 - auc_1: 0.9496 - val_loss: 0.5772 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 678/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2787 - acc: 0.8696 - auc_1: 0.9489 - val_loss: 0.5771 - val_acc: 0.7917 - val_auc_1: 0.8593\n",
      "Epoch 679/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2784 - acc: 0.8804 - auc_1: 0.9499 - val_loss: 0.5789 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 680/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2782 - acc: 0.8696 - auc_1: 0.9489 - val_loss: 0.5789 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 681/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2779 - acc: 0.8804 - auc_1: 0.9499 - val_loss: 0.5806 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 682/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2776 - acc: 0.8696 - auc_1: 0.9489 - val_loss: 0.5807 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 683/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2773 - acc: 0.8804 - auc_1: 0.9504 - val_loss: 0.5823 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 684/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2771 - acc: 0.8696 - auc_1: 0.9491 - val_loss: 0.5826 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 685/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2768 - acc: 0.8804 - auc_1: 0.9504 - val_loss: 0.5841 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 686/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2766 - acc: 0.8696 - auc_1: 0.9494 - val_loss: 0.5844 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 687/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2763 - acc: 0.8804 - auc_1: 0.9501 - val_loss: 0.5859 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 688/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2760 - acc: 0.8804 - auc_1: 0.9499 - val_loss: 0.5862 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 689/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2758 - acc: 0.8804 - auc_1: 0.9504 - val_loss: 0.5877 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 690/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2755 - acc: 0.8804 - auc_1: 0.9504 - val_loss: 0.5881 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 691/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2753 - acc: 0.8804 - auc_1: 0.9509 - val_loss: 0.5895 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 692/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2750 - acc: 0.8804 - auc_1: 0.9516 - val_loss: 0.5899 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 693/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2747 - acc: 0.8804 - auc_1: 0.9511 - val_loss: 0.5913 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 694/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2745 - acc: 0.8804 - auc_1: 0.9518 - val_loss: 0.5918 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 695/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2742 - acc: 0.8804 - auc_1: 0.9511 - val_loss: 0.5931 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 696/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2740 - acc: 0.8804 - auc_1: 0.9521 - val_loss: 0.5936 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 697/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2738 - acc: 0.8804 - auc_1: 0.9516 - val_loss: 0.5949 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 698/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2735 - acc: 0.8804 - auc_1: 0.9521 - val_loss: 0.5955 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 699/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2733 - acc: 0.8804 - auc_1: 0.9518 - val_loss: 0.5967 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 700/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2730 - acc: 0.8804 - auc_1: 0.9521 - val_loss: 0.5973 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 701/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.2728 - acc: 0.8804 - auc_1: 0.9526 - val_loss: 0.5985 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 702/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2726 - acc: 0.8804 - auc_1: 0.9528 - val_loss: 0.5992 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 703/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2723 - acc: 0.8804 - auc_1: 0.9526 - val_loss: 0.6004 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 704/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2721 - acc: 0.8804 - auc_1: 0.9528 - val_loss: 0.6010 - val_acc: 0.7917 - val_auc_1: 0.8556\n",
      "Epoch 705/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2718 - acc: 0.8804 - auc_1: 0.9523 - val_loss: 0.6022 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 706/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2716 - acc: 0.8696 - auc_1: 0.9531 - val_loss: 0.6029 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 707/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2714 - acc: 0.8804 - auc_1: 0.9528 - val_loss: 0.6040 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 708/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2712 - acc: 0.8696 - auc_1: 0.9531 - val_loss: 0.6047 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 709/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2709 - acc: 0.8804 - auc_1: 0.9528 - val_loss: 0.6058 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 710/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2707 - acc: 0.8696 - auc_1: 0.9533 - val_loss: 0.6066 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 711/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2705 - acc: 0.8804 - auc_1: 0.9533 - val_loss: 0.6076 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 712/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2703 - acc: 0.8696 - auc_1: 0.9533 - val_loss: 0.6084 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 713/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2701 - acc: 0.8804 - auc_1: 0.9536 - val_loss: 0.6094 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 714/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2699 - acc: 0.8696 - auc_1: 0.9543 - val_loss: 0.6103 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 715/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2696 - acc: 0.8804 - auc_1: 0.9541 - val_loss: 0.6112 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 716/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2694 - acc: 0.8696 - auc_1: 0.9543 - val_loss: 0.6121 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 717/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2692 - acc: 0.8804 - auc_1: 0.9538 - val_loss: 0.6129 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 718/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2690 - acc: 0.8696 - auc_1: 0.9548 - val_loss: 0.6139 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 719/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2688 - acc: 0.8804 - auc_1: 0.9541 - val_loss: 0.6147 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 720/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2686 - acc: 0.8696 - auc_1: 0.9548 - val_loss: 0.6157 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 721/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2684 - acc: 0.8804 - auc_1: 0.9541 - val_loss: 0.6164 - val_acc: 0.7917 - val_auc_1: 0.8407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 722/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2682 - acc: 0.8696 - auc_1: 0.9548 - val_loss: 0.6175 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 723/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2680 - acc: 0.8804 - auc_1: 0.9550 - val_loss: 0.6181 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 724/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2678 - acc: 0.8696 - auc_1: 0.9553 - val_loss: 0.6193 - val_acc: 0.7917 - val_auc_1: 0.8519\n",
      "Epoch 725/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2675 - acc: 0.8804 - auc_1: 0.9553 - val_loss: 0.6199 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 726/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2674 - acc: 0.8696 - auc_1: 0.9563 - val_loss: 0.6210 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 727/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2671 - acc: 0.8804 - auc_1: 0.9555 - val_loss: 0.6215 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 728/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2669 - acc: 0.8696 - auc_1: 0.9563 - val_loss: 0.6228 - val_acc: 0.7917 - val_auc_1: 0.8481\n",
      "Epoch 729/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2666 - acc: 0.8804 - auc_1: 0.9558 - val_loss: 0.6232 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 730/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2664 - acc: 0.8696 - auc_1: 0.9568 - val_loss: 0.6245 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 731/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2661 - acc: 0.8804 - auc_1: 0.9560 - val_loss: 0.6249 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 732/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2659 - acc: 0.8696 - auc_1: 0.9575 - val_loss: 0.6262 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 733/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2656 - acc: 0.8804 - auc_1: 0.9560 - val_loss: 0.6265 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 734/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2654 - acc: 0.8696 - auc_1: 0.9572 - val_loss: 0.6279 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 735/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2651 - acc: 0.8804 - auc_1: 0.9560 - val_loss: 0.6282 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 736/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2649 - acc: 0.8696 - auc_1: 0.9572 - val_loss: 0.6296 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 737/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2646 - acc: 0.8804 - auc_1: 0.9563 - val_loss: 0.6299 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 738/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.2643 - acc: 0.8696 - auc_1: 0.9572 - val_loss: 0.6313 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 739/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.2640 - acc: 0.8804 - auc_1: 0.9563 - val_loss: 0.6315 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 740/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.2638 - acc: 0.8696 - auc_1: 0.9575 - val_loss: 0.6330 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 741/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.2635 - acc: 0.8804 - auc_1: 0.9565 - val_loss: 0.6332 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 742/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2633 - acc: 0.8696 - auc_1: 0.9570 - val_loss: 0.6347 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 743/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2630 - acc: 0.8804 - auc_1: 0.9570 - val_loss: 0.6349 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 744/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2628 - acc: 0.8696 - auc_1: 0.9570 - val_loss: 0.6364 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 745/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2625 - acc: 0.8804 - auc_1: 0.9570 - val_loss: 0.6365 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 746/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2623 - acc: 0.8696 - auc_1: 0.9575 - val_loss: 0.6381 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 747/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2620 - acc: 0.8804 - auc_1: 0.9575 - val_loss: 0.6382 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 748/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2618 - acc: 0.8696 - auc_1: 0.9575 - val_loss: 0.6398 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 749/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2615 - acc: 0.8804 - auc_1: 0.9577 - val_loss: 0.6398 - val_acc: 0.7917 - val_auc_1: 0.8444\n",
      "Epoch 750/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2613 - acc: 0.8696 - auc_1: 0.9575 - val_loss: 0.6414 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 751/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2610 - acc: 0.8804 - auc_1: 0.9580 - val_loss: 0.6415 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 752/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2608 - acc: 0.8696 - auc_1: 0.9580 - val_loss: 0.6431 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 753/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2605 - acc: 0.8804 - auc_1: 0.9587 - val_loss: 0.6431 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 754/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2603 - acc: 0.8696 - auc_1: 0.9582 - val_loss: 0.6448 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 755/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2601 - acc: 0.8804 - auc_1: 0.9587 - val_loss: 0.6447 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 756/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2599 - acc: 0.8696 - auc_1: 0.9580 - val_loss: 0.6464 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 757/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2596 - acc: 0.8804 - auc_1: 0.9587 - val_loss: 0.6463 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 758/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2594 - acc: 0.8696 - auc_1: 0.9580 - val_loss: 0.6480 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 759/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2592 - acc: 0.8804 - auc_1: 0.9590 - val_loss: 0.6479 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 760/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2590 - acc: 0.8696 - auc_1: 0.9587 - val_loss: 0.6497 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 761/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2587 - acc: 0.8804 - auc_1: 0.9592 - val_loss: 0.6494 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 762/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2585 - acc: 0.8696 - auc_1: 0.9592 - val_loss: 0.6513 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 763/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2583 - acc: 0.8804 - auc_1: 0.9600 - val_loss: 0.6510 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 764/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2581 - acc: 0.8696 - auc_1: 0.9592 - val_loss: 0.6529 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 765/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2579 - acc: 0.8804 - auc_1: 0.9604 - val_loss: 0.6525 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 766/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2577 - acc: 0.8696 - auc_1: 0.9590 - val_loss: 0.6545 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 767/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2575 - acc: 0.8804 - auc_1: 0.9602 - val_loss: 0.6540 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 768/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2573 - acc: 0.8696 - auc_1: 0.9592 - val_loss: 0.6561 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 769/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2571 - acc: 0.8804 - auc_1: 0.9602 - val_loss: 0.6555 - val_acc: 0.7917 - val_auc_1: 0.8296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2569 - acc: 0.8696 - auc_1: 0.9592 - val_loss: 0.6577 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 771/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2567 - acc: 0.8804 - auc_1: 0.9607 - val_loss: 0.6570 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 772/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2565 - acc: 0.8696 - auc_1: 0.9592 - val_loss: 0.6593 - val_acc: 0.7917 - val_auc_1: 0.8407\n",
      "Epoch 773/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2563 - acc: 0.8804 - auc_1: 0.9609 - val_loss: 0.6585 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 774/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2561 - acc: 0.8696 - auc_1: 0.9600 - val_loss: 0.6609 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 775/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2559 - acc: 0.8804 - auc_1: 0.9612 - val_loss: 0.6600 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 776/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2558 - acc: 0.8696 - auc_1: 0.9602 - val_loss: 0.6625 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 777/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2555 - acc: 0.8804 - auc_1: 0.9612 - val_loss: 0.6614 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 778/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2554 - acc: 0.8696 - auc_1: 0.9609 - val_loss: 0.6640 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 779/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2551 - acc: 0.8804 - auc_1: 0.9609 - val_loss: 0.6628 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 780/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2550 - acc: 0.8696 - auc_1: 0.9607 - val_loss: 0.6655 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 781/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2547 - acc: 0.8804 - auc_1: 0.9609 - val_loss: 0.6643 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 782/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2546 - acc: 0.8696 - auc_1: 0.9604 - val_loss: 0.6670 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 783/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2543 - acc: 0.8804 - auc_1: 0.9609 - val_loss: 0.6657 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 784/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2542 - acc: 0.8696 - auc_1: 0.9612 - val_loss: 0.6685 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 785/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2539 - acc: 0.8804 - auc_1: 0.9612 - val_loss: 0.6671 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 786/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2538 - acc: 0.8696 - auc_1: 0.9612 - val_loss: 0.6700 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 787/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2535 - acc: 0.8804 - auc_1: 0.9612 - val_loss: 0.6686 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 788/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2533 - acc: 0.8696 - auc_1: 0.9612 - val_loss: 0.6714 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 789/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2530 - acc: 0.8804 - auc_1: 0.9612 - val_loss: 0.6700 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 790/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2529 - acc: 0.8696 - auc_1: 0.9614 - val_loss: 0.6729 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 791/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2526 - acc: 0.8804 - auc_1: 0.9612 - val_loss: 0.6714 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 792/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2524 - acc: 0.8696 - auc_1: 0.9614 - val_loss: 0.6743 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 793/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2521 - acc: 0.8804 - auc_1: 0.9609 - val_loss: 0.6728 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 794/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2519 - acc: 0.8696 - auc_1: 0.9617 - val_loss: 0.6757 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 795/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2516 - acc: 0.8804 - auc_1: 0.9614 - val_loss: 0.6743 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 796/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2514 - acc: 0.8696 - auc_1: 0.9617 - val_loss: 0.6771 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 797/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2512 - acc: 0.8804 - auc_1: 0.9619 - val_loss: 0.6757 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 798/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2510 - acc: 0.8696 - auc_1: 0.9617 - val_loss: 0.6786 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 799/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2507 - acc: 0.8804 - auc_1: 0.9622 - val_loss: 0.6771 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 800/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2505 - acc: 0.8696 - auc_1: 0.9619 - val_loss: 0.6800 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 801/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2502 - acc: 0.8804 - auc_1: 0.9624 - val_loss: 0.6786 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 802/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2500 - acc: 0.8696 - auc_1: 0.9617 - val_loss: 0.6814 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 803/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2498 - acc: 0.8804 - auc_1: 0.9631 - val_loss: 0.6800 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 804/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2495 - acc: 0.8696 - auc_1: 0.9619 - val_loss: 0.6828 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 805/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2493 - acc: 0.8804 - auc_1: 0.9631 - val_loss: 0.6814 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 806/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2491 - acc: 0.8696 - auc_1: 0.9622 - val_loss: 0.6842 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 807/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2488 - acc: 0.8804 - auc_1: 0.9631 - val_loss: 0.6828 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 808/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2486 - acc: 0.8804 - auc_1: 0.9622 - val_loss: 0.6857 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 809/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2484 - acc: 0.8804 - auc_1: 0.9631 - val_loss: 0.6842 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 810/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2482 - acc: 0.8804 - auc_1: 0.9622 - val_loss: 0.6871 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 811/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2480 - acc: 0.8804 - auc_1: 0.9629 - val_loss: 0.6856 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 812/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2478 - acc: 0.8804 - auc_1: 0.9624 - val_loss: 0.6885 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 813/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2475 - acc: 0.8804 - auc_1: 0.9629 - val_loss: 0.6870 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 814/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2474 - acc: 0.8804 - auc_1: 0.9624 - val_loss: 0.6900 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 815/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2471 - acc: 0.8804 - auc_1: 0.9634 - val_loss: 0.6884 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 816/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2470 - acc: 0.8804 - auc_1: 0.9627 - val_loss: 0.6914 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 817/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2467 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.6897 - val_acc: 0.7917 - val_auc_1: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 818/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2465 - acc: 0.8804 - auc_1: 0.9627 - val_loss: 0.6928 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 819/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2463 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.6911 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 820/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2462 - acc: 0.8804 - auc_1: 0.9629 - val_loss: 0.6942 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 821/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2459 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.6924 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 822/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2458 - acc: 0.8804 - auc_1: 0.9631 - val_loss: 0.6957 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 823/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2455 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.6938 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 824/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2454 - acc: 0.8804 - auc_1: 0.9631 - val_loss: 0.6971 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 825/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2452 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.6951 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 826/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2450 - acc: 0.8804 - auc_1: 0.9631 - val_loss: 0.6985 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 827/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2448 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.6964 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 828/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2446 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.7000 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 829/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2444 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.6977 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 830/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2443 - acc: 0.8696 - auc_1: 0.9639 - val_loss: 0.7014 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 831/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2441 - acc: 0.8804 - auc_1: 0.9634 - val_loss: 0.6990 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 832/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2439 - acc: 0.8696 - auc_1: 0.9634 - val_loss: 0.7028 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 833/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2437 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.7003 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 834/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2435 - acc: 0.8696 - auc_1: 0.9636 - val_loss: 0.7042 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 835/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2433 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.7016 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 836/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2432 - acc: 0.8696 - auc_1: 0.9636 - val_loss: 0.7055 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 837/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2429 - acc: 0.8804 - auc_1: 0.9634 - val_loss: 0.7028 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 838/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2428 - acc: 0.8696 - auc_1: 0.9631 - val_loss: 0.7069 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 839/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2425 - acc: 0.8804 - auc_1: 0.9634 - val_loss: 0.7041 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 840/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2424 - acc: 0.8696 - auc_1: 0.9634 - val_loss: 0.7082 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 841/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2421 - acc: 0.8804 - auc_1: 0.9634 - val_loss: 0.7054 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 842/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2420 - acc: 0.8696 - auc_1: 0.9634 - val_loss: 0.7095 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 843/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2417 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.7067 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 844/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2415 - acc: 0.8696 - auc_1: 0.9634 - val_loss: 0.7108 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 845/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2413 - acc: 0.8804 - auc_1: 0.9639 - val_loss: 0.7080 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 846/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2411 - acc: 0.8804 - auc_1: 0.9639 - val_loss: 0.7121 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 847/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2408 - acc: 0.8804 - auc_1: 0.9641 - val_loss: 0.7093 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 848/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2407 - acc: 0.8804 - auc_1: 0.9641 - val_loss: 0.7134 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 849/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2404 - acc: 0.8804 - auc_1: 0.9646 - val_loss: 0.7106 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 850/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2402 - acc: 0.8804 - auc_1: 0.9641 - val_loss: 0.7147 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 851/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2400 - acc: 0.8804 - auc_1: 0.9646 - val_loss: 0.7119 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 852/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2398 - acc: 0.8804 - auc_1: 0.9646 - val_loss: 0.7159 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 853/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2395 - acc: 0.8804 - auc_1: 0.9646 - val_loss: 0.7132 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 854/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2393 - acc: 0.8804 - auc_1: 0.9646 - val_loss: 0.7172 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 855/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2391 - acc: 0.8804 - auc_1: 0.9654 - val_loss: 0.7145 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 856/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2389 - acc: 0.8804 - auc_1: 0.9649 - val_loss: 0.7185 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 857/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2386 - acc: 0.8804 - auc_1: 0.9654 - val_loss: 0.7158 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 858/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2385 - acc: 0.8804 - auc_1: 0.9651 - val_loss: 0.7197 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 859/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2382 - acc: 0.8804 - auc_1: 0.9654 - val_loss: 0.7170 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 860/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2380 - acc: 0.8804 - auc_1: 0.9651 - val_loss: 0.7210 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 861/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2378 - acc: 0.8804 - auc_1: 0.9656 - val_loss: 0.7183 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 862/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2376 - acc: 0.8804 - auc_1: 0.9654 - val_loss: 0.7223 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 863/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2374 - acc: 0.8804 - auc_1: 0.9661 - val_loss: 0.7196 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 864/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2372 - acc: 0.8804 - auc_1: 0.9656 - val_loss: 0.7235 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 865/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2370 - acc: 0.8804 - auc_1: 0.9658 - val_loss: 0.7208 - val_acc: 0.7917 - val_auc_1: 0.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 866/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2368 - acc: 0.8804 - auc_1: 0.9661 - val_loss: 0.7248 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 867/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2366 - acc: 0.8913 - auc_1: 0.9661 - val_loss: 0.7220 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 868/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2364 - acc: 0.8804 - auc_1: 0.9661 - val_loss: 0.7261 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 869/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2362 - acc: 0.8913 - auc_1: 0.9663 - val_loss: 0.7232 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 870/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2360 - acc: 0.8804 - auc_1: 0.9663 - val_loss: 0.7273 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 871/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2358 - acc: 0.8913 - auc_1: 0.9666 - val_loss: 0.7244 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 872/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2356 - acc: 0.8804 - auc_1: 0.9671 - val_loss: 0.7286 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 873/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2354 - acc: 0.8804 - auc_1: 0.9668 - val_loss: 0.7256 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 874/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2353 - acc: 0.8804 - auc_1: 0.9666 - val_loss: 0.7299 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 875/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2350 - acc: 0.8804 - auc_1: 0.9671 - val_loss: 0.7268 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 876/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2349 - acc: 0.8804 - auc_1: 0.9668 - val_loss: 0.7311 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 877/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2347 - acc: 0.8913 - auc_1: 0.9671 - val_loss: 0.7279 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 878/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2345 - acc: 0.8804 - auc_1: 0.9668 - val_loss: 0.7324 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 879/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2343 - acc: 0.8913 - auc_1: 0.9678 - val_loss: 0.7291 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 880/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2342 - acc: 0.8804 - auc_1: 0.9666 - val_loss: 0.7336 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 881/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2340 - acc: 0.8913 - auc_1: 0.9678 - val_loss: 0.7302 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 882/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2338 - acc: 0.8804 - auc_1: 0.9668 - val_loss: 0.7348 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 883/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2336 - acc: 0.9022 - auc_1: 0.9681 - val_loss: 0.7313 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 884/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2335 - acc: 0.8804 - auc_1: 0.9671 - val_loss: 0.7361 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 885/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2333 - acc: 0.9022 - auc_1: 0.9683 - val_loss: 0.7324 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 886/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2331 - acc: 0.8804 - auc_1: 0.9668 - val_loss: 0.7372 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 887/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2329 - acc: 0.9022 - auc_1: 0.9683 - val_loss: 0.7335 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 888/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2328 - acc: 0.8804 - auc_1: 0.9676 - val_loss: 0.7384 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 889/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2326 - acc: 0.9022 - auc_1: 0.9683 - val_loss: 0.7346 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 890/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2324 - acc: 0.8804 - auc_1: 0.9678 - val_loss: 0.7395 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 891/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2322 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7357 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 892/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2321 - acc: 0.8804 - auc_1: 0.9678 - val_loss: 0.7407 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 893/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2318 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7368 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 894/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2317 - acc: 0.8804 - auc_1: 0.9678 - val_loss: 0.7417 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 895/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2314 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7379 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 896/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2313 - acc: 0.8804 - auc_1: 0.9678 - val_loss: 0.7428 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 897/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2310 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7389 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 898/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2309 - acc: 0.8804 - auc_1: 0.9678 - val_loss: 0.7438 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 899/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2306 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7400 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 900/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2305 - acc: 0.8804 - auc_1: 0.9678 - val_loss: 0.7449 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 901/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2302 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7410 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 902/3000\n",
      "92/92 [==============================] - 0s 196us/step - loss: 0.2301 - acc: 0.8804 - auc_1: 0.9678 - val_loss: 0.7459 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 903/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.2298 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7421 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 904/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.2297 - acc: 0.8913 - auc_1: 0.9681 - val_loss: 0.7468 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 905/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2294 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7431 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 906/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2293 - acc: 0.8913 - auc_1: 0.9686 - val_loss: 0.7478 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 907/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2290 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7441 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 908/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2289 - acc: 0.8913 - auc_1: 0.9688 - val_loss: 0.7488 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 909/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2286 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7451 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 910/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2285 - acc: 0.8913 - auc_1: 0.9688 - val_loss: 0.7497 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 911/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2282 - acc: 0.9022 - auc_1: 0.9686 - val_loss: 0.7461 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 912/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2281 - acc: 0.8913 - auc_1: 0.9688 - val_loss: 0.7507 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 913/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2278 - acc: 0.9022 - auc_1: 0.9686 - val_loss: 0.7470 - val_acc: 0.7917 - val_auc_1: 0.8111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2277 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7516 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 915/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2275 - acc: 0.9022 - auc_1: 0.9686 - val_loss: 0.7480 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 916/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2273 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7525 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 917/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2271 - acc: 0.9022 - auc_1: 0.9686 - val_loss: 0.7489 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 918/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2270 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7535 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 919/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2267 - acc: 0.9022 - auc_1: 0.9686 - val_loss: 0.7498 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 920/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2266 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7544 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 921/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2264 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7507 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 922/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2262 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7553 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 923/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2260 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7516 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 924/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2259 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7562 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 925/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2257 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7524 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 926/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2256 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7570 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 927/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2254 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7532 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 928/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2252 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7579 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 929/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2250 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7541 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 930/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2249 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7587 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 931/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2247 - acc: 0.9022 - auc_1: 0.9693 - val_loss: 0.7549 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 932/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2246 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7595 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 933/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2244 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7556 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 934/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2243 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7603 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 935/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2241 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7564 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 936/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2239 - acc: 0.9022 - auc_1: 0.9688 - val_loss: 0.7611 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 937/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2237 - acc: 0.9022 - auc_1: 0.9693 - val_loss: 0.7572 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 938/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2236 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7618 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 939/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2234 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7579 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 940/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2233 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7626 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 941/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2231 - acc: 0.9022 - auc_1: 0.9693 - val_loss: 0.7586 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 942/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2229 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7632 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 943/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2227 - acc: 0.9022 - auc_1: 0.9693 - val_loss: 0.7594 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 944/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2226 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.7639 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 945/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2224 - acc: 0.9022 - auc_1: 0.9693 - val_loss: 0.7601 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 946/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2222 - acc: 0.9022 - auc_1: 0.9698 - val_loss: 0.7645 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 947/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2220 - acc: 0.9022 - auc_1: 0.9698 - val_loss: 0.7607 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 948/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2218 - acc: 0.9022 - auc_1: 0.9698 - val_loss: 0.7651 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 949/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2216 - acc: 0.9022 - auc_1: 0.9700 - val_loss: 0.7614 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 950/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2215 - acc: 0.9022 - auc_1: 0.9698 - val_loss: 0.7657 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 951/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2213 - acc: 0.9022 - auc_1: 0.9700 - val_loss: 0.7621 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 952/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2211 - acc: 0.9022 - auc_1: 0.9700 - val_loss: 0.7663 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 953/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2209 - acc: 0.9022 - auc_1: 0.9703 - val_loss: 0.7627 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 954/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2207 - acc: 0.9022 - auc_1: 0.9703 - val_loss: 0.7668 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 955/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2205 - acc: 0.9130 - auc_1: 0.9703 - val_loss: 0.7634 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 956/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2203 - acc: 0.9022 - auc_1: 0.9700 - val_loss: 0.7674 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 957/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2201 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7640 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 958/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2200 - acc: 0.9022 - auc_1: 0.9700 - val_loss: 0.7679 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 959/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2198 - acc: 0.9130 - auc_1: 0.9703 - val_loss: 0.7646 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 960/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2196 - acc: 0.9022 - auc_1: 0.9703 - val_loss: 0.7684 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 961/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2194 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7652 - val_acc: 0.7917 - val_auc_1: 0.8037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2192 - acc: 0.9130 - auc_1: 0.9703 - val_loss: 0.7689 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 963/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2190 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7658 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 964/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2189 - acc: 0.9130 - auc_1: 0.9703 - val_loss: 0.7694 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 965/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2187 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7664 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 966/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2185 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7699 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 967/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2183 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7669 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 968/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2182 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7704 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 969/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2180 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7675 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 970/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2178 - acc: 0.9130 - auc_1: 0.9708 - val_loss: 0.7709 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 971/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2176 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7681 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 972/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2175 - acc: 0.9130 - auc_1: 0.9703 - val_loss: 0.7714 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 973/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2173 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7686 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 974/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2171 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7719 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 975/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2169 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7692 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 976/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2168 - acc: 0.9130 - auc_1: 0.9703 - val_loss: 0.7724 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 977/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2166 - acc: 0.9130 - auc_1: 0.9713 - val_loss: 0.7697 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 978/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2164 - acc: 0.9130 - auc_1: 0.9703 - val_loss: 0.7728 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 979/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2163 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7702 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 980/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2161 - acc: 0.9130 - auc_1: 0.9703 - val_loss: 0.7733 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 981/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2159 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7707 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 982/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2158 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7738 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 983/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.2156 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7713 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 984/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.2154 - acc: 0.9130 - auc_1: 0.9705 - val_loss: 0.7743 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 985/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2153 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7718 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 986/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2151 - acc: 0.9130 - auc_1: 0.9708 - val_loss: 0.7747 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 987/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2149 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7723 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 988/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2148 - acc: 0.9130 - auc_1: 0.9708 - val_loss: 0.7752 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 989/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2146 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7728 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 990/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2145 - acc: 0.9130 - auc_1: 0.9708 - val_loss: 0.7756 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 991/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2143 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7733 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 992/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2141 - acc: 0.9130 - auc_1: 0.9708 - val_loss: 0.7761 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 993/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2139 - acc: 0.9022 - auc_1: 0.9715 - val_loss: 0.7738 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 994/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2138 - acc: 0.9130 - auc_1: 0.9708 - val_loss: 0.7765 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 995/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2136 - acc: 0.9022 - auc_1: 0.9717 - val_loss: 0.7743 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 996/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2135 - acc: 0.9130 - auc_1: 0.9708 - val_loss: 0.7770 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 997/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2133 - acc: 0.9022 - auc_1: 0.9715 - val_loss: 0.7748 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 998/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.2131 - acc: 0.9130 - auc_1: 0.9710 - val_loss: 0.7774 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 999/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2129 - acc: 0.9022 - auc_1: 0.9715 - val_loss: 0.7753 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1000/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2128 - acc: 0.9130 - auc_1: 0.9710 - val_loss: 0.7778 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1001/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2126 - acc: 0.9022 - auc_1: 0.9717 - val_loss: 0.7758 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1002/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2124 - acc: 0.9130 - auc_1: 0.9710 - val_loss: 0.7783 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1003/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2123 - acc: 0.9022 - auc_1: 0.9717 - val_loss: 0.7763 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1004/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2121 - acc: 0.9130 - auc_1: 0.9710 - val_loss: 0.7787 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1005/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2119 - acc: 0.9022 - auc_1: 0.9717 - val_loss: 0.7768 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1006/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2118 - acc: 0.9130 - auc_1: 0.9713 - val_loss: 0.7791 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1007/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2116 - acc: 0.9022 - auc_1: 0.9717 - val_loss: 0.7773 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1008/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2114 - acc: 0.9130 - auc_1: 0.9713 - val_loss: 0.7796 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1009/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2112 - acc: 0.9022 - auc_1: 0.9717 - val_loss: 0.7778 - val_acc: 0.7917 - val_auc_1: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1010/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2111 - acc: 0.9130 - auc_1: 0.9713 - val_loss: 0.7800 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1011/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2109 - acc: 0.9022 - auc_1: 0.9720 - val_loss: 0.7783 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1012/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2107 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7805 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1013/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2106 - acc: 0.9022 - auc_1: 0.9720 - val_loss: 0.7788 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1014/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2104 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7809 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1015/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2102 - acc: 0.9022 - auc_1: 0.9720 - val_loss: 0.7793 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1016/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2101 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7814 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1017/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2099 - acc: 0.9022 - auc_1: 0.9720 - val_loss: 0.7798 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1018/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2097 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7818 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1019/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2096 - acc: 0.9022 - auc_1: 0.9720 - val_loss: 0.7803 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1020/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2094 - acc: 0.9130 - auc_1: 0.9715 - val_loss: 0.7823 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1021/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2092 - acc: 0.9022 - auc_1: 0.9720 - val_loss: 0.7808 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1022/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2091 - acc: 0.9130 - auc_1: 0.9720 - val_loss: 0.7827 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1023/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2089 - acc: 0.9022 - auc_1: 0.9722 - val_loss: 0.7813 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1024/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2087 - acc: 0.9130 - auc_1: 0.9720 - val_loss: 0.7832 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1025/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2086 - acc: 0.9022 - auc_1: 0.9722 - val_loss: 0.7819 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1026/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2084 - acc: 0.9130 - auc_1: 0.9720 - val_loss: 0.7837 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1027/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2082 - acc: 0.9022 - auc_1: 0.9722 - val_loss: 0.7824 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1028/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2081 - acc: 0.9130 - auc_1: 0.9720 - val_loss: 0.7842 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1029/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2079 - acc: 0.9022 - auc_1: 0.9722 - val_loss: 0.7829 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1030/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2077 - acc: 0.9130 - auc_1: 0.9717 - val_loss: 0.7847 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1031/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2076 - acc: 0.9022 - auc_1: 0.9722 - val_loss: 0.7834 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1032/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2074 - acc: 0.9130 - auc_1: 0.9717 - val_loss: 0.7852 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1033/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2072 - acc: 0.9022 - auc_1: 0.9722 - val_loss: 0.7840 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1034/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.2071 - acc: 0.9130 - auc_1: 0.9720 - val_loss: 0.7857 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1035/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2069 - acc: 0.9022 - auc_1: 0.9722 - val_loss: 0.7845 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1036/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2067 - acc: 0.9130 - auc_1: 0.9720 - val_loss: 0.7862 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1037/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2066 - acc: 0.9022 - auc_1: 0.9722 - val_loss: 0.7850 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1038/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2064 - acc: 0.9130 - auc_1: 0.9720 - val_loss: 0.7867 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1039/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2063 - acc: 0.9022 - auc_1: 0.9722 - val_loss: 0.7856 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1040/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2061 - acc: 0.9130 - auc_1: 0.9722 - val_loss: 0.7873 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1041/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2059 - acc: 0.9022 - auc_1: 0.9725 - val_loss: 0.7861 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1042/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2058 - acc: 0.9130 - auc_1: 0.9730 - val_loss: 0.7878 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1043/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.2056 - acc: 0.9022 - auc_1: 0.9725 - val_loss: 0.7867 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1044/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2055 - acc: 0.9130 - auc_1: 0.9732 - val_loss: 0.7883 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1045/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2053 - acc: 0.9022 - auc_1: 0.9725 - val_loss: 0.7872 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1046/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2051 - acc: 0.9130 - auc_1: 0.9732 - val_loss: 0.7889 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1047/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2050 - acc: 0.9022 - auc_1: 0.9725 - val_loss: 0.7878 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1048/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2048 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7894 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1049/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2047 - acc: 0.9022 - auc_1: 0.9725 - val_loss: 0.7883 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1050/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2045 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7899 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1051/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2044 - acc: 0.9022 - auc_1: 0.9725 - val_loss: 0.7889 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1052/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.2042 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7905 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1053/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2040 - acc: 0.9022 - auc_1: 0.9727 - val_loss: 0.7894 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1054/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2039 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7910 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1055/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2037 - acc: 0.9022 - auc_1: 0.9732 - val_loss: 0.7900 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1056/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2036 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7916 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1057/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2034 - acc: 0.9022 - auc_1: 0.9732 - val_loss: 0.7906 - val_acc: 0.7917 - val_auc_1: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1058/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2033 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7921 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1059/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2031 - acc: 0.9022 - auc_1: 0.9732 - val_loss: 0.7911 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1060/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2029 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7927 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1061/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2028 - acc: 0.9022 - auc_1: 0.9732 - val_loss: 0.7917 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1062/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2026 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7932 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1063/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2025 - acc: 0.9022 - auc_1: 0.9735 - val_loss: 0.7922 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1064/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2023 - acc: 0.9130 - auc_1: 0.9732 - val_loss: 0.7938 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1065/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2022 - acc: 0.9022 - auc_1: 0.9735 - val_loss: 0.7928 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1066/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2020 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7943 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1067/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2018 - acc: 0.9022 - auc_1: 0.9735 - val_loss: 0.7933 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1068/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2017 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7949 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1069/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2015 - acc: 0.9022 - auc_1: 0.9737 - val_loss: 0.7939 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1070/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2014 - acc: 0.9130 - auc_1: 0.9735 - val_loss: 0.7954 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1071/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2012 - acc: 0.9130 - auc_1: 0.9740 - val_loss: 0.7945 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1072/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2011 - acc: 0.9130 - auc_1: 0.9737 - val_loss: 0.7960 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1073/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2009 - acc: 0.9130 - auc_1: 0.9742 - val_loss: 0.7950 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1074/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2007 - acc: 0.9130 - auc_1: 0.9740 - val_loss: 0.7965 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1075/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2006 - acc: 0.9130 - auc_1: 0.9742 - val_loss: 0.7956 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1076/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2004 - acc: 0.9130 - auc_1: 0.9742 - val_loss: 0.7971 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1077/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2003 - acc: 0.9130 - auc_1: 0.9744 - val_loss: 0.7961 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1078/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2001 - acc: 0.9130 - auc_1: 0.9744 - val_loss: 0.7976 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1079/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1999 - acc: 0.9130 - auc_1: 0.9747 - val_loss: 0.7967 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1080/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1998 - acc: 0.9130 - auc_1: 0.9742 - val_loss: 0.7982 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1081/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.1996 - acc: 0.9130 - auc_1: 0.9747 - val_loss: 0.7972 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1082/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1994 - acc: 0.9130 - auc_1: 0.9742 - val_loss: 0.7987 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1083/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1993 - acc: 0.9130 - auc_1: 0.9749 - val_loss: 0.7978 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1084/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1991 - acc: 0.9130 - auc_1: 0.9742 - val_loss: 0.7993 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1085/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1990 - acc: 0.9130 - auc_1: 0.9749 - val_loss: 0.7984 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1086/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1988 - acc: 0.9130 - auc_1: 0.9742 - val_loss: 0.7998 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1087/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1986 - acc: 0.9130 - auc_1: 0.9752 - val_loss: 0.7989 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1088/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1985 - acc: 0.9130 - auc_1: 0.9742 - val_loss: 0.8004 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1089/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1983 - acc: 0.9130 - auc_1: 0.9754 - val_loss: 0.7995 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1090/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1981 - acc: 0.9130 - auc_1: 0.9742 - val_loss: 0.8009 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1091/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1980 - acc: 0.9130 - auc_1: 0.9754 - val_loss: 0.8001 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1092/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1978 - acc: 0.9130 - auc_1: 0.9742 - val_loss: 0.8015 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1093/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1976 - acc: 0.9130 - auc_1: 0.9754 - val_loss: 0.8006 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1094/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1975 - acc: 0.9130 - auc_1: 0.9747 - val_loss: 0.8020 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1095/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1973 - acc: 0.9130 - auc_1: 0.9754 - val_loss: 0.8012 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1096/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1971 - acc: 0.9130 - auc_1: 0.9747 - val_loss: 0.8026 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1097/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1970 - acc: 0.9130 - auc_1: 0.9757 - val_loss: 0.8017 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1098/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1968 - acc: 0.9130 - auc_1: 0.9747 - val_loss: 0.8031 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1099/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1966 - acc: 0.9130 - auc_1: 0.9757 - val_loss: 0.8023 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1100/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1965 - acc: 0.9130 - auc_1: 0.9747 - val_loss: 0.8037 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1101/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1963 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8029 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1102/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1961 - acc: 0.9130 - auc_1: 0.9744 - val_loss: 0.8043 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1103/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1960 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8035 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1104/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1958 - acc: 0.9130 - auc_1: 0.9744 - val_loss: 0.8048 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1105/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1957 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8040 - val_acc: 0.7917 - val_auc_1: 0.8296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1106/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1955 - acc: 0.9130 - auc_1: 0.9749 - val_loss: 0.8054 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1107/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1953 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8046 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1108/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1952 - acc: 0.9130 - auc_1: 0.9749 - val_loss: 0.8060 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1109/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1950 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8052 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1110/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1948 - acc: 0.9130 - auc_1: 0.9752 - val_loss: 0.8065 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1111/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1947 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8058 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1112/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1945 - acc: 0.9130 - auc_1: 0.9752 - val_loss: 0.8071 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1113/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1943 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8063 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1114/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1942 - acc: 0.9130 - auc_1: 0.9754 - val_loss: 0.8077 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1115/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1940 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8069 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1116/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1938 - acc: 0.9130 - auc_1: 0.9754 - val_loss: 0.8083 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1117/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1937 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8075 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1118/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1935 - acc: 0.9130 - auc_1: 0.9754 - val_loss: 0.8088 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1119/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1933 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8081 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1120/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1932 - acc: 0.9239 - auc_1: 0.9754 - val_loss: 0.8094 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1121/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1930 - acc: 0.9130 - auc_1: 0.9762 - val_loss: 0.8087 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1122/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1928 - acc: 0.9239 - auc_1: 0.9749 - val_loss: 0.8100 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1123/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1927 - acc: 0.9130 - auc_1: 0.9762 - val_loss: 0.8092 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1124/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1925 - acc: 0.9239 - auc_1: 0.9752 - val_loss: 0.8106 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1125/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1924 - acc: 0.9130 - auc_1: 0.9762 - val_loss: 0.8098 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1126/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1922 - acc: 0.9239 - auc_1: 0.9752 - val_loss: 0.8112 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1127/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1920 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8104 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1128/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1919 - acc: 0.9239 - auc_1: 0.9754 - val_loss: 0.8118 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1129/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1917 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8110 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1130/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1915 - acc: 0.9239 - auc_1: 0.9757 - val_loss: 0.8124 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1131/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1914 - acc: 0.9130 - auc_1: 0.9762 - val_loss: 0.8116 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1132/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1912 - acc: 0.9239 - auc_1: 0.9757 - val_loss: 0.8130 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1133/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1910 - acc: 0.9130 - auc_1: 0.9762 - val_loss: 0.8122 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1134/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1909 - acc: 0.9239 - auc_1: 0.9759 - val_loss: 0.8136 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1135/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1907 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8128 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1136/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1905 - acc: 0.9239 - auc_1: 0.9757 - val_loss: 0.8142 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1137/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1904 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8134 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1138/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1902 - acc: 0.9239 - auc_1: 0.9759 - val_loss: 0.8148 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1139/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1900 - acc: 0.9130 - auc_1: 0.9762 - val_loss: 0.8140 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1140/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1899 - acc: 0.9239 - auc_1: 0.9759 - val_loss: 0.8154 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1141/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1897 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8146 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1142/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1895 - acc: 0.9239 - auc_1: 0.9762 - val_loss: 0.8160 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1143/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1894 - acc: 0.9130 - auc_1: 0.9759 - val_loss: 0.8152 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1144/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1892 - acc: 0.9239 - auc_1: 0.9762 - val_loss: 0.8166 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1145/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1890 - acc: 0.9239 - auc_1: 0.9759 - val_loss: 0.8158 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1146/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1889 - acc: 0.9239 - auc_1: 0.9764 - val_loss: 0.8172 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1147/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1887 - acc: 0.9239 - auc_1: 0.9759 - val_loss: 0.8164 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1148/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1885 - acc: 0.9239 - auc_1: 0.9767 - val_loss: 0.8178 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1149/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1884 - acc: 0.9239 - auc_1: 0.9764 - val_loss: 0.8170 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1150/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1882 - acc: 0.9239 - auc_1: 0.9771 - val_loss: 0.8184 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1151/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1880 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.8176 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1152/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1879 - acc: 0.9239 - auc_1: 0.9774 - val_loss: 0.8191 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1153/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1877 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.8183 - val_acc: 0.7917 - val_auc_1: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1154/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1875 - acc: 0.9239 - auc_1: 0.9774 - val_loss: 0.8197 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1155/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1874 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.8189 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1156/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1872 - acc: 0.9239 - auc_1: 0.9779 - val_loss: 0.8203 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1157/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1870 - acc: 0.9239 - auc_1: 0.9771 - val_loss: 0.8195 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1158/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1868 - acc: 0.9239 - auc_1: 0.9779 - val_loss: 0.8210 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1159/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1867 - acc: 0.9239 - auc_1: 0.9767 - val_loss: 0.8202 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1160/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1865 - acc: 0.9239 - auc_1: 0.9781 - val_loss: 0.8216 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1161/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1863 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.8208 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1162/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1862 - acc: 0.9239 - auc_1: 0.9779 - val_loss: 0.8222 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1163/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1860 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.8214 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1164/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1858 - acc: 0.9239 - auc_1: 0.9779 - val_loss: 0.8229 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1165/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1856 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.8221 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1166/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1855 - acc: 0.9239 - auc_1: 0.9781 - val_loss: 0.8236 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1167/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1853 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.8228 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1168/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1851 - acc: 0.9239 - auc_1: 0.9784 - val_loss: 0.8242 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1169/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1849 - acc: 0.9239 - auc_1: 0.9771 - val_loss: 0.8234 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1170/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1848 - acc: 0.9239 - auc_1: 0.9784 - val_loss: 0.8249 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1171/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1846 - acc: 0.9239 - auc_1: 0.9771 - val_loss: 0.8241 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1172/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.1844 - acc: 0.9348 - auc_1: 0.9784 - val_loss: 0.8256 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1173/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1842 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.8248 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1174/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1841 - acc: 0.9348 - auc_1: 0.9784 - val_loss: 0.8263 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1175/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1839 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.8255 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1176/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1837 - acc: 0.9348 - auc_1: 0.9781 - val_loss: 0.8270 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1177/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1835 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.8262 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1178/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1834 - acc: 0.9348 - auc_1: 0.9784 - val_loss: 0.8277 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1179/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1832 - acc: 0.9239 - auc_1: 0.9771 - val_loss: 0.8269 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1180/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1830 - acc: 0.9348 - auc_1: 0.9786 - val_loss: 0.8284 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1181/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1828 - acc: 0.9239 - auc_1: 0.9771 - val_loss: 0.8276 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1182/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1827 - acc: 0.9348 - auc_1: 0.9789 - val_loss: 0.8291 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1183/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1825 - acc: 0.9239 - auc_1: 0.9774 - val_loss: 0.8283 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1184/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1823 - acc: 0.9348 - auc_1: 0.9789 - val_loss: 0.8298 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1185/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1821 - acc: 0.9239 - auc_1: 0.9774 - val_loss: 0.8290 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1186/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1820 - acc: 0.9348 - auc_1: 0.9789 - val_loss: 0.8306 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1187/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1818 - acc: 0.9239 - auc_1: 0.9774 - val_loss: 0.8297 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1188/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1816 - acc: 0.9348 - auc_1: 0.9789 - val_loss: 0.8313 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1189/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1814 - acc: 0.9239 - auc_1: 0.9776 - val_loss: 0.8305 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1190/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1813 - acc: 0.9348 - auc_1: 0.9794 - val_loss: 0.8320 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1191/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1811 - acc: 0.9239 - auc_1: 0.9779 - val_loss: 0.8312 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1192/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1809 - acc: 0.9348 - auc_1: 0.9796 - val_loss: 0.8328 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1193/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1808 - acc: 0.9239 - auc_1: 0.9779 - val_loss: 0.8320 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1194/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1806 - acc: 0.9348 - auc_1: 0.9796 - val_loss: 0.8336 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1195/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1804 - acc: 0.9239 - auc_1: 0.9779 - val_loss: 0.8327 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1196/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1802 - acc: 0.9457 - auc_1: 0.9796 - val_loss: 0.8344 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1197/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1801 - acc: 0.9239 - auc_1: 0.9779 - val_loss: 0.8335 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1198/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1799 - acc: 0.9457 - auc_1: 0.9796 - val_loss: 0.8351 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1199/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1797 - acc: 0.9239 - auc_1: 0.9779 - val_loss: 0.8343 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1200/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1795 - acc: 0.9457 - auc_1: 0.9796 - val_loss: 0.8359 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1201/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1794 - acc: 0.9239 - auc_1: 0.9779 - val_loss: 0.8350 - val_acc: 0.7917 - val_auc_1: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1202/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1792 - acc: 0.9457 - auc_1: 0.9796 - val_loss: 0.8367 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1203/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1790 - acc: 0.9239 - auc_1: 0.9784 - val_loss: 0.8358 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1204/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1789 - acc: 0.9457 - auc_1: 0.9796 - val_loss: 0.8375 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1205/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1787 - acc: 0.9239 - auc_1: 0.9791 - val_loss: 0.8366 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1206/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1785 - acc: 0.9457 - auc_1: 0.9799 - val_loss: 0.8383 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1207/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1783 - acc: 0.9239 - auc_1: 0.9791 - val_loss: 0.8374 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1208/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1782 - acc: 0.9457 - auc_1: 0.9801 - val_loss: 0.8392 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1209/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1780 - acc: 0.9239 - auc_1: 0.9794 - val_loss: 0.8382 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1210/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1778 - acc: 0.9457 - auc_1: 0.9803 - val_loss: 0.8400 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1211/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1777 - acc: 0.9239 - auc_1: 0.9799 - val_loss: 0.8390 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1212/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1775 - acc: 0.9457 - auc_1: 0.9806 - val_loss: 0.8408 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1213/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1773 - acc: 0.9239 - auc_1: 0.9796 - val_loss: 0.8398 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1214/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1771 - acc: 0.9457 - auc_1: 0.9803 - val_loss: 0.8417 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1215/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1770 - acc: 0.9239 - auc_1: 0.9796 - val_loss: 0.8406 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1216/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1768 - acc: 0.9457 - auc_1: 0.9806 - val_loss: 0.8425 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1217/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1766 - acc: 0.9239 - auc_1: 0.9796 - val_loss: 0.8414 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1218/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1764 - acc: 0.9457 - auc_1: 0.9808 - val_loss: 0.8433 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1219/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1763 - acc: 0.9239 - auc_1: 0.9799 - val_loss: 0.8423 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1220/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1761 - acc: 0.9457 - auc_1: 0.9808 - val_loss: 0.8442 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1221/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1759 - acc: 0.9239 - auc_1: 0.9799 - val_loss: 0.8431 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1222/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1757 - acc: 0.9457 - auc_1: 0.9808 - val_loss: 0.8451 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1223/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1756 - acc: 0.9239 - auc_1: 0.9799 - val_loss: 0.8439 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1224/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1754 - acc: 0.9457 - auc_1: 0.9808 - val_loss: 0.8459 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1225/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1752 - acc: 0.9239 - auc_1: 0.9799 - val_loss: 0.8448 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1226/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1750 - acc: 0.9457 - auc_1: 0.9811 - val_loss: 0.8468 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1227/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1749 - acc: 0.9239 - auc_1: 0.9799 - val_loss: 0.8456 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1228/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1747 - acc: 0.9457 - auc_1: 0.9811 - val_loss: 0.8477 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1229/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1745 - acc: 0.9239 - auc_1: 0.9801 - val_loss: 0.8465 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1230/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1743 - acc: 0.9457 - auc_1: 0.9813 - val_loss: 0.8486 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1231/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1742 - acc: 0.9348 - auc_1: 0.9801 - val_loss: 0.8473 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1232/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1740 - acc: 0.9457 - auc_1: 0.9813 - val_loss: 0.8494 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1233/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1738 - acc: 0.9348 - auc_1: 0.9799 - val_loss: 0.8482 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1234/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1736 - acc: 0.9457 - auc_1: 0.9811 - val_loss: 0.8503 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1235/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1735 - acc: 0.9348 - auc_1: 0.9799 - val_loss: 0.8490 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1236/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1733 - acc: 0.9457 - auc_1: 0.9811 - val_loss: 0.8512 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1237/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1731 - acc: 0.9348 - auc_1: 0.9799 - val_loss: 0.8499 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1238/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1729 - acc: 0.9348 - auc_1: 0.9811 - val_loss: 0.8521 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1239/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1727 - acc: 0.9348 - auc_1: 0.9799 - val_loss: 0.8508 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1240/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1726 - acc: 0.9348 - auc_1: 0.9811 - val_loss: 0.8531 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1241/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1724 - acc: 0.9348 - auc_1: 0.9799 - val_loss: 0.8517 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1242/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1722 - acc: 0.9348 - auc_1: 0.9811 - val_loss: 0.8540 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1243/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1720 - acc: 0.9348 - auc_1: 0.9799 - val_loss: 0.8526 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1244/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1718 - acc: 0.9348 - auc_1: 0.9813 - val_loss: 0.8549 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1245/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1717 - acc: 0.9348 - auc_1: 0.9799 - val_loss: 0.8535 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1246/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1715 - acc: 0.9348 - auc_1: 0.9813 - val_loss: 0.8558 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1247/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1713 - acc: 0.9348 - auc_1: 0.9801 - val_loss: 0.8544 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1248/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1711 - acc: 0.9348 - auc_1: 0.9816 - val_loss: 0.8568 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1249/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1709 - acc: 0.9348 - auc_1: 0.9801 - val_loss: 0.8553 - val_acc: 0.7917 - val_auc_1: 0.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1250/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1708 - acc: 0.9348 - auc_1: 0.9816 - val_loss: 0.8577 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1251/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1706 - acc: 0.9348 - auc_1: 0.9801 - val_loss: 0.8562 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1252/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1704 - acc: 0.9348 - auc_1: 0.9816 - val_loss: 0.8587 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1253/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1702 - acc: 0.9348 - auc_1: 0.9801 - val_loss: 0.8571 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1254/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1701 - acc: 0.9348 - auc_1: 0.9816 - val_loss: 0.8597 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1255/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1699 - acc: 0.9348 - auc_1: 0.9799 - val_loss: 0.8581 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1256/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1697 - acc: 0.9348 - auc_1: 0.9816 - val_loss: 0.8606 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1257/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1695 - acc: 0.9348 - auc_1: 0.9799 - val_loss: 0.8590 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1258/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1693 - acc: 0.9348 - auc_1: 0.9816 - val_loss: 0.8616 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1259/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1692 - acc: 0.9348 - auc_1: 0.9799 - val_loss: 0.8599 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1260/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1690 - acc: 0.9348 - auc_1: 0.9821 - val_loss: 0.8626 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1261/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1688 - acc: 0.9348 - auc_1: 0.9801 - val_loss: 0.8609 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1262/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1686 - acc: 0.9348 - auc_1: 0.9821 - val_loss: 0.8636 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1263/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1685 - acc: 0.9348 - auc_1: 0.9803 - val_loss: 0.8618 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1264/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1683 - acc: 0.9348 - auc_1: 0.9821 - val_loss: 0.8646 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1265/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1681 - acc: 0.9348 - auc_1: 0.9803 - val_loss: 0.8627 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1266/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1679 - acc: 0.9348 - auc_1: 0.9821 - val_loss: 0.8656 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1267/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1678 - acc: 0.9348 - auc_1: 0.9803 - val_loss: 0.8637 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1268/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1676 - acc: 0.9348 - auc_1: 0.9826 - val_loss: 0.8666 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1269/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1674 - acc: 0.9348 - auc_1: 0.9806 - val_loss: 0.8646 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1270/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1672 - acc: 0.9348 - auc_1: 0.9826 - val_loss: 0.8676 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1271/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1671 - acc: 0.9348 - auc_1: 0.9806 - val_loss: 0.8656 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1272/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1669 - acc: 0.9348 - auc_1: 0.9826 - val_loss: 0.8686 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1273/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1667 - acc: 0.9348 - auc_1: 0.9811 - val_loss: 0.8665 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1274/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1665 - acc: 0.9348 - auc_1: 0.9826 - val_loss: 0.8697 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1275/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1664 - acc: 0.9348 - auc_1: 0.9811 - val_loss: 0.8675 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1276/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1662 - acc: 0.9348 - auc_1: 0.9823 - val_loss: 0.8707 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1277/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1660 - acc: 0.9348 - auc_1: 0.9808 - val_loss: 0.8685 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1278/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1658 - acc: 0.9348 - auc_1: 0.9826 - val_loss: 0.8717 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1279/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1657 - acc: 0.9348 - auc_1: 0.9808 - val_loss: 0.8694 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1280/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1655 - acc: 0.9348 - auc_1: 0.9830 - val_loss: 0.8727 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1281/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1653 - acc: 0.9348 - auc_1: 0.9811 - val_loss: 0.8704 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1282/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1651 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8738 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1283/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1650 - acc: 0.9348 - auc_1: 0.9813 - val_loss: 0.8713 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1284/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1648 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8748 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1285/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1646 - acc: 0.9348 - auc_1: 0.9818 - val_loss: 0.8723 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1286/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1644 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8758 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1287/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1643 - acc: 0.9348 - auc_1: 0.9818 - val_loss: 0.8733 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1288/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1641 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8769 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1289/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1639 - acc: 0.9348 - auc_1: 0.9821 - val_loss: 0.8742 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1290/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1637 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8779 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1291/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1636 - acc: 0.9348 - auc_1: 0.9818 - val_loss: 0.8752 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1292/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1634 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8790 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1293/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1632 - acc: 0.9348 - auc_1: 0.9818 - val_loss: 0.8762 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1294/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1630 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8800 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1295/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1628 - acc: 0.9348 - auc_1: 0.9821 - val_loss: 0.8772 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1296/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1627 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8811 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1297/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1625 - acc: 0.9348 - auc_1: 0.9823 - val_loss: 0.8781 - val_acc: 0.7917 - val_auc_1: 0.8296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1298/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1623 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8821 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1299/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1621 - acc: 0.9348 - auc_1: 0.9826 - val_loss: 0.8791 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1300/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1619 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8832 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1301/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1618 - acc: 0.9348 - auc_1: 0.9826 - val_loss: 0.8801 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1302/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1616 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8842 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1303/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1614 - acc: 0.9348 - auc_1: 0.9823 - val_loss: 0.8811 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1304/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1612 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8853 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1305/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1610 - acc: 0.9348 - auc_1: 0.9823 - val_loss: 0.8821 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1306/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1609 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8864 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1307/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1607 - acc: 0.9348 - auc_1: 0.9823 - val_loss: 0.8831 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1308/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1605 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8874 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1309/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1603 - acc: 0.9348 - auc_1: 0.9826 - val_loss: 0.8841 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1310/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1601 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8885 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1311/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1600 - acc: 0.9348 - auc_1: 0.9826 - val_loss: 0.8851 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1312/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1598 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8896 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1313/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1596 - acc: 0.9348 - auc_1: 0.9828 - val_loss: 0.8861 - val_acc: 0.7917 - val_auc_1: 0.8333\n",
      "Epoch 1314/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1594 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8907 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1315/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1592 - acc: 0.9348 - auc_1: 0.9835 - val_loss: 0.8871 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 1316/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1591 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.8918 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1317/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1589 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.8881 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 1318/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1587 - acc: 0.9348 - auc_1: 0.9835 - val_loss: 0.8929 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1319/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1585 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.8891 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 1320/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1583 - acc: 0.9348 - auc_1: 0.9835 - val_loss: 0.8940 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1321/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1582 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.8901 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 1322/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1580 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.8951 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1323/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1578 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.8911 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 1324/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1576 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.8962 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1325/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1575 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.8921 - val_acc: 0.7917 - val_auc_1: 0.8370\n",
      "Epoch 1326/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1573 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.8973 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1327/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1571 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.8931 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1328/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1569 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.8984 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1329/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1568 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.8942 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1330/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1566 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.8995 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1331/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1564 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.8952 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1332/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1562 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.9006 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1333/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1561 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.8962 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1334/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1559 - acc: 0.9348 - auc_1: 0.9840 - val_loss: 0.9017 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1335/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1557 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.8972 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1336/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1556 - acc: 0.9348 - auc_1: 0.9840 - val_loss: 0.9029 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1337/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1554 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.8982 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1338/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1552 - acc: 0.9348 - auc_1: 0.9845 - val_loss: 0.9040 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1339/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1550 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.8992 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1340/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1549 - acc: 0.9348 - auc_1: 0.9845 - val_loss: 0.9051 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1341/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.1547 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.9002 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1342/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1545 - acc: 0.9348 - auc_1: 0.9845 - val_loss: 0.9062 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1343/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1543 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.9012 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1344/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1541 - acc: 0.9348 - auc_1: 0.9845 - val_loss: 0.9073 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1345/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1540 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.9022 - val_acc: 0.7917 - val_auc_1: 0.7926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1346/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1538 - acc: 0.9348 - auc_1: 0.9848 - val_loss: 0.9084 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1347/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1536 - acc: 0.9457 - auc_1: 0.9838 - val_loss: 0.9032 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1348/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1534 - acc: 0.9348 - auc_1: 0.9848 - val_loss: 0.9095 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1349/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1533 - acc: 0.9457 - auc_1: 0.9840 - val_loss: 0.9042 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1350/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1531 - acc: 0.9348 - auc_1: 0.9848 - val_loss: 0.9106 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1351/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1529 - acc: 0.9457 - auc_1: 0.9840 - val_loss: 0.9052 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1352/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1527 - acc: 0.9348 - auc_1: 0.9848 - val_loss: 0.9117 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1353/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1525 - acc: 0.9457 - auc_1: 0.9840 - val_loss: 0.9062 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1354/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1524 - acc: 0.9348 - auc_1: 0.9850 - val_loss: 0.9128 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1355/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1522 - acc: 0.9457 - auc_1: 0.9840 - val_loss: 0.9072 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1356/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1520 - acc: 0.9348 - auc_1: 0.9850 - val_loss: 0.9139 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1357/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1518 - acc: 0.9457 - auc_1: 0.9840 - val_loss: 0.9082 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1358/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1516 - acc: 0.9348 - auc_1: 0.9850 - val_loss: 0.9150 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1359/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1515 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9092 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1360/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1513 - acc: 0.9348 - auc_1: 0.9853 - val_loss: 0.9161 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1361/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1511 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9102 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1362/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1509 - acc: 0.9348 - auc_1: 0.9853 - val_loss: 0.9173 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1363/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1507 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9113 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1364/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1506 - acc: 0.9348 - auc_1: 0.9853 - val_loss: 0.9184 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1365/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1504 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9123 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1366/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1502 - acc: 0.9348 - auc_1: 0.9853 - val_loss: 0.9195 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1367/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1500 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9133 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1368/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1499 - acc: 0.9348 - auc_1: 0.9855 - val_loss: 0.9206 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1369/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1497 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9143 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1370/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1495 - acc: 0.9348 - auc_1: 0.9855 - val_loss: 0.9217 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1371/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1493 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9153 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1372/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1492 - acc: 0.9348 - auc_1: 0.9855 - val_loss: 0.9229 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1373/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1490 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9163 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1374/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1488 - acc: 0.9457 - auc_1: 0.9855 - val_loss: 0.9240 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1375/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1486 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9173 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1376/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1485 - acc: 0.9457 - auc_1: 0.9862 - val_loss: 0.9251 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1377/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1483 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9183 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1378/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1481 - acc: 0.9457 - auc_1: 0.9862 - val_loss: 0.9262 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1379/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1480 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9193 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1380/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1478 - acc: 0.9457 - auc_1: 0.9865 - val_loss: 0.9274 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1381/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1476 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.9203 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1382/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1474 - acc: 0.9457 - auc_1: 0.9865 - val_loss: 0.9285 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1383/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1473 - acc: 0.9457 - auc_1: 0.9850 - val_loss: 0.9213 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1384/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1471 - acc: 0.9457 - auc_1: 0.9865 - val_loss: 0.9296 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1385/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1469 - acc: 0.9457 - auc_1: 0.9850 - val_loss: 0.9223 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1386/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1468 - acc: 0.9457 - auc_1: 0.9867 - val_loss: 0.9307 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1387/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1466 - acc: 0.9457 - auc_1: 0.9850 - val_loss: 0.9233 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1388/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1464 - acc: 0.9457 - auc_1: 0.9867 - val_loss: 0.9319 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1389/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1462 - acc: 0.9457 - auc_1: 0.9853 - val_loss: 0.9243 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1390/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1461 - acc: 0.9457 - auc_1: 0.9870 - val_loss: 0.9330 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1391/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1459 - acc: 0.9457 - auc_1: 0.9853 - val_loss: 0.9253 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1392/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1457 - acc: 0.9457 - auc_1: 0.9880 - val_loss: 0.9341 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1393/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1456 - acc: 0.9457 - auc_1: 0.9857 - val_loss: 0.9263 - val_acc: 0.7917 - val_auc_1: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1394/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1454 - acc: 0.9457 - auc_1: 0.9880 - val_loss: 0.9352 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1395/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1452 - acc: 0.9457 - auc_1: 0.9862 - val_loss: 0.9273 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1396/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1451 - acc: 0.9457 - auc_1: 0.9880 - val_loss: 0.9363 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1397/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1449 - acc: 0.9457 - auc_1: 0.9865 - val_loss: 0.9283 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1398/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1447 - acc: 0.9457 - auc_1: 0.9880 - val_loss: 0.9374 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1399/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1445 - acc: 0.9457 - auc_1: 0.9865 - val_loss: 0.9293 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1400/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1444 - acc: 0.9457 - auc_1: 0.9880 - val_loss: 0.9385 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1401/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1442 - acc: 0.9457 - auc_1: 0.9865 - val_loss: 0.9303 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1402/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1440 - acc: 0.9457 - auc_1: 0.9880 - val_loss: 0.9396 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1403/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1438 - acc: 0.9457 - auc_1: 0.9867 - val_loss: 0.9313 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1404/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.1437 - acc: 0.9457 - auc_1: 0.9882 - val_loss: 0.9407 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1405/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1435 - acc: 0.9457 - auc_1: 0.9870 - val_loss: 0.9323 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1406/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1433 - acc: 0.9457 - auc_1: 0.9882 - val_loss: 0.9418 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1407/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1431 - acc: 0.9457 - auc_1: 0.9870 - val_loss: 0.9333 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1408/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1430 - acc: 0.9457 - auc_1: 0.9885 - val_loss: 0.9429 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1409/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1428 - acc: 0.9457 - auc_1: 0.9872 - val_loss: 0.9343 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1410/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1426 - acc: 0.9457 - auc_1: 0.9885 - val_loss: 0.9440 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1411/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1425 - acc: 0.9457 - auc_1: 0.9872 - val_loss: 0.9353 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1412/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1423 - acc: 0.9457 - auc_1: 0.9885 - val_loss: 0.9451 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1413/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1421 - acc: 0.9457 - auc_1: 0.9872 - val_loss: 0.9363 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1414/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1420 - acc: 0.9457 - auc_1: 0.9885 - val_loss: 0.9462 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1415/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1418 - acc: 0.9457 - auc_1: 0.9872 - val_loss: 0.9373 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1416/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1416 - acc: 0.9457 - auc_1: 0.9885 - val_loss: 0.9472 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1417/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1414 - acc: 0.9457 - auc_1: 0.9875 - val_loss: 0.9383 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1418/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1413 - acc: 0.9457 - auc_1: 0.9885 - val_loss: 0.9483 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1419/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1411 - acc: 0.9457 - auc_1: 0.9875 - val_loss: 0.9393 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1420/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1409 - acc: 0.9457 - auc_1: 0.9887 - val_loss: 0.9494 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1421/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1408 - acc: 0.9457 - auc_1: 0.9875 - val_loss: 0.9403 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1422/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1406 - acc: 0.9457 - auc_1: 0.9894 - val_loss: 0.9505 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1423/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.1404 - acc: 0.9457 - auc_1: 0.9875 - val_loss: 0.9412 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1424/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1403 - acc: 0.9457 - auc_1: 0.9897 - val_loss: 0.9516 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1425/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1401 - acc: 0.9457 - auc_1: 0.9875 - val_loss: 0.9422 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1426/3000\n",
      "92/92 [==============================] - 0s 315us/step - loss: 0.1399 - acc: 0.9457 - auc_1: 0.9899 - val_loss: 0.9527 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1427/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1398 - acc: 0.9457 - auc_1: 0.9875 - val_loss: 0.9432 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1428/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1396 - acc: 0.9457 - auc_1: 0.9899 - val_loss: 0.9538 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1429/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1394 - acc: 0.9457 - auc_1: 0.9875 - val_loss: 0.9442 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1430/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1393 - acc: 0.9457 - auc_1: 0.9899 - val_loss: 0.9549 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1431/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1391 - acc: 0.9457 - auc_1: 0.9875 - val_loss: 0.9452 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1432/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1389 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.9560 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1433/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1388 - acc: 0.9457 - auc_1: 0.9875 - val_loss: 0.9461 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1434/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1386 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.9570 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1435/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1384 - acc: 0.9457 - auc_1: 0.9875 - val_loss: 0.9471 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1436/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1383 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.9581 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1437/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.1381 - acc: 0.9457 - auc_1: 0.9882 - val_loss: 0.9481 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1438/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1380 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.9592 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1439/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1378 - acc: 0.9457 - auc_1: 0.9882 - val_loss: 0.9491 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1440/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1376 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.9603 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1441/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1375 - acc: 0.9457 - auc_1: 0.9887 - val_loss: 0.9500 - val_acc: 0.7917 - val_auc_1: 0.8037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1442/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1373 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.9613 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1443/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1371 - acc: 0.9457 - auc_1: 0.9887 - val_loss: 0.9510 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1444/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1370 - acc: 0.9457 - auc_1: 0.9904 - val_loss: 0.9624 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1445/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1368 - acc: 0.9457 - auc_1: 0.9885 - val_loss: 0.9520 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1446/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1367 - acc: 0.9457 - auc_1: 0.9904 - val_loss: 0.9635 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1447/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1365 - acc: 0.9457 - auc_1: 0.9887 - val_loss: 0.9529 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1448/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1363 - acc: 0.9457 - auc_1: 0.9904 - val_loss: 0.9645 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1449/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1362 - acc: 0.9457 - auc_1: 0.9889 - val_loss: 0.9539 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1450/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1360 - acc: 0.9457 - auc_1: 0.9907 - val_loss: 0.9656 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1451/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1358 - acc: 0.9457 - auc_1: 0.9899 - val_loss: 0.9549 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1452/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.1357 - acc: 0.9457 - auc_1: 0.9909 - val_loss: 0.9666 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1453/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1355 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.9559 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1454/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1354 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.9677 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1455/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1352 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.9568 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1456/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1350 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.9687 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1457/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1348 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.9578 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1458/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1347 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.9697 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1459/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1345 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.9588 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1460/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1344 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.9708 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1461/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1342 - acc: 0.9457 - auc_1: 0.9904 - val_loss: 0.9597 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1462/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1341 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.9718 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1463/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1339 - acc: 0.9457 - auc_1: 0.9904 - val_loss: 0.9607 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1464/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1337 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 0.9729 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1465/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1335 - acc: 0.9457 - auc_1: 0.9907 - val_loss: 0.9616 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1466/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1334 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 0.9739 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1467/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1332 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9626 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1468/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1331 - acc: 0.9565 - auc_1: 0.9914 - val_loss: 0.9749 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1469/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1329 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9636 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1470/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1328 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9760 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1471/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1326 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9645 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1472/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1324 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9770 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1473/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1323 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9655 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1474/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1321 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9780 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1475/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1319 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9664 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1476/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1318 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9791 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1477/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1316 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9674 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1478/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1315 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9801 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1479/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1313 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9683 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1480/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1312 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9811 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1481/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1310 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9693 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1482/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1309 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9821 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1483/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1307 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9702 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1484/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1306 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9832 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1485/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1304 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9712 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1486/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1302 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9842 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1487/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1301 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9721 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1488/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1299 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9852 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1489/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1298 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9731 - val_acc: 0.7917 - val_auc_1: 0.8074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1490/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1296 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9862 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1491/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1294 - acc: 0.9348 - auc_1: 0.9909 - val_loss: 0.9740 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1492/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1293 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9872 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1493/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1291 - acc: 0.9348 - auc_1: 0.9909 - val_loss: 0.9749 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1494/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1290 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9882 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1495/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1288 - acc: 0.9348 - auc_1: 0.9909 - val_loss: 0.9759 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1496/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1287 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9892 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1497/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1285 - acc: 0.9348 - auc_1: 0.9909 - val_loss: 0.9768 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1498/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1284 - acc: 0.9565 - auc_1: 0.9916 - val_loss: 0.9902 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1499/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1282 - acc: 0.9348 - auc_1: 0.9912 - val_loss: 0.9778 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1500/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1281 - acc: 0.9457 - auc_1: 0.9916 - val_loss: 0.9912 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1501/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1279 - acc: 0.9348 - auc_1: 0.9912 - val_loss: 0.9787 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1502/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1277 - acc: 0.9457 - auc_1: 0.9916 - val_loss: 0.9922 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1503/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1276 - acc: 0.9348 - auc_1: 0.9912 - val_loss: 0.9796 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1504/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1274 - acc: 0.9457 - auc_1: 0.9916 - val_loss: 0.9932 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1505/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1273 - acc: 0.9348 - auc_1: 0.9912 - val_loss: 0.9806 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1506/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1271 - acc: 0.9457 - auc_1: 0.9916 - val_loss: 0.9942 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1507/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1270 - acc: 0.9348 - auc_1: 0.9914 - val_loss: 0.9815 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1508/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1268 - acc: 0.9457 - auc_1: 0.9916 - val_loss: 0.9952 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1509/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1266 - acc: 0.9348 - auc_1: 0.9914 - val_loss: 0.9825 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1510/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1265 - acc: 0.9457 - auc_1: 0.9916 - val_loss: 0.9962 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1511/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1263 - acc: 0.9348 - auc_1: 0.9914 - val_loss: 0.9834 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1512/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1262 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.9972 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1513/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1260 - acc: 0.9348 - auc_1: 0.9919 - val_loss: 0.9843 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1514/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1259 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.9982 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1515/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1257 - acc: 0.9348 - auc_1: 0.9919 - val_loss: 0.9853 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1516/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1256 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.9991 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1517/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1254 - acc: 0.9348 - auc_1: 0.9919 - val_loss: 0.9862 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1518/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1253 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 1.0001 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1519/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1251 - acc: 0.9348 - auc_1: 0.9919 - val_loss: 0.9871 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1520/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1250 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0011 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1521/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1248 - acc: 0.9348 - auc_1: 0.9916 - val_loss: 0.9881 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1522/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1247 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0021 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1523/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1245 - acc: 0.9348 - auc_1: 0.9916 - val_loss: 0.9890 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1524/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1244 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0031 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1525/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1242 - acc: 0.9348 - auc_1: 0.9921 - val_loss: 0.9900 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1526/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1240 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0041 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1527/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1239 - acc: 0.9348 - auc_1: 0.9924 - val_loss: 0.9909 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1528/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1237 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0050 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1529/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1236 - acc: 0.9348 - auc_1: 0.9924 - val_loss: 0.9918 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1530/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1234 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0060 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1531/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1233 - acc: 0.9348 - auc_1: 0.9924 - val_loss: 0.9928 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1532/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1231 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0070 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1533/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1230 - acc: 0.9348 - auc_1: 0.9924 - val_loss: 0.9937 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1534/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1228 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0080 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1535/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1227 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 0.9946 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1536/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1225 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0090 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1537/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1224 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 0.9956 - val_acc: 0.7917 - val_auc_1: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1538/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1222 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0099 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1539/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1220 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 0.9965 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1540/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1219 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0109 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1541/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1217 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 0.9975 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1542/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1216 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.0119 - val_acc: 0.7917 - val_auc_1: 0.8037\n",
      "Epoch 1543/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1214 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 0.9984 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1544/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1213 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 1.0129 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1545/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1211 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 0.9993 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1546/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1210 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 1.0139 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1547/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1208 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0003 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1548/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1207 - acc: 0.9457 - auc_1: 0.9926 - val_loss: 1.0148 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1549/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1205 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0012 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1550/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1204 - acc: 0.9457 - auc_1: 0.9926 - val_loss: 1.0158 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1551/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1202 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0022 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1552/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1201 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0168 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1553/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1199 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0031 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1554/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1198 - acc: 0.9457 - auc_1: 0.9934 - val_loss: 1.0178 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1555/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1196 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0040 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1556/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1195 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0188 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1557/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1193 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0050 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1558/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1192 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0197 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1559/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1190 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0059 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1560/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1189 - acc: 0.9457 - auc_1: 0.9936 - val_loss: 1.0207 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1561/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1187 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0069 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1562/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1186 - acc: 0.9457 - auc_1: 0.9936 - val_loss: 1.0217 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1563/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1184 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0079 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1564/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1183 - acc: 0.9457 - auc_1: 0.9936 - val_loss: 1.0227 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1565/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1181 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0088 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1566/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1180 - acc: 0.9457 - auc_1: 0.9936 - val_loss: 1.0237 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1567/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1178 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0098 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1568/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1177 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0246 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1569/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1175 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0107 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1570/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1174 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0256 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1571/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1172 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0117 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1572/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1171 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0266 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1573/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1169 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0127 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1574/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1168 - acc: 0.9457 - auc_1: 0.9939 - val_loss: 1.0276 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1575/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1166 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0136 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1576/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1165 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0286 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1577/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1163 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0146 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1578/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1162 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0296 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 1579/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1160 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0156 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1580/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1159 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0306 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1581/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1157 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0165 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1582/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1156 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0316 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1583/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1154 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0175 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1584/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1153 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0326 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1585/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1151 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0185 - val_acc: 0.7917 - val_auc_1: 0.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1586/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1150 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0336 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1587/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1148 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0195 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1588/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1147 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0346 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1589/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1145 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0205 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1590/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1144 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0356 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1591/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1142 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0215 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1592/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1141 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0366 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1593/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1139 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0225 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1594/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1138 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0376 - val_acc: 0.7917 - val_auc_1: 0.8074\n",
      "Epoch 1595/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1136 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0234 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1596/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1135 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0386 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1597/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1133 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0244 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1598/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1132 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0396 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1599/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1130 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0255 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1600/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1129 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0407 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1601/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1127 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0265 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1602/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1126 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0417 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1603/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1124 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0275 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1604/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1123 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0427 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1605/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1121 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0285 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1606/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1120 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0437 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1607/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1118 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0295 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1608/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1117 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0448 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1609/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1115 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0305 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1610/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1114 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0458 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1611/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1112 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0316 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1612/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1111 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0468 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1613/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1109 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0326 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1614/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1108 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0479 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1615/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1106 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.0336 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1616/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1105 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0489 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1617/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1103 - acc: 0.9457 - auc_1: 0.9934 - val_loss: 1.0347 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1618/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1102 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0500 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1619/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1100 - acc: 0.9457 - auc_1: 0.9936 - val_loss: 1.0357 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1620/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1099 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0510 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1621/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1097 - acc: 0.9457 - auc_1: 0.9939 - val_loss: 1.0368 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1622/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1096 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0521 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1623/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1094 - acc: 0.9457 - auc_1: 0.9939 - val_loss: 1.0378 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1624/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1093 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0531 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1625/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1091 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0389 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1626/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1090 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0542 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1627/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1088 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0399 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1628/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1087 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0553 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1629/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1085 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0410 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1630/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1084 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0563 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1631/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1082 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0421 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1632/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1081 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0574 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1633/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1079 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0431 - val_acc: 0.7917 - val_auc_1: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1634/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1078 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0585 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1635/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1076 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0442 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1636/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1075 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0596 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1637/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1073 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0453 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1638/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.1072 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0606 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1639/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1070 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0464 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1640/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1069 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0617 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1641/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1067 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0475 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1642/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1066 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0628 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1643/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1064 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0486 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1644/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1063 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0639 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1645/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1061 - acc: 0.9457 - auc_1: 0.9941 - val_loss: 1.0497 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1646/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1060 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0650 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1647/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1058 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 1.0508 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1648/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1057 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0661 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1649/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1055 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 1.0519 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1650/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1054 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0673 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1651/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1052 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0531 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1652/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1051 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0684 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1653/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1049 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0542 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1654/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1048 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0695 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1655/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1046 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0553 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1656/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.1045 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0706 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1657/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1043 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0565 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1658/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1042 - acc: 0.9457 - auc_1: 0.9953 - val_loss: 1.0717 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1659/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1040 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0576 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1660/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1039 - acc: 0.9457 - auc_1: 0.9953 - val_loss: 1.0729 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1661/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1037 - acc: 0.9457 - auc_1: 0.9946 - val_loss: 1.0588 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1662/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1036 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0740 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1663/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1035 - acc: 0.9457 - auc_1: 0.9948 - val_loss: 1.0599 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1664/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1033 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0752 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1665/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1032 - acc: 0.9457 - auc_1: 0.9948 - val_loss: 1.0611 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1666/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1030 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0763 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1667/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1029 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0622 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1668/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1027 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0775 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1669/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1026 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0634 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1670/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1024 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0786 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1671/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1023 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0646 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1672/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1021 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0798 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1673/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1020 - acc: 0.9457 - auc_1: 0.9951 - val_loss: 1.0658 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1674/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1018 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0810 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1675/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1017 - acc: 0.9457 - auc_1: 0.9953 - val_loss: 1.0669 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1676/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1016 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0821 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1677/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1014 - acc: 0.9457 - auc_1: 0.9953 - val_loss: 1.0681 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1678/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1013 - acc: 0.9457 - auc_1: 0.9958 - val_loss: 1.0833 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1679/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1011 - acc: 0.9457 - auc_1: 0.9953 - val_loss: 1.0693 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1680/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1010 - acc: 0.9457 - auc_1: 0.9958 - val_loss: 1.0845 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1681/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1008 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0705 - val_acc: 0.7917 - val_auc_1: 0.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1682/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1007 - acc: 0.9457 - auc_1: 0.9963 - val_loss: 1.0857 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1683/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1005 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0717 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1684/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1004 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0869 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1685/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1003 - acc: 0.9457 - auc_1: 0.9956 - val_loss: 1.0729 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1686/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1001 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0880 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1687/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1000 - acc: 0.9457 - auc_1: 0.9963 - val_loss: 1.0742 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1688/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0998 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0892 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1689/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0997 - acc: 0.9457 - auc_1: 0.9963 - val_loss: 1.0754 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1690/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0995 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0905 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1691/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0994 - acc: 0.9457 - auc_1: 0.9963 - val_loss: 1.0766 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1692/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0992 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0917 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1693/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0991 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0778 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1694/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0990 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0929 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1695/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0988 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0791 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1696/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0987 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0941 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1697/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0985 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0803 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1698/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0984 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0953 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1699/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0983 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0816 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1700/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0981 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0965 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1701/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0980 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0828 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1702/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0978 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0978 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1703/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0977 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0841 - val_acc: 0.7917 - val_auc_1: 0.8111\n",
      "Epoch 1704/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0975 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.0990 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1705/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0974 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0854 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1706/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.0973 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1003 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1707/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0971 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0866 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1708/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.0970 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1015 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1709/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.0968 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0879 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1710/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0967 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1028 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1711/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0966 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0892 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1712/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0964 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1040 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1713/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0963 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0905 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1714/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0962 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1053 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1715/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0960 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0917 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1716/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0959 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1065 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1717/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0957 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0930 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1718/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0956 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1078 - val_acc: 0.7917 - val_auc_1: 0.8222\n",
      "Epoch 1719/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0955 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0943 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1720/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0953 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1091 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1721/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.0952 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0956 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1722/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0951 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1104 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1723/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.0949 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0969 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1724/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0948 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1117 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1725/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0946 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0983 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1726/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0945 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1129 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 1727/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0944 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.0996 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1728/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0942 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1142 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 1729/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0941 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1009 - val_acc: 0.7917 - val_auc_1: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1730/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0940 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1155 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 1731/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0938 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1022 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1732/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0937 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1168 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 1733/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0936 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1035 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1734/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0934 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1181 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 1735/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0933 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1049 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1736/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0932 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1194 - val_acc: 0.7917 - val_auc_1: 0.7852\n",
      "Epoch 1737/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0930 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1062 - val_acc: 0.7917 - val_auc_1: 0.8148\n",
      "Epoch 1738/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0929 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1208 - val_acc: 0.7917 - val_auc_1: 0.7852\n",
      "Epoch 1739/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0928 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1076 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1740/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0926 - acc: 0.9457 - auc_1: 0.9966 - val_loss: 1.1221 - val_acc: 0.7917 - val_auc_1: 0.7852\n",
      "Epoch 1741/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0925 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1089 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1742/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0924 - acc: 0.9457 - auc_1: 0.9968 - val_loss: 1.1234 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1743/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0922 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1103 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1744/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0921 - acc: 0.9457 - auc_1: 0.9968 - val_loss: 1.1247 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1745/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0920 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1116 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1746/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0919 - acc: 0.9457 - auc_1: 0.9968 - val_loss: 1.1261 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1747/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0917 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1130 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1748/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0916 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1274 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1749/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0915 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1143 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1750/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0913 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1287 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1751/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0912 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1157 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1752/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0911 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1301 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1753/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0910 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1171 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1754/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0908 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1314 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1755/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0907 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1184 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1756/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0906 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1328 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1757/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0904 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1198 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1758/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0903 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1341 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1759/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0902 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1212 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1760/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0901 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1355 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1761/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0899 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1226 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1762/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0898 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1368 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1763/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0897 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1240 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1764/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0896 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1382 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1765/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0894 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1254 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1766/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0893 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1396 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1767/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0892 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1268 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1768/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0891 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1409 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1769/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0889 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1281 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1770/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0888 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1423 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1771/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0887 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1295 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1772/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0886 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1437 - val_acc: 0.7917 - val_auc_1: 0.7815\n",
      "Epoch 1773/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0884 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1309 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1774/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0883 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1450 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1775/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0882 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1323 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1776/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0881 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1464 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1777/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0879 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1338 - val_acc: 0.7917 - val_auc_1: 0.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1778/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0878 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1478 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1779/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0877 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1352 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1780/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0876 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1492 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1781/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0875 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1366 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1782/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0873 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1506 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1783/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0872 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1380 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1784/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0871 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1519 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1785/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.0870 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1394 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1786/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0869 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1533 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1787/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0867 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1408 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1788/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0866 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1547 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1789/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0865 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1422 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1790/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0864 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1561 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1791/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0863 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1437 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1792/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0862 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1575 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1793/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0860 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1451 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1794/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0859 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1589 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1795/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0858 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1465 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1796/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0857 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1603 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1797/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0856 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1479 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1798/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0854 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1617 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1799/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0853 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1494 - val_acc: 0.7917 - val_auc_1: 0.8185\n",
      "Epoch 1800/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0852 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1631 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1801/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0851 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1508 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1802/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0850 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1645 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1803/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0849 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1522 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1804/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0848 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1659 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1805/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0846 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1537 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1806/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0845 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1673 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1807/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0844 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1551 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1808/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0843 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1687 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1809/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0842 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1565 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1810/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0841 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1701 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1811/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0839 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1580 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1812/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0838 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1715 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1813/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0837 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1594 - val_acc: 0.7917 - val_auc_1: 0.8259\n",
      "Epoch 1814/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0836 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1729 - val_acc: 0.7917 - val_auc_1: 0.7926\n",
      "Epoch 1815/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0835 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1608 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1816/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0834 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1743 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1817/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0833 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1623 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1818/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0832 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1757 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1819/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0830 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1637 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1820/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0829 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1771 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1821/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0828 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1652 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1822/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0827 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1785 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1823/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0826 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1666 - val_acc: 0.7917 - val_auc_1: 0.8296\n",
      "Epoch 1824/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0825 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1799 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1825/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0824 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1680 - val_acc: 0.7917 - val_auc_1: 0.8296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1826/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0823 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1814 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1827/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0822 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1695 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1828/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0821 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1828 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1829/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0819 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1709 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1830/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0818 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1842 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1831/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0817 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1724 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1832/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0816 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1856 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1833/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0815 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1738 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1834/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0814 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1870 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1835/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0813 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1753 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1836/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0812 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1884 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1837/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0811 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1767 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1838/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0810 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1898 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1839/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0809 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1781 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1840/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0808 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1912 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1841/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0807 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1796 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1842/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0806 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1926 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1843/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0804 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1810 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1844/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0803 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1940 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1845/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0802 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1825 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1846/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0801 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1954 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1847/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0800 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1839 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1848/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0799 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1968 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1849/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0798 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1853 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1850/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0797 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1982 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1851/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0796 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1868 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1852/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0795 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1996 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1853/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0794 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1882 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1854/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0793 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.2010 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1855/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0792 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1897 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1856/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0791 - acc: 0.9565 - auc_1: 0.9973 - val_loss: 1.2024 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1857/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0790 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1911 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1858/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0789 - acc: 0.9565 - auc_1: 0.9973 - val_loss: 1.2038 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1859/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0788 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1925 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1860/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0787 - acc: 0.9565 - auc_1: 0.9973 - val_loss: 1.2052 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1861/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0786 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1940 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1862/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0785 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2066 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1863/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0784 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1954 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1864/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0783 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2080 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1865/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0782 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1968 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1866/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0781 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2094 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1867/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0780 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1983 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1868/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0779 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2108 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1869/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0778 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.1997 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1870/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0777 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2122 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1871/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0776 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.2011 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1872/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0775 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2136 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1873/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0774 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.2026 - val_acc: 0.7917 - val_auc_1: 0.7889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1874/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0773 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2150 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1875/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0772 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.2040 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1876/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0771 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2164 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1877/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0770 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.2054 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1878/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0769 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2178 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1879/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0768 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.2068 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1880/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0767 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2192 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1881/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0766 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.2083 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1882/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0765 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2206 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1883/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0764 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.2097 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1884/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0763 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2219 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1885/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0762 - acc: 0.9565 - auc_1: 0.9973 - val_loss: 1.2111 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1886/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0761 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2233 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1887/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0760 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2125 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1888/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0759 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2247 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1889/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0758 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2139 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1890/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0757 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2261 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1891/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0756 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2154 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1892/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0755 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2274 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1893/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0754 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2168 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1894/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0753 - acc: 0.9565 - auc_1: 0.9975 - val_loss: 1.2288 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1895/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0752 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2182 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1896/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0751 - acc: 0.9565 - auc_1: 0.9978 - val_loss: 1.2302 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1897/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0750 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2196 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1898/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0749 - acc: 0.9565 - auc_1: 0.9978 - val_loss: 1.2316 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1899/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0748 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2210 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1900/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0748 - acc: 0.9565 - auc_1: 0.9978 - val_loss: 1.2329 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1901/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0747 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2224 - val_acc: 0.7917 - val_auc_1: 0.7889\n",
      "Epoch 1902/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0746 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2343 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1903/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0745 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2238 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1904/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0744 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2356 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1905/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0743 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2252 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1906/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0742 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2370 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1907/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0741 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2266 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1908/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0740 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2384 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1909/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0739 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2280 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1910/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0738 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2397 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1911/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0737 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2294 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1912/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0736 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2411 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1913/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0735 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2308 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1914/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0735 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2424 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1915/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0734 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2322 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1916/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0733 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2438 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1917/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0732 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2336 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1918/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0731 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2451 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1919/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0730 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2350 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1920/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0729 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2465 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1921/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0728 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2364 - val_acc: 0.7917 - val_auc_1: 0.7963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1922/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0727 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2478 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1923/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0726 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2377 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1924/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0725 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2491 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1925/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0724 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2391 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1926/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0724 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2505 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1927/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0723 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2405 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1928/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0722 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2518 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1929/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0721 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2419 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1930/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0720 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2531 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1931/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0719 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2433 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1932/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0718 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2545 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1933/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0717 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2446 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1934/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0717 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2558 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1935/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0716 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2460 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1936/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0715 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2571 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1937/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0714 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2474 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1938/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0713 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2584 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1939/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0712 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2487 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1940/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0711 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2598 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1941/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0710 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2501 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1942/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0710 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2611 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1943/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0709 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2514 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1944/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0708 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2624 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1945/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0707 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2528 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1946/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0706 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2637 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1947/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0705 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2542 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1948/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0704 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2650 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1949/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0703 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2555 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1950/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0703 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2663 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1951/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0702 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2569 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1952/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0701 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2676 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1953/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0700 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2582 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1954/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0699 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2689 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1955/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0698 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2595 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1956/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0697 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2702 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1957/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0697 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2609 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1958/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0696 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2715 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1959/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0695 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2622 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1960/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0694 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2728 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1961/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0693 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2636 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1962/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0692 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2741 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1963/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0692 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2649 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1964/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0691 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2754 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1965/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0690 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2662 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1966/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0689 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2767 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1967/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0688 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2675 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1968/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0687 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2779 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1969/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0687 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2689 - val_acc: 0.7917 - val_auc_1: 0.7963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1970/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0686 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2792 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1971/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0685 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2702 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1972/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0684 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2805 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1973/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0683 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2715 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1974/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0682 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2818 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1975/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0682 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2728 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1976/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0681 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2830 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1977/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0680 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2741 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1978/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0679 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2843 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1979/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0678 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2754 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1980/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0678 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2856 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1981/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0677 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2768 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1982/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0676 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2868 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1983/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0675 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2781 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1984/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0674 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2881 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1985/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0673 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2794 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1986/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0673 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2893 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1987/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0672 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2807 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1988/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0671 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2906 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1989/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0670 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2820 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1990/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0670 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2918 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1991/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0669 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2833 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1992/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0668 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2931 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1993/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0667 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2845 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1994/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0666 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2943 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1995/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0665 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2858 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1996/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0665 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2956 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1997/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0664 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2871 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1998/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0663 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2968 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 1999/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0662 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2884 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2000/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0662 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2980 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2001/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0661 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2897 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2002/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0660 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2993 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2003/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0659 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2910 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2004/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0658 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3005 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2005/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0658 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2922 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2006/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0657 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3017 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2007/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0656 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2935 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2008/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0655 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3029 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2009/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0655 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2948 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2010/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0654 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3042 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2011/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0653 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2961 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2012/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0652 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3054 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2013/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0651 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2973 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2014/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0651 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3066 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2015/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0650 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2986 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2016/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0649 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3078 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2017/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0648 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.2998 - val_acc: 0.7917 - val_auc_1: 0.7963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2018/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0648 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3090 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2019/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0647 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3011 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2020/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0646 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3102 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2021/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0645 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3023 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2022/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0645 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3114 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2023/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0644 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3036 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2024/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0643 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3126 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2025/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0642 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3049 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2026/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0642 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3138 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2027/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0641 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3061 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2028/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0640 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3150 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2029/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0639 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3073 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2030/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0639 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3162 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2031/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0638 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3086 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2032/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0637 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3174 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2033/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0636 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3098 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2034/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0636 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3186 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2035/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0635 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3111 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2036/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0634 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3198 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2037/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0633 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3123 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2038/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0633 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3209 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2039/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0632 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3135 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2040/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0631 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3221 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2041/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0630 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3148 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2042/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0630 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3233 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2043/3000\n",
      "92/92 [==============================] - 0s 185us/step - loss: 0.0629 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3160 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2044/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0628 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3245 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2045/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0627 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3172 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2046/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0627 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3256 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2047/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0626 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3184 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2048/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0625 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3268 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2049/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0624 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3196 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2050/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0624 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3280 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2051/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0623 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3209 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2052/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0622 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3291 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2053/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0622 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3221 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2054/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0621 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3303 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2055/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0620 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3233 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2056/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0619 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3314 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2057/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0619 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3245 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2058/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0618 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3326 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2059/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0617 - acc: 0.9674 - auc_1: 0.9980 - val_loss: 1.3257 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2060/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0616 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3338 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2061/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0616 - acc: 0.9674 - auc_1: 0.9980 - val_loss: 1.3269 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2062/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0615 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3349 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2063/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0614 - acc: 0.9674 - auc_1: 0.9980 - val_loss: 1.3281 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2064/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0614 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3360 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2065/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0613 - acc: 0.9674 - auc_1: 0.9980 - val_loss: 1.3293 - val_acc: 0.7917 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2066/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0612 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3372 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2067/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0611 - acc: 0.9674 - auc_1: 0.9980 - val_loss: 1.3305 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2068/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0611 - acc: 0.9565 - auc_1: 0.9980 - val_loss: 1.3383 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2069/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0610 - acc: 0.9674 - auc_1: 0.9980 - val_loss: 1.3317 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2070/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0609 - acc: 0.9674 - auc_1: 0.9980 - val_loss: 1.3395 - val_acc: 0.7917 - val_auc_1: 0.7963\n",
      "Epoch 2071/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0609 - acc: 0.9674 - auc_1: 0.9980 - val_loss: 1.3329 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2072/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0608 - acc: 0.9674 - auc_1: 0.9980 - val_loss: 1.3406 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2073/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0607 - acc: 0.9674 - auc_1: 0.9983 - val_loss: 1.3341 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2074/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0607 - acc: 0.9674 - auc_1: 0.9983 - val_loss: 1.3417 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2075/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0606 - acc: 0.9674 - auc_1: 0.9983 - val_loss: 1.3353 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2076/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0605 - acc: 0.9674 - auc_1: 0.9985 - val_loss: 1.3429 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2077/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0604 - acc: 0.9674 - auc_1: 0.9983 - val_loss: 1.3365 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2078/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0604 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3440 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2079/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0603 - acc: 0.9674 - auc_1: 0.9985 - val_loss: 1.3377 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2080/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0602 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3451 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2081/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0602 - acc: 0.9674 - auc_1: 0.9985 - val_loss: 1.3389 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2082/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0601 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3463 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2083/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0600 - acc: 0.9674 - auc_1: 0.9985 - val_loss: 1.3400 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2084/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0600 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3474 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2085/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0599 - acc: 0.9674 - auc_1: 0.9985 - val_loss: 1.3412 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2086/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0598 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3485 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2087/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0597 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3424 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2088/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0597 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3496 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2089/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0596 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3436 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2090/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0595 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3507 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2091/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0595 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3447 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2092/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0594 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3519 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2093/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0593 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3459 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2094/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0593 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3530 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2095/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0592 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3471 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2096/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0591 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3541 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2097/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0591 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3483 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2098/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0590 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3552 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2099/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0589 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3494 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2100/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0589 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3563 - val_acc: 0.7917 - val_auc_1: 0.7778\n",
      "Epoch 2101/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0588 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3506 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2102/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0587 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 1.3574 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2103/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0586 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3517 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2104/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0586 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 1.3585 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2105/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0585 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3529 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2106/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0584 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 1.3596 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2107/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0584 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3541 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2108/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0583 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 1.3607 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2109/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0582 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3552 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2110/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0582 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 1.3618 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2111/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0581 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3564 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2112/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0580 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3629 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2113/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0580 - acc: 0.9783 - auc_1: 0.9985 - val_loss: 1.3575 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2114/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0579 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3640 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2115/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0578 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 1.3587 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2116/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0578 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3651 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2117/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0577 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 1.3598 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2118/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0576 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3661 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2119/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0576 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3610 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2120/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0575 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3672 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2121/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0574 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3622 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2122/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0574 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3683 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2123/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0573 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3633 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2124/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0572 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3694 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2125/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0572 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3644 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2126/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0571 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3705 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2127/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0570 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3656 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2128/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0570 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3716 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2129/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0569 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3667 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2130/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0569 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3726 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2131/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0568 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3679 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2132/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0567 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3737 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2133/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0567 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3690 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2134/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0566 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3748 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2135/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0565 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3702 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2136/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0565 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3759 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2137/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0564 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3713 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2138/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0563 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3769 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2139/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0563 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3724 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2140/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0562 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3780 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2141/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0561 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3736 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2142/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0561 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3791 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2143/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0560 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3747 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2144/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0559 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3801 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2145/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0559 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3758 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2146/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0558 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3812 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2147/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0558 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3770 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2148/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0557 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3823 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2149/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0556 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3781 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2150/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0556 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3833 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2151/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0555 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3793 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2152/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0554 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3844 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2153/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0554 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3804 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2154/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0553 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3855 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2155/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0552 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3815 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2156/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0552 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3865 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2157/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0551 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3826 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2158/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0551 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3876 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2159/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0550 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3838 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2160/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0549 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3887 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2161/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0549 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3849 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2162/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0548 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3897 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2163/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0547 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3860 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2164/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0547 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3908 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2165/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0546 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3872 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2166/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0545 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3918 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2167/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0545 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3883 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2168/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0544 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3929 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2169/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0544 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3894 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2170/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0543 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3939 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2171/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0542 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3905 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2172/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0542 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3950 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2173/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0541 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3917 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2174/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0541 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3961 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2175/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0540 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3928 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2176/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0539 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3971 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2177/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0539 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3939 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2178/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0538 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3982 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2179/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0537 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3950 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2180/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0537 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3992 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2181/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0536 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3962 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2182/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0536 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4003 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2183/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0535 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3973 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2184/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0534 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4013 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2185/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0534 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3984 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2186/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0533 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4024 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2187/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0533 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3995 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2188/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0532 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4034 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2189/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0531 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4007 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2190/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0531 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4045 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2191/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0530 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4018 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2192/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0529 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4055 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2193/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0529 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4029 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2194/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0528 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4066 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2195/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0528 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4040 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2196/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0527 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4077 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2197/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0526 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4052 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2198/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0526 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4087 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2199/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0525 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4063 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2200/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0525 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4098 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2201/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0524 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4074 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2202/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0523 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4108 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2203/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0523 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4085 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2204/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0522 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4119 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2205/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0522 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4097 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2206/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0521 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4129 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2207/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0520 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4108 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2208/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0520 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4140 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2209/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0519 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4119 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2210/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0519 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4150 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2211/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0518 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4130 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2212/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0517 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4161 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2213/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0517 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4142 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2214/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0516 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4172 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2215/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0516 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4153 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2216/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0515 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4182 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2217/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0515 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4164 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2218/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0514 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4193 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2219/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0513 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4176 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2220/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0513 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4203 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2221/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0512 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4187 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2222/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0512 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4214 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2223/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0511 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4198 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2224/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0510 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4225 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2225/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0510 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4209 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2226/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0509 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4235 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2227/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0509 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4221 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2228/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0508 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4246 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2229/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0508 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4232 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2230/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0507 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4257 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2231/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0506 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.4243 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2232/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0506 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.4267 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2233/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0505 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.4255 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2234/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0505 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.4278 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2235/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0504 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4266 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2236/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0503 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.4289 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2237/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0503 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4277 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2238/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0502 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.4300 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2239/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0502 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4289 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2240/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0501 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.4310 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2241/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0501 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4300 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2242/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0500 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4321 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2243/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0499 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4311 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2244/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0499 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4332 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2245/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0498 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4323 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2246/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0498 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4343 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2247/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0497 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4334 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2248/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0497 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4354 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2249/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0496 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4346 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2250/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0495 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4364 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2251/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0495 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4357 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2252/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0494 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4375 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2253/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0494 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4368 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2254/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0493 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4386 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2255/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0493 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4380 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2256/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0492 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4397 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2257/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0492 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4391 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2258/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0491 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4408 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2259/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0490 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4403 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2260/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0490 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4419 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2261/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0489 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4414 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2262/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0489 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4430 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2263/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0488 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4426 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2264/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0488 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4441 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2265/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0487 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4437 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2266/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0486 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4452 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2267/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0486 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4449 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2268/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0485 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4463 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2269/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0485 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4460 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2270/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0484 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4474 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2271/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0484 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4472 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2272/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0483 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4485 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2273/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0483 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4483 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2274/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0482 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4497 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2275/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0482 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4495 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2276/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0481 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4508 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2277/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0480 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4506 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2278/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0480 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4519 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2279/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0479 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4518 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2280/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0479 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4530 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2281/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0478 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4530 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2282/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0478 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4541 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2283/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0477 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4541 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2284/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0477 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4553 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2285/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0476 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4553 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2286/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0475 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4564 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2287/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0475 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4565 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2288/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0474 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4575 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2289/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0474 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4576 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2290/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0473 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4587 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2291/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0473 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4588 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2292/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0472 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4598 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2293/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0472 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4600 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2294/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0471 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4610 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2295/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0471 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4611 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2296/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0470 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4621 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2297/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0470 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4623 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2298/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0469 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4633 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2299/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0468 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4635 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2300/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0468 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4644 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2301/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0467 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4647 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2302/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0467 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4656 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2303/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0466 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4659 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2304/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0466 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4667 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2305/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0465 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4670 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2306/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0465 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4679 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2307/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0464 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4682 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2308/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0464 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4691 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2309/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0463 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4694 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2310/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0463 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4702 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2311/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0462 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4706 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2312/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0462 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4714 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2313/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0461 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4718 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2314/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0460 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4726 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2315/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0460 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4730 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2316/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0459 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4738 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2317/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0459 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4742 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2318/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0458 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4750 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2319/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0458 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4754 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2320/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0457 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4762 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2321/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0457 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4766 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2322/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0456 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4773 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2323/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0456 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4778 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2324/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0455 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4785 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2325/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0455 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4790 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2326/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0454 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4797 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2327/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0454 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4802 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2328/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0453 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4809 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2329/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0453 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4814 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2330/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0452 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4821 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2331/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0452 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4826 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2332/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0451 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4833 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2333/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0451 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4839 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2334/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0450 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4846 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2335/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0450 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4851 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2336/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0449 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4858 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2337/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0449 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4863 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2338/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0448 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4870 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2339/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0447 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4875 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2340/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0447 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4882 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2341/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0446 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4888 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2342/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0446 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4894 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2343/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0445 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4900 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2344/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0445 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4907 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2345/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0444 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4912 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2346/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0444 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4919 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2347/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0443 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4925 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2348/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0443 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4931 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2349/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0442 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4937 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2350/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0442 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4944 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2351/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0441 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4949 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2352/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0441 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4956 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2353/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0440 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4962 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2354/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0440 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4968 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2355/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0439 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4974 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2356/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0439 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4981 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2357/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0438 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4987 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2358/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0438 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4993 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2359/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0437 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4999 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2360/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0437 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5006 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2361/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0436 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5012 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2362/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0436 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5018 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2363/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0435 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5025 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2364/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0435 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5031 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2365/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0434 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5037 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2366/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0434 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5044 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2367/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0433 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5050 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2368/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0433 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5056 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2369/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0432 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5063 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2370/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0432 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5069 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2371/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0431 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5075 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2372/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0431 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5082 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2373/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0430 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5088 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2374/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0430 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5094 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2375/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0429 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5101 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2376/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0429 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5107 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2377/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0428 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5114 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2378/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0428 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5120 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2379/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0427 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5126 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2380/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0427 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5133 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2381/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0426 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5139 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2382/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0426 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5146 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2383/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0425 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5152 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2384/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0425 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5159 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2385/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0424 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5165 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2386/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0424 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5171 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2387/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0424 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5178 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2388/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0423 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5184 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2389/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0423 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5191 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2390/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0422 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5197 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2391/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0422 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5204 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2392/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0421 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5210 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2393/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0421 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5217 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2394/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0420 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5223 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2395/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0420 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5230 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2396/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0419 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5236 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2397/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0419 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5243 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2398/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0418 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5250 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2399/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0418 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5256 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2400/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0417 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5263 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2401/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0417 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5269 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2402/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0416 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5276 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2403/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0416 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5282 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2404/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0415 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5289 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2405/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0415 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5295 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2406/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0414 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5302 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2407/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0414 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5309 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2408/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0413 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5315 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2409/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0413 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5322 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2410/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0413 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5329 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2411/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0412 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5335 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2412/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0412 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5342 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2413/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0411 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5348 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2414/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0411 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5355 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2415/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0410 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5362 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2416/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0410 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5368 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2417/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0409 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5375 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2418/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0409 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5382 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2419/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0408 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5388 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2420/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0408 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5395 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2421/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0407 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5402 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2422/3000\n",
      "92/92 [==============================] - 0s 207us/step - loss: 0.0407 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5409 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2423/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0406 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5415 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2424/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0406 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5422 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2425/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0405 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5429 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2426/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0405 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5435 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2427/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0405 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5442 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2428/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0404 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5449 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2429/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0404 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5456 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2430/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0403 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5462 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2431/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0403 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5469 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2432/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0402 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5476 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2433/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0402 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5483 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2434/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0401 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5489 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2435/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0401 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5496 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2436/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0400 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5503 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2437/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0400 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5510 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2438/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0399 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5516 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2439/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0399 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5523 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2440/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0399 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5530 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2441/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0398 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5537 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2442/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0398 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5544 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2443/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0397 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5550 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2444/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0397 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5557 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2445/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0396 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5564 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2446/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0396 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5571 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2447/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0395 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5578 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2448/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0395 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5585 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2449/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0394 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5591 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2450/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0394 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5598 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2451/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0394 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5605 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2452/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0393 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5612 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2453/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0393 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5619 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2454/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0392 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5626 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2455/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0392 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5633 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2456/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0391 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5639 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2457/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0391 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5646 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2458/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0390 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5653 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2459/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0390 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5660 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2460/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0390 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5667 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2461/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0389 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5674 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2462/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0389 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5681 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2463/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0388 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5688 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2464/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0388 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5695 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2465/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0387 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5701 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2466/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0387 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5708 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2467/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0386 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5715 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2468/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0386 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5722 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2469/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0386 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5729 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2470/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0385 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5736 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2471/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0385 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5743 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2472/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0384 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5750 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2473/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0384 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5757 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2474/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0383 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5764 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2475/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0383 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5771 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2476/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0382 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5778 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2477/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0382 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5785 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2478/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0382 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5792 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2479/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0381 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5799 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2480/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0381 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5806 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2481/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0380 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5813 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2482/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0380 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5820 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2483/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0379 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5827 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2484/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0379 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5834 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2485/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0378 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5840 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2486/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0378 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5847 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2487/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0378 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5854 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2488/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0377 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5861 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2489/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0377 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5868 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2490/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0376 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5875 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2491/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0376 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5882 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2492/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0375 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5889 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2493/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0375 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5896 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2494/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0375 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5903 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2495/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0374 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5910 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2496/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0374 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5917 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2497/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0373 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5924 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2498/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0373 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5931 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2499/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0372 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5938 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2500/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0372 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5946 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2501/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0372 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5953 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2502/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0371 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5960 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2503/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0371 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5967 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2504/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0370 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5974 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2505/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0370 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5981 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2506/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0369 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5988 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2507/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0369 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5995 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2508/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0369 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6002 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2509/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0368 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6009 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2510/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0368 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6016 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2511/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0367 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6023 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2512/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0367 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6030 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2513/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0366 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6037 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2514/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0366 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6044 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2515/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0366 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6051 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2516/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0365 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6058 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2517/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0365 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6065 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2518/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0364 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6072 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2519/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0364 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6079 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2520/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0363 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6086 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2521/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0363 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6093 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2522/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0363 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6100 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2523/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0362 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6107 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2524/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0362 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6114 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2525/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0361 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6121 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2526/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0361 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6128 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2527/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0361 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6136 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2528/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0360 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6143 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2529/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0360 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6150 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2530/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0359 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6157 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2531/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0359 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6164 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2532/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0358 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6171 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2533/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0358 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6178 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2534/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0358 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6185 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2535/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0357 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6192 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2536/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0357 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6199 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2537/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0356 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6206 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2538/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0356 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6213 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2539/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0355 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6220 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2540/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0355 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6227 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2541/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0355 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6234 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2542/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0354 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6241 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2543/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0354 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6248 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2544/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0353 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6255 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2545/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0353 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 1.6262 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2546/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0353 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 1.6269 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2547/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0352 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 1.6276 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2548/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0352 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 1.6283 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2549/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0351 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 1.6290 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2550/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0351 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6297 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2551/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0351 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6304 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2552/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0350 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6312 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2553/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0350 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6319 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2554/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0349 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6326 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2555/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0349 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6333 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2556/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0348 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6340 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2557/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0348 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6347 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2558/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0348 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6354 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2559/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0347 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6361 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2560/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0347 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6368 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2561/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0346 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6375 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2562/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0346 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6382 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2563/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0346 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6389 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2564/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0345 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6396 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2565/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0345 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6403 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2566/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0344 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6410 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2567/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0344 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6417 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2568/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0344 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6424 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2569/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0343 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6431 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2570/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0343 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6438 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2571/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0342 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6445 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2572/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0342 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6452 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2573/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0341 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6459 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2574/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0341 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6466 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2575/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0341 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6473 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2576/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0340 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6480 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2577/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0340 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6487 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2578/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0339 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6493 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2579/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0339 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6500 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2580/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0339 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6507 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2581/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0338 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6514 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2582/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0338 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6521 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2583/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0337 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6528 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2584/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0337 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6535 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2585/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0337 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6542 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2586/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0336 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6549 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2587/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0336 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6556 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2588/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0335 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6563 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2589/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0335 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6570 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2590/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0335 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6577 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2591/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0334 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6584 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2592/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0334 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6590 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2593/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0333 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6597 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2594/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0333 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6604 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2595/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0333 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6611 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2596/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0332 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6618 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2597/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0332 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6625 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2598/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0331 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6632 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2599/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0331 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6639 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2600/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0331 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6645 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2601/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0330 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6652 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2602/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0330 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6659 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2603/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0329 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6666 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2604/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0329 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6673 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2605/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0329 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6680 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2606/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0328 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6686 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2607/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0328 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6693 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2608/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0327 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6700 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2609/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0327 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6707 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2610/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0326 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6714 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2611/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0326 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6721 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2612/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0326 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6727 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2613/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0325 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6734 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2614/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0325 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6741 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2615/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0324 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6748 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2616/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0324 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6754 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2617/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0324 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6761 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2618/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0323 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6768 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2619/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0323 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6775 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2620/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0322 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6781 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2621/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0322 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6788 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2622/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0322 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6795 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2623/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0321 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6802 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2624/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.0321 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6808 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2625/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0320 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6815 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2626/3000\n",
      "92/92 [==============================] - 0s 185us/step - loss: 0.0320 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6822 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2627/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0320 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6828 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2628/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0319 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6835 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2629/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0319 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6842 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2630/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0318 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6848 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2631/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0318 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6855 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2632/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0318 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6862 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2633/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0317 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6868 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2634/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0317 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6875 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2635/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0316 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6881 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2636/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0316 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6888 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2637/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0316 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6895 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2638/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0315 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6901 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2639/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0315 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6908 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2640/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0314 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6914 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2641/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0314 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6921 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2642/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0314 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6928 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2643/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0313 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6934 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2644/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0313 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6941 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2645/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0312 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6947 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2646/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0312 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6954 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2647/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0312 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6960 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2648/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0311 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6967 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2649/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0311 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6973 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2650/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0310 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6980 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2651/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0310 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6986 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2652/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0310 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6993 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2653/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0309 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6999 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2654/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0309 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7006 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2655/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0309 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7012 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2656/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0308 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7018 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2657/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0308 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7025 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2658/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0307 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7031 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2659/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0307 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7038 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2660/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0307 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7044 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2661/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0306 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7050 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2662/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0306 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7057 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2663/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0305 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7063 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2664/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0305 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7069 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2665/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0305 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7076 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2666/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0304 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7082 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2667/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0304 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7088 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2668/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0303 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7095 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2669/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0303 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7101 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2670/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0303 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7107 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2671/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0302 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7114 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2672/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0302 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7120 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2673/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0301 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7126 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2674/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0301 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7132 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2675/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0301 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7139 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2676/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0300 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7145 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2677/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0300 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7151 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2678/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0299 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7157 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2679/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0299 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7164 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2680/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0299 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7170 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2681/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0298 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7176 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2682/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0298 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7182 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2683/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0297 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7188 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2684/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0297 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7194 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2685/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0297 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7201 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2686/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0296 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7207 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2687/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0296 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7213 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2688/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0295 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7219 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2689/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0295 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7225 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2690/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0295 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7231 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2691/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0294 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7237 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2692/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0294 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7243 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2693/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0293 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7249 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2694/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0293 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7255 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2695/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0293 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7261 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2696/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0292 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7267 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2697/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0292 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7273 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2698/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0291 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7279 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2699/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0291 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7285 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2700/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0291 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7291 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2701/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0290 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7297 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2702/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0290 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7303 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2703/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0289 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7309 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2704/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0289 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7315 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2705/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0289 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7321 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2706/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0288 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7327 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2707/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0288 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7333 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2708/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0288 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7339 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2709/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0287 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7344 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2710/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0287 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7350 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2711/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0286 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7356 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2712/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0286 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7362 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2713/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0286 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7368 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2714/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0285 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7374 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2715/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0285 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7379 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2716/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0284 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7385 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2717/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0284 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7391 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2718/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0284 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7397 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2719/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0283 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7402 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2720/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0283 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7408 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2721/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0282 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7414 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2722/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0282 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7420 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2723/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0282 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7425 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2724/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0281 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7431 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2725/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0281 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7437 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2726/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0280 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7442 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2727/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0280 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7448 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2728/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0280 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7454 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2729/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0279 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7459 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2730/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0279 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7465 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2731/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0278 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7471 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2732/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0278 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7476 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2733/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0278 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7482 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2734/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0277 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7487 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2735/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0277 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7493 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2736/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0276 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7498 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2737/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0276 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7504 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2738/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0276 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7510 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2739/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0275 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7515 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2740/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0275 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7521 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2741/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0275 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7526 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2742/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0274 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7532 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2743/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0274 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7537 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2744/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0273 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7543 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2745/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0273 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7548 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2746/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0273 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7553 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2747/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0272 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7559 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2748/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0272 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7564 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2749/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0271 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7570 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2750/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0271 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7575 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2751/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0271 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7580 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2752/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0270 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7586 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2753/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0270 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7591 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2754/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0269 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7597 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2755/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0269 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7602 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2756/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0269 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7607 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2757/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0268 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7613 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2758/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0268 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7618 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2759/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0267 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7623 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2760/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0267 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7629 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2761/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0267 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7634 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2762/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0266 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7639 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2763/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0266 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7644 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2764/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0266 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7650 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2765/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0265 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7655 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2766/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0265 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7660 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2767/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0264 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7665 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2768/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0264 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7670 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2769/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0264 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7676 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2770/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0263 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7681 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2771/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0263 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7686 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2772/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0262 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7691 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2773/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0262 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7696 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2774/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0262 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7701 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2775/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0261 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7707 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2776/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0261 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7712 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2777/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0260 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7717 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2778/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0260 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7722 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2779/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0260 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7727 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2780/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0259 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7732 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2781/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0259 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7737 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2782/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0259 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7742 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2783/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0258 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7747 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2784/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0258 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7752 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2785/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0257 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7757 - val_acc: 0.7500 - val_auc_1: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2786/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0257 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7762 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2787/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0257 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7767 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2788/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0256 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7772 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2789/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0256 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7777 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2790/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0255 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7782 - val_acc: 0.7500 - val_auc_1: 0.7778\n",
      "Epoch 2791/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0255 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7787 - val_acc: 0.7500 - val_auc_1: 0.7741\n",
      "Epoch 2792/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0255 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7792 - val_acc: 0.7500 - val_auc_1: 0.7741\n",
      "Epoch 2793/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0254 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7797 - val_acc: 0.7500 - val_auc_1: 0.7741\n",
      "Epoch 2794/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0254 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7802 - val_acc: 0.7500 - val_auc_1: 0.7741\n",
      "Epoch 2795/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0254 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7807 - val_acc: 0.7500 - val_auc_1: 0.7741\n",
      "Epoch 2796/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0253 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7812 - val_acc: 0.7500 - val_auc_1: 0.7741\n",
      "Epoch 2797/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0253 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7817 - val_acc: 0.7500 - val_auc_1: 0.7741\n",
      "Epoch 2798/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0252 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7822 - val_acc: 0.7500 - val_auc_1: 0.7741\n",
      "Epoch 2799/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0252 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7827 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2800/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0252 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7832 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2801/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0251 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7837 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2802/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0251 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7842 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2803/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0250 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7846 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2804/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0250 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7851 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2805/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0250 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7856 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2806/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0249 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7861 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2807/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0249 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7866 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2808/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0249 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7871 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2809/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0248 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7875 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2810/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0248 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7880 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2811/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0247 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7885 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2812/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0247 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7890 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2813/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0247 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7895 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2814/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0246 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7899 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2815/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0246 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7904 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2816/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0245 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7909 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2817/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0245 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7914 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2818/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0245 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7918 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2819/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0244 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7923 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2820/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0244 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7928 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2821/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0244 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7933 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2822/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0243 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7937 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2823/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0243 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7942 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2824/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0242 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7947 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2825/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0242 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7951 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2826/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0242 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7956 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2827/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0241 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7961 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2828/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0241 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7965 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2829/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0241 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7970 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2830/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0240 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7975 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2831/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0240 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7979 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2832/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0239 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7984 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2833/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0239 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7989 - val_acc: 0.7500 - val_auc_1: 0.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2834/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0239 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7993 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2835/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0238 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7998 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2836/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0238 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8003 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2837/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0238 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8007 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2838/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0237 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8012 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2839/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0237 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8016 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2840/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0236 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8021 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2841/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0236 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8025 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2842/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0236 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8030 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2843/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0235 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8035 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2844/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0235 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8039 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2845/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0235 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8044 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2846/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0234 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8048 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2847/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0234 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8053 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2848/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0233 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8057 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2849/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0233 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8062 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2850/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0233 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8066 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2851/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0232 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8071 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2852/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0232 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8075 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2853/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0232 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8080 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2854/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0231 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8084 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2855/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0231 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8089 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2856/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0230 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8093 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2857/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0230 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8098 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2858/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0230 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8102 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2859/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0229 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8107 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2860/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0229 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8111 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2861/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0229 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8116 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2862/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0228 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8120 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2863/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0228 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8125 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2864/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0227 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8129 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2865/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0227 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8134 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2866/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0227 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8138 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2867/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0226 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8142 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2868/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0226 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8147 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2869/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0226 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8151 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2870/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0225 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8156 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2871/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0225 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8160 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2872/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0225 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8164 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2873/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0224 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8169 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2874/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0224 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8173 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2875/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0223 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8178 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2876/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0223 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8182 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2877/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0223 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8186 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2878/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0222 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8191 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2879/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0222 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8195 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2880/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0222 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8199 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2881/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0221 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8204 - val_acc: 0.7500 - val_auc_1: 0.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2882/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0221 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8208 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2883/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0221 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8213 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2884/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0220 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8217 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2885/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0220 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8221 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2886/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0219 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8226 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2887/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0219 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8230 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2888/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0219 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8234 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2889/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0218 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8239 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2890/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0218 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8243 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2891/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0218 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8247 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2892/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0217 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8251 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2893/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0217 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8256 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2894/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0217 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8260 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2895/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0216 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8264 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2896/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0216 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8269 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2897/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0215 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8273 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2898/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0215 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8277 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2899/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0215 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8282 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2900/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0214 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8286 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2901/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0214 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8290 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2902/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0214 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8294 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2903/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0213 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8299 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2904/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0213 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8303 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2905/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0213 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8307 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2906/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0212 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8311 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2907/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0212 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8316 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2908/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0212 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8320 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2909/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0211 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8324 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2910/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0211 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8328 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2911/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0211 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8333 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2912/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0210 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8337 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2913/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0210 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8341 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2914/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0209 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8345 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2915/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0209 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8350 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2916/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0209 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8354 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2917/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0208 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8358 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2918/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0208 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8362 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2919/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0208 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8367 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2920/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0207 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8371 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2921/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0207 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8375 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2922/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0207 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8379 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2923/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0206 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8383 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2924/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0206 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8388 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2925/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0206 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8392 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2926/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0205 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8396 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2927/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0205 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8400 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2928/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0205 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8404 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2929/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0204 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8409 - val_acc: 0.7500 - val_auc_1: 0.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2930/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0204 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8413 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2931/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0204 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8417 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2932/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0203 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8421 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2933/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0203 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8425 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2934/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0203 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8429 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2935/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0202 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8434 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2936/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0202 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8438 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2937/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0202 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8442 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2938/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0201 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8446 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2939/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0201 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8450 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2940/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0200 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8454 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2941/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0200 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8459 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2942/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0200 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8463 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2943/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0199 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8467 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2944/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0199 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8471 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2945/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0199 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8475 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2946/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0198 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8479 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2947/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0198 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8483 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2948/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0198 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8488 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2949/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0197 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8492 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2950/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0197 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8496 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2951/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0197 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8500 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2952/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0196 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8504 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2953/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0196 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8508 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2954/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0196 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8512 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2955/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0195 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8516 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2956/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0195 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8521 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2957/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0195 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8525 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2958/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0194 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8529 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2959/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0194 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8533 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2960/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0194 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8537 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2961/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0193 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8541 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2962/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0193 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8545 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2963/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0193 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8549 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2964/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0192 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8553 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2965/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0192 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8558 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2966/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0192 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8562 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2967/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0191 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8566 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2968/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0191 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8570 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2969/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0191 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8574 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2970/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0190 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8578 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2971/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0190 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8582 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2972/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0190 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8586 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2973/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0189 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8590 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2974/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0189 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8594 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2975/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0189 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8598 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2976/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0189 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8603 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2977/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0188 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8607 - val_acc: 0.7500 - val_auc_1: 0.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2978/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0188 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8611 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2979/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0188 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8615 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2980/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0187 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8619 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2981/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0187 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8623 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2982/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0187 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8627 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2983/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0186 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8631 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2984/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0186 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8635 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2985/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0186 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8639 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2986/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0185 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8643 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2987/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0185 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8647 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2988/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0185 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8651 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2989/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0184 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8655 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2990/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0184 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8659 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2991/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0184 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8663 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2992/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0183 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8667 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2993/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0183 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8671 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2994/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0183 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8676 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2995/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0182 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8680 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2996/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0182 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8684 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2997/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0182 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8688 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2998/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0182 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8692 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 2999/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0181 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8696 - val_acc: 0.7500 - val_auc_1: 0.7704\n",
      "Epoch 3000/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0181 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8700 - val_acc: 0.7500 - val_auc_1: 0.7704\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4], Y, validation_split=0.2, epochs = 3000, batch_size = 92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.92293805, -0.01973957,  0.4909476 ,  0.5784587 ,  1.4190514 ,\n",
      "         1.0885419 , -0.57211614, -1.0861453 , -1.0525569 ],\n",
      "       [ 1.4419516 ,  1.8577743 ,  1.5976292 ,  2.3412657 , -0.78612   ,\n",
      "         0.47126198, -0.28444088, -1.3001678 , -1.6118292 ],\n",
      "       [-1.2921165 ,  0.68299294, -1.2692714 ,  1.0252382 , -0.2535342 ,\n",
      "        -0.71761155,  1.0828415 , -0.46717468, -0.67239517],\n",
      "       [ 1.9031463 , -1.0424744 ,  0.37903252, -0.47695315, -0.71708924,\n",
      "        -0.09298698,  0.44011366, -0.07852141, -0.0274884 ]],\n",
      "      dtype=float32), array([-0.33354023, -0.7908755 , -0.23712876, -0.40208402,  0.08010165,\n",
      "        0.1280512 , -0.23182449,  0.55417895,  0.18928789], dtype=float32), array([[ 0.59674984,  0.8772208 ,  1.7671219 , -0.67801094,  1.9692974 ,\n",
      "        -0.03588733,  1.8530796 ,  0.03480025,  3.5933151 ],\n",
      "       [-1.0090553 , -0.5093221 , -1.102645  , -0.5846472 , -0.91274667,\n",
      "         0.04003584,  0.43387583, -2.09877   , -0.39284614],\n",
      "       [ 0.91527003,  1.1757592 , -0.71430683, -0.7712712 ,  0.5743136 ,\n",
      "        -0.16112575,  1.3803467 , -0.06000554,  1.6787951 ],\n",
      "       [-2.6078944 , -0.16598237, -1.0081295 , -1.5153126 , -1.5475012 ,\n",
      "         0.44468087,  0.7684069 , -2.1246014 ,  1.5163575 ],\n",
      "       [-0.6145792 ,  1.2543143 ,  0.98306435,  1.9205769 , -1.2864674 ,\n",
      "        -1.3352015 ,  0.19458286,  0.09252095, -1.6021634 ],\n",
      "       [ 0.12068862,  2.0169513 ,  0.6330643 ,  1.3462403 , -0.34702566,\n",
      "        -1.4589497 ,  1.6924013 ,  1.5385168 ,  2.159966  ],\n",
      "       [-0.9942172 , -1.12435   ,  0.33706108, -0.3418697 ,  0.06796648,\n",
      "         0.67805356, -0.21117799, -0.5769945 , -0.4345601 ],\n",
      "       [ 2.198294  ,  0.34014514, -0.00474776,  0.80037624,  0.6095775 ,\n",
      "         0.504374  , -2.295359  ,  2.329218  , -0.9010973 ],\n",
      "       [ 1.5774907 , -0.3473031 ,  0.29520297,  1.1058546 ,  0.5904113 ,\n",
      "         0.41981488, -0.7622047 ,  1.033485  , -1.1705875 ]],\n",
      "      dtype=float32), array([ 0.13166858,  0.23635887,  0.29186028,  0.15059467, -0.24865437,\n",
      "       -0.09629908, -0.54650426,  1.3663259 ,  0.8583765 ], dtype=float32), array([[-0.08288058, -2.1759646 ,  1.2504196 , -2.9010031 ,  0.48179874,\n",
      "         1.981856  , -0.09774484, -1.474527  ,  1.7940723 ],\n",
      "       [ 0.3697267 ,  0.94088775, -2.422542  ,  1.9792873 ,  2.5506854 ,\n",
      "        -0.53625435, -1.7896103 ,  1.4418743 ,  1.1563703 ],\n",
      "       [-0.89507806,  0.04992097, -0.9582234 , -1.5944068 , -0.98710245,\n",
      "         1.1560351 , -2.3967583 , -0.06431018,  0.805568  ],\n",
      "       [-1.1570213 ,  1.5258923 , -1.2660033 , -0.06919537, -1.7419333 ,\n",
      "        -0.63364923,  0.38567922,  0.04237735, -0.88970757],\n",
      "       [-0.13673323,  0.41316718,  0.01693164, -1.4547174 , -1.0250018 ,\n",
      "         0.36256564, -2.5814254 , -2.6147757 ,  0.02005752],\n",
      "       [-0.728606  , -1.7016306 ,  2.6374586 , -1.3668659 , -1.4811934 ,\n",
      "         0.6621646 ,  1.7172258 , -2.5444818 , -0.33848664],\n",
      "       [ 3.1062226 ,  0.37343448,  0.13463204,  2.3549426 , -1.2227211 ,\n",
      "        -2.250415  , -1.1938246 ,  0.57745177,  0.17086932],\n",
      "       [-2.387025  ,  1.7587318 , -3.3745677 , -0.91222143, -0.5678383 ,\n",
      "         1.1513314 , -2.4678524 ,  0.4864159 , -2.4176917 ],\n",
      "       [ 1.6747257 , -0.8196398 ,  1.1468405 ,  2.210733  ,  0.09225097,\n",
      "        -1.8466989 , -0.90626407,  0.36279315, -0.8416601 ]],\n",
      "      dtype=float32), array([ 0.02644181, -0.5353218 , -0.2880684 , -0.46976584,  0.00190688,\n",
      "        0.24170691, -0.8281764 ,  0.13241966,  0.20003219], dtype=float32), array([[ 3.2482393],\n",
      "       [ 3.7443075],\n",
      "       [-3.1345384],\n",
      "       [ 3.2880409],\n",
      "       [-2.7479658],\n",
      "       [-2.4265032],\n",
      "       [ 3.5079548],\n",
      "       [ 3.6580656],\n",
      "       [-3.0994244]], dtype=float32), array([-0.567272], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.8695868e-01]\n",
      " [1.1042588e-03]\n",
      " [9.9999988e-01]\n",
      " [9.9999928e-01]\n",
      " [9.9975222e-01]\n",
      " [9.7809666e-01]\n",
      " [9.8715198e-01]\n",
      " [9.9880791e-01]\n",
      " [7.4824397e-06]\n",
      " [1.1494365e-01]\n",
      " [9.9997771e-01]\n",
      " [9.9999976e-01]\n",
      " [2.2884531e-07]\n",
      " [9.9680424e-01]\n",
      " [9.8662138e-01]\n",
      " [9.9830329e-01]\n",
      " [8.5792845e-01]\n",
      " [9.8854107e-01]\n",
      " [9.9999976e-01]\n",
      " [2.6504474e-04]\n",
      " [9.5769393e-01]\n",
      " [1.2367156e-02]\n",
      " [9.9789482e-01]\n",
      " [9.9630606e-01]\n",
      " [1.0000000e+00]\n",
      " [3.1397242e-06]\n",
      " [9.9978119e-01]\n",
      " [1.8930907e-05]\n",
      " [2.8684026e-02]\n",
      " [9.9999964e-01]\n",
      " [3.3749357e-02]\n",
      " [9.9637395e-01]\n",
      " [9.8892689e-01]\n",
      " [1.2397629e-03]\n",
      " [1.8565806e-04]\n",
      " [9.9859685e-01]\n",
      " [1.8348315e-05]\n",
      " [9.9903917e-01]\n",
      " [1.1784247e-01]\n",
      " [4.1028036e-07]\n",
      " [9.9997473e-01]\n",
      " [4.9260459e-03]\n",
      " [9.9666214e-01]\n",
      " [9.9861932e-01]\n",
      " [9.8140258e-01]\n",
      " [9.7239201e-05]\n",
      " [9.8612052e-01]\n",
      " [9.9987853e-01]\n",
      " [9.7417194e-01]\n",
      " [8.7884301e-04]\n",
      " [1.9271776e-05]\n",
      " [9.9999249e-01]\n",
      " [9.9998951e-01]\n",
      " [2.1064213e-07]\n",
      " [1.0000000e+00]\n",
      " [3.5051957e-01]\n",
      " [9.8878074e-01]\n",
      " [1.9453650e-03]\n",
      " [3.3418903e-05]\n",
      " [8.8203466e-03]\n",
      " [9.9999905e-01]\n",
      " [9.9997723e-01]\n",
      " [1.7301365e-03]\n",
      " [9.7063375e-01]\n",
      " [1.7991627e-03]\n",
      " [5.8939096e-02]\n",
      " [7.4036068e-01]\n",
      " [9.9998736e-01]\n",
      " [1.4656582e-06]\n",
      " [2.8366692e-04]\n",
      " [9.4734198e-01]\n",
      " [1.5851994e-05]\n",
      " [9.9674690e-01]\n",
      " [2.5587074e-02]\n",
      " [9.9981457e-01]\n",
      " [1.8696020e-04]\n",
      " [9.9999058e-01]\n",
      " [5.5733197e-03]\n",
      " [9.9999988e-01]\n",
      " [1.5629646e-03]\n",
      " [1.0000000e+00]\n",
      " [9.9802470e-01]\n",
      " [2.6533687e-03]\n",
      " [9.9795532e-01]\n",
      " [9.9999571e-01]\n",
      " [1.3353187e-02]\n",
      " [9.9968350e-01]\n",
      " [4.0321313e-03]\n",
      " [1.0000000e+00]\n",
      " [9.9999976e-01]\n",
      " [9.9811447e-01]\n",
      " [9.9988043e-01]\n",
      " [9.9996710e-01]\n",
      " [1.4764363e-04]\n",
      " [3.1305185e-06]\n",
      " [2.7453422e-04]\n",
      " [9.2284630e-05]\n",
      " [9.5231742e-01]\n",
      " [5.5990437e-05]\n",
      " [7.5663964e-05]\n",
      " [9.9995637e-01]\n",
      " [2.6033042e-06]\n",
      " [5.2616560e-08]\n",
      " [9.9968994e-01]\n",
      " [6.7714696e-05]\n",
      " [2.0202177e-05]\n",
      " [8.8804859e-01]\n",
      " [9.9984944e-01]\n",
      " [9.9999404e-01]\n",
      " [9.9980885e-01]\n",
      " [9.9999988e-01]\n",
      " [7.5322583e-05]\n",
      " [7.2368008e-01]\n",
      " [1.5069265e-04]\n",
      " [2.0400854e-05]\n",
      " [9.6360362e-01]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
