{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,2:3] #Glucose\n",
    "X2 = dataset[:,7:8] #Resistin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,1:2] #BMI\n",
    "X5 = dataset[:,4:5] #HOMA\n",
    "X6 = dataset[:,5:6] #Leptin\n",
    "X7 = dataset[:,3:4] #Insulin\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "X6 = normalization(X6)\n",
    "X7 = normalization(X7)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X6 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X7 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 7)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "                                                                 input_layer_X6[0][0]             \n",
      "                                                                 input_layer_X7[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            72          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 262\n",
      "Trainable params: 262\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "input_layer_X6 = keras.layers.Input(shape=(1, ), name='input_layer_X6')\n",
    "input_layer_X7 = keras.layers.Input(shape=(1, ), name='input_layer_X7')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.7017 - acc: 0.5217 - auc_1: 0.5348 - val_loss: 0.6624 - val_acc: 0.7500 - val_auc_1: 0.6893\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6654 - acc: 0.5870 - auc_1: 0.6357 - val_loss: 0.6231 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6417 - acc: 0.6413 - auc_1: 0.6974 - val_loss: 0.5922 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6094 - acc: 0.6304 - auc_1: 0.7331 - val_loss: 0.5676 - val_acc: 0.7500 - val_auc_1: 0.7821\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5811 - acc: 0.6957 - auc_1: 0.7621 - val_loss: 0.5277 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5641 - acc: 0.6522 - auc_1: 0.7669 - val_loss: 0.5583 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5507 - acc: 0.7174 - auc_1: 0.7831 - val_loss: 0.5210 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5424 - acc: 0.6739 - auc_1: 0.7805 - val_loss: 0.5685 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5353 - acc: 0.7065 - auc_1: 0.7840 - val_loss: 0.5287 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5320 - acc: 0.6957 - auc_1: 0.7814 - val_loss: 0.6057 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5238 - acc: 0.7500 - auc_1: 0.8124 - val_loss: 0.5013 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5215 - acc: 0.7174 - auc_1: 0.8010 - val_loss: 0.5407 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5182 - acc: 0.7500 - auc_1: 0.8081 - val_loss: 0.5559 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5139 - acc: 0.7391 - auc_1: 0.8121 - val_loss: 0.6283 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5117 - acc: 0.7500 - auc_1: 0.8181 - val_loss: 0.4847 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5142 - acc: 0.7283 - auc_1: 0.8114 - val_loss: 0.5400 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5060 - acc: 0.7500 - auc_1: 0.8229 - val_loss: 0.4993 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5022 - acc: 0.7609 - auc_1: 0.8252 - val_loss: 0.4656 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5060 - acc: 0.7500 - auc_1: 0.8288 - val_loss: 0.5943 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5086 - acc: 0.7283 - auc_1: 0.8186 - val_loss: 0.5472 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4994 - acc: 0.7174 - auc_1: 0.8283 - val_loss: 0.6084 - val_acc: 0.6250 - val_auc_1: 0.9000\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5100 - acc: 0.7500 - auc_1: 0.8105 - val_loss: 0.5322 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4994 - acc: 0.7609 - auc_1: 0.8312 - val_loss: 0.4733 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5059 - acc: 0.7717 - auc_1: 0.8257 - val_loss: 0.5460 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4991 - acc: 0.7283 - auc_1: 0.8214 - val_loss: 0.5361 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4967 - acc: 0.7391 - auc_1: 0.8276 - val_loss: 0.4980 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5033 - acc: 0.7391 - auc_1: 0.8245 - val_loss: 0.5090 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4988 - acc: 0.7283 - auc_1: 0.8271 - val_loss: 0.5444 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4926 - acc: 0.7391 - auc_1: 0.8321 - val_loss: 0.5866 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5040 - acc: 0.7609 - auc_1: 0.8188 - val_loss: 0.5450 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4870 - acc: 0.7935 - auc_1: 0.8390 - val_loss: 0.5813 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4962 - acc: 0.7500 - auc_1: 0.8333 - val_loss: 0.5030 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4949 - acc: 0.7609 - auc_1: 0.8352 - val_loss: 0.5342 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4907 - acc: 0.7500 - auc_1: 0.8319 - val_loss: 0.4815 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4920 - acc: 0.7391 - auc_1: 0.8467 - val_loss: 0.5521 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5064 - acc: 0.7609 - auc_1: 0.8310 - val_loss: 0.4621 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4900 - acc: 0.7609 - auc_1: 0.8360 - val_loss: 0.5439 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4843 - acc: 0.7609 - auc_1: 0.8424 - val_loss: 0.5794 - val_acc: 0.6667 - val_auc_1: 0.9143\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4910 - acc: 0.7500 - auc_1: 0.8350 - val_loss: 0.5092 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4868 - acc: 0.7391 - auc_1: 0.8352 - val_loss: 0.5134 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4798 - acc: 0.7500 - auc_1: 0.8436 - val_loss: 0.5995 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4786 - acc: 0.7609 - auc_1: 0.8457 - val_loss: 0.4822 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4852 - acc: 0.7717 - auc_1: 0.8386 - val_loss: 0.4891 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4913 - acc: 0.7609 - auc_1: 0.8360 - val_loss: 0.6060 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4910 - acc: 0.7609 - auc_1: 0.8383 - val_loss: 0.5591 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4861 - acc: 0.7391 - auc_1: 0.8457 - val_loss: 0.5282 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4731 - acc: 0.7609 - auc_1: 0.8548 - val_loss: 0.4981 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4817 - acc: 0.7609 - auc_1: 0.8431 - val_loss: 0.5096 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4814 - acc: 0.7717 - auc_1: 0.8417 - val_loss: 0.5924 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4705 - acc: 0.7826 - auc_1: 0.8529 - val_loss: 0.4938 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4884 - acc: 0.7609 - auc_1: 0.8417 - val_loss: 0.5473 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4800 - acc: 0.8043 - auc_1: 0.8486 - val_loss: 0.6483 - val_acc: 0.6250 - val_auc_1: 0.8857\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4825 - acc: 0.7717 - auc_1: 0.8429 - val_loss: 0.5688 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4778 - acc: 0.7609 - auc_1: 0.8479 - val_loss: 0.5479 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4733 - acc: 0.7500 - auc_1: 0.8517 - val_loss: 0.5273 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4638 - acc: 0.7500 - auc_1: 0.8548 - val_loss: 0.6082 - val_acc: 0.6667 - val_auc_1: 0.8929\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4755 - acc: 0.7717 - auc_1: 0.8502 - val_loss: 0.6060 - val_acc: 0.6667 - val_auc_1: 0.8929\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4772 - acc: 0.7500 - auc_1: 0.8505 - val_loss: 0.5999 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4670 - acc: 0.7826 - auc_1: 0.8507 - val_loss: 0.5232 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4828 - acc: 0.7391 - auc_1: 0.8374 - val_loss: 0.5790 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4679 - acc: 0.7500 - auc_1: 0.8576 - val_loss: 0.5395 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4691 - acc: 0.7717 - auc_1: 0.8481 - val_loss: 0.5074 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4591 - acc: 0.7826 - auc_1: 0.8581 - val_loss: 0.6601 - val_acc: 0.6250 - val_auc_1: 0.8786\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4701 - acc: 0.7826 - auc_1: 0.8519 - val_loss: 0.5839 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4683 - acc: 0.7609 - auc_1: 0.8560 - val_loss: 0.5870 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4562 - acc: 0.7826 - auc_1: 0.8731 - val_loss: 0.6659 - val_acc: 0.6250 - val_auc_1: 0.8786\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4724 - acc: 0.7717 - auc_1: 0.8529 - val_loss: 0.6425 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4527 - acc: 0.7935 - auc_1: 0.8676 - val_loss: 0.5206 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4664 - acc: 0.7609 - auc_1: 0.8481 - val_loss: 0.5755 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4571 - acc: 0.7609 - auc_1: 0.8638 - val_loss: 0.5637 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4552 - acc: 0.7717 - auc_1: 0.8652 - val_loss: 0.6237 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4547 - acc: 0.7717 - auc_1: 0.8660 - val_loss: 0.6007 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4548 - acc: 0.7500 - auc_1: 0.8719 - val_loss: 0.5551 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4557 - acc: 0.7717 - auc_1: 0.8690 - val_loss: 0.5839 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4469 - acc: 0.7935 - auc_1: 0.8712 - val_loss: 0.6268 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4590 - acc: 0.7391 - auc_1: 0.8617 - val_loss: 0.6187 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4477 - acc: 0.7717 - auc_1: 0.8740 - val_loss: 0.6027 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4525 - acc: 0.7935 - auc_1: 0.8695 - val_loss: 0.6348 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4439 - acc: 0.7609 - auc_1: 0.8748 - val_loss: 0.5844 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4353 - acc: 0.7935 - auc_1: 0.8790 - val_loss: 0.6818 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4483 - acc: 0.7826 - auc_1: 0.8607 - val_loss: 0.6031 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4468 - acc: 0.7826 - auc_1: 0.8690 - val_loss: 0.6217 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4434 - acc: 0.7935 - auc_1: 0.8807 - val_loss: 0.6031 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4397 - acc: 0.7935 - auc_1: 0.8764 - val_loss: 0.5682 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4351 - acc: 0.7935 - auc_1: 0.8819 - val_loss: 0.5612 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4355 - acc: 0.8043 - auc_1: 0.8869 - val_loss: 0.6395 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4307 - acc: 0.7609 - auc_1: 0.8888 - val_loss: 0.5691 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4377 - acc: 0.8043 - auc_1: 0.8762 - val_loss: 0.6013 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4361 - acc: 0.7935 - auc_1: 0.8826 - val_loss: 0.5813 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4296 - acc: 0.7935 - auc_1: 0.8881 - val_loss: 0.6287 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4211 - acc: 0.7717 - auc_1: 0.8926 - val_loss: 0.5914 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4234 - acc: 0.8152 - auc_1: 0.8924 - val_loss: 0.5679 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4240 - acc: 0.8152 - auc_1: 0.8938 - val_loss: 0.5939 - val_acc: 0.6250 - val_auc_1: 0.8250\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4249 - acc: 0.7935 - auc_1: 0.8921 - val_loss: 0.5815 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4206 - acc: 0.7935 - auc_1: 0.8900 - val_loss: 0.5846 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4258 - acc: 0.8370 - auc_1: 0.8860 - val_loss: 0.6156 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 97/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4145 - acc: 0.8152 - auc_1: 0.8974 - val_loss: 0.5655 - val_acc: 0.7083 - val_auc_1: 0.8286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4208 - acc: 0.7717 - auc_1: 0.8817 - val_loss: 0.5916 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4117 - acc: 0.8261 - auc_1: 0.8967 - val_loss: 0.5888 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4056 - acc: 0.8152 - auc_1: 0.9010 - val_loss: 0.5794 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4100 - acc: 0.8152 - auc_1: 0.8986 - val_loss: 0.5798 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4103 - acc: 0.8370 - auc_1: 0.8912 - val_loss: 0.6139 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3937 - acc: 0.8478 - auc_1: 0.9074 - val_loss: 0.5992 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4058 - acc: 0.8152 - auc_1: 0.8924 - val_loss: 0.5862 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3954 - acc: 0.8152 - auc_1: 0.9012 - val_loss: 0.5443 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3964 - acc: 0.8152 - auc_1: 0.9055 - val_loss: 0.5678 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3869 - acc: 0.8261 - auc_1: 0.9052 - val_loss: 0.6091 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3976 - acc: 0.8261 - auc_1: 0.8995 - val_loss: 0.5666 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3862 - acc: 0.8478 - auc_1: 0.9129 - val_loss: 0.5488 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3894 - acc: 0.8152 - auc_1: 0.9067 - val_loss: 0.5829 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3901 - acc: 0.8261 - auc_1: 0.9007 - val_loss: 0.5362 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3871 - acc: 0.7935 - auc_1: 0.9050 - val_loss: 0.5889 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3821 - acc: 0.8261 - auc_1: 0.9110 - val_loss: 0.5860 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3752 - acc: 0.8261 - auc_1: 0.9157 - val_loss: 0.5585 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3741 - acc: 0.8043 - auc_1: 0.9129 - val_loss: 0.6237 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3694 - acc: 0.8478 - auc_1: 0.9190 - val_loss: 0.5318 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3762 - acc: 0.8152 - auc_1: 0.9160 - val_loss: 0.5376 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3701 - acc: 0.8043 - auc_1: 0.9176 - val_loss: 0.5616 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3628 - acc: 0.8152 - auc_1: 0.9248 - val_loss: 0.5123 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3816 - acc: 0.8152 - auc_1: 0.9069 - val_loss: 0.5622 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3530 - acc: 0.8478 - auc_1: 0.9260 - val_loss: 0.5291 - val_acc: 0.8333 - val_auc_1: 0.8286\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3657 - acc: 0.8478 - auc_1: 0.9210 - val_loss: 0.5799 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3628 - acc: 0.8370 - auc_1: 0.9152 - val_loss: 0.5177 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3631 - acc: 0.8261 - auc_1: 0.9174 - val_loss: 0.5321 - val_acc: 0.6250 - val_auc_1: 0.8286\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3613 - acc: 0.8370 - auc_1: 0.9214 - val_loss: 0.5867 - val_acc: 0.6250 - val_auc_1: 0.8286\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3568 - acc: 0.8587 - auc_1: 0.9214 - val_loss: 0.5378 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3456 - acc: 0.8478 - auc_1: 0.9279 - val_loss: 0.5987 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3506 - acc: 0.8261 - auc_1: 0.9281 - val_loss: 0.5798 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3519 - acc: 0.8587 - auc_1: 0.9226 - val_loss: 0.5525 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3389 - acc: 0.8587 - auc_1: 0.9283 - val_loss: 0.5754 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3451 - acc: 0.8370 - auc_1: 0.9248 - val_loss: 0.5571 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3432 - acc: 0.8696 - auc_1: 0.9238 - val_loss: 0.5516 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3332 - acc: 0.8696 - auc_1: 0.9319 - val_loss: 0.5997 - val_acc: 0.6250 - val_auc_1: 0.8214\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3399 - acc: 0.8478 - auc_1: 0.9271 - val_loss: 0.6159 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3400 - acc: 0.8370 - auc_1: 0.9260 - val_loss: 0.6271 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3449 - acc: 0.8478 - auc_1: 0.9231 - val_loss: 0.5996 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3270 - acc: 0.8696 - auc_1: 0.9336 - val_loss: 0.5891 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3379 - acc: 0.8261 - auc_1: 0.9276 - val_loss: 0.6388 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3310 - acc: 0.8696 - auc_1: 0.9333 - val_loss: 0.6087 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3202 - acc: 0.8804 - auc_1: 0.9412 - val_loss: 0.6237 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3283 - acc: 0.8696 - auc_1: 0.9350 - val_loss: 0.6536 - val_acc: 0.6250 - val_auc_1: 0.8214\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3308 - acc: 0.8804 - auc_1: 0.9329 - val_loss: 0.6576 - val_acc: 0.6250 - val_auc_1: 0.8036\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3210 - acc: 0.8587 - auc_1: 0.9340 - val_loss: 0.6720 - val_acc: 0.6250 - val_auc_1: 0.8000\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3225 - acc: 0.8804 - auc_1: 0.9348 - val_loss: 0.6372 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 145/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3223 - acc: 0.8587 - auc_1: 0.9352 - val_loss: 0.6733 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 146/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3259 - acc: 0.8370 - auc_1: 0.9340 - val_loss: 0.6629 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3170 - acc: 0.8587 - auc_1: 0.9374 - val_loss: 0.6324 - val_acc: 0.7083 - val_auc_1: 0.7643\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3072 - acc: 0.8587 - auc_1: 0.9421 - val_loss: 0.6655 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3110 - acc: 0.8696 - auc_1: 0.9417 - val_loss: 0.6307 - val_acc: 0.7917 - val_auc_1: 0.7679\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3243 - acc: 0.8478 - auc_1: 0.9333 - val_loss: 0.6448 - val_acc: 0.6667 - val_auc_1: 0.7714\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3103 - acc: 0.8696 - auc_1: 0.9390 - val_loss: 0.6893 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3040 - acc: 0.8804 - auc_1: 0.9398 - val_loss: 0.6660 - val_acc: 0.7083 - val_auc_1: 0.7714\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3057 - acc: 0.8696 - auc_1: 0.9424 - val_loss: 0.7306 - val_acc: 0.6250 - val_auc_1: 0.7643\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3042 - acc: 0.8913 - auc_1: 0.9412 - val_loss: 0.6797 - val_acc: 0.7500 - val_auc_1: 0.7607\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3026 - acc: 0.8913 - auc_1: 0.9464 - val_loss: 0.6952 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3025 - acc: 0.8587 - auc_1: 0.9452 - val_loss: 0.6786 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3048 - acc: 0.8696 - auc_1: 0.9374 - val_loss: 0.7136 - val_acc: 0.6667 - val_auc_1: 0.7714\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2936 - acc: 0.8696 - auc_1: 0.9471 - val_loss: 0.7014 - val_acc: 0.6667 - val_auc_1: 0.7571\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2987 - acc: 0.8478 - auc_1: 0.9450 - val_loss: 0.7581 - val_acc: 0.6250 - val_auc_1: 0.7643\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3101 - acc: 0.8587 - auc_1: 0.9383 - val_loss: 0.7348 - val_acc: 0.6250 - val_auc_1: 0.7607\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2939 - acc: 0.8804 - auc_1: 0.9462 - val_loss: 0.7274 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2883 - acc: 0.8587 - auc_1: 0.9505 - val_loss: 0.6896 - val_acc: 0.6667 - val_auc_1: 0.7500\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2892 - acc: 0.8804 - auc_1: 0.9481 - val_loss: 0.6936 - val_acc: 0.6667 - val_auc_1: 0.7429\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2857 - acc: 0.9022 - auc_1: 0.9483 - val_loss: 0.7391 - val_acc: 0.6667 - val_auc_1: 0.7536\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2921 - acc: 0.8804 - auc_1: 0.9445 - val_loss: 0.7161 - val_acc: 0.6667 - val_auc_1: 0.7500\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2819 - acc: 0.8913 - auc_1: 0.9488 - val_loss: 0.7228 - val_acc: 0.7083 - val_auc_1: 0.7536\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2892 - acc: 0.8913 - auc_1: 0.9457 - val_loss: 0.7208 - val_acc: 0.7083 - val_auc_1: 0.7393\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2898 - acc: 0.8587 - auc_1: 0.9490 - val_loss: 0.7885 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2781 - acc: 0.8696 - auc_1: 0.9536 - val_loss: 0.7213 - val_acc: 0.7500 - val_auc_1: 0.7464\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2862 - acc: 0.8804 - auc_1: 0.9486 - val_loss: 0.7301 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2743 - acc: 0.8804 - auc_1: 0.9586 - val_loss: 0.7543 - val_acc: 0.7083 - val_auc_1: 0.7286\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2766 - acc: 0.8913 - auc_1: 0.9502 - val_loss: 0.7612 - val_acc: 0.7083 - val_auc_1: 0.7357\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2711 - acc: 0.9022 - auc_1: 0.9538 - val_loss: 0.7606 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2706 - acc: 0.8913 - auc_1: 0.9545 - val_loss: 0.7450 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2660 - acc: 0.8913 - auc_1: 0.9557 - val_loss: 0.7454 - val_acc: 0.7500 - val_auc_1: 0.7429\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2749 - acc: 0.8913 - auc_1: 0.9555 - val_loss: 0.7762 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2743 - acc: 0.8696 - auc_1: 0.9517 - val_loss: 0.7349 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2630 - acc: 0.9022 - auc_1: 0.9567 - val_loss: 0.7657 - val_acc: 0.7083 - val_auc_1: 0.7357\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2632 - acc: 0.8913 - auc_1: 0.9583 - val_loss: 0.7971 - val_acc: 0.7083 - val_auc_1: 0.7429\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2709 - acc: 0.8804 - auc_1: 0.9533 - val_loss: 0.7649 - val_acc: 0.7083 - val_auc_1: 0.7429\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2631 - acc: 0.9022 - auc_1: 0.9560 - val_loss: 0.7793 - val_acc: 0.7083 - val_auc_1: 0.7429\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2672 - acc: 0.9022 - auc_1: 0.9545 - val_loss: 0.7966 - val_acc: 0.7083 - val_auc_1: 0.7357\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2674 - acc: 0.8804 - auc_1: 0.9579 - val_loss: 0.7710 - val_acc: 0.7500 - val_auc_1: 0.7429\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2588 - acc: 0.9130 - auc_1: 0.9598 - val_loss: 0.7822 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2561 - acc: 0.9130 - auc_1: 0.9583 - val_loss: 0.7648 - val_acc: 0.8333 - val_auc_1: 0.7250\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2654 - acc: 0.8913 - auc_1: 0.9567 - val_loss: 0.8016 - val_acc: 0.7083 - val_auc_1: 0.7214\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2532 - acc: 0.9022 - auc_1: 0.9590 - val_loss: 0.7802 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2575 - acc: 0.8913 - auc_1: 0.9621 - val_loss: 0.7877 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2400 - acc: 0.9130 - auc_1: 0.9683 - val_loss: 0.8356 - val_acc: 0.5833 - val_auc_1: 0.7357\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2584 - acc: 0.8587 - auc_1: 0.9614 - val_loss: 0.7805 - val_acc: 0.7083 - val_auc_1: 0.7286\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2411 - acc: 0.9022 - auc_1: 0.9626 - val_loss: 0.8265 - val_acc: 0.7083 - val_auc_1: 0.7536\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2430 - acc: 0.9022 - auc_1: 0.9650 - val_loss: 0.7916 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2450 - acc: 0.9130 - auc_1: 0.9643 - val_loss: 0.8106 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 194/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2531 - acc: 0.9130 - auc_1: 0.9574 - val_loss: 0.8225 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2374 - acc: 0.9130 - auc_1: 0.9686 - val_loss: 0.8159 - val_acc: 0.7083 - val_auc_1: 0.7464\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2379 - acc: 0.9348 - auc_1: 0.9664 - val_loss: 0.8744 - val_acc: 0.7083 - val_auc_1: 0.7250\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2454 - acc: 0.8913 - auc_1: 0.9652 - val_loss: 0.8630 - val_acc: 0.7083 - val_auc_1: 0.7286\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2318 - acc: 0.8913 - auc_1: 0.9683 - val_loss: 0.8199 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2309 - acc: 0.9239 - auc_1: 0.9707 - val_loss: 0.9361 - val_acc: 0.5417 - val_auc_1: 0.7286\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2209 - acc: 0.8913 - auc_1: 0.9729 - val_loss: 0.8553 - val_acc: 0.7083 - val_auc_1: 0.7071\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2560 - acc: 0.9130 - auc_1: 0.9595 - val_loss: 0.8430 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2241 - acc: 0.9457 - auc_1: 0.9721 - val_loss: 0.8645 - val_acc: 0.7083 - val_auc_1: 0.7179\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2369 - acc: 0.9130 - auc_1: 0.9660 - val_loss: 0.9143 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2288 - acc: 0.9022 - auc_1: 0.9724 - val_loss: 0.8875 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2171 - acc: 0.8913 - auc_1: 0.9714 - val_loss: 0.8532 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2364 - acc: 0.9022 - auc_1: 0.9676 - val_loss: 0.8813 - val_acc: 0.7083 - val_auc_1: 0.7214\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2267 - acc: 0.9348 - auc_1: 0.9707 - val_loss: 0.8684 - val_acc: 0.7083 - val_auc_1: 0.7286\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2221 - acc: 0.9130 - auc_1: 0.9714 - val_loss: 0.8799 - val_acc: 0.7083 - val_auc_1: 0.7286\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2265 - acc: 0.9239 - auc_1: 0.9660 - val_loss: 0.9613 - val_acc: 0.5833 - val_auc_1: 0.7357\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2245 - acc: 0.9130 - auc_1: 0.9714 - val_loss: 0.8833 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2098 - acc: 0.9130 - auc_1: 0.9774 - val_loss: 0.9032 - val_acc: 0.5833 - val_auc_1: 0.7393\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2192 - acc: 0.9130 - auc_1: 0.9700 - val_loss: 0.9082 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2212 - acc: 0.8913 - auc_1: 0.9717 - val_loss: 0.9271 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2137 - acc: 0.9130 - auc_1: 0.9721 - val_loss: 0.8982 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2089 - acc: 0.9348 - auc_1: 0.9767 - val_loss: 0.9473 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2002 - acc: 0.9457 - auc_1: 0.9762 - val_loss: 0.9118 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1997 - acc: 0.9130 - auc_1: 0.9802 - val_loss: 0.9022 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2093 - acc: 0.9130 - auc_1: 0.9762 - val_loss: 0.9141 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2000 - acc: 0.9239 - auc_1: 0.9771 - val_loss: 0.9434 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1911 - acc: 0.9457 - auc_1: 0.9807 - val_loss: 0.8972 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1862 - acc: 0.9457 - auc_1: 0.9840 - val_loss: 1.0030 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1966 - acc: 0.9022 - auc_1: 0.9774 - val_loss: 0.9841 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2059 - acc: 0.9130 - auc_1: 0.9740 - val_loss: 0.9505 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1919 - acc: 0.9348 - auc_1: 0.9795 - val_loss: 0.9723 - val_acc: 0.5833 - val_auc_1: 0.7286\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1949 - acc: 0.9457 - auc_1: 0.9755 - val_loss: 0.9518 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1824 - acc: 0.9239 - auc_1: 0.9843 - val_loss: 0.9796 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1763 - acc: 0.9130 - auc_1: 0.9824 - val_loss: 1.0472 - val_acc: 0.5417 - val_auc_1: 0.7250\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1844 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.9759 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1812 - acc: 0.9457 - auc_1: 0.9829 - val_loss: 1.0518 - val_acc: 0.5833 - val_auc_1: 0.7071\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1874 - acc: 0.9348 - auc_1: 0.9826 - val_loss: 1.0083 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1718 - acc: 0.9348 - auc_1: 0.9867 - val_loss: 0.9885 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1692 - acc: 0.9348 - auc_1: 0.9852 - val_loss: 1.0162 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1708 - acc: 0.9239 - auc_1: 0.9869 - val_loss: 0.9945 - val_acc: 0.6667 - val_auc_1: 0.7071\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1716 - acc: 0.9457 - auc_1: 0.9855 - val_loss: 1.0579 - val_acc: 0.6667 - val_auc_1: 0.7393\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1735 - acc: 0.9348 - auc_1: 0.9836 - val_loss: 1.0716 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1582 - acc: 0.9457 - auc_1: 0.9879 - val_loss: 1.1093 - val_acc: 0.5833 - val_auc_1: 0.7214\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1773 - acc: 0.9348 - auc_1: 0.9848 - val_loss: 1.0850 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1674 - acc: 0.9130 - auc_1: 0.9869 - val_loss: 1.0754 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1694 - acc: 0.9239 - auc_1: 0.9860 - val_loss: 1.0511 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1591 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 1.0707 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 241/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1552 - acc: 0.9565 - auc_1: 0.9871 - val_loss: 1.1415 - val_acc: 0.5833 - val_auc_1: 0.6857\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1700 - acc: 0.9239 - auc_1: 0.9852 - val_loss: 1.0780 - val_acc: 0.6667 - val_auc_1: 0.7214\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1470 - acc: 0.9457 - auc_1: 0.9910 - val_loss: 1.0901 - val_acc: 0.7083 - val_auc_1: 0.7000\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1523 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 1.1193 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1483 - acc: 0.9348 - auc_1: 0.9888 - val_loss: 1.1420 - val_acc: 0.5833 - val_auc_1: 0.7214\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1576 - acc: 0.9348 - auc_1: 0.9879 - val_loss: 1.1330 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1486 - acc: 0.9457 - auc_1: 0.9888 - val_loss: 1.1787 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1684 - acc: 0.9348 - auc_1: 0.9848 - val_loss: 1.1512 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1439 - acc: 0.9565 - auc_1: 0.9902 - val_loss: 1.1538 - val_acc: 0.6667 - val_auc_1: 0.7071\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1459 - acc: 0.9348 - auc_1: 0.9912 - val_loss: 1.1612 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1476 - acc: 0.9130 - auc_1: 0.9886 - val_loss: 1.1708 - val_acc: 0.6667 - val_auc_1: 0.6893\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1305 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 1.1974 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1399 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 1.2011 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1405 - acc: 0.9348 - auc_1: 0.9921 - val_loss: 1.1898 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1391 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 1.1669 - val_acc: 0.6667 - val_auc_1: 0.7214\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1388 - acc: 0.9348 - auc_1: 0.9914 - val_loss: 1.1784 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1390 - acc: 0.9565 - auc_1: 0.9905 - val_loss: 1.2311 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1334 - acc: 0.9565 - auc_1: 0.9898 - val_loss: 1.2506 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1323 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.2898 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1170 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 1.2793 - val_acc: 0.5833 - val_auc_1: 0.7071\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1584 - acc: 0.9348 - auc_1: 0.9864 - val_loss: 1.2518 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1317 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 1.3069 - val_acc: 0.5833 - val_auc_1: 0.6964\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1255 - acc: 0.9565 - auc_1: 0.9926 - val_loss: 1.2960 - val_acc: 0.5833 - val_auc_1: 0.6893\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1127 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 1.3634 - val_acc: 0.5833 - val_auc_1: 0.7143\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1167 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 1.3351 - val_acc: 0.5833 - val_auc_1: 0.7214\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1182 - acc: 0.9565 - auc_1: 0.9945 - val_loss: 1.2949 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1261 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 1.3370 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1230 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 1.3469 - val_acc: 0.5833 - val_auc_1: 0.7071\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1204 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 1.3540 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1112 - acc: 0.9783 - auc_1: 0.9955 - val_loss: 1.3976 - val_acc: 0.5833 - val_auc_1: 0.7143\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1119 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.3270 - val_acc: 0.6667 - val_auc_1: 0.6929\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1297 - acc: 0.9674 - auc_1: 0.9910 - val_loss: 1.3643 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1021 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 1.4132 - val_acc: 0.5833 - val_auc_1: 0.7179\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1038 - acc: 0.9457 - auc_1: 0.9962 - val_loss: 1.4777 - val_acc: 0.5833 - val_auc_1: 0.7036\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1120 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 1.4074 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0980 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 1.4121 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0989 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 1.4750 - val_acc: 0.5833 - val_auc_1: 0.7036\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0968 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.4753 - val_acc: 0.5833 - val_auc_1: 0.7000\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1119 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 1.4895 - val_acc: 0.5833 - val_auc_1: 0.6964\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1034 - acc: 0.9565 - auc_1: 0.9960 - val_loss: 1.3744 - val_acc: 0.7083 - val_auc_1: 0.6857\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1096 - acc: 0.9348 - auc_1: 0.9924 - val_loss: 1.4248 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1139 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 1.4666 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0914 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 1.4214 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1037 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 1.5363 - val_acc: 0.5833 - val_auc_1: 0.7214\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1079 - acc: 0.9348 - auc_1: 0.9952 - val_loss: 1.4840 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0890 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 1.4724 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0866 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.5152 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0805 - acc: 0.9783 - auc_1: 0.9983 - val_loss: 1.4977 - val_acc: 0.6667 - val_auc_1: 0.6857\n",
      "Epoch 289/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0883 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.5140 - val_acc: 0.6667 - val_auc_1: 0.6714\n",
      "Epoch 290/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1074 - acc: 0.9565 - auc_1: 0.9943 - val_loss: 1.6192 - val_acc: 0.5833 - val_auc_1: 0.7321\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0967 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.5486 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0906 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 1.5992 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0849 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.6205 - val_acc: 0.5833 - val_auc_1: 0.7000\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0977 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.5937 - val_acc: 0.5833 - val_auc_1: 0.7393\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0777 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.5186 - val_acc: 0.7083 - val_auc_1: 0.6786\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1233 - acc: 0.9348 - auc_1: 0.9917 - val_loss: 1.5755 - val_acc: 0.6667 - val_auc_1: 0.6321\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0770 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 1.6059 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0734 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6209 - val_acc: 0.5833 - val_auc_1: 0.7179\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0771 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.6376 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0708 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.6551 - val_acc: 0.5833 - val_auc_1: 0.7107\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0731 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.6840 - val_acc: 0.5833 - val_auc_1: 0.7321\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0808 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.6747 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0706 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6966 - val_acc: 0.5833 - val_auc_1: 0.7250\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0805 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.6332 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0848 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 1.6169 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0972 - acc: 0.9783 - auc_1: 0.9948 - val_loss: 1.6859 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0657 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.6944 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0593 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6408 - val_acc: 0.6667 - val_auc_1: 0.6893\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0529 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.7720 - val_acc: 0.5833 - val_auc_1: 0.6964\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0545 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6979 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0631 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6799 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0626 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7474 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0906 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.7921 - val_acc: 0.5833 - val_auc_1: 0.7214\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0647 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7285 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0649 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.7365 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0561 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.7677 - val_acc: 0.5833 - val_auc_1: 0.7071\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0731 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 1.7623 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1129 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 1.8006 - val_acc: 0.5833 - val_auc_1: 0.6964\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0593 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.8502 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0488 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.8688 - val_acc: 0.5833 - val_auc_1: 0.7071\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0609 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8228 - val_acc: 0.5833 - val_auc_1: 0.6964\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0520 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7581 - val_acc: 0.6667 - val_auc_1: 0.6857\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0634 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.9324 - val_acc: 0.5833 - val_auc_1: 0.6964\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0402 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7963 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0751 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 1.8421 - val_acc: 0.5833 - val_auc_1: 0.7143\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0465 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8590 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0471 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8973 - val_acc: 0.5833 - val_auc_1: 0.7250\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0800 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.7678 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0482 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8491 - val_acc: 0.5833 - val_auc_1: 0.6964\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0483 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.9253 - val_acc: 0.5833 - val_auc_1: 0.7071\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0377 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8784 - val_acc: 0.5833 - val_auc_1: 0.7036\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0413 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9650 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0794 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.8916 - val_acc: 0.6250 - val_auc_1: 0.6464\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0450 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.9404 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0631 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.9426 - val_acc: 0.6250 - val_auc_1: 0.6071\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0466 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.9139 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 337/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0428 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9420 - val_acc: 0.6250 - val_auc_1: 0.6214\n",
      "Epoch 338/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0484 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9568 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0458 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 2.0199 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0494 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.9704 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0360 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9170 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0355 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0387 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0406 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9461 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0391 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.0464 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0353 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9901 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0353 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0306 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0352 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9525 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0277 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0571 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0372 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9818 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0586 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.8743 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1778 - acc: 0.9348 - auc_1: 0.9776 - val_loss: 2.0190 - val_acc: 0.6667 - val_auc_1: 0.6464\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0396 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0741 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0437 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 2.0893 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0424 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.0633 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0274 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1072 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0299 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0609 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0283 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0816 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0296 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0632 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0270 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0678 - val_acc: 0.6250 - val_auc_1: 0.6464\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0274 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1110 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0248 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0583 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0301 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1642 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0223 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1046 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0295 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1454 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0303 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2220 - val_acc: 0.5833 - val_auc_1: 0.6357\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0643 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 2.0453 - val_acc: 0.6667 - val_auc_1: 0.6464\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0253 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1368 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0238 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1008 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0234 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0804 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0226 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0908 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0241 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1465 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0207 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1324 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0205 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2180 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0234 - acc: 1.0000 - auc_1: 1.000 - 1s 9ms/step - loss: 0.0230 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1112 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0209 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1511 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0240 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1714 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0196 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2067 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0195 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1893 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0166 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1445 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0216 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1290 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.3016 - acc: 0.8804 - auc_1: 0.9686 - val_loss: 1.8796 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.1573 - acc: 0.9674 - auc_1: 0.9781 - val_loss: 2.0374 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0249 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0777 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0219 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0913 - val_acc: 0.6250 - val_auc_1: 0.66070\n",
      "Epoch 385/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0182 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0837 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 386/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0190 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1041 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0172 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0930 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0168 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0902 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0158 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0983 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0151 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1354 - val_acc: 0.5833 - val_auc_1: 0.6750\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0159 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1294 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0153 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1352 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0146 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1684 - val_acc: 0.5833 - val_auc_1: 0.6821\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0152 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1524 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0156 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1504 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0150 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2364 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0150 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1231 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0154 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2422 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0133 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1618 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0167 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2228 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0131 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2660 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0132 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2420 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0139 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2714 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0144 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2872 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0140 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2412 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0176 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2938 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0159 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3059 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0125 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3179 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0128 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2992 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0143 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2843 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0104 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3684 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0200 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3272 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0150 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2986 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0390 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1863 - val_acc: 0.6667 - val_auc_1: 0.6821\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4045 - acc: 0.8913 - auc_1: 0.9462 - val_loss: 1.7772 - val_acc: 0.6667 - val_auc_1: 0.6893\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1119 - acc: 0.9674 - auc_1: 0.9898 - val_loss: 2.0772 - val_acc: 0.5833 - val_auc_1: 0.7071\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0357 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 2.0301 - val_acc: 0.5833 - val_auc_1: 0.6821\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0459 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0559 - val_acc: 0.5833 - val_auc_1: 0.6857\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0100 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0370 - val_acc: 0.5833 - val_auc_1: 0.6821\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0466 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0098 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0926 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0093 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0523 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0094 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0456 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0867 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0744 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0935 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0088 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1007 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0728 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1187 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1046 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1021 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 433/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1301 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 434/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0960 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1137 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0848 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1752 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1760 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1305 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1304 - val_acc: 0.6667 - val_auc_1: 0.6821\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2589 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1719 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2284 - val_acc: 0.5833 - val_auc_1: 0.6929\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2179 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1235 - val_acc: 0.6667 - val_auc_1: 0.6857\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0116 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3193 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2747 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.6224 - acc: 0.8478 - auc_1: 0.9233 - val_loss: 1.9707 - val_acc: 0.7500 - val_auc_1: 0.7000\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4088 - acc: 0.8913 - auc_1: 0.9531 - val_loss: 1.7770 - val_acc: 0.6667 - val_auc_1: 0.6893\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0623 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 2.1458 - val_acc: 0.6667 - val_auc_1: 0.6821\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0111 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1506 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1537 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1602 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1628 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1650 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1662 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1695 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1791 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1708 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1801 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1780 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1898 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1976 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1889 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1829 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2025 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2020 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2057 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1923 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2266 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2169 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2050 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2125 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2317 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2237 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2465 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2562 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2212 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2688 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2927 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 481/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2641 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 482/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2770 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2852 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2800 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2660 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2997 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2539 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3042 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2722 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2232 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3271 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3255 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3099 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3366 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3467 - val_acc: 0.5833 - val_auc_1: 0.6821\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3143 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3579 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4107 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3821 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3666 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2740 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3415 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3527 - val_acc: 0.6667 - val_auc_1: 0.6821\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4254 - val_acc: 0.5833 - val_auc_1: 0.6821\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3925 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1188 - acc: 0.9674 - auc_1: 0.9955 - val_loss: 2.1356 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.7415 - acc: 0.8804 - auc_1: 0.9186 - val_loss: 1.9761 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3087 - acc: 0.9239 - auc_1: 0.9612 - val_loss: 2.2619 - val_acc: 0.7083 - val_auc_1: 0.6464\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0264 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 2.2434 - val_acc: 0.6667 - val_auc_1: 0.6714\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0152 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3608 - val_acc: 0.7083 - val_auc_1: 0.6429\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0136 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3201 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3299 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3345 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3381 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3410 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3436 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3475 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3443 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3493 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3480 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3506 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3545 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3522 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3542 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3587 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3667 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3635 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3659 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 529/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3655 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 530/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3624 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3667 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3718 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3685 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3774 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3834 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3770 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3869 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3930 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4000 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3864 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3905 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3776 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4052 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4136 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3905 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4042 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4267 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4191 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4128 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4139 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4258 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4478 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4503 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4553 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4213 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4486 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4769 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4621 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4635 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4142 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4580 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4319 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5154 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4915 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5205 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5690 - val_acc: 0.6250 - val_auc_1: 0.6393\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5487 - val_acc: 0.6250 - val_auc_1: 0.6393\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5017 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1569 - acc: 0.9783 - auc_1: 0.9729 - val_loss: 2.4632 - val_acc: 0.6250 - val_auc_1: 0.6321\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3703 - acc: 0.8913 - auc_1: 0.9555 - val_loss: 2.5635 - val_acc: 0.6250 - val_auc_1: 0.6107\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1043 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 2.4441 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0857 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 2.4756 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0189 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.1699 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1889 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1962 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2018 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 577/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2106 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 578/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2198 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2221 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2338 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2335 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2445 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2491 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2481 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2528 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2594 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2590 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2777 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2779 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2867 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2901 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2902 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2820 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3106 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3090 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3133 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3139 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3331 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3387 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3402 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3230 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3240 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3539 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3478 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3479 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3511 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3572 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3512 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3614 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3438 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3839 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3656 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3812 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3979 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3989 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3859 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3886 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3925 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3940 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4180 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4108 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3964 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4014 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4786 - val_acc: 0.6250 - val_auc_1: 0.6393\n",
      "Epoch 625/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4619 - val_acc: 0.6250 - val_auc_1: 0.6393\n",
      "Epoch 626/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4509 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4113 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5260 - val_acc: 0.6250 - val_auc_1: 0.6393\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4953 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5103 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5147 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4890 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5745 - val_acc: 0.6250 - val_auc_1: 0.6393\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4380 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5150 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5630 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5251 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5600 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5018 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 9.9589e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.6071 - val_acc: 0.6250 - val_auc_1: 0.6321\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5162 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 9.7936e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5260 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.6693 - val_acc: 0.6250 - val_auc_1: 0.6321\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5057 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5569 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0204 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.6057 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4933 - acc: 0.9022 - auc_1: 0.9517 - val_loss: 2.4221 - val_acc: 0.7083 - val_auc_1: 0.6714\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0535 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 2.6579 - val_acc: 0.6667 - val_auc_1: 0.6214\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0169 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4759 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4249 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4171 - val_acc: 0.7083 - val_auc_1: 0.6571\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4150 - val_acc: 0.7083 - val_auc_1: 0.6571\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4148 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4155 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4168 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4174 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4203 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4184 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4239 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4260 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4261 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4263 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.9531e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4286 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 9.8854e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4314 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.8722e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4343 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.7057e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4291 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.6570e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4349 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.5056e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4349 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.3655e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4336 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.2993e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4351 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.2393e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4377 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.1085e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4435 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 673/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 8.9884e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4410 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 674/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 8.9699e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4435 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.8879e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4409 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.7939e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4468 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.6542e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4495 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.5913e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4474 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.4738e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4485 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.4119e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4510 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.3840e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4524 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.1980e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4609 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.2105e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4616 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 8.0931e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4559 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.0655e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4701 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 8.0225e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4616 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.8472e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4569 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.7438e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4588 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.7055e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4692 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.6544e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4868 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.4729e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4749 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.4345e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4832 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.3658e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4895 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.3534e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4960 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 7.2664e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4813 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.3147e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4974 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 7.1652e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4941 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.1851e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4964 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 7.0319e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4907 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 7.0387e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.5074 - val_acc: 0.6667 - val_auc_1: 0.6643\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5, X6, X7], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2deXxU1dn4vyeTjZCQQICwhB1UEBDZ3CoqbrjXihVErVutW7Vub/VXF2pta1vra23V1qqtW914RSmuqCi44A4iO7JI2AlbCFlnzu+Pc2/mzuROMpPMZGZyn+/nM59777nn3vskmZznPs9znucorTWCIAiCd8lItgCCIAhCchFFIAiC4HFEEQiCIHgcUQSCIAgeRxSBIAiCxxFFIAiC4HFEEQieRynlU0rtU0r1TdD9Byql9iXi3oIQD0QRCGmHNWjbn4BSqspxPC3W+2mt/VrrfK319y2QZbBSqlEyjlLqGaXUdOv+a7TW+VHc63Kl1PuxyiAIrSUz2QIIQqw4B1Wl1Drgcq31O5H6K6Uytdb1bSFbMvHKzynEH7EIhHaHUuoepdQLSqnnlFIVwAVKqSOUUguUUruVUpuVUg8qpbKs/plKKa2U6m8dP2Odf0MpVaGU+kQpNaAV8oRYDUqpy5RS66x7r1FKTVFKjQD+BhxtWTY7rL5FljzbrWtuU0op69zlSql5lqw7gXusn2+o41k9lVL7lVLFLZVfaP+IIhDaK2cD/wEKgReAeuB6oCtwFDAJ+FkT158P3AF0Ab4HfhMPoZRSnYD7gRO11gWWLN9orRcD1wLzLTdVV+uSh4E8YCAwEbgMuMhxyyOBZUA34NfAi8AFYT/HW1rr8njIL7RPRBEI7ZUPtdb/1VoHtNZVWuvPtdafaq3rtdZrgEeBY5q4fobW+gutdR3wLDCqqYdZb+INH+DHTXTXwHClVK7WerPWemmEe2ZZ97lVa11hyf2/wIWObt9rrR+x4hxVwJPA+bbVYPV9uinZBUEUgdBe2eA8UEodpJR6TSm1RSm1F7gbYx1EYotjfz/QZLBXa13k/GDezN367QWmAtcAW5RSs5VSB0S4bXfAB6x3tK0HejuOQ35OrfVHGOvnB0qp4UBf4LWmZBcEUQRCeyV8Js8/gG+BwVrrTsCdgGp0VRugtX5Da30C0BNYbckGjWXeBviBfo62vsBG5+1cHvEUxj10IfCi1romHnIL7RdRBIJXKAD2AJVWMLWp+EDCsIK3Zyil8oBaoBIz2ANsBUrtILbllpoB/E4plW8FrG8AnmnmMU8DkzHxgacS8GMI7QxRBIJXuAn4CVCBeQN/IUly+IBbgM1AOSbYe611bg6wCtiqlLJdU1djFMZa4ANMDKDJwV1rvQ5YDNRqrT+Os/xCO0TJwjSC0P5QSj0FrNFaT0+2LELqIwllgtDOUEoNBM4CRiRbFiE9ENeQILQjlFK/BxYBv2tJyQzBm4hrSBAEweOIRSAIguBx0i5G0LVrV92/f/9kiyEIgpBWfPnllzu01t3czqWdIujfvz9ffPFFssUQBEFIK5RS6yOdE9eQIAiCxxFFIAiC4HFEEQiCIHictIsRCILQvqirq6OsrIzq6upki9IuyM3NpbS0lKysrKivEUUgCEJSKSsro6CggP79+xNcRkFoCVprysvLKSsrY8CA6BfVS5hrSCn1hFJqm1Lq2wjnlbXE3mql1DdKqdGJkkUQhNSlurqa4uJiUQJxQClFcXFxzNZVImME/8YsBxiJU4Ah1ucK4JEEyiIIQgojSiB+tOR3mTDXkNZ6nr0YeATOAp7SpsbFAmuR7p5a682JkknwNuvLK/ls7U5OGtaDrRXV9CzM5ZuyPXy1fhcBDUrBiNJCOuVm8sHKHVRU15GdmUFdvSY/x0dVnZ8MpcjJ8tEtP5vyyloCAVOiRSnFIX0KWbBmJ7mZjd+vKmrqKchp/O/Ws6gDtfUByvfFvnbMIX2KKN9XS9mu/TFd1zEnk+OHdue/izaTqBIzSikmjynl83U7Wbejssm+R3WtY8ue1sUHOmRn0DE7k/LKWpJZNScnK4N6fwB/IDH379Qhk7zs+A/byYwR9CZ0mb0yq62RIlBKXYGxGujbt2+bCCekB//44DsO7lXIEYOK2bK3mvycTD75rpzlW/by9fe70cCvTh3KfW+vYM7SrQDcwjdxe7798hU++DhfypznIrWHn2uOll5rX/fw+9+xp6oupmfGgtYwZ+lWlm7e26x8I8/oybaK1ikCX4aia34OW/e274Bzlq9Du1MEbl8NV12utX4Us9g4Y8eOlSp5HmX3/lpq6gN8/f0uKqrrGd2vM79/Y3mz181buT3kePyALny2dmfD8VOXjufeN5Y3DFoAf5w8koUbdvPC5xvwKcWfzh3J9c8vBOCdGycQ0NCrqAP51lv+395bxX1vrwRg1W9PIcsXtAr+9dFanvvse/778x+Qk+lraH/+s++59eXFAPz9gjFMGt4j6t/FbS9/w3Ofmfeor+84kc4ds6O67tM15Zz36AL2VNVx4eH9+M0Ph0f9zFg4/58L+Pi7cgBmXn0kh/btHLHvsmXLGFpa1OJnbd5TxY59tVRU19Mhy8eQkoIW36s1bNxVRXllDXnZmQzubpa4vvTSS5k9ezbdu3fn229dw6UpQTIVQRnQx3FcCmxKkixCCqK15tWFmzhiUDElnXIZdfecmK6fPKaUD1ftYMveag7qUcDyLRXkZGbw4s+OYM/+Og65+20AJhzQjfEDulBV6+fY+95nT1Udw3sV8uOxffjd2cGS/hOGdKNDto/cLF+jZxV2MFP1+nbJC1ECAJccNYBLjmo8gyMnK9ivY07jezaFL8O8R2VnZlCUF/00Qfs6MG6GRDGke36DIsh2cZXFkwyl0Fqzv7aeHoW5CX1WU9hWj+NXzMUXX8y1117LRRddlByhoiSZimAWcK1S6nngMGCPxAe8TSCguX/OSsb068yhfYuY9MB8tlimfmZGqAFZ3NH46G1uOOEAThvZkxPu/wCAxdNPoiA3i7Jd+9lWUcPg7vmMnP42/Ys7AlCYl8XSu0+mps44c3OzzAD/5KXj+fv73zGkJL+RfE29ddvmunY3al1xWgexmvuZGWZw7dEpN6bgoFMRhCuseJLpuHdODIrg1/9dwtJNe5vv6KDOH6C23vwdO2T7yAj7fQzr1Ym7zji4yXv88Ic/ZMOGDVRXV3P99ddzxRVXkJ+fz759+wCYMWMGs2fP5t///jdbt27lyiuvZM2aNQA88sgjHHnkkQ2KwPn3mDBhAuvWrYvp50kGCVMESqnngGOBrkqpMuAuwF6U++/A68CpwGpgP3BJomQRUpsv1+9Ea7jyma/YESFoWh8IDrA/OrQ3v/nhcPbX+llXXsm/PlrLNccNItOXwfLfTGJvVR0FueYtubRzHqWd8wB4cOqhjO0XdFHkZWeSFza2j+pTxN8vHBPzz9DRchHFEqjMbYVFkOUzg033gpyYrmszRdBGzwF3H3OsPPHEE3Tp0oWqqirGjRvHOeecE7HvddddxzHHHMPMmTPx+/0NysKWIx3nPyVy1tDUZs5r4JpEPV9IbdbuqOS4+95vtt/ovkXcfdZwehV14J7ZS3n56430LMqlY04mHXMy6VaQw7j+XRr622/2bpx5SK94id+IWAdyCLUIOsZqEViDa4fslrmUALITOEBnOJ8Tg0XQ3Ju7GzsrgzOnDigpiPj3b4oHH3yQmTNnArBhwwZWrVoVse97773HU089BYDP56OwsBAIWgLpOBNWMouFNuH1xZvZssf46u+evZSa+sjz6768/QTG3PMOxR2zefnqoxra7zxjGH6tufwHA9tC5JhorUWQF+OAnmXHCGIczJ2KINOXuBGrLS0Cp9ewJT/R+++/zzvvvMMnn3xCXl4exx57LNXV1SEunmgStNJw/G9AFIGQULTW1PoDXP3sVwAcPaQry7dUANCtIIep4/rw5CfreeLisRzcq5Cte6spzs/hPz89jD6WS8emKC+bv0w5tM1/hmiI9Y0ewiwClxyDprAtgoyM2IYfn2qbAdrpp2+LYLFNS5Kp9uzZQ+fOncnLy2P58uUsWLAAgJKSEpYtW8aBBx7IzJkzKSgws5GOP/54HnnkEX7xi1/g9/uprKykU6dOaWkJ2Ej1USGh/Oez7znw9jcbjuev2gEYf/2LPzuCG086kEV3ncSYfl3IzfLRzwrmHjmoK3265LneMxWx3+hjSdByBlFjCahC8M0+1rGnrVxDmW30HAizCFowGE+aNIn6+npGjhzJHXfcweGHHw7Avffey+mnn87EiRPp2bNnQ/+//OUvzJ07lxEjRjBmzBiWLFlinu3y15g6dSpHHHEEK1asoLS0lMcffzx2AdsAsQiEuOMPaKY9toALDu/Hr2a6z51OpL8+Gdh+6b7F0Ssvpy871jdZO1gc68AXEizOTNwrbEZbBotDLILYr8/JyeGNN95wPTd58uRGbSUlJbz66qsucjS+/rnnnotdoCQgikCIO+vLK1mwZicL1gSTtkb1KWLhht0ADck27YluBTk8PG00hw8sjvqaWK0AJ/b0Ube30KZIxqwhX4zuq1hxuoYykuipT2fXkCgCodWc/88FLNqwm4Hd8rnq2EF8sW5Xw7m8bB9f3XEiuVk+zvvHJ+zeX8fTl41PorSJ49QRPZvv5CCnBbNbbOJiESRQESR68HfSWtdQaykvL+f444/HH9DU+QNkZCiyfRm8++67FBdH/2KQTEQRCC1mX009K7ZUNGSQLt64pyEobHPh4f0aXCAv/OyINpcxlWmVRWAHi2Mc+dps+mgbjshON1QyqpgWFxezcOFCdu+v5fud+ynskNUQ60oXRBEIMXH7K4uZtXATi+46ieF3vdVk359NGMitpxzURpKlH7YicCa5RUuD6yVWi6CNZg1lttBiaQm+dPbJpAiiCISYeGbB9wDc+OIi1/MnDithztKt5GRmcNupQ9tStLRDKcUb1x/dotlRDQNtjNeFuoYSGCy2Bue2GKRFD7QeUQRCi5j59UbAvNUWdshiW0UNFx/Zn+lnHsxna3fSM4nFv9KJoT07teg6O0gcqyskdNZQ4oPFseY5tIRUW9QmtaSJDskjEKJi9bYK5q/a3qj9X5eMY0BX4w89cVgJYMo8p1MOQDpiF7dL1TwCWwGEFwsUUhNRBEII81dt55S/zKem3o8/oLn5pUXMWrSJE+6fx4WPfwbA7380gk65xpjsmp/DSQebOvp9ZfBvM+y8tVSdNWQrgPbov8/PT97050mTJlFUVMTpp58e1/uKa0gI4baXF1O2q4r7317Jy19vZHtFDTO+LGs4P7h7PlPH92V/rZ/fzF5Kj8JcLj2qP2cf2psuUS6OIrQeWxHEPGvI0T+RtYZ8bega8hK33HIL+/fv5x//+Edc7yuKQGhg0+4qynZVAfCPeWsanX/1mqMo7dwBgEuP6s/FR/Zv+IcXJdC22IUsWmMRtMX00ZjzCd64FbYsjvl5B9b7ze8k0yU3o8cIOOXeiNf+8pe/pF+/flx99dUATJ8+HaUU8+bNY9euXdTV1XHPPfdw1llnNSvH/sp9XHX+BVTt2xty3bp16zj99NMbVim777772LdvH9OnT2f16tVceeWVbN++HZ/Px0svvcSgQYNc73/88cfz/vvvNytHrIhryOPsr63n1YUbCQQ0f7aWWgzn6CFdmXvzsRzSp4jifFP/XinVpklDQigBbccIYvsbOAOriSwG1xAsbiPXUE6mj1w3JRAFU6ZM4YUXXmg4fvHFF7nkkkuYOXMmX331FXPnzuWmm25qto5UhlJk5+TyxDMvxHTdtGnTuOaaa1i0aBEff/xxSF2jtkIsAg+jtebhud/xt7mrufmlRdT5g1/Yi47ox4nDSijqkM2I0sIkSim40sIYgZOWDpzRYLuEYjY6mnhzTxSHHnoo27ZtY9OmTWzfvp3OnTvTs2dPbrjhBubNm0dGRgYbN25k69at9OgReV3pgtxMehXm8pvbf8n8+fNDrotERUUFGzdu5OyzzwYgNzc5s+1EEXiQlVsr+PPbK3hrSfAL6lQCvzt7BFPG9RH/bgrT0llDTpxrJsebdAsWT548mRkzZrBlyxamTJnCs88+y/bt2/nyyy/Jysqif//+za5JoJTizVdnsGPHjkbXZWZmEggE1+Cw7xVLtdpEIq4hD/Li5xtClMAQRxG4Zy47jPMP6ytKIMU5aVgPDupRwFXHuvuSo6E1JS6aIyPNgsVTpkzh+eefZ8aMGUyePJk9e/bQvXt3srKymDt3LuvXr4/qPpGuKykpYdu2bZSXl1NTU8Ps2bMB6NSpE6WlpbzyyisA1NTUsH///sT8kE0gFkE75p2lWxncPZ/+XTvywcrt/P71ZVx8ZH8e+3BtSL9jD+zGxUf157gDu9OrqEOSpBVioXPHbN78xYRW3SORiVgNFkGaKIKDDz6YiooKevfuTc+ePZk2bRpnnHEGY8eOZdSoURx0UHSlUiJdl5WVxZ133slhhx3GgAEDQu739NNP87Of/Yw777yTrKwsXnrpJQYOdF+F7+ijj2b58uXs27evYX2Dk08+udU/vyiCdkogoLn8qS/IycxgxT2nMHvRJpZvqeDWlxvPyMhQimmH9UuClEJ7xdeGJSbixeLFwf+Nrl278sknn7j2sxerd6Op66677jquu+66Ru1Dhgzhvffei0rG+fPnR9UvVsQ11E7ZVlED0LA2sL0WAMDNJx1AB0cJ5PEDuiAI8UTyCNILsQjaKe8uD8YARkx/i4rq+objs0b1ZtLwHny1fjcTh3anqzUlVBDihS/NgsWxsnjxYi688MKQtpycHD799NOUvnckRBG0M2Z8WUZFdR2//u/ShraK6nqKO2ajgZ2VtZR27oBSisHdC5InqNCuiTVYrLVOueJxTTFixAgWLlyYkvduyUwkUQTtiOo6Pze/FFoe+r5zD+GowcX0LOzAnqo6dlbWptU/nJCeNMQIonA+5+bmUl5eTnFxsXw3W4nWmvLy8pjzEUQRtANe+mIDt8z4xvXc5DGlDfuFHbIo7JDVVmIJHsZ+J43GNVRaWkpZWRnbtzeubivETm5uLqWlpc13dCCKIE3589sr+Ot7q3n28sNCisI5+cuUUW0slSAY/AGjCqJxDWVlZTFgwIBEiyQ0gcwaSkNWbq3gr++tBuCf89ewfEuFa7+zRvVuS7EEoQG7FlJ7DRa3N8QiSDO01qzdUdlw/P4KY053zPZx3ri+nHRwCftr6ynfV5ssEYUU56lLxyfcRRiLRSAkH1EEacasRZu4/vnGMwo+vu148f8LUTHhgG4Jf4a9HnKXPClPng6IInBDa6jZC7mFUGcVmsrIhPpqyO4IOgAZvmDfNjJ/91TVuSqBH48tFSUgpBSj+3bm9tOGcu6YPskWRYgCUQQAtZXwu15w4t0w585g+7QZMPsGqN0HJcNh3Xw48FRY+SbcuRP2bYU/HwhnPwqHnJcw8Xbvr2XBmp1sq2hc/TAnM4MrJrS88JggJAKlFJcf7V4vR0g9RBEAVO4w2wWPhLavfAv2bDD766waHyteN9vV7waVxuePGQuhx0jodkDcxbvt5cW88e2WhsXhLzy8H08vMFUNl/9mksy9FgShVcisIYDqPWbrrwttX/V25GteuAC2LTH7gTr4v8vg8RPjKtb+2noCAd1QN2jO0q2MLC3kNz8c3tBHlIAgCK1FFAFA1U6zrd4d2r7bqkF+1PWNr6mvCu6Xf+d+fSvYX1vPsDvf4oYXF7JhZ7A++cG9OsXtGYIgCJBg15BSahLwF8AHPKa1vjfsfD/gCaAbsBO4QGvtnh2VSKp2mW0gWJiNw6+GTr0gvwSGT4Zeh0JesRn0Z//C9Dn/JZj1c9i3xRznFcdNpD1Vxjp5deGmkPZhvcyyka9fd7RrzEAQBCFWEqYIlFI+4CHgRKAM+FwpNUtrvdTR7T7gKa31k0qpicDvgQsb3y3B7N/ZuO2g06H/UcHjg82aogyYANtXQOV2OOAkOOBk+OpJc65TfBK4quv8vPzVRtdzY/p2BmBYr04MQ6wDQRBaTyJdQ+OB1VrrNVrrWuB54KywPsOAd639uS7nE8+KN+G1Gxu3F/WNfM0p98Lkx81+dnCZR8pXw/RC2PBZq0T6xwdr+NNbK1zPHdhDKoYKghBfEuka6g1scByXAYeF9VkEnINxH50NFCilirXW5c5OSqkrgCsA+vZtYoBuCZ86ZgpNvB0CAeg+FIqinP+c3TG4X2f58pfMhD7jWyTOg++u4n/fWRnSNu2wvpw4rITR/TqnzdJ/giCkD4lUBG4jVnih7JuBvymlLgbmARuB+kYXaf0o8CjA2LFjYy+2HS0Tbon9miyXcq9O5RAlVbV+vt20h/vnrGx07n9OPojCPEkYEwQhMSRSEZQBztfqUiAk8qm13gT8CEAplQ+co7Xek0CZ4o/bIhDz/gQomPirqG7xffl+JvxpbsTznTpIuocgCIkjkTGCz4EhSqkBSqlsYAowy9lBKdVVKWXLcBtmBlF6oc2awAyfHNo+749RXb5h535eW7w54vlfTjpIcgUEQUgoCVMEWut64FrgLWAZ8KLWeolS6m6l1JlWt2OBFUqplUAJ8NtEydOEoK283lIEXQbAyNjKTKzbUcnRf5zLH95cTq/CXO44fVjDuQsO78tnvzqeq46V8hGCICSWhPoctNavA6+Htd3p2J8BzEikDBGprYS/Hw271rbuPrlmXj8dOptg8zcvRH3pzK+DU0SH9y5kXP/ODceZGRl0L4htuTlBEISW4F3n88L/wM7v4MDTzNv86J+07D7jLgcUjLsstD07HwJ+WPEGHHSaa4XSJZuC4ZADexQwsrSIwwd2YcGanW1V0FQQBMGjJSYCAXj9ZrN/5M/h5N+2vFicLwsOv9JsQ1Dw2T/hhWmwONToqa0P8Nj8NbyzbFtD2wElJj/gmuMGA3BIaVHL5BEEQYgRb1oENXuD+/ndE/OM2gp485dmv3x1Q/Pu/bWMuntOo+52otjRQ7rx7k3HMLBr7FNQBUEQWoI3FUGVo6REfkl8733hTNhTBpsXmfLUADXBNYUXbnAvTNe/ODjwD+qW79pHEAQhEXhUEewK7ufEedAdNBGAQECTYSuC3esJBDSfrt3Jxf/6vKFrt4IcnrxkPMu37CU705teOkEQko+3FcElbyTsEfNWbedYa9+/4zsG/b/XG/W58phBpniclJYWBCGJePM1dL+lCPK6JuwRVbV+Lqi9jbKMXrBrDYpAoz5d82Vhb0EQko83FcHudWab3y1hjwho+DAwgr/VnIrPX8NA1Th7uEcnyRMQBCH5eFMRfDfXrC/coXPzfVtIrd8PwIcBs6zkeZ0bF5Mr7ZKXsOcLgiBEizcVwZ4N0H1Y8/1aQUW1KaJapruzOtCLSzNmM1BtohvBQHVJQU5CZRAEQYgGbyqC2v2Qnbi38Xp/gLU7KhuO3wmMIXPfZt7LuZkFeTdy+MAuAGT6vPnrFwQhtfDmrKG6KshKjCL4+LsdnP/PT0Pa7qs/lytz3gJ/Lb5ADU9NG0pdpuQKCIKQGnjvlVRrs5JYKxXBkk17uPGFhdT7zWygD1ft4JczvmHGF2WN+taTCec8DhlG72bv20jHHG/qYEEQUg/vKYL6akBDVodW3eaKp77k5a83MvhXbzB3+TYuePxTXvhiA9v31bhfMOxMuOBls+9MaBMEQUgy3lMEtda6wi1YTtJJZW1wRc27Zi1p2J+/akfD/nUTB4delGdiA+zfiSAIQqrgPUVgLzAfg0WwraKaNdv3hbRV1fob9r/fae5ZFLau8I0nHRh6I3u6arhFsHONqYgqCIKQBDyoCKrMNoYYweG/e5eJf/4AgAfeWckVT31BTX3jgfu/1/6gYf+dGycA8PRl43nj+qNNYwfLInAWvdu2HB48FD75aww/hCAIQvzwXsSyzprWGYNrKGCtZvnEh2t54J1VEfv1LgpaGYO7B8tKN5DVAZQP3pluSlNPvBN2rzfn5twJXQbB0NOjlksQBCEeeM8i2GctBhOFa0hrTU190AV09+ylEfv+73mHkJHRzLJiSkG/I83+18/AazdC5fbg+RemNSuTIAhCvPGeRfDhA2abV9xs1xe/2MAv/29xxPNPXDyW7gW5lHTKpVu0WcI/ehTuH2r2l882H0EQhCTiPUXgy4KcTlAyvNmuc5ZubfL8mH5dKOwQGiDuXdSBgtwmfq2dejX90CfPgKrdUNAztF37zYI3Rf1g11rw5UBWLhxxjVFqa+eZIPSJv0lo1rQgCO0P7ymCQL0pOBfF6vBuSV9dOmZz2ykHoTWNlADAR7dObJ18a+eZrb8WMh3VSTcvNNvty0P7v3Rx6HHvMTDq/NbJIAiCp/CmImgiPvCXd1ZxQEk+SileXbgp5NzJB5fw0PmjW18jKL8H7NvSdJ+LX4eODvfV9EKzzewA9VWRr/PJGgeCIMSG9xSBvw5yCho1v/ntZp76ZD0ff1cOwKg+RQ3nHjp/NE8vWMddZxwcn0JxV38CO1ZBUV+o3g3v3wtLXwntYyefhdN1MGyJHLfgzdvg4B9B5Tb49O8w8Q7I8LVeZkEQ2i3eUwSBOsho7NK58pmvQo6di8yfNrInp43sGX5Jy8nrAn0PM/udeoYGrg8538QRwl1XU56D1XNg3E/hseODiXHhVG6D7cvg3d/Ayjdg8AnQ/wfufQVBEPDi9NGAH3yh+u/78giDalvR85Dg/oSb4fg7Gvc56FQ4/X+hZBhcErb+8SFTQ493b4BaKxPaXxdfWQVBaHd4zyLw1zVUAbX57zebInRuI0ZfBF0GmCS34kHN9w/Piu53FIy5BJ44yRzvXBM89+H9MOi4+MkqCEK7w4MWQX2Ia0hrzdff727U7clLx7edTErBgAlmxk80dB4AfY+AM/8KpeNNNnLfw+Cwq8z53d8H+66dB/URKqIKgiDgRYsgUG9yCSwe/3At7ywLzRd44LxRHHNAN0b3LeKgnp3aWsLmycyGS980+6MvCrafci+segv2heU/1FRApiyLKQiCO95TBP66kFk0b34bnMZ5xiG9+O+ioJvo5auPalPR4kJeV1jycmjb0ldMHSNxEQmC4MjdIX0AACAASURBVIL3FIHlGqr3B7hlxjcs27y34ZTPmqjjt6vMpSO71jZue+0ms52+p21lEQQhLfBgjMAEi1dt28fMrzdSaa0rcO6YUko6mUze/KZKRKQ6XQYG9zt2T54cgiCkDWk84rWQgB98WWT5gvP0/zh5JJNHl1LrDzCga0dOGlaSRAFbyXnPwL9Pgx0rIb+7ySuw0Tqq0hqCIHiLhFoESqlJSqkVSqnVSqlbXc73VUrNVUp9rZT6Ril1aiLlARqmj1bXBReWOaS0iIwMRW6Wjynj+6LSebDM725mIEHjCqvVjWdHCYIgJEwRKKV8wEPAKcAwYKpSalhYt9uBF7XWhwJTgIcTJU8DlmvIucJYv+J2Vq3TZ80Qyg9zDe3b1rivIAieJ5EWwXhgtdZ6jda6FngeOCusjwbs+ZmFQGIzuwIB0AHwZVFTF1xwJjerndXisaeKFvSAzv2D7bWVSRFHEITUJpGKoDewwXFcZrU5mQ5coJQqA14Hfu52I6XUFUqpL5RSX2zfvt2tS3QE6s02w9dgEVx//JCW3y9VsRVBRhb0PTLYLuUmBEFwIZGKwM3RHj4vcyrwb611KXAq8LRSqpFMWutHtdZjtdZju3XrFn46ehoUQRbVlkUwaXiPlt8vVVGWhaMUdAhWUcUvGcaCIDQmkYqgDOjjOC6lsevnMuBFAK31J0Au0DVhEgWsN2JfVoNFkJPZzmfQOhe3qa9NnhyCIKQsiRwFPweGKKUGKKWyMcHgWWF9vgeOB1BKDcUoglb4fprBb1sEmQ0WQbuLD0CoLeZchMcvikAQhMYkTBForeuBa4G3gGWY2UFLlFJ3K6XOtLrdBPxUKbUIeA64WGuduLTeQFARtGuLwPkbdFoE4hoSBMGFhCaUaa1fxwSBnW13OvaXAm1X0Md2DbV3i8CJ0yIQ15AgCC40qwiUUjnAOUB/Z3+t9d2JEytBWBbBtv1+fv+GWQS+XVoETgY6Cs2Ja0gQBBeiGQVfxcz/rwcqHZ/0w6rLf88bqxua4rIGcSrTdTDctNLsi2tIEAQXonENlWqtJyVckrZgw2cArNKlAIzr3zmZ0iSO8Im7mdlmu+odGHd5m4sjCEJqE83r8MdKqREJl6Qt2PQ1OreQ5fTllOE9eOnKI5u/Jh0ZNNFsh5xstj5LEax8Ayp3JEcmQRBSlmgsgh8AFyul1gI1mPdNrbUemVDJEoG/Bp3VEa0Vo/oUNd8/Xek9JnTtAZ9jdbLK7dAxcakagiCkH9EoglMSLkVb4a8noMyP3KlDVjOd2xE+x5/588fgsCtNZdJda6NfJ1kQhHZLREWglOqktd4LVLShPInFXxtUBLkeUgROPn/MfLoeCDtWwF27ZY0CQfA4TVkE/wFOB77EpCg5RwsNDHS7KKUJ1FHfYBF4b02eEHasMNuaCsjt1HRfQRDaNRFHQ6316dZ2QNuJk2D89dRqk0DWNT+nmc4eYfFLcMDJUFiabEkEQUgSUb0WK6U6A0MwtYAA0FrPS5RQCSNQx746RW5WBkO65ydbmtTgtRvhzWy4I3ElngRBSG2anT6qlLocmIepGfRrazs9sWIlCH8d+/2KA0oK2n8iWTi3b4PznnU/JxnHguBpohkNrwfGAeu11scBh5LICqGJxF9HrfaRl93O6wu5kZkDPkeA/ERHhZDcwraXRxCElCEaRVCtta4GU3dIa70cODCxYiWIQB11OpOcTA8qAoDiwWZ72v0walqwPXH1XgVBSAOiUQRlSqki4BVgjlLqVRK9tnCi8NdRqzPIzfKYW8imeBD8z1oYe6lJKvuftXDMrVCzB37TDebcFd19PvsnfPzXxMoqCEKb0eyIqLU+W2u9W2s9HbgDeBz4YaIFSwgBM2vIsxYBQF6XYN5AXhfzARMn+OiB6O7x+s3w9u2JkU8QhDanyVlD1vrB32ithwNorT9oE6kShb+WWt2p/ZeejoW84tDjgB8yPKwoBcGDNDkiaq0DwCKlVN82kiex+Ouo0T5yvOoacqNz/9DjZydD9R7Xro1461fw/YK4iyQIQtsSzYjYE1iilHpXKTXL/iRasIQQqKcm4HHXUDhdwhLEv3sPPv6bUQbbV8Dmb8xgv2MVhK8i+snf4ImTW/f8uirYu7l19xAEoVVEk1CWjyk1YaOAPyRGnATjr6NGZ4hryIkdI3CyYwU8eCjsLw9tP+dxGDE5vs9/7ETYuji0WqogCG1KNCNiptb6A8fnfaBDcxelIjpQR61YBI25aSVc5DDy6qoaKwGAzQsbt9lrHTjRGt6+A1a+Bf+ZAt++7P5crY0SsPfjQcAPr98CO9eGtn/yMKx+Jz7PEIR2RlPVR68CrgYGKqW+cZwqAD5KtGAJwV9LHZkSIwinoAQyHF+F7cvd+2V2gNr9oW22IvDXGXdSx66wcw18/KD5AOzbCsN/1Ph+1hrS5vpak/TWWrZ8A589CmWfwxXvB9vfus1sxfJoOyq2Qn53qW6bBjQ1Iv4HOAOYZW3tzxit9QVtIFv88ddTh09cQ250dMwe2v29e5+qnfD4iaFttiKYfQP8aZBRCH8dHdqnMkIien11cL9mX2zyRkJZf1t/fdP9hMRS/h38+QD45KFkSyJEQcQRUWu9R2u9Tms9VWu93vHZ2ZYCxpVAHfWIaygiN6+G7gcHj0/5E1zzGfxyHeR0gootsPXb0GuqdsLnj8Myy7XkZk3s2QBr54e2LZkJi54PHtfGSxFYf9uti2H567B2nll/wclXT8OqOfF5nuDOjpVmuzb9alN6Ee8U5dcaFai3FIFYBK7kdwvNIRh2JhT0MPul42D5a+7XvXajURQAS18NPVfU11gYi1+CnoeY/dxO8NLFof1qK+PyI4TI//xU9z6zrjVbcRMljroqs83KbbqfkBJ4RxH46wCo05nkZolFEJHSscbPDpBfEmzvMhC+ezfydTV7zXben0Lb+08wb4c718BzU2H9h+7Xx0sRCKmB7fbLTMt5JZ7DO6/GVqnlWjLFImiKk38Pl74NP/8qNMhXPMjaUXBIhDfthr5DYOiZZj8r11y7br5RAl0PcL/mtRsaB6JbQiCG2MDmb5rvs3WpyasQYqPO+ltmiSJIB7wzIjYogiyZNdQUWbnQ9zDHwG9RMtza0TDxDhg0Ec78q3EZhTNqKgyYYPbra8wKaDaHRphnsGUxfPG4cSmEWwe1lcaisKeYBgKRlUZziiAQCO7/4+jgvr/eyBrOPyfC278y01KF6KmzLAJRBGmBd0ZE65/cWATiGoqZPoeZbckIKOwNF86E0RfBj59q3Ld4MGRbK8DVVcHBZwfPdTvIKBI33r4dftsDftcrNJj779NNgps9A+Wt2+B3Pd1nBjkHejfqq9zbn50M93SP3N85w0lonoYYgSiCdMA7isCyCOrENdQyMrPh6gVw0Suh7dkdG/fte2RwAKgLG3j7HBZUEk2xzjHLaOd3Zrtrndl++nez3bPBbBc8YqYrQvMWwTvTQ4/3WhXV18xt+ro6UQQxYStQiRGkBd4ZEW3XkBbXUIvpPtQkjDlxDuoDjoHRPzGzjwYdZ2YJTfyVOXfqfXDYldChKLrEsaw8qK81b/jVViC6Kmzm8s41ULUb3rwVnrRiEs0pgs8eDT1+rol4hzPbOZIlIbhjvwA4V8UTUhbvzBoS11BicE7X/ImjTEVuIfzMMYd8/E+D+yoKRfz+783nyJ/TsIRa1a7QPh89EJynbietaYcv35fd/HrMu9eHHgcCkGHJ95XD7RVu2QhNY7vStMRW0gHvvBrLrKHUIRpFYOPMTA1XBM5kJW3FBpwWQWYUc9jD7+l88//mxeC+KILYsKZrNxuzEVIC74yIzllDogiSS7giGNVExRJ7MM8thP07jbvIjQZFEGYRxIpzwPdlurcLzWP/HcQiSAu8MyJarqE6nUmOJJQll4KS0OOT74nc1x7Muwwybpx7urn3c1MELVlp7U+D4MkzYHohZDj820+cZKqpphJ/HQMPH5FsKdwJ2BaBKIJ0IKGKQCk1SSm1Qim1Wil1q8v5/1VKLbQ+K5VSuxMmjLiGEsdVH8N1X0fff/AJMPSM4HFuEZz+v+597ZyCTr2auak2bqQ6R36B7Z5ojt0bQo9tl5MOc2u8f29092srylfDtqXJlsIdOydDLIK0IGHBYqWUD3gIOBEoAz5XSs3SWjd8c7XWNzj6/xw4NFHy2IqgPiOLLJ8ogrhScnDzfcIZehYs+6+ZXqgU9B7r3s9+s8x3meMfzlv/D7oNdVwbZZbxlsXu7eGzlPbviO5+giNGIIogHUjkiDgeWK21XqO1rgWeB85qov9U4LmESWO9oaiW+I2F+GPnH/Q8xGybC+x2jEIRAGxfFtyP1iIIH/Bt9oe15xZFd79U569j4NlzE/sMv1gE6UQip4/2Bpw2dxlwmFtHpVQ/YADwXoTzVwBXAPTt27dl0lgWgRZFkBoMOs7kFgw8zhw7cwtyC80iN05izVAt6htMFmuODx9wbw+fWppKC6y0ZkW38tXmk0jsoL7MGkoLEmkRuP3XRPr2TgFmaO3++qC1flRrPVZrPbZbtwjBwuZoUARxWAVLaD1ZHUxuQdfB5thpEbi9/ceqwPseGb1rqHxVdP0izVhKBi0peRGv5UCjwc7fEIsgLUikIigD+jiOS4FIr2hTSKRbCBpcQ4EMyXRMSZwWgVsN+1gzVJuqg1/QM7Z75RbCiHPjX29Ia5heBB9GCJQ3hZ1tbd+nOVa8Ab8uMovytAW2a0hiBGlBIhXB58AQpdQApVQ2ZrCfFd5JKXUg0Bn4JIGyiGso1XG6frLyQs9d/l5ji2DyE3Dxa3DRLONiCqepmEOsLwNXfgi+nOazlMu/g3UxLOftrwN04/pH0VDjUARucm34PFhme+NX8PUzZn/N+457xGlVODds6yl85pWQkiQsRqC1rldKXQu8BfiAJ7TWS5RSdwNfaK1tpTAVeF7rBNut1j9LIEMUQUriHOjtQbxkuFn4vnRMcOlDm4HHQV4Xs5/jUsSuKUXgi/FrX9TXWCxuZaqd2Gs1R7vymb+Z+zVFpWMGU93+xvWbHj8hKMs/jwu27ykL7u/dBN0irA/RWsQ1lFYktNaQ1vp14PWwtjvDjqcnUoYGjvoF1647Cv/WOCx+IsQfOxCbXQCd+8FaYNK9MMBaM8B2DfU5HC4LS+xym83TVHC5qJ8pWAcwbYYpQd0cmVFYBLHSmpiDXZEV4A/94baNMPNnsHx2aL/phaHHGxaE3iPeimDLt/CvU4IWi7iG0gLvFJ1TitpABpmSQ5C6TPmPyUno2A16j4H+Pwiea8ql16Fz47amKpye85jJIIbgWsvN4cs2MYI9ZbBno1m8p7VEsgi2fGuyorsPdT8PwbLbNnN/21gJ2OQWQbVLrqatDFtLXRWsfsckCS6ZGeq2EtdQWuCpUdEf0GT6UmgKoBDKQadB5/4mx2DMxaHTNZtSBLmFjduaqoOfV+y4NoIiCI9TZOYai+Avo0y5iXgQKfj896Pg4cObvnZPWDb0gocj9z37H+7t4RnVLWXu7+CFC0xGdrglJhZBWuApRVAf0PgyPPUjtx+amjXkVlMokkXgywlVMJEsgvA32UxLEdmZzi9cGFmeaHG6htxWW2uKyu2gwn7uY34ZquRsCnq438P55t4SHj4CPn8M9peb4/LvTEzHicQI0gLvuIawLIIMsQjSklhne/UYGd19cgrc++mAWY4zx7I2woPPy2bBvu2way30GR92rY4u+czpGqqtMC6u75pZKc2mshxKhoWWxzjoNBh5Hmz41GRFd+wGPUeGxlCy86HWmi3UGkWw6WtT5+i1m+DI60zb0ldg08LQdSASZRGsnQc9R0W26ISY8JQiqPMH8IkiSE9irSTaK0LZKtuyOOwq+PSRyEFlHYBBEx3XuSiif00yGbp37gouZgNm8ItmZpJzFlL1XrMc5tM/bP46MHWPBkwIVQQ9RhoFVDwotK/T2ujYNagIqluhCB491nFgTfizp6b2GAlbrKmribAI9u80FWKHnATTXor//T2Ip/wk/oAmS2IE3iAjA67/xnFsKQB7QD/lXjO1MpLLqZFryMXVZJdpePFC+Ndpwfb7hxproTmciqBmL1Ruc3nGd8YFs3MNPHykyVN48kyo2ByaGHfnrshWiFMpDT4h9JnxIFyhnPw7uGu3ibMsfRV2fx+f59jUVJjtphgq3rYFlTvgzwdFLmKYwnhKEUiMoB0QabC7+DWY9n+hbZ37Qek4s28rgGhdTOFpLU3lJSyfDes/DB5XboOVbzT/DH+YRbDizcZ9PvmbccG8/wfYtgRm3wBrPzDnOnaFyf+CK94PtUjcOPdJ+Ol7cOLdcNztcNDpLbcIwt094QqlY1fzd7JLgi+O81u7rQicJUS0NhZJW5bRCGfV20ZBf/y35MnQQjw1KkqMoB3T/wcw5AQYNS20fexlZmu/+UeyAA46HQqdBQ3DFUGMNaqiyTlwWgQVm+H934We1zo4sNnTP52VUvO6wvAfRXaDOTn4h2ZKbnZHOOYWM1i31CIILwi4Z2PocYcuYRfE+X+uIUfBYbUtfBaeOit0edG2xlZ8sRZITAEkRiCkB7ZrJ9sli9jJWQ/BmX8NHtsDf26hGUzdLII7d9IwWAXq4J7ujWcT2WWzo6Wu2rhEnv2xCUhfPNsok1euNlnRI88NVQTLHNVXxl4GXzxuXA1f/su0rbSshUqHy6lj19hkcpLTydzrAZeg+u71RinmdzMyZneE0T8xg+25TzZWIGWfmcHfVlLheR3xrtpqWzJOi2DvZrOdeYXJqbCfe8ytMGpqfJ8fiTprOnAkRTDnLpNn0Rom3g4jf9y6e7jgKUUgMYI0pnSs+ScY/ZOm+ykVOq1y2A9hxyroMQJemOZuETgD0Rk5pnbRgGNC+zSngMKp3AabFwXXR9iy2ARQFz5rPiPPDbUalr5qtifeHVR63zdTfsttqmi0jDzPKJrwWEjVLqMI9nxvPjYbPjXbWddCtwMb3+/wq4IDcGaYsg1fo7q1uLmGnEUGS8dBRqZx1Sz7bxsqAmtdazdFsPod+OgBUzalZHjLn5Ff0nyfFuA5RSAxgjRFKZhwS+zX+TLhuNtg/cfmOBoXz/ifNm6L1SLYu8kMqjaPHR/ct+MNdkJZ6XjzVj38HDjqevjy36Z967fB/m7JZ62xCHoMh7MfadxeVw2/bWKwWflm0DoB6D7MWD5H/twogsI+LhfF2zVkuab8NWZGlC8zdPD90T9NzOS58+OXPR0N9ZYiCE9m3LkWnjnH7J90j1mLI8XwlCKolxiBdwmfNRQrkRRBTid3X/vONcYKcaO+GtZ9CB/9xRyf+2/jXy6yYhR2VvMHfzBy9xgBZZ83vk9eKxRBJLJy4bYy80a9v9xYQn/oFzx/6n3w+s3Q/2g4/wUjX6DeDMS3rGlsDQDMucNYQfFi+/Lg/hMnwbifQpbj72O/7BUPNEH7hyKUAynoYQLfP3zY/O73lJm+3Q40FlPFZph4B/znPOgywFg2PUcZC2POnbDyrcbyAMy9B76dETy2q7xeNAsGhlmaKYK3FIHECLyLPYUy1nUNbLIjJJ7ll7grgo1fmsE0nN5jYeMXZn2AvZuMP71Tr1A/unN95oxMUxvptZtMbOHtX5n2XqMhO6wMRrywk+wKS832wpnw9Nlmf/RFsGsdHHGNQzlag3/HJlxVxYNjzwVxw44F2Gz80nzOfrRx35FTTCDbLZdhx+pg3sP8++GMB+CjB02OhX1PMPkmq+eEXjtqqvH1NzVBqaBnaLJb8XkpqwTAa4pALALvkiiLoKBH5BXObL+6k9Jx5u1//UfGMjjpnsbB1C6OhDClTP2lC6ypsbYiOPbWmMRvFc7EuswcOPm3sd/jx083P8U1Gla/C8/8qHG722p0PYbDuf9yv8+nj8IbtquxiRE90syq6r1msaJAfTCg7+SUPyauxHcC8JTDXIrOeRhfKxVBpJkgbnV8IrmEwAzsXQYGk6G6DGzcp1Pv4L5bZVVoOq8hFYlXbM6twCAEa0BFfZ8oS1O45VpobQLWuZ0aFye0iXW6cZLxoEXgKd0n2GS00jUUaQqk7T5xkuMYrA69ILg6mLkRjL3EvEnmFEAfF/91Rgac9FtTu+f0B9yf29Zz1c95PP6zf1pCpCKBtkVwZpTJXCH3aeLlsNIlQ7xuv3E35XSK/DsRRZC6SIzAwzQogjivUOfmMsrJN/78NXPNTKcQRaBNmQdnqQc3jrzWfMLp2N1MTW1ri2BEFIv3hNOhc+jMqXgQqUigXU/poNPczzd5Hx22dRBe7huCVkJOQeRaSmm2JG4KqPi2Q2IEHqa5zOJoOPffjdvcAsI5nWDq82YWTbjroLUB0yJremasrpBkcMOS+N8zkkvH/n24/T2au4/futZtiu7ejY3b7DyG3EJT1tyNNHPdecoikBiBh2kIFrfCZA+frnnes2YGjZM+h5tgalau+YT7mH9wY8ufD6a20Pw/Ry6znUpkd4TT/mysmHgRySdvFwCMVhE4XUO71pvpvDvXNu63eVHjtnXzg/cIX3/BRlxDqYnWWorOeRlfHFxDzkHmgEkw9PTGBcZ+Mit0EHD68gdMgLzwOjwx0rkfnPlg6+7Rloy7PL73s2M1peNMZrY9UNtJeNFafM6s7PUfwr8juJS+e69x22uWMi8oiTxjLB5TZdsQzyiCgOX+E9eQR8mIg2vI9W3T+mKN+yn84IbGb4LO59klCITWcdMK45+vqzYW2cd/CZboiMU1dPWnJjvZWUQvr6txM9VVmVIl9VVQ0AvqKk0cwl9jAtPZ+cYqWzs/7j9eMvCMIqi3KhVKsNijtHb6KIS95VnfI7s6aGYOFPZudAkAR1wLy1+LfkaL0DT2lN3sjiaJ7ZDzg4oglgJ33Q+Kv2xpimf8JHbF2ox4V0IU0oOMLJMd3JpCbdG+bYZz8m/h+oUy8CSKLgOS92zn37Rb+v59PWMRBKw3N59nVJ8QQkYGXDk/8kLuUd2jCdeQkDycazK3NYNPgKsXGFdRbiHc61Z0L/XxjCLwW4pALAIP09o3RzdFYLuG5HuVPGKtDBtvug9N7vPjgGfejwMBUQRCK2lyJoh8r5JGpCmlQtR4RxFYL24SKxZajLiGUhOZEt5qvOMaCtgxAtEEQgtxWgQn3BV6TixNAcwqevVRrFedYnhGEWg7RiCKQGgptkWQ0ynoF7ZjBOIaEqBlq+ilAJ6xqSRYLLQaWxFopztIgsVC+uMdRWC7huQfVmgpbsHikVOgqB+MubjNxRGEeOEh15DZimtIaDHKVgQOi6CwN/zim6SIIwjxwjOKwN8wfTTJggjpi1iTqcv135gidEKLSKhrSCk1SSm1Qim1WinlusiqUurHSqmlSqklSqn/JEqWYGax/DMLLSQrDzoPSK/qn16hcz/oOiTZUqQtCbMIlFI+4CHgRKAM+FwpNUtrvdTRZwhwG3CU1nqXUiqOhctDsRWBkrc6oaVk+EzNIEFoZyTSIhgPrNZar9Fa1wLPA2eF9fkp8JDWeheA1npbooTxW0XnJFgsCIIQSiIVQW/AueBnmdXm5ADgAKXUR0qpBUqpSW43UkpdoZT6Qin1xfbtLotJR4EUnRMEQXAnkcOi26t3eD5+JjAEOBaYCjymlGpUSlBr/ajWeqzWemy3bt1aJIwdLBbXkCAIQiiJVARlgLMmaymwyaXPq1rrOq31WmAFRjHEHXv6qLiGBEEQQkmkIvgcGKKUGqCUygamALPC+rwCHAeglOqKcRWtSYQwDZnF4hoSBEEIIWHDota6HrgWeAtYBryotV6ilLpbKXWm1e0toFwptRSYC9yitS5PhDx+KUMtCILgSkITyrTWrwOvh7Xd6djXwI3WJ6FoySMQBEFwxTOOErEIBEEQ3PGOIpDqo4IgCK54RhFoWaFMEATBFc8oAlmhTBAEwR3PKIKArFAmCILgivcUgcQIBEEQQvCMIpCic4IgCO54RhEEJLNYEATBFc8MiwHJIxAEQXDFO4rALjonwWJBEIQQPKMIggllSRZEEAQhxfCMIhDXkCAIgjveUQRSdE4QBMEVzygCKTonCILgjmcUQUOtIbEIBEEQQvCMIpBgsSAIgjveUQR20TlxDQmCIITgGUWgpeicIAiCK55RBBIsFgRBcMc7isDOLBZFIAiCEIJnFIGWonOCIAiueGZYFNeQIAiCO55RBAO6duTUET3I9IkiEARBcJKZbAHaipMO7sFJB/dIthiCIAgph2csAkEQBMEdUQSCIAgeRxSBIAiCxxFFIAiC4HFEEQiCIHgcUQSCIAgeRxSBIAiCxxFFIAiC4HGUXYMnXVBKbQfWt/DyrsCOOIqTaNJJ3nSSFdJL3nSSFUTeRNIaWftprbu5nUg7RdAalFJfaK3HJluOaEknedNJVkgvedNJVhB5E0miZBXXkCAIgscRRSAIguBxvKYIHk22ADGSTvKmk6yQXvKmk6wg8iaShMjqqRiBIAiC0BivWQSCIAhCGKIIBEEQPI5nFIFSapJSaoVSarVS6tZkywOglHpCKbVNKfWto62LUmqOUmqVte1stSul1IOW/N8opUa3sax9lFJzlVLLlFJLlFLXp6q8SqlcpdRnSqlFlqy/ttoHKKU+tWR9QSmVbbXnWMerrfP920rWMLl9SqmvlVKzU1lepdQ6pdRipdRCpdQXVlvKfQ8c8hYppWYopZZb398jUlFepdSB1u/U/uxVSv2iTWTVWrf7D+ADvgMGAtnAImBYCsg1ARgNfOto+yNwq7V/K/AHa/9U4A1AAYcDn7axrD2B0dZ+AbASGJaK8lrPzLf2s4BPLRleBKZY7X8HrrL2rwb+bu1PAV5I0vfhRuA/wGzrOCXlBdYBXcPaUu574JDtSeByaz8bKEpleS05fMAWoF9byNrmP2CSfqlHAG85jm8Dbku2XJYs/cMUwQqgp7XfE1hh7f8DmOrW+C742QAABHVJREFUL0lyvwqcmOryAnnAV8BhmIzMzPDvBPAWcIS1n2n1U20sZynwLjARmG39c6ekvBEUQUp+D4BOwNrw30+qyut47knAR20lq1dcQ72BDY7jMqstFSnRWm8GsLbdrfaU+RksV8ShmDftlJTXcrMsBLYBczAW4W6tdb2LPA2yWuf3AMVtJavFA8D/AAHruJjUlVcDbyulvlRKXWG1peT3AOMF2A78y3K7PaaU6pjC8tpMAZ6z9hMuq1cUgXJpS7d5synxMyil8oH/A36htd7bVFeXtjaTV2vt11qPwrxpjweGNiFPUmVVSp0ObNNaf+lsdumaEvICR2mtRwOnANcopSY00TfZsmZi3K+PaK0PBSox7pVIJFterFjQmcBLzXV1aWuRrF5RBGVAH8dxKbApSbI0x1alVE8Aa7vNak/6z6CUysIogWe11i9bzSkrL4DWejfwPsaHWqSUynSRp0FW63whsLMNxTwKOFMptQ54HuMeeiBV5dVab7K224CZGEWbqt+DMqBMa/2pdTwDoxhSVV4wCvYrrfVW6zjhsnpFEXwODLFmYWRjzK5ZSZYpErOAn1j7P8H44u32i6yZAocDe2xzsS1QSingcWCZ1vr+VJZXKdVNKVVk7XcATgCWAXOByRFktX+GycB72nK6tgVa69u01qVa6/6Y7+Z7WutpqSivUqqjUqrA3sf4sr8lBb8HAFrrLcAGpdSBVtPxwNJUlddiKkG3kC1TYmVt6yBIsj6YCPtKjK/4V8mWx5LpOWAzUIfR7pdhfL3vAqusbRerrwIesuRfDIxtY1l/gDE7vwEWWp9TU1FeYCTwtSXrt8CdVvtA4DNgNcbszrHac63j1db5gUn8ThxLcNZQyslrybTI+iyx/5dS8XvgkHkU8IX1fXgF6Jyq8mImN5QDhY62hMsqJSYEQRA8jldcQ4IgCEIERBEIgiB4HFEEgiAIHkcUgSAIgscRRSAIguBxRBEIQhhKKX9YFci4VatVSvVXjmqzgpAKZDbfRRA8R5U25SkEwROIRSAIUWLV4f+DMmsdfKaUGmy191NKvWvVhH9XKdXXai9RSs1UZl2ERUqpI61b+ZRS/1RmrYS3rexnQUgaoggEoTEdwlxD5znO7dVajwf+hqkHhLX/lNZ6JPAs8KDV/iDwgdb6EEx9myVW+xDgIa31wcBu4JwE/zyC0CSSWSwIYSil9mmt813a1wETtdZrrAJ8W7TWxUqpHZg68HVW+2atdVel1HagVGtd47hHf2CO1nqIdfxLIEtrfU/ifzJBcEcsAkGIDR1hP1IfN2oc+34kVickGVEEghAb5zm2n1j7H2OqhgJMAz609t8FroKGhXI6tZWQghAL8iYiCI3pYK1uZvOm1tqeQpqjlPoU8xI11Wq7DnhCKXULZjWsS6z264FHlVKXYd78r8JUmxWElEJiBIIQJVaMYKzWekeyZRGEeCKuIUEQBI8jFoEgCILHEYtAEATB44giEARB8DiiCARBEDyOKAJBEASPI4pAEATB4/x/CqeB7Yh7yGoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-3.4833211e-01,  1.2274959e+00, -1.0010453e+00, -1.5415255e+00,\n",
      "         8.6972189e-01,  1.7227785e-01, -1.6262650e+00, -2.3031461e-01,\n",
      "        -9.6952224e-01],\n",
      "       [-2.4253297e+00,  1.3379552e+00, -2.1887057e+00, -1.2440876e+00,\n",
      "         2.3563204e+00,  2.4738996e+00, -1.0865197e+00, -3.0347905e+00,\n",
      "        -7.0125228e-01],\n",
      "       [-3.1932271e-01,  3.5080841e-01,  8.8245028e-01,  2.2659926e-03,\n",
      "        -3.8963085e-01, -1.2417318e+00,  7.5943863e-01, -2.5400597e-01,\n",
      "        -1.2393621e+00],\n",
      "       [-1.1244729e-01,  8.2250714e-01, -6.2531149e-01,  5.8729649e-01,\n",
      "         1.1785367e-01,  9.7241275e-02,  4.7249982e-01, -3.8637376e-01,\n",
      "         4.2790440e-01],\n",
      "       [-1.0208195e+00, -3.9240015e-01, -1.3670799e-01, -7.1433902e-01,\n",
      "        -1.1426220e+00,  1.7321187e-01,  5.9423971e-01, -3.4049800e-01,\n",
      "        -3.2408226e-01],\n",
      "       [ 2.8961957e-01,  7.5050086e-01,  2.0031823e-01, -8.5308957e-01,\n",
      "         1.1108766e+00, -1.4415737e+00, -1.0460620e+00,  2.1709360e-01,\n",
      "         1.1011368e+00],\n",
      "       [-5.8455914e-01,  1.0554036e-01,  2.5823462e-01, -7.6154381e-02,\n",
      "        -1.0465484e+00, -3.7060529e-02,  5.4565912e-01, -5.9988624e-01,\n",
      "        -5.6590438e-01]], dtype=float32), array([ 0.64147395, -0.81213343,  0.31300443,  0.30015773, -0.3053737 ,\n",
      "        0.11189649, -0.01619672,  0.7263692 ,  0.4561648 ], dtype=float32), array([[-0.07727272, -1.3055748 ,  1.258567  ,  1.5385666 , -0.40918896,\n",
      "         1.0615734 ,  1.1097873 , -1.300824  ,  1.4747682 ],\n",
      "       [-0.46822247,  1.7805223 , -1.5984099 ,  1.5816231 ,  0.25931036,\n",
      "         0.7419795 , -1.6720169 , -0.7644092 , -0.886657  ],\n",
      "       [ 0.22429864, -0.548795  ,  1.7912372 ,  0.38174433, -1.5181164 ,\n",
      "        -0.6249245 , -0.6122505 , -1.1805087 ,  3.113426  ],\n",
      "       [-0.36345813, -0.34370604,  1.8824215 , -0.14425021, -2.254586  ,\n",
      "        -0.1512366 ,  1.8445613 ,  0.22393261, -0.416716  ],\n",
      "       [-0.78781545,  0.65027666, -3.3481464 ,  0.1407443 ,  1.5165372 ,\n",
      "         1.3380725 ,  0.30445004, -0.8661368 , -0.6566435 ],\n",
      "       [ 0.21417105, -0.53056055, -0.41959155, -2.1690123 ,  0.4826122 ,\n",
      "        -0.6921246 ,  1.83326   ,  2.0584195 , -1.8208044 ],\n",
      "       [-0.20873065,  1.9706805 ,  2.0833797 , -0.28848678, -3.1307878 ,\n",
      "        -2.779313  , -0.93113244,  0.29602778, -0.03272502],\n",
      "       [ 0.86657685, -1.5784799 ,  2.1469827 ,  1.7843245 , -0.35675386,\n",
      "         1.5502553 ,  1.5632182 ,  0.04646437,  1.7525669 ],\n",
      "       [-2.0306277 , -1.760926  , -0.4291065 ,  0.9809258 , -0.22847012,\n",
      "         2.245876  ,  2.0872138 , -0.46596906,  0.23059542]],\n",
      "      dtype=float32), array([-0.20285432, -0.5260782 ,  0.25468212,  0.26904395,  0.440962  ,\n",
      "        0.44419873, -0.04053173,  0.3156469 ,  0.59985816], dtype=float32), array([[-0.9643314 , -0.68166274, -0.16301343,  0.19639167,  0.7267375 ,\n",
      "        -0.61429995,  1.3022976 ,  2.4053447 ,  0.9195116 ],\n",
      "       [-1.7926767 ,  1.5707548 , -1.0360856 ,  0.98738706, -2.2037039 ,\n",
      "        -1.6706855 ,  0.40907916, -1.2010951 ,  0.8186991 ],\n",
      "       [ 1.5526975 ,  0.7554634 ,  2.7991986 , -2.9908824 , -1.3122714 ,\n",
      "         2.1746519 , -1.7962099 , -1.5843052 , -2.443889  ],\n",
      "       [ 2.6597495 ,  1.0275273 , -0.7268523 , -0.01016737, -0.7637624 ,\n",
      "        -0.5105673 , -1.862712  , -0.78894556,  0.5866771 ],\n",
      "       [-1.0816839 , -0.90389776, -1.7875109 ,  1.8517811 ,  1.267235  ,\n",
      "         1.2721876 ,  1.1211742 , -0.5604534 ,  1.696413  ],\n",
      "       [ 3.0465195 , -1.2830479 , -0.19164518,  0.4721095 ,  0.99879175,\n",
      "         0.6841649 , -2.2167141 , -1.0136545 ,  0.3106546 ],\n",
      "       [-0.17601718,  1.0599796 ,  0.6885963 , -0.9169908 ,  0.3649914 ,\n",
      "         4.4208875 , -0.36408365, -0.8538896 , -1.1412627 ],\n",
      "       [-1.4119958 , -1.0624437 ,  0.60935926, -0.7713849 , -0.32108256,\n",
      "         0.9704489 ,  1.5731448 , -0.16175923, -0.78123325],\n",
      "       [ 1.1216468 , -2.1261632 ,  0.6166964 , -0.35822344,  2.533809  ,\n",
      "        -0.82022154, -0.00610914,  0.6981124 , -0.5735955 ]],\n",
      "      dtype=float32), array([ 1.3601756 , -0.00981854, -0.02371026,  0.03286509, -0.05236189,\n",
      "       -0.68046385, -0.5996375 ,  0.02190051, -0.34333673], dtype=float32), array([[-2.3917162],\n",
      "       [-4.707554 ],\n",
      "       [-1.8430957],\n",
      "       [ 1.3659383],\n",
      "       [ 4.2429395],\n",
      "       [-4.716239 ],\n",
      "       [ 2.6728377],\n",
      "       [ 4.440337 ],\n",
      "       [ 1.6781739]], dtype=float32), array([0.00392322], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.03060788e-05]\n",
      " [9.99951839e-01]\n",
      " [9.92864847e-01]\n",
      " [4.62243588e-05]\n",
      " [2.24511401e-04]\n",
      " [9.99999762e-01]\n",
      " [9.99875903e-01]\n",
      " [9.99999642e-01]\n",
      " [9.99127328e-01]\n",
      " [1.00000000e+00]\n",
      " [1.76758098e-04]\n",
      " [7.76157030e-05]\n",
      " [9.99947548e-01]\n",
      " [4.71665408e-06]\n",
      " [4.33326524e-04]\n",
      " [9.99967813e-01]\n",
      " [3.09406139e-04]\n",
      " [9.98683512e-01]\n",
      " [9.99965668e-01]\n",
      " [9.99665499e-01]\n",
      " [2.59373628e-05]\n",
      " [4.40888034e-05]\n",
      " [5.67123236e-04]\n",
      " [9.99151111e-01]\n",
      " [9.99814451e-01]\n",
      " [9.99973416e-01]\n",
      " [9.99976873e-01]\n",
      " [9.99863505e-01]\n",
      " [2.14777741e-04]\n",
      " [9.99654531e-01]\n",
      " [3.02096760e-06]\n",
      " [2.31847796e-03]\n",
      " [8.39373912e-04]\n",
      " [9.26809967e-04]\n",
      " [7.66503945e-05]\n",
      " [1.00000000e+00]\n",
      " [9.99972343e-01]\n",
      " [9.98603404e-01]\n",
      " [9.99103963e-01]\n",
      " [9.99979734e-01]\n",
      " [9.99949098e-01]\n",
      " [1.00000000e+00]\n",
      " [1.94987821e-04]\n",
      " [4.39720964e-07]\n",
      " [8.38454289e-05]\n",
      " [9.99050558e-01]\n",
      " [9.99109566e-01]\n",
      " [1.00000000e+00]\n",
      " [9.98024940e-01]\n",
      " [1.62360855e-04]\n",
      " [1.17965756e-04]\n",
      " [9.98111963e-01]\n",
      " [5.35846048e-05]\n",
      " [9.64519768e-06]\n",
      " [8.19336201e-05]\n",
      " [3.67192551e-04]\n",
      " [4.10064170e-03]\n",
      " [1.00000000e+00]\n",
      " [4.04767846e-08]\n",
      " [3.75285093e-03]\n",
      " [5.03541110e-03]\n",
      " [9.99999762e-01]\n",
      " [9.97434199e-01]\n",
      " [9.99998331e-01]\n",
      " [1.72031996e-05]\n",
      " [2.67966534e-04]\n",
      " [3.17290600e-04]\n",
      " [1.00000000e+00]\n",
      " [1.78358358e-04]\n",
      " [2.19392381e-03]\n",
      " [1.11816544e-03]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [9.99854207e-01]\n",
      " [9.99988794e-01]\n",
      " [1.14476723e-04]\n",
      " [9.99879837e-01]\n",
      " [2.94287274e-05]\n",
      " [9.97390985e-01]\n",
      " [1.03121030e-03]\n",
      " [1.92497129e-04]\n",
      " [7.17099392e-05]\n",
      " [9.99160647e-01]\n",
      " [9.99897242e-01]\n",
      " [9.96089995e-01]\n",
      " [9.99565899e-01]\n",
      " [9.99972463e-01]\n",
      " [9.99485612e-01]\n",
      " [3.15768790e-04]\n",
      " [9.99850154e-01]\n",
      " [9.99212861e-01]\n",
      " [9.99974132e-01]\n",
      " [9.99867201e-01]\n",
      " [9.99967337e-01]\n",
      " [5.57688624e-02]\n",
      " [3.58852587e-04]\n",
      " [9.99960184e-01]\n",
      " [9.99821126e-01]\n",
      " [2.52259010e-03]\n",
      " [1.00000000e+00]\n",
      " [7.66362250e-01]\n",
      " [3.33440912e-05]\n",
      " [9.99931931e-01]\n",
      " [9.99981880e-01]\n",
      " [5.21778536e-04]\n",
      " [1.00000000e+00]\n",
      " [2.20564216e-05]\n",
      " [5.08364551e-02]\n",
      " [9.99998569e-01]\n",
      " [2.18818386e-04]\n",
      " [8.73772278e-02]\n",
      " [8.56600106e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99892473e-01]\n",
      " [2.54135084e-04]\n",
      " [9.99925017e-01]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5, X6, X7])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
