{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,2:3] #Glucose\n",
    "X2 = dataset[:,7:8] #Resistin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,1:2] #BMI\n",
    "X5 = dataset[:,4:5] #HOMA\n",
    "X6 = dataset[:,5:6] #Leptin\n",
    "X7 = dataset[:,3:4] #Insulin\n",
    "X8 = dataset[:,6:7] #Adiponectin\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "X6 = normalization(X6)\n",
    "X7 = normalization(X7)\n",
    "X8 = normalization(X8)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X6 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X7 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X8 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 8)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "                                                                 input_layer_X6[0][0]             \n",
      "                                                                 input_layer_X7[0][0]             \n",
      "                                                                 input_layer_X8[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            81          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 271\n",
      "Trainable params: 271\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "input_layer_X6 = keras.layers.Input(shape=(1, ), name='input_layer_X6')\n",
    "input_layer_X7 = keras.layers.Input(shape=(1, ), name='input_layer_X7')\n",
    "input_layer_X8 = keras.layers.Input(shape=(1, ), name='input_layer_X8')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7, input_layer_X8], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7, input_layer_X8], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.7060 - acc: 0.4891 - auc_1: 0.5445 - val_loss: 0.6646 - val_acc: 0.7500 - val_auc_1: 0.6893\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6695 - acc: 0.6087 - auc_1: 0.6133 - val_loss: 0.6322 - val_acc: 0.7083 - val_auc_1: 0.7179\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6497 - acc: 0.6413 - auc_1: 0.6752 - val_loss: 0.6060 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6209 - acc: 0.5978 - auc_1: 0.7210 - val_loss: 0.5778 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5911 - acc: 0.6522 - auc_1: 0.7545 - val_loss: 0.5330 - val_acc: 0.8333 - val_auc_1: 0.8036\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5739 - acc: 0.6630 - auc_1: 0.7643 - val_loss: 0.5628 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5554 - acc: 0.7283 - auc_1: 0.7821 - val_loss: 0.5111 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5450 - acc: 0.6630 - auc_1: 0.7826 - val_loss: 0.5665 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5362 - acc: 0.7391 - auc_1: 0.7848 - val_loss: 0.5211 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5323 - acc: 0.6957 - auc_1: 0.7798 - val_loss: 0.5954 - val_acc: 0.7083 - val_auc_1: 0.8893\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5233 - acc: 0.7609 - auc_1: 0.8102 - val_loss: 0.4991 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5208 - acc: 0.6848 - auc_1: 0.8048 - val_loss: 0.5328 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5168 - acc: 0.7500 - auc_1: 0.8098 - val_loss: 0.5519 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5106 - acc: 0.7174 - auc_1: 0.8107 - val_loss: 0.6250 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5085 - acc: 0.7609 - auc_1: 0.8195 - val_loss: 0.4806 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5114 - acc: 0.7283 - auc_1: 0.8100 - val_loss: 0.5346 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5033 - acc: 0.7500 - auc_1: 0.8202 - val_loss: 0.5045 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4951 - acc: 0.7609 - auc_1: 0.8281 - val_loss: 0.4653 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4987 - acc: 0.7391 - auc_1: 0.8264 - val_loss: 0.5909 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5002 - acc: 0.7391 - auc_1: 0.8219 - val_loss: 0.5443 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4915 - acc: 0.7391 - auc_1: 0.8310 - val_loss: 0.6143 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4986 - acc: 0.7609 - auc_1: 0.8117 - val_loss: 0.5513 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4880 - acc: 0.7500 - auc_1: 0.8336 - val_loss: 0.4852 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4936 - acc: 0.7609 - auc_1: 0.8295 - val_loss: 0.5451 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4834 - acc: 0.7391 - auc_1: 0.8288 - val_loss: 0.5392 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4808 - acc: 0.7500 - auc_1: 0.8326 - val_loss: 0.5109 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4850 - acc: 0.7500 - auc_1: 0.8310 - val_loss: 0.5222 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4806 - acc: 0.7391 - auc_1: 0.8367 - val_loss: 0.5495 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4729 - acc: 0.7609 - auc_1: 0.8338 - val_loss: 0.6153 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4834 - acc: 0.7609 - auc_1: 0.8326 - val_loss: 0.5779 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4643 - acc: 0.7609 - auc_1: 0.8519 - val_loss: 0.5899 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4729 - acc: 0.7500 - auc_1: 0.8405 - val_loss: 0.5242 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4710 - acc: 0.7391 - auc_1: 0.8414 - val_loss: 0.5434 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4644 - acc: 0.7935 - auc_1: 0.8445 - val_loss: 0.4844 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4675 - acc: 0.7391 - auc_1: 0.8519 - val_loss: 0.5968 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4875 - acc: 0.7935 - auc_1: 0.8443 - val_loss: 0.4948 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4626 - acc: 0.7609 - auc_1: 0.8524 - val_loss: 0.5575 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4596 - acc: 0.7826 - auc_1: 0.8486 - val_loss: 0.5845 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4619 - acc: 0.7717 - auc_1: 0.8521 - val_loss: 0.5231 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4561 - acc: 0.7609 - auc_1: 0.8457 - val_loss: 0.5025 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4493 - acc: 0.7174 - auc_1: 0.8486 - val_loss: 0.5915 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4451 - acc: 0.7935 - auc_1: 0.8588 - val_loss: 0.4705 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4525 - acc: 0.8043 - auc_1: 0.8562 - val_loss: 0.4845 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4621 - acc: 0.7609 - auc_1: 0.8493 - val_loss: 0.6273 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4644 - acc: 0.7826 - auc_1: 0.8486 - val_loss: 0.6117 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4591 - acc: 0.7609 - auc_1: 0.8467 - val_loss: 0.5506 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4433 - acc: 0.8043 - auc_1: 0.8593 - val_loss: 0.4887 - val_acc: 0.8750 - val_auc_1: 0.8857\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4531 - acc: 0.7826 - auc_1: 0.8569 - val_loss: 0.5086 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4462 - acc: 0.7935 - auc_1: 0.8631 - val_loss: 0.6130 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4330 - acc: 0.7935 - auc_1: 0.8752 - val_loss: 0.4588 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4690 - acc: 0.7500 - auc_1: 0.8550 - val_loss: 0.5142 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4505 - acc: 0.7935 - auc_1: 0.8640 - val_loss: 0.6169 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4520 - acc: 0.8152 - auc_1: 0.8438 - val_loss: 0.5798 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4495 - acc: 0.7826 - auc_1: 0.8590 - val_loss: 0.5635 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4404 - acc: 0.7717 - auc_1: 0.8705 - val_loss: 0.4904 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4417 - acc: 0.7826 - auc_1: 0.8545 - val_loss: 0.5440 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4425 - acc: 0.8043 - auc_1: 0.8667 - val_loss: 0.6003 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4457 - acc: 0.8043 - auc_1: 0.8550 - val_loss: 0.5737 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4372 - acc: 0.7717 - auc_1: 0.8636 - val_loss: 0.4832 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4566 - acc: 0.7826 - auc_1: 0.8600 - val_loss: 0.5920 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4400 - acc: 0.8152 - auc_1: 0.8671 - val_loss: 0.4926 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4350 - acc: 0.7935 - auc_1: 0.8645 - val_loss: 0.4677 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4372 - acc: 0.8261 - auc_1: 0.8740 - val_loss: 0.5829 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4373 - acc: 0.8043 - auc_1: 0.8674 - val_loss: 0.5366 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4386 - acc: 0.8152 - auc_1: 0.8693 - val_loss: 0.5124 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4298 - acc: 0.8152 - auc_1: 0.8860 - val_loss: 0.6009 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4391 - acc: 0.8043 - auc_1: 0.8626 - val_loss: 0.5797 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4239 - acc: 0.8152 - auc_1: 0.8819 - val_loss: 0.4762 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4347 - acc: 0.8043 - auc_1: 0.8726 - val_loss: 0.5101 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4269 - acc: 0.7935 - auc_1: 0.8769 - val_loss: 0.5087 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4337 - acc: 0.8152 - auc_1: 0.8745 - val_loss: 0.5332 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4358 - acc: 0.7935 - auc_1: 0.8702 - val_loss: 0.5419 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4279 - acc: 0.8152 - auc_1: 0.8814 - val_loss: 0.4710 - val_acc: 0.8750 - val_auc_1: 0.8857\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4340 - acc: 0.8043 - auc_1: 0.8795 - val_loss: 0.5073 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4230 - acc: 0.7935 - auc_1: 0.8852 - val_loss: 0.5543 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4298 - acc: 0.8261 - auc_1: 0.8869 - val_loss: 0.5033 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4153 - acc: 0.8043 - auc_1: 0.8924 - val_loss: 0.5413 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4112 - acc: 0.8370 - auc_1: 0.8945 - val_loss: 0.5055 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4186 - acc: 0.8261 - auc_1: 0.8902 - val_loss: 0.5150 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4120 - acc: 0.8152 - auc_1: 0.8919 - val_loss: 0.5804 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4148 - acc: 0.8152 - auc_1: 0.8867 - val_loss: 0.5638 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4138 - acc: 0.8152 - auc_1: 0.8912 - val_loss: 0.5478 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4106 - acc: 0.8370 - auc_1: 0.8990 - val_loss: 0.5477 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4030 - acc: 0.8043 - auc_1: 0.9045 - val_loss: 0.5165 - val_acc: 0.8750 - val_auc_1: 0.8857\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3894 - acc: 0.8370 - auc_1: 0.9055 - val_loss: 0.4486 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3894 - acc: 0.8587 - auc_1: 0.9133 - val_loss: 0.6115 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3983 - acc: 0.8370 - auc_1: 0.8964 - val_loss: 0.5135 - val_acc: 0.8750 - val_auc_1: 0.8857\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4002 - acc: 0.8261 - auc_1: 0.9012 - val_loss: 0.5493 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3911 - acc: 0.8370 - auc_1: 0.9057 - val_loss: 0.4907 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3805 - acc: 0.8478 - auc_1: 0.9086 - val_loss: 0.5740 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3688 - acc: 0.8478 - auc_1: 0.9195 - val_loss: 0.5755 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3799 - acc: 0.8152 - auc_1: 0.9095 - val_loss: 0.5187 - val_acc: 0.8750 - val_auc_1: 0.8857\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3698 - acc: 0.8696 - auc_1: 0.9157 - val_loss: 0.5073 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3643 - acc: 0.8478 - auc_1: 0.9164 - val_loss: 0.5150 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3612 - acc: 0.8804 - auc_1: 0.9212 - val_loss: 0.5319 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3736 - acc: 0.8478 - auc_1: 0.9105 - val_loss: 0.5320 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 97/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3533 - acc: 0.8913 - auc_1: 0.9224 - val_loss: 0.4881 - val_acc: 0.8750 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3594 - acc: 0.8478 - auc_1: 0.9198 - val_loss: 0.5134 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3517 - acc: 0.8804 - auc_1: 0.9162 - val_loss: 0.5328 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3384 - acc: 0.9022 - auc_1: 0.9262 - val_loss: 0.5016 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3547 - acc: 0.8696 - auc_1: 0.9176 - val_loss: 0.5230 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3450 - acc: 0.8804 - auc_1: 0.9193 - val_loss: 0.5462 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3270 - acc: 0.8804 - auc_1: 0.9452 - val_loss: 0.5954 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3410 - acc: 0.8804 - auc_1: 0.9283 - val_loss: 0.5940 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3368 - acc: 0.9022 - auc_1: 0.9255 - val_loss: 0.5031 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3274 - acc: 0.8913 - auc_1: 0.9288 - val_loss: 0.4997 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2950 - acc: 0.9022 - auc_1: 0.9521 - val_loss: 0.6814 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3287 - acc: 0.8804 - auc_1: 0.9295 - val_loss: 0.5348 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3182 - acc: 0.9130 - auc_1: 0.9388 - val_loss: 0.5431 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3219 - acc: 0.9022 - auc_1: 0.9312 - val_loss: 0.5794 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3249 - acc: 0.8804 - auc_1: 0.9376 - val_loss: 0.5210 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3135 - acc: 0.8913 - auc_1: 0.9360 - val_loss: 0.5907 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3118 - acc: 0.8696 - auc_1: 0.9386 - val_loss: 0.5544 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3087 - acc: 0.9239 - auc_1: 0.9386 - val_loss: 0.5434 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3130 - acc: 0.8804 - auc_1: 0.9419 - val_loss: 0.6552 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3082 - acc: 0.8804 - auc_1: 0.9402 - val_loss: 0.5210 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3050 - acc: 0.9022 - auc_1: 0.9448 - val_loss: 0.5784 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2995 - acc: 0.9022 - auc_1: 0.9419 - val_loss: 0.5696 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2897 - acc: 0.9022 - auc_1: 0.9474 - val_loss: 0.5418 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3014 - acc: 0.9022 - auc_1: 0.9412 - val_loss: 0.5863 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2912 - acc: 0.8913 - auc_1: 0.9481 - val_loss: 0.5051 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3107 - acc: 0.8913 - auc_1: 0.9369 - val_loss: 0.5570 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2873 - acc: 0.9130 - auc_1: 0.9455 - val_loss: 0.5322 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2879 - acc: 0.9130 - auc_1: 0.9429 - val_loss: 0.6080 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2940 - acc: 0.9130 - auc_1: 0.9440 - val_loss: 0.6037 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2777 - acc: 0.9239 - auc_1: 0.9500 - val_loss: 0.5666 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2806 - acc: 0.9130 - auc_1: 0.9498 - val_loss: 0.6408 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2822 - acc: 0.9130 - auc_1: 0.9448 - val_loss: 0.5915 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2749 - acc: 0.9239 - auc_1: 0.9479 - val_loss: 0.6293 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2719 - acc: 0.9239 - auc_1: 0.9507 - val_loss: 0.6318 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2724 - acc: 0.9130 - auc_1: 0.9533 - val_loss: 0.5645 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2719 - acc: 0.9239 - auc_1: 0.9448 - val_loss: 0.5476 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2693 - acc: 0.9130 - auc_1: 0.9533 - val_loss: 0.5907 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2701 - acc: 0.9239 - auc_1: 0.9507 - val_loss: 0.5685 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2640 - acc: 0.9348 - auc_1: 0.9526 - val_loss: 0.5577 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2686 - acc: 0.9130 - auc_1: 0.9519 - val_loss: 0.6298 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2528 - acc: 0.9239 - auc_1: 0.9576 - val_loss: 0.6253 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2595 - acc: 0.9239 - auc_1: 0.9517 - val_loss: 0.6266 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2655 - acc: 0.9130 - auc_1: 0.9517 - val_loss: 0.6026 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2549 - acc: 0.9239 - auc_1: 0.9545 - val_loss: 0.6217 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2609 - acc: 0.9239 - auc_1: 0.9488 - val_loss: 0.6545 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2554 - acc: 0.9239 - auc_1: 0.9562 - val_loss: 0.7014 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2602 - acc: 0.9130 - auc_1: 0.9564 - val_loss: 0.7344 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2641 - acc: 0.9239 - auc_1: 0.9526 - val_loss: 0.6738 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 145/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2613 - acc: 0.9239 - auc_1: 0.9464 - val_loss: 0.7070 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 146/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2564 - acc: 0.9022 - auc_1: 0.9605 - val_loss: 0.6641 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2602 - acc: 0.9130 - auc_1: 0.9500 - val_loss: 0.6532 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2401 - acc: 0.9239 - auc_1: 0.9612 - val_loss: 0.6474 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2374 - acc: 0.9239 - auc_1: 0.9633 - val_loss: 0.6087 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2371 - acc: 0.9239 - auc_1: 0.9614 - val_loss: 0.6305 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2429 - acc: 0.9239 - auc_1: 0.9595 - val_loss: 0.6019 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2294 - acc: 0.9348 - auc_1: 0.9640 - val_loss: 0.6083 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2339 - acc: 0.9130 - auc_1: 0.9610 - val_loss: 0.6837 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2388 - acc: 0.9239 - auc_1: 0.9636 - val_loss: 0.6465 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2260 - acc: 0.9348 - auc_1: 0.9638 - val_loss: 0.6744 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2228 - acc: 0.9239 - auc_1: 0.9683 - val_loss: 0.6870 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2335 - acc: 0.9130 - auc_1: 0.9614 - val_loss: 0.7263 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2212 - acc: 0.9348 - auc_1: 0.9652 - val_loss: 0.6158 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2418 - acc: 0.9130 - auc_1: 0.9598 - val_loss: 0.6923 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2424 - acc: 0.9130 - auc_1: 0.9640 - val_loss: 0.6289 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2312 - acc: 0.9130 - auc_1: 0.9643 - val_loss: 0.6527 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2185 - acc: 0.9348 - auc_1: 0.9664 - val_loss: 0.6544 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2137 - acc: 0.9348 - auc_1: 0.9674 - val_loss: 0.7057 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2129 - acc: 0.9348 - auc_1: 0.9712 - val_loss: 0.6978 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2272 - acc: 0.9239 - auc_1: 0.9638 - val_loss: 0.6773 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2073 - acc: 0.9348 - auc_1: 0.9693 - val_loss: 0.7387 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2064 - acc: 0.9239 - auc_1: 0.9705 - val_loss: 0.6848 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2182 - acc: 0.9348 - auc_1: 0.9662 - val_loss: 0.6926 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2191 - acc: 0.9130 - auc_1: 0.9707 - val_loss: 0.6575 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2075 - acc: 0.9348 - auc_1: 0.9693 - val_loss: 0.7157 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2144 - acc: 0.9130 - auc_1: 0.9690 - val_loss: 0.6581 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2006 - acc: 0.9348 - auc_1: 0.9721 - val_loss: 0.6467 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2130 - acc: 0.9348 - auc_1: 0.9688 - val_loss: 0.6515 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2040 - acc: 0.9348 - auc_1: 0.9710 - val_loss: 0.6931 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2129 - acc: 0.9348 - auc_1: 0.9710 - val_loss: 0.7011 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2333 - acc: 0.9130 - auc_1: 0.9610 - val_loss: 0.7266 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1977 - acc: 0.9348 - auc_1: 0.9764 - val_loss: 0.5884 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2003 - acc: 0.9239 - auc_1: 0.9726 - val_loss: 0.6817 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1922 - acc: 0.9348 - auc_1: 0.9764 - val_loss: 0.6826 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2015 - acc: 0.9239 - auc_1: 0.9771 - val_loss: 0.6623 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1850 - acc: 0.9565 - auc_1: 0.9757 - val_loss: 0.6579 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1936 - acc: 0.9348 - auc_1: 0.9764 - val_loss: 0.6288 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2139 - acc: 0.9239 - auc_1: 0.9769 - val_loss: 0.6514 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1869 - acc: 0.9348 - auc_1: 0.9774 - val_loss: 0.6470 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1880 - acc: 0.9348 - auc_1: 0.9774 - val_loss: 0.6382 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1879 - acc: 0.9348 - auc_1: 0.9776 - val_loss: 0.6429 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1889 - acc: 0.9348 - auc_1: 0.9781 - val_loss: 0.6426 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1831 - acc: 0.9348 - auc_1: 0.9798 - val_loss: 0.6113 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1746 - acc: 0.9457 - auc_1: 0.9795 - val_loss: 0.6822 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1827 - acc: 0.9239 - auc_1: 0.9836 - val_loss: 0.6271 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1842 - acc: 0.9348 - auc_1: 0.9798 - val_loss: 0.6648 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1799 - acc: 0.9348 - auc_1: 0.9829 - val_loss: 0.5784 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1833 - acc: 0.9239 - auc_1: 0.9831 - val_loss: 0.6194 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 194/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1713 - acc: 0.9457 - auc_1: 0.9829 - val_loss: 0.6412 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1669 - acc: 0.9348 - auc_1: 0.9845 - val_loss: 0.5836 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1618 - acc: 0.9457 - auc_1: 0.9840 - val_loss: 0.6335 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1729 - acc: 0.9565 - auc_1: 0.9805 - val_loss: 0.6336 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1749 - acc: 0.9457 - auc_1: 0.9814 - val_loss: 0.6281 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1705 - acc: 0.9457 - auc_1: 0.9831 - val_loss: 0.6386 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1740 - acc: 0.9457 - auc_1: 0.9821 - val_loss: 0.5834 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1682 - acc: 0.9565 - auc_1: 0.9812 - val_loss: 0.6068 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1614 - acc: 0.9348 - auc_1: 0.9857 - val_loss: 0.5880 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1537 - acc: 0.9457 - auc_1: 0.9855 - val_loss: 0.6318 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1623 - acc: 0.9348 - auc_1: 0.9850 - val_loss: 0.5948 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1487 - acc: 0.9457 - auc_1: 0.9871 - val_loss: 0.5798 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1518 - acc: 0.9457 - auc_1: 0.9843 - val_loss: 0.5866 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1523 - acc: 0.9348 - auc_1: 0.9871 - val_loss: 0.5660 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1454 - acc: 0.9457 - auc_1: 0.9871 - val_loss: 0.5961 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1564 - acc: 0.9457 - auc_1: 0.9836 - val_loss: 0.6338 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1494 - acc: 0.9565 - auc_1: 0.9869 - val_loss: 0.5635 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1570 - acc: 0.9457 - auc_1: 0.9845 - val_loss: 0.5387 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1443 - acc: 0.9457 - auc_1: 0.9890 - val_loss: 0.5256 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1562 - acc: 0.9348 - auc_1: 0.9869 - val_loss: 0.5909 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1465 - acc: 0.9457 - auc_1: 0.9867 - val_loss: 0.5717 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1341 - acc: 0.9565 - auc_1: 0.9910 - val_loss: 0.5229 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1348 - acc: 0.9565 - auc_1: 0.9879 - val_loss: 0.5347 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1337 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.5357 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1297 - acc: 0.9565 - auc_1: 0.9898 - val_loss: 0.5046 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1331 - acc: 0.9565 - auc_1: 0.9867 - val_loss: 0.5409 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1310 - acc: 0.9565 - auc_1: 0.9876 - val_loss: 0.5491 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1295 - acc: 0.9565 - auc_1: 0.9893 - val_loss: 0.5591 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1253 - acc: 0.9565 - auc_1: 0.9883 - val_loss: 0.5695 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1209 - acc: 0.9565 - auc_1: 0.9900 - val_loss: 0.5480 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1251 - acc: 0.9457 - auc_1: 0.9890 - val_loss: 0.5444 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1160 - acc: 0.9674 - auc_1: 0.9914 - val_loss: 0.5730 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1187 - acc: 0.9565 - auc_1: 0.9912 - val_loss: 0.5726 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1194 - acc: 0.9565 - auc_1: 0.9919 - val_loss: 0.5627 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1193 - acc: 0.9565 - auc_1: 0.9912 - val_loss: 0.5568 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1146 - acc: 0.9565 - auc_1: 0.9900 - val_loss: 0.5460 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1163 - acc: 0.9565 - auc_1: 0.9921 - val_loss: 0.5022 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1069 - acc: 0.9783 - auc_1: 0.9907 - val_loss: 0.5562 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1177 - acc: 0.9565 - auc_1: 0.9898 - val_loss: 0.5211 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1104 - acc: 0.9674 - auc_1: 0.9902 - val_loss: 0.5659 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1180 - acc: 0.9565 - auc_1: 0.9907 - val_loss: 0.5292 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1359 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.5911 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1131 - acc: 0.9783 - auc_1: 0.9919 - val_loss: 0.5767 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1045 - acc: 0.9783 - auc_1: 0.9948 - val_loss: 0.5598 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1059 - acc: 0.9674 - auc_1: 0.9936 - val_loss: 0.5262 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0995 - acc: 0.9783 - auc_1: 0.9931 - val_loss: 0.5904 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1009 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.4958 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 241/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0983 - acc: 0.9674 - auc_1: 0.9950 - val_loss: 0.5192 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0970 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 0.5005 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0962 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 0.5346 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0953 - acc: 0.9674 - auc_1: 0.9945 - val_loss: 0.5102 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0921 - acc: 0.9783 - auc_1: 0.9938 - val_loss: 0.5522 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0945 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.5135 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0986 - acc: 0.9783 - auc_1: 0.9943 - val_loss: 0.5778 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0963 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6019 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0899 - acc: 0.9783 - auc_1: 0.9960 - val_loss: 0.5646 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0972 - acc: 0.9674 - auc_1: 0.9945 - val_loss: 0.5785 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0949 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.5152 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0870 - acc: 0.9783 - auc_1: 0.9955 - val_loss: 0.5581 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0867 - acc: 0.9783 - auc_1: 0.9957 - val_loss: 0.4939 - val_acc: 0.8750 - val_auc_1: 0.9179\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0856 - acc: 0.9783 - auc_1: 0.9957 - val_loss: 0.5236 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0853 - acc: 0.9783 - auc_1: 0.9957 - val_loss: 0.5545 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0899 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.5850 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0850 - acc: 0.9783 - auc_1: 0.9957 - val_loss: 0.5834 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0823 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.5856 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0810 - acc: 0.9783 - auc_1: 0.9964 - val_loss: 0.5743 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0824 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 0.5888 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0789 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 0.5580 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0784 - acc: 0.9783 - auc_1: 0.9969 - val_loss: 0.5878 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0779 - acc: 0.9783 - auc_1: 0.9957 - val_loss: 0.5998 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0769 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.5744 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0774 - acc: 0.9891 - auc_1: 0.9967 - val_loss: 0.6049 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0754 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.5685 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0743 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.6184 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0731 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.6086 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0754 - acc: 0.9891 - auc_1: 0.9971 - val_loss: 0.5977 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0738 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.5881 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0735 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.5522 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0692 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.6261 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0705 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.5975 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0689 - acc: 0.9891 - auc_1: 0.9971 - val_loss: 0.5886 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0662 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.6299 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0665 - acc: 0.9891 - auc_1: 0.9971 - val_loss: 0.5456 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0676 - acc: 0.9891 - auc_1: 0.9976 - val_loss: 0.6076 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0652 - acc: 0.9891 - auc_1: 0.9979 - val_loss: 0.6279 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0683 - acc: 0.9891 - auc_1: 0.9979 - val_loss: 0.5981 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0692 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.5720 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0625 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.5760 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0656 - acc: 0.9891 - auc_1: 0.9979 - val_loss: 0.6169 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0631 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.5713 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0625 - acc: 0.9891 - auc_1: 0.9976 - val_loss: 0.7208 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0699 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.6312 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0597 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.6207 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0597 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6226 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0606 - acc: 0.9891 - auc_1: 0.9979 - val_loss: 0.6147 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 289/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0591 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.5858 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 290/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0568 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6356 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0587 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.6465 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0586 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.6911 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0604 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.6546 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0600 - acc: 0.9891 - auc_1: 0.9976 - val_loss: 0.6646 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0580 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.5181 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0603 - acc: 0.9891 - auc_1: 0.9976 - val_loss: 0.5730 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0571 - acc: 0.9891 - auc_1: 0.9971 - val_loss: 0.5781 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0534 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6159 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0521 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.5625 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0587 - acc: 0.9891 - auc_1: 0.9976 - val_loss: 0.6247 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0526 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.6334 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0524 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.6161 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0509 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6371 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0501 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.5824 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0539 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.5864 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0552 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.5926 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0513 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6014 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0583 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.5487 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1285 - acc: 0.9348 - auc_1: 0.9895 - val_loss: 0.6348 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0644 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.6926 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0488 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7137 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0490 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6951 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0467 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7032 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0480 - acc: 0.9891 - auc_1: 0.9983 - val_loss: 0.7015 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0468 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6827 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0458 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6907 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0453 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6646 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0443 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6567 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0444 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6780 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0451 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.6573 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0438 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6959 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0433 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6867 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0434 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6839 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0424 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6766 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0422 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6877 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0428 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6845 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0431 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6865 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0422 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6819 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0411 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6706 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0409 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6744 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0417 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6641 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0405 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6456 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0397 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7136 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0398 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7104 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0420 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7462 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0398 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7213 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 337/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0407 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7251 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 338/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0417 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7761 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0407 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7191 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0390 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7323 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0380 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7016 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0372 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7152 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0385 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7083 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0387 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7561 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0391 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7249 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0374 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7602 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0875 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6759 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1440 - acc: 0.9130 - auc_1: 0.9876 - val_loss: 1.1320 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1630 - acc: 0.9239 - auc_1: 0.9862 - val_loss: 0.8258 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0559 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8834 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0404 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.9011 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0385 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8655 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0380 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8769 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0371 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8834 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0371 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8840 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0365 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8677 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0360 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8744 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0355 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8760 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0349 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8613 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0352 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8615 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0358 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8634 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0348 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8682 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0343 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8678 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0342 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8730 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0337 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8580 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0336 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8689 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0345 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8586 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0337 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8726 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0336 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8650 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0335 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8784 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0337 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8540 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0331 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8687 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0326 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8593 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0329 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8575 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0334 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8534 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0325 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8616 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0328 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8560 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0321 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8786 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0321 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8490 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0316 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 0.8664 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0322 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.8736 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0340 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8555 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0320 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8233 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0312 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.8586 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 385/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0299 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.8357 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 386/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0303 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.8515 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0318 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.8730 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0314 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8630 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0284 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8834 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0329 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0186 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0482 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.0473 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0960 - acc: 0.9783 - auc_1: 0.9919 - val_loss: 0.8486 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0699 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.8592 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0321 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.7869 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0276 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8151 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0268 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8342 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0248 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8211 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0248 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8040 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0249 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8239 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0244 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8404 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0230 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8419 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0225 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8596 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0216 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8569 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0226 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8448 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0215 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8620 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0203 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8650 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0213 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8322 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0235 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8014 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0321 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.9088 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0759 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.5981 - val_acc: 0.9167 - val_auc_1: 0.9107\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1401 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 1.0423 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1479 - acc: 0.9565 - auc_1: 0.9867 - val_loss: 1.1008 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0443 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.8542 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0219 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8518 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0202 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8452 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0189 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8482 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0186 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8399 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0177 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8351 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0176 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8334 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0171 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8352 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0170 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8367 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0163 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8358 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0163 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8363 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0157 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8386 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0156 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8380 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0153 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8375 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0151 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8463 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0148 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8497 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0145 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8591 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0141 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8650 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0139 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8659 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0138 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8803 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 433/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0136 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8842 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 434/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0132 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8895 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0130 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8905 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0128 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9049 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0136 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8945 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0127 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8840 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8940 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0118 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9031 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9022 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9224 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0113 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9443 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0112 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9327 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0108 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9361 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0109 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9442 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0105 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9480 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0108 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9431 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0100 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9361 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0102 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9364 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9582 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9753 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0094 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9740 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9672 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9663 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9695 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9728 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9759 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9621 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9776 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9853 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1428 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0189 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2512 - acc: 0.9130 - auc_1: 0.9838 - val_loss: 1.0636 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4155 - acc: 0.9130 - auc_1: 0.9362 - val_loss: 0.9127 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0631 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.9018 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0129 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9166 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0115 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9242 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0108 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9293 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0102 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9331 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9431 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9431 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0092 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9488 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9547 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9624 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9673 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9682 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9747 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9742 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9804 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 481/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9844 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 482/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9880 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9912 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9959 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0023 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0064 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0085 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0144 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0162 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0166 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0201 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0283 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0303 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0350 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0464 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0551 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0452 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0503 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0501 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0568 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0620 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0687 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0796 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0638 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0850 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0618 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0964 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1004 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0911 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1017 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0689 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1080 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0870 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1064 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1288 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1320 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1337 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1684 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1660 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1436 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1370 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1658 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1564 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1981 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1400 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0925 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1692 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1460 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 529/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2009 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 530/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1116 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1902 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2084 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1618 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3033 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2419 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1164 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2812 - acc: 0.9457 - auc_1: 0.9717 - val_loss: 1.2866 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1214 - acc: 0.9457 - auc_1: 0.9962 - val_loss: 1.1382 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0641 - acc: 0.9891 - auc_1: 0.9952 - val_loss: 1.2747 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1248 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1235 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1220 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1230 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1219 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1236 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1252 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1247 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1268 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1297 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1343 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1368 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1384 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1369 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1396 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1423 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1479 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1467 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1508 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1529 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1579 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1575 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1620 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1628 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1634 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1666 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1712 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1691 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1751 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1757 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1804 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1843 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1890 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1949 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1945 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2024 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1954 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 577/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2062 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 578/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2080 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2138 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2147 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2186 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2262 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2260 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2385 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2298 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2304 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2279 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2438 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2427 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2480 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2739 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2521 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2761 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2628 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2842 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2718 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2662 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2964 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3055 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2783 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2844 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3170 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2943 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3262 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3143 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3177 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3322 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3390 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3567 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3051 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3695 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3597 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3950 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3919 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3182 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3006 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4330 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3371 - val_acc: 0.6667 - val_auc_1: 0.8179\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3584 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3771 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.4248e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3525 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1377 - acc: 0.9674 - auc_1: 0.9855 - val_loss: 1.6991 - val_acc: 0.6667 - val_auc_1: 0.7714\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4130 - acc: 0.9022 - auc_1: 0.9614 - val_loss: 1.6147 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1640 - acc: 0.9565 - auc_1: 0.9848 - val_loss: 1.7150 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 625/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2067 - acc: 0.9348 - auc_1: 0.9752 - val_loss: 1.6135 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 626/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5679 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0316 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.5942 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0368 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.5250 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4729 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4764 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4797 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4783 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4843 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4878 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4894 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4851 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4934 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4968 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4986 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4972 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4986 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4986 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4914 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4954 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4914 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4894 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4913 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4888 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4868 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4835 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4769 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4798 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4752 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4832 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4808 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4741 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4655 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4693 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4690 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4595 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4658 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4618 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4565 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4538 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4567 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4552 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4547 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4582 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4558 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4590 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4546 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4536 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 673/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4535 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 674/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 9.9886e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4505 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.8545e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4500 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.7043e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4447 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 9.6503e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4478 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.5353e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4524 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.3803e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4442 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 9.2362e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4408 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.1253e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4481 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.0444e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4352 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.0767e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4264 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.8305e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4527 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.6941e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4363 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.6587e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4528 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 8.4447e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4478 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 8.3619e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4344 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 8.2120e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4431 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 8.1204e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4541 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.1228e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4363 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.9119e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4241 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.8543e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4397 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 7.7060e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4521 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 7.8647e-04 - acc: 1.0000 - auc_1: 1.000 - 0s 4ms/step - loss: 7.5817e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4521 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.4161e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4295 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.4235e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4188 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.1720e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4371 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 7.0952e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4318 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.9709e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4299 - val_acc: 0.6667 - val_auc_1: 0.8321\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5, X6, X7, X8], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.92546594,  0.7658647 , -1.0870438 , -1.2051817 , -1.1733627 ,\n",
      "         1.814037  , -1.2957255 , -0.67039937, -1.8313352 ],\n",
      "       [-1.1504388 ,  0.81129175, -2.342549  , -0.68388045,  0.3399492 ,\n",
      "         1.6252788 , -0.40077797, -3.0309038 , -0.8071629 ],\n",
      "       [ 0.3009304 , -0.29114106,  0.8675925 ,  0.19670545, -0.5690612 ,\n",
      "        -0.6237475 ,  0.67039347,  0.52884805, -0.7612408 ],\n",
      "       [ 0.96364784,  1.0275303 , -0.51204145,  1.1588782 , -0.6635277 ,\n",
      "        -0.27799484,  1.3665531 ,  0.80315423,  0.41791734],\n",
      "       [-1.5676271 ,  0.05506226, -0.5877372 , -1.2101465 , -0.3995773 ,\n",
      "         0.43882525, -0.09795661,  0.42912227,  0.19815339],\n",
      "       [ 0.07714547,  0.18312344, -0.32498807, -0.7205265 ,  0.6391082 ,\n",
      "        -0.912091  , -0.6958851 , -0.43322724,  0.86059743],\n",
      "       [-0.8648792 ,  0.38779426,  0.00952423, -0.96985066,  0.6302235 ,\n",
      "        -0.5865803 , -0.45372716,  0.23153906,  0.40897572],\n",
      "       [ 0.22513774,  0.26702332,  0.60896426, -0.58098656,  2.258353  ,\n",
      "        -0.08914907, -0.91999024, -0.06809596,  1.0037863 ]],\n",
      "      dtype=float32), array([ 0.10022571, -0.53209877,  0.11967529,  0.04063251,  0.15821612,\n",
      "        0.16145498, -0.17537895,  0.11693938,  0.1259935 ], dtype=float32), array([[-0.60355884, -1.101545  ,  0.89355487,  2.2128947 ,  0.08710322,\n",
      "        -0.35360298, -2.202093  ,  1.1867486 ,  2.4198315 ],\n",
      "       [ 0.07027534, -0.01941085,  0.14945152,  0.4778187 ,  0.15497825,\n",
      "         0.75319093, -2.0248866 ,  0.7760654 , -1.1900285 ],\n",
      "       [-0.7006127 , -0.541811  ,  0.00827854, -0.42423934, -4.1571755 ,\n",
      "        -1.0377276 ,  0.9907303 , -0.6330074 ,  4.2220354 ],\n",
      "       [-0.73514706, -1.1287156 ,  2.389179  ,  3.335245  , -0.3348899 ,\n",
      "         0.4097906 , -1.0246481 ,  1.8499597 ,  1.1506971 ],\n",
      "       [-0.33679694, -0.22691394, -2.704257  , -0.6753392 , -0.07061965,\n",
      "         1.043789  ,  0.5299497 , -1.294675  ,  1.3189403 ],\n",
      "       [ 0.52807426, -0.01034821, -0.65120924, -2.2126484 ,  1.2907112 ,\n",
      "        -0.49095348,  2.4881387 ,  3.3728583 , -2.5774615 ],\n",
      "       [-0.6682874 , -0.24559276,  2.2981687 ,  3.520075  , -0.58396804,\n",
      "        -0.27600467, -1.3244506 , -0.17094643,  0.24091123],\n",
      "       [-1.4292567 ,  0.1499939 ,  0.513124  ,  3.0831335 , -2.4243863 ,\n",
      "        -0.27797192, -1.8764436 ,  0.46294373,  1.2606823 ],\n",
      "       [-2.034651  , -1.817384  , -1.449775  ,  1.727443  ,  0.04574384,\n",
      "         3.5305042 , -1.105512  , -3.1463318 ,  1.7960515 ]],\n",
      "      dtype=float32), array([-0.7588932 , -0.06308505, -0.29982   ,  0.32909596,  0.4102467 ,\n",
      "       -0.27381715,  0.06940898,  0.300798  ,  0.27886727], dtype=float32), array([[-1.1443409 , -1.8629019 ,  0.26669934, -1.5934336 ,  0.14336564,\n",
      "        -1.9867666 ,  1.8338856 ,  0.9923918 ,  0.18521968],\n",
      "       [-2.6722353 , -0.3789676 ,  0.26329836, -0.60862225,  0.20376651,\n",
      "        -1.8713433 ,  2.3502312 , -0.02174837,  0.11502568],\n",
      "       [-0.27870005, -2.624105  ,  1.1553012 , -2.1408606 , -3.85296   ,\n",
      "         2.3791325 , -0.18805884, -4.8277297 , -1.5065831 ],\n",
      "       [ 1.8795005 ,  0.12603372, -2.3800538 , -0.05713064, -1.6713641 ,\n",
      "         0.12129611, -2.0672128 , -1.3048804 ,  2.4034495 ],\n",
      "       [-1.1711196 ,  1.1537609 , -1.7448605 ,  3.5430489 ,  0.8841608 ,\n",
      "         0.7752475 ,  1.1883738 ,  0.97441167,  1.8005008 ],\n",
      "       [ 2.987166  ,  2.6188154 , -1.1783227 ,  1.3961395 , -0.34130263,\n",
      "         0.81622756, -2.930277  , -0.32081234,  1.4368507 ],\n",
      "       [-1.2229578 ,  0.7524193 ,  0.6163092 ,  1.0024251 ,  1.6595774 ,\n",
      "         1.1977834 ,  0.73782176,  1.8011214 , -1.0695678 ],\n",
      "       [-2.0197594 , -1.7998521 ,  0.17638685,  0.2880367 , -1.6472274 ,\n",
      "         1.9453061 ,  2.3908749 , -1.5449332 , -0.35626364],\n",
      "       [ 1.6826348 , -1.2721336 ,  2.1382434 , -0.24034333,  2.266688  ,\n",
      "        -2.077529  , -1.3736033 ,  2.816019  , -2.100726  ]],\n",
      "      dtype=float32), array([-0.24892443,  0.5141584 , -0.07282148,  2.1700513 , -0.41472086,\n",
      "        0.88715523,  0.357167  , -0.5103565 ,  0.49463275], dtype=float32), array([[-1.5783315],\n",
      "       [-5.6184087],\n",
      "       [-4.090538 ],\n",
      "       [ 1.8127471],\n",
      "       [ 1.32578  ],\n",
      "       [-3.9463315],\n",
      "       [ 2.008748 ],\n",
      "       [ 2.4939523],\n",
      "       [ 4.5426383]], dtype=float32), array([-0.3595047], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.9732188e-05]\n",
      " [9.9999797e-01]\n",
      " [9.9942553e-01]\n",
      " [1.2951952e-07]\n",
      " [1.8408448e-04]\n",
      " [1.0000000e+00]\n",
      " [9.9999988e-01]\n",
      " [9.9999964e-01]\n",
      " [9.8016858e-01]\n",
      " [9.9987912e-01]\n",
      " [1.1820536e-03]\n",
      " [2.0254251e-04]\n",
      " [9.9999928e-01]\n",
      " [1.5046183e-03]\n",
      " [7.7930906e-08]\n",
      " [9.9997902e-01]\n",
      " [6.1356195e-04]\n",
      " [9.9956244e-01]\n",
      " [9.9999762e-01]\n",
      " [9.9994242e-01]\n",
      " [4.5375404e-05]\n",
      " [2.7473664e-04]\n",
      " [2.2723058e-03]\n",
      " [9.9924219e-01]\n",
      " [9.9999976e-01]\n",
      " [9.9999261e-01]\n",
      " [9.9967587e-01]\n",
      " [9.9990833e-01]\n",
      " [1.9951310e-04]\n",
      " [9.9999952e-01]\n",
      " [1.3089515e-03]\n",
      " [7.6556645e-08]\n",
      " [1.3054890e-04]\n",
      " [6.9081020e-06]\n",
      " [2.3466167e-05]\n",
      " [9.9999940e-01]\n",
      " [9.9999988e-01]\n",
      " [9.9934882e-01]\n",
      " [9.9978715e-01]\n",
      " [9.9994159e-01]\n",
      " [9.9998760e-01]\n",
      " [9.9996710e-01]\n",
      " [1.3239842e-03]\n",
      " [7.2578111e-08]\n",
      " [1.3993112e-05]\n",
      " [9.9884099e-01]\n",
      " [9.9975270e-01]\n",
      " [9.9999964e-01]\n",
      " [9.9928659e-01]\n",
      " [3.7509139e-04]\n",
      " [1.1549037e-04]\n",
      " [9.9980575e-01]\n",
      " [7.3206799e-08]\n",
      " [1.2360458e-03]\n",
      " [3.6295908e-04]\n",
      " [1.9753617e-04]\n",
      " [1.8230062e-03]\n",
      " [9.9999964e-01]\n",
      " [6.9814725e-08]\n",
      " [5.9591336e-03]\n",
      " [1.7452269e-03]\n",
      " [9.9992239e-01]\n",
      " [9.9961615e-01]\n",
      " [9.9959713e-01]\n",
      " [1.0734302e-04]\n",
      " [4.6684636e-05]\n",
      " [1.0242664e-03]\n",
      " [9.9979836e-01]\n",
      " [6.9040588e-08]\n",
      " [1.1826628e-03]\n",
      " [1.2052079e-03]\n",
      " [9.9999392e-01]\n",
      " [9.9977058e-01]\n",
      " [9.9999988e-01]\n",
      " [9.9995267e-01]\n",
      " [1.6801088e-03]\n",
      " [9.9999595e-01]\n",
      " [2.4347811e-04]\n",
      " [9.9995387e-01]\n",
      " [1.0219032e-03]\n",
      " [3.0989191e-03]\n",
      " [1.6866074e-05]\n",
      " [9.9950206e-01]\n",
      " [9.9980599e-01]\n",
      " [9.9977559e-01]\n",
      " [9.9999988e-01]\n",
      " [9.9999976e-01]\n",
      " [9.9945718e-01]\n",
      " [1.5833450e-03]\n",
      " [9.9994159e-01]\n",
      " [9.9975473e-01]\n",
      " [9.9973696e-01]\n",
      " [5.4731786e-01]\n",
      " [9.9977285e-01]\n",
      " [9.9998701e-01]\n",
      " [9.9998927e-01]\n",
      " [2.3686285e-03]\n",
      " [9.9998558e-01]\n",
      " [7.3154318e-08]\n",
      " [9.9996185e-01]\n",
      " [9.9893314e-01]\n",
      " [2.7476617e-05]\n",
      " [5.3163297e-02]\n",
      " [1.0000000e+00]\n",
      " [1.8853146e-01]\n",
      " [9.9999988e-01]\n",
      " [6.8825486e-08]\n",
      " [1.0679154e-02]\n",
      " [9.9999976e-01]\n",
      " [6.7124165e-06]\n",
      " [8.7954318e-03]\n",
      " [7.3274770e-03]\n",
      " [7.8628343e-03]\n",
      " [2.4232527e-03]\n",
      " [7.5604724e-08]\n",
      " [2.6210231e-05]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5, X6, X7, X8])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
