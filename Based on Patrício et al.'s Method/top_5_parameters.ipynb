{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,2:3] #Glucose\n",
    "X2 = dataset[:,7:8] #Resistin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,1:2] #BMI\n",
    "X5 = dataset[:,4:5] #HOMA\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 5)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            54          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 244\n",
      "Trainable params: 244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 0.6983 - acc: 0.5326 - auc_1: 0.5136 - val_loss: 0.6629 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6684 - acc: 0.6196 - auc_1: 0.6600 - val_loss: 0.6124 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6410 - acc: 0.6304 - auc_1: 0.7217 - val_loss: 0.5721 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6013 - acc: 0.6848 - auc_1: 0.7633 - val_loss: 0.5562 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5697 - acc: 0.6957 - auc_1: 0.7779 - val_loss: 0.5115 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5520 - acc: 0.7174 - auc_1: 0.7883 - val_loss: 0.5661 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5397 - acc: 0.7174 - auc_1: 0.8007 - val_loss: 0.5106 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5291 - acc: 0.6413 - auc_1: 0.7969 - val_loss: 0.5747 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5249 - acc: 0.7174 - auc_1: 0.8014 - val_loss: 0.5259 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5210 - acc: 0.7065 - auc_1: 0.8024 - val_loss: 0.6109 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5166 - acc: 0.7391 - auc_1: 0.8186 - val_loss: 0.5041 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5121 - acc: 0.7283 - auc_1: 0.8090 - val_loss: 0.5409 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5104 - acc: 0.7500 - auc_1: 0.8098 - val_loss: 0.5437 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5072 - acc: 0.7391 - auc_1: 0.8212 - val_loss: 0.6193 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5060 - acc: 0.7391 - auc_1: 0.8217 - val_loss: 0.4841 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5085 - acc: 0.7283 - auc_1: 0.8210 - val_loss: 0.5447 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4994 - acc: 0.7609 - auc_1: 0.8276 - val_loss: 0.4950 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4982 - acc: 0.7391 - auc_1: 0.8355 - val_loss: 0.4689 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5010 - acc: 0.7609 - auc_1: 0.8386 - val_loss: 0.5981 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5062 - acc: 0.7391 - auc_1: 0.8217 - val_loss: 0.5399 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4938 - acc: 0.7283 - auc_1: 0.8338 - val_loss: 0.6071 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5069 - acc: 0.7500 - auc_1: 0.8186 - val_loss: 0.5226 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4971 - acc: 0.7500 - auc_1: 0.8336 - val_loss: 0.4791 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5040 - acc: 0.7717 - auc_1: 0.8267 - val_loss: 0.5472 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4977 - acc: 0.7391 - auc_1: 0.8276 - val_loss: 0.5435 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4957 - acc: 0.7283 - auc_1: 0.8324 - val_loss: 0.5034 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5016 - acc: 0.7174 - auc_1: 0.8331 - val_loss: 0.5090 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4982 - acc: 0.7283 - auc_1: 0.8300 - val_loss: 0.5550 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4929 - acc: 0.7391 - auc_1: 0.8343 - val_loss: 0.5885 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5037 - acc: 0.7391 - auc_1: 0.8221 - val_loss: 0.5543 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4855 - acc: 0.7935 - auc_1: 0.8388 - val_loss: 0.5979 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4977 - acc: 0.7609 - auc_1: 0.8329 - val_loss: 0.5118 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4960 - acc: 0.7391 - auc_1: 0.8321 - val_loss: 0.5364 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4910 - acc: 0.7500 - auc_1: 0.8319 - val_loss: 0.4902 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4930 - acc: 0.7283 - auc_1: 0.8433 - val_loss: 0.5622 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5047 - acc: 0.7717 - auc_1: 0.8352 - val_loss: 0.4745 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4910 - acc: 0.7500 - auc_1: 0.8412 - val_loss: 0.5578 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4871 - acc: 0.7500 - auc_1: 0.8390 - val_loss: 0.5900 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4938 - acc: 0.7500 - auc_1: 0.8336 - val_loss: 0.5221 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4891 - acc: 0.7391 - auc_1: 0.8360 - val_loss: 0.5334 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4836 - acc: 0.7609 - auc_1: 0.8410 - val_loss: 0.6051 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4823 - acc: 0.7391 - auc_1: 0.8457 - val_loss: 0.5013 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4883 - acc: 0.7717 - auc_1: 0.8321 - val_loss: 0.4938 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4978 - acc: 0.7500 - auc_1: 0.8324 - val_loss: 0.6087 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4952 - acc: 0.7609 - auc_1: 0.8295 - val_loss: 0.5785 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4872 - acc: 0.7391 - auc_1: 0.8417 - val_loss: 0.5329 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4761 - acc: 0.7391 - auc_1: 0.8540 - val_loss: 0.5020 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4871 - acc: 0.7500 - auc_1: 0.8374 - val_loss: 0.5287 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4868 - acc: 0.7717 - auc_1: 0.8348 - val_loss: 0.5956 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4727 - acc: 0.7826 - auc_1: 0.8548 - val_loss: 0.5069 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4931 - acc: 0.7500 - auc_1: 0.8393 - val_loss: 0.5497 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4823 - acc: 0.7717 - auc_1: 0.8474 - val_loss: 0.6556 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4855 - acc: 0.7500 - auc_1: 0.8417 - val_loss: 0.5798 - val_acc: 0.6667 - val_auc_1: 0.9179\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4812 - acc: 0.7609 - auc_1: 0.8421 - val_loss: 0.5689 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4763 - acc: 0.7500 - auc_1: 0.8519 - val_loss: 0.5415 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4673 - acc: 0.7609 - auc_1: 0.8557 - val_loss: 0.6138 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4788 - acc: 0.7826 - auc_1: 0.8581 - val_loss: 0.6127 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4791 - acc: 0.7500 - auc_1: 0.8481 - val_loss: 0.6206 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4676 - acc: 0.7826 - auc_1: 0.8524 - val_loss: 0.5118 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4900 - acc: 0.7391 - auc_1: 0.8381 - val_loss: 0.5962 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4724 - acc: 0.7391 - auc_1: 0.8574 - val_loss: 0.5541 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4716 - acc: 0.7717 - auc_1: 0.8529 - val_loss: 0.5075 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4634 - acc: 0.7826 - auc_1: 0.8545 - val_loss: 0.6681 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4749 - acc: 0.7609 - auc_1: 0.8569 - val_loss: 0.5764 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4724 - acc: 0.7717 - auc_1: 0.8583 - val_loss: 0.5825 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4592 - acc: 0.7935 - auc_1: 0.8717 - val_loss: 0.6719 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4770 - acc: 0.7717 - auc_1: 0.8433 - val_loss: 0.6476 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4625 - acc: 0.7826 - auc_1: 0.8590 - val_loss: 0.5320 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4728 - acc: 0.7609 - auc_1: 0.8457 - val_loss: 0.5691 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4639 - acc: 0.7609 - auc_1: 0.8700 - val_loss: 0.5571 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4606 - acc: 0.7609 - auc_1: 0.8660 - val_loss: 0.6188 - val_acc: 0.6667 - val_auc_1: 0.9107\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4609 - acc: 0.7500 - auc_1: 0.8698 - val_loss: 0.5835 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4603 - acc: 0.7717 - auc_1: 0.8740 - val_loss: 0.5378 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4633 - acc: 0.7826 - auc_1: 0.8607 - val_loss: 0.5711 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4552 - acc: 0.7826 - auc_1: 0.8707 - val_loss: 0.6187 - val_acc: 0.6667 - val_auc_1: 0.9179\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4672 - acc: 0.7500 - auc_1: 0.8614 - val_loss: 0.6137 - val_acc: 0.6667 - val_auc_1: 0.9179\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4551 - acc: 0.7935 - auc_1: 0.8752 - val_loss: 0.5992 - val_acc: 0.7083 - val_auc_1: 0.9179\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4611 - acc: 0.7826 - auc_1: 0.8574 - val_loss: 0.6259 - val_acc: 0.7083 - val_auc_1: 0.9179\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4537 - acc: 0.7826 - auc_1: 0.8733 - val_loss: 0.5581 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4464 - acc: 0.7935 - auc_1: 0.8781 - val_loss: 0.6439 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4561 - acc: 0.7935 - auc_1: 0.8602 - val_loss: 0.5902 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4518 - acc: 0.7935 - auc_1: 0.8738 - val_loss: 0.6012 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4492 - acc: 0.8152 - auc_1: 0.8810 - val_loss: 0.5902 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4419 - acc: 0.7717 - auc_1: 0.8798 - val_loss: 0.5355 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4436 - acc: 0.7935 - auc_1: 0.8736 - val_loss: 0.5444 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4399 - acc: 0.8152 - auc_1: 0.8800 - val_loss: 0.6276 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4359 - acc: 0.7935 - auc_1: 0.8919 - val_loss: 0.5438 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4406 - acc: 0.8152 - auc_1: 0.8769 - val_loss: 0.5827 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4408 - acc: 0.7826 - auc_1: 0.8810 - val_loss: 0.5627 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4336 - acc: 0.8152 - auc_1: 0.8881 - val_loss: 0.6052 - val_acc: 0.7083 - val_auc_1: 0.8964\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4256 - acc: 0.7935 - auc_1: 0.8931 - val_loss: 0.5941 - val_acc: 0.7083 - val_auc_1: 0.8964\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4250 - acc: 0.8261 - auc_1: 0.8910 - val_loss: 0.5415 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4291 - acc: 0.8261 - auc_1: 0.8840 - val_loss: 0.5839 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4256 - acc: 0.7935 - auc_1: 0.8917 - val_loss: 0.5630 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4220 - acc: 0.8043 - auc_1: 0.8948 - val_loss: 0.5530 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4324 - acc: 0.8152 - auc_1: 0.8821 - val_loss: 0.5842 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 97/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4163 - acc: 0.8261 - auc_1: 0.8929 - val_loss: 0.5448 - val_acc: 0.8333 - val_auc_1: 0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4217 - acc: 0.7935 - auc_1: 0.8869 - val_loss: 0.5824 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4171 - acc: 0.8261 - auc_1: 0.8910 - val_loss: 0.5755 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4103 - acc: 0.8043 - auc_1: 0.8969 - val_loss: 0.5624 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4136 - acc: 0.8152 - auc_1: 0.8943 - val_loss: 0.5484 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4120 - acc: 0.8261 - auc_1: 0.8898 - val_loss: 0.6377 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3987 - acc: 0.8261 - auc_1: 0.9048 - val_loss: 0.6104 - val_acc: 0.7083 - val_auc_1: 0.8821\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4152 - acc: 0.8152 - auc_1: 0.8881 - val_loss: 0.5979 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4030 - acc: 0.8152 - auc_1: 0.8988 - val_loss: 0.5458 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4026 - acc: 0.8261 - auc_1: 0.9000 - val_loss: 0.5591 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3871 - acc: 0.8587 - auc_1: 0.9107 - val_loss: 0.6785 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4042 - acc: 0.8152 - auc_1: 0.8952 - val_loss: 0.5887 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3928 - acc: 0.8478 - auc_1: 0.9031 - val_loss: 0.5435 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3959 - acc: 0.8043 - auc_1: 0.9021 - val_loss: 0.6045 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4000 - acc: 0.8478 - auc_1: 0.8993 - val_loss: 0.5343 - val_acc: 0.8750 - val_auc_1: 0.8821\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3944 - acc: 0.8152 - auc_1: 0.9031 - val_loss: 0.5977 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3911 - acc: 0.8152 - auc_1: 0.8990 - val_loss: 0.5770 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3885 - acc: 0.7826 - auc_1: 0.9029 - val_loss: 0.5671 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3824 - acc: 0.8478 - auc_1: 0.9105 - val_loss: 0.6684 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3826 - acc: 0.8043 - auc_1: 0.9138 - val_loss: 0.5188 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3840 - acc: 0.8370 - auc_1: 0.9086 - val_loss: 0.5239 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3762 - acc: 0.8261 - auc_1: 0.9148 - val_loss: 0.6034 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3756 - acc: 0.8587 - auc_1: 0.9145 - val_loss: 0.5243 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3849 - acc: 0.8152 - auc_1: 0.9079 - val_loss: 0.5696 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3679 - acc: 0.8478 - auc_1: 0.9207 - val_loss: 0.5027 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3757 - acc: 0.8587 - auc_1: 0.9121 - val_loss: 0.5790 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3713 - acc: 0.8152 - auc_1: 0.9155 - val_loss: 0.5174 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3687 - acc: 0.8261 - auc_1: 0.9162 - val_loss: 0.5633 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3769 - acc: 0.8152 - auc_1: 0.9107 - val_loss: 0.6068 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3667 - acc: 0.8261 - auc_1: 0.9140 - val_loss: 0.5090 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3638 - acc: 0.8152 - auc_1: 0.9162 - val_loss: 0.5798 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3651 - acc: 0.8370 - auc_1: 0.9155 - val_loss: 0.5224 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3690 - acc: 0.8152 - auc_1: 0.9129 - val_loss: 0.5510 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3546 - acc: 0.8370 - auc_1: 0.9231 - val_loss: 0.5839 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3632 - acc: 0.8261 - auc_1: 0.9186 - val_loss: 0.5311 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3628 - acc: 0.8152 - auc_1: 0.9171 - val_loss: 0.5399 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3591 - acc: 0.8261 - auc_1: 0.9145 - val_loss: 0.5636 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3501 - acc: 0.8152 - auc_1: 0.9221 - val_loss: 0.5136 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3598 - acc: 0.8587 - auc_1: 0.9174 - val_loss: 0.5431 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3561 - acc: 0.8478 - auc_1: 0.9200 - val_loss: 0.5558 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3503 - acc: 0.8478 - auc_1: 0.9271 - val_loss: 0.5578 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3575 - acc: 0.8370 - auc_1: 0.9193 - val_loss: 0.5469 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3568 - acc: 0.8370 - auc_1: 0.9176 - val_loss: 0.5735 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3480 - acc: 0.8696 - auc_1: 0.9255 - val_loss: 0.5573 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3511 - acc: 0.8370 - auc_1: 0.9226 - val_loss: 0.5331 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3490 - acc: 0.8261 - auc_1: 0.9229 - val_loss: 0.5740 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3425 - acc: 0.8370 - auc_1: 0.9250 - val_loss: 0.5569 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3453 - acc: 0.8587 - auc_1: 0.9300 - val_loss: 0.5542 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 145/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3481 - acc: 0.8478 - auc_1: 0.9252 - val_loss: 0.5858 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 146/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3392 - acc: 0.8261 - auc_1: 0.9267 - val_loss: 0.5031 - val_acc: 0.9167 - val_auc_1: 0.9036\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3352 - acc: 0.8587 - auc_1: 0.9300 - val_loss: 0.5919 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3415 - acc: 0.8478 - auc_1: 0.9271 - val_loss: 0.5313 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3402 - acc: 0.8370 - auc_1: 0.9293 - val_loss: 0.4861 - val_acc: 0.9583 - val_auc_1: 0.9107\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3496 - acc: 0.8370 - auc_1: 0.9224 - val_loss: 0.5177 - val_acc: 0.9167 - val_auc_1: 0.9036\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3395 - acc: 0.8370 - auc_1: 0.9302 - val_loss: 0.5762 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3291 - acc: 0.8478 - auc_1: 0.9352 - val_loss: 0.5218 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3334 - acc: 0.8370 - auc_1: 0.9274 - val_loss: 0.6271 - val_acc: 0.7083 - val_auc_1: 0.8964\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3324 - acc: 0.8478 - auc_1: 0.9331 - val_loss: 0.5061 - val_acc: 0.9167 - val_auc_1: 0.9107\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3303 - acc: 0.8804 - auc_1: 0.9350 - val_loss: 0.5643 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3287 - acc: 0.8370 - auc_1: 0.9352 - val_loss: 0.5010 - val_acc: 0.9167 - val_auc_1: 0.9107\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3229 - acc: 0.8696 - auc_1: 0.9331 - val_loss: 0.5923 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3266 - acc: 0.8696 - auc_1: 0.9398 - val_loss: 0.5296 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3314 - acc: 0.8261 - auc_1: 0.9283 - val_loss: 0.5805 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3342 - acc: 0.8587 - auc_1: 0.9250 - val_loss: 0.5726 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3207 - acc: 0.8478 - auc_1: 0.9367 - val_loss: 0.5398 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3174 - acc: 0.8587 - auc_1: 0.9386 - val_loss: 0.5258 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3260 - acc: 0.8587 - auc_1: 0.9329 - val_loss: 0.5651 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3236 - acc: 0.8587 - auc_1: 0.9362 - val_loss: 0.5529 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3201 - acc: 0.8261 - auc_1: 0.9352 - val_loss: 0.5651 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3119 - acc: 0.8370 - auc_1: 0.9407 - val_loss: 0.5593 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3176 - acc: 0.8804 - auc_1: 0.9374 - val_loss: 0.5414 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3094 - acc: 0.8587 - auc_1: 0.9402 - val_loss: 0.5979 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3064 - acc: 0.8587 - auc_1: 0.9429 - val_loss: 0.5213 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3208 - acc: 0.8587 - auc_1: 0.9383 - val_loss: 0.5272 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3085 - acc: 0.8696 - auc_1: 0.9426 - val_loss: 0.5427 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3081 - acc: 0.8696 - auc_1: 0.9412 - val_loss: 0.5923 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3022 - acc: 0.8478 - auc_1: 0.9452 - val_loss: 0.5066 - val_acc: 0.9583 - val_auc_1: 0.9107\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3103 - acc: 0.8478 - auc_1: 0.9386 - val_loss: 0.5603 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3038 - acc: 0.8696 - auc_1: 0.9445 - val_loss: 0.5408 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3095 - acc: 0.8696 - auc_1: 0.9395 - val_loss: 0.6731 - val_acc: 0.7083 - val_auc_1: 0.8893\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3048 - acc: 0.8804 - auc_1: 0.9433 - val_loss: 0.4986 - val_acc: 0.9583 - val_auc_1: 0.9107\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3010 - acc: 0.8587 - auc_1: 0.9464 - val_loss: 0.5475 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3004 - acc: 0.8696 - auc_1: 0.9490 - val_loss: 0.6208 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2916 - acc: 0.8913 - auc_1: 0.9526 - val_loss: 0.5029 - val_acc: 0.9583 - val_auc_1: 0.9107\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3038 - acc: 0.8804 - auc_1: 0.9445 - val_loss: 0.5792 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3012 - acc: 0.8478 - auc_1: 0.9460 - val_loss: 0.5710 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3010 - acc: 0.8587 - auc_1: 0.9448 - val_loss: 0.5482 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3011 - acc: 0.8696 - auc_1: 0.9431 - val_loss: 0.5467 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2991 - acc: 0.8478 - auc_1: 0.9433 - val_loss: 0.4847 - val_acc: 0.9583 - val_auc_1: 0.9107\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3078 - acc: 0.8587 - auc_1: 0.9405 - val_loss: 0.5516 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2931 - acc: 0.8696 - auc_1: 0.9479 - val_loss: 0.5962 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2956 - acc: 0.8696 - auc_1: 0.9507 - val_loss: 0.5484 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2847 - acc: 0.8804 - auc_1: 0.9529 - val_loss: 0.6349 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2955 - acc: 0.8587 - auc_1: 0.9448 - val_loss: 0.5241 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2922 - acc: 0.8804 - auc_1: 0.9479 - val_loss: 0.6284 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2931 - acc: 0.8696 - auc_1: 0.9490 - val_loss: 0.5661 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2820 - acc: 0.9022 - auc_1: 0.9500 - val_loss: 0.5511 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 194/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2894 - acc: 0.8804 - auc_1: 0.9486 - val_loss: 0.5759 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2829 - acc: 0.8804 - auc_1: 0.9540 - val_loss: 0.5386 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2798 - acc: 0.8696 - auc_1: 0.9545 - val_loss: 0.5892 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2998 - acc: 0.8804 - auc_1: 0.9433 - val_loss: 0.5344 - val_acc: 0.9167 - val_auc_1: 0.9036\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2803 - acc: 0.8913 - auc_1: 0.9529 - val_loss: 0.5418 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2679 - acc: 0.9130 - auc_1: 0.9588 - val_loss: 0.6367 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2914 - acc: 0.8587 - auc_1: 0.9460 - val_loss: 0.5698 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2996 - acc: 0.8478 - auc_1: 0.9421 - val_loss: 0.5737 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2713 - acc: 0.8913 - auc_1: 0.9567 - val_loss: 0.5547 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2802 - acc: 0.8804 - auc_1: 0.9524 - val_loss: 0.6207 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2764 - acc: 0.8696 - auc_1: 0.9536 - val_loss: 0.6596 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2673 - acc: 0.8696 - auc_1: 0.9567 - val_loss: 0.5351 - val_acc: 0.9167 - val_auc_1: 0.8964\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2823 - acc: 0.8804 - auc_1: 0.9533 - val_loss: 0.5768 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2719 - acc: 0.8804 - auc_1: 0.9562 - val_loss: 0.5456 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2805 - acc: 0.8804 - auc_1: 0.9498 - val_loss: 0.5673 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2841 - acc: 0.8804 - auc_1: 0.9505 - val_loss: 0.7231 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2677 - acc: 0.8370 - auc_1: 0.9581 - val_loss: 0.5478 - val_acc: 0.8750 - val_auc_1: 0.9071\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2768 - acc: 0.8696 - auc_1: 0.9514 - val_loss: 0.5575 - val_acc: 0.8750 - val_auc_1: 0.9036\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2860 - acc: 0.8478 - auc_1: 0.9471 - val_loss: 0.5704 - val_acc: 0.8750 - val_auc_1: 0.8893\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2802 - acc: 0.8587 - auc_1: 0.9500 - val_loss: 0.5561 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2756 - acc: 0.8696 - auc_1: 0.9500 - val_loss: 0.6165 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2704 - acc: 0.8913 - auc_1: 0.9557 - val_loss: 0.6437 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2630 - acc: 0.8913 - auc_1: 0.9593 - val_loss: 0.5767 - val_acc: 0.8750 - val_auc_1: 0.8821\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2690 - acc: 0.8804 - auc_1: 0.9555 - val_loss: 0.6037 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2663 - acc: 0.9022 - auc_1: 0.9567 - val_loss: 0.6138 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2583 - acc: 0.9022 - auc_1: 0.9595 - val_loss: 0.5910 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2548 - acc: 0.8696 - auc_1: 0.9600 - val_loss: 0.5308 - val_acc: 0.9167 - val_auc_1: 0.9143\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2704 - acc: 0.8696 - auc_1: 0.9531 - val_loss: 0.6295 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2607 - acc: 0.8913 - auc_1: 0.9569 - val_loss: 0.6547 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2604 - acc: 0.8696 - auc_1: 0.9590 - val_loss: 0.6500 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2687 - acc: 0.8696 - auc_1: 0.9536 - val_loss: 0.6490 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2598 - acc: 0.8804 - auc_1: 0.9576 - val_loss: 0.6166 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2538 - acc: 0.8804 - auc_1: 0.9602 - val_loss: 0.5735 - val_acc: 0.8750 - val_auc_1: 0.8964\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2639 - acc: 0.8804 - auc_1: 0.9579 - val_loss: 0.7501 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2597 - acc: 0.8804 - auc_1: 0.9586 - val_loss: 0.6078 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2551 - acc: 0.8804 - auc_1: 0.9581 - val_loss: 0.6593 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2578 - acc: 0.8913 - auc_1: 0.9605 - val_loss: 0.6139 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2529 - acc: 0.8913 - auc_1: 0.9605 - val_loss: 0.5769 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2477 - acc: 0.8913 - auc_1: 0.9633 - val_loss: 0.6558 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2504 - acc: 0.8587 - auc_1: 0.9600 - val_loss: 0.5934 - val_acc: 0.8750 - val_auc_1: 0.8821\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2710 - acc: 0.8696 - auc_1: 0.9510 - val_loss: 0.6251 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2609 - acc: 0.8696 - auc_1: 0.9579 - val_loss: 0.5945 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2472 - acc: 0.8804 - auc_1: 0.9612 - val_loss: 0.6910 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2488 - acc: 0.8913 - auc_1: 0.9619 - val_loss: 0.6243 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2544 - acc: 0.8804 - auc_1: 0.9617 - val_loss: 0.6067 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2495 - acc: 0.8696 - auc_1: 0.9595 - val_loss: 0.6019 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2442 - acc: 0.8913 - auc_1: 0.9648 - val_loss: 0.5566 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 241/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2502 - acc: 0.8913 - auc_1: 0.9593 - val_loss: 0.6500 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2526 - acc: 0.8913 - auc_1: 0.9602 - val_loss: 0.6340 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2540 - acc: 0.8804 - auc_1: 0.9593 - val_loss: 0.5949 - val_acc: 0.8750 - val_auc_1: 0.8821\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2407 - acc: 0.8913 - auc_1: 0.9648 - val_loss: 0.6047 - val_acc: 0.8750 - val_auc_1: 0.8786\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2423 - acc: 0.8913 - auc_1: 0.9648 - val_loss: 0.6196 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2429 - acc: 0.8804 - auc_1: 0.9624 - val_loss: 0.6858 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2529 - acc: 0.8913 - auc_1: 0.9605 - val_loss: 0.6616 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2607 - acc: 0.8587 - auc_1: 0.9576 - val_loss: 0.6049 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2557 - acc: 0.8587 - auc_1: 0.9576 - val_loss: 0.6636 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2489 - acc: 0.8804 - auc_1: 0.9633 - val_loss: 0.6805 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2451 - acc: 0.8696 - auc_1: 0.9636 - val_loss: 0.6497 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2349 - acc: 0.9022 - auc_1: 0.9655 - val_loss: 0.7179 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2372 - acc: 0.8913 - auc_1: 0.9633 - val_loss: 0.6862 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2445 - acc: 0.9022 - auc_1: 0.9621 - val_loss: 0.6042 - val_acc: 0.8750 - val_auc_1: 0.8714\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2376 - acc: 0.9022 - auc_1: 0.9636 - val_loss: 0.6539 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2282 - acc: 0.8804 - auc_1: 0.9693 - val_loss: 0.6319 - val_acc: 0.8750 - val_auc_1: 0.8714\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2356 - acc: 0.8913 - auc_1: 0.9648 - val_loss: 0.6302 - val_acc: 0.8750 - val_auc_1: 0.8714\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2376 - acc: 0.9022 - auc_1: 0.9645 - val_loss: 0.6878 - val_acc: 0.8333 - val_auc_1: 0.8393\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2391 - acc: 0.8804 - auc_1: 0.9631 - val_loss: 0.6186 - val_acc: 0.8750 - val_auc_1: 0.8714\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2298 - acc: 0.8804 - auc_1: 0.9686 - val_loss: 0.6572 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2409 - acc: 0.8587 - auc_1: 0.9636 - val_loss: 0.6935 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2428 - acc: 0.8913 - auc_1: 0.9629 - val_loss: 0.7397 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2322 - acc: 0.9022 - auc_1: 0.9676 - val_loss: 0.6332 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2376 - acc: 0.8587 - auc_1: 0.9674 - val_loss: 0.7482 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2349 - acc: 0.8913 - auc_1: 0.9674 - val_loss: 0.6550 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2262 - acc: 0.8913 - auc_1: 0.9679 - val_loss: 0.5806 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2435 - acc: 0.8696 - auc_1: 0.9626 - val_loss: 0.6319 - val_acc: 0.8750 - val_auc_1: 0.8714\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2299 - acc: 0.9130 - auc_1: 0.9648 - val_loss: 0.6219 - val_acc: 0.8750 - val_auc_1: 0.8786\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2237 - acc: 0.9130 - auc_1: 0.9700 - val_loss: 0.6896 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2230 - acc: 0.9022 - auc_1: 0.9693 - val_loss: 0.7761 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2412 - acc: 0.9022 - auc_1: 0.9638 - val_loss: 0.6453 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2289 - acc: 0.9022 - auc_1: 0.9679 - val_loss: 0.6517 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2251 - acc: 0.8913 - auc_1: 0.9688 - val_loss: 0.6957 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2182 - acc: 0.9130 - auc_1: 0.9726 - val_loss: 0.6804 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2158 - acc: 0.9130 - auc_1: 0.9695 - val_loss: 0.6879 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2224 - acc: 0.8804 - auc_1: 0.9712 - val_loss: 0.6901 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2221 - acc: 0.8913 - auc_1: 0.9702 - val_loss: 0.6861 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2153 - acc: 0.9130 - auc_1: 0.9714 - val_loss: 0.7089 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2157 - acc: 0.9130 - auc_1: 0.9724 - val_loss: 0.6858 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2131 - acc: 0.8913 - auc_1: 0.9729 - val_loss: 0.6792 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2118 - acc: 0.9130 - auc_1: 0.9726 - val_loss: 0.6786 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2180 - acc: 0.8913 - auc_1: 0.9719 - val_loss: 0.7597 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2253 - acc: 0.9022 - auc_1: 0.9676 - val_loss: 0.6854 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2200 - acc: 0.8696 - auc_1: 0.9662 - val_loss: 0.7938 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2292 - acc: 0.8913 - auc_1: 0.9700 - val_loss: 0.6908 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2115 - acc: 0.9022 - auc_1: 0.9736 - val_loss: 0.6948 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2109 - acc: 0.8913 - auc_1: 0.9729 - val_loss: 0.6777 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2096 - acc: 0.9022 - auc_1: 0.9712 - val_loss: 0.6821 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 289/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2101 - acc: 0.8913 - auc_1: 0.9714 - val_loss: 0.6750 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 290/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2153 - acc: 0.9022 - auc_1: 0.9748 - val_loss: 0.7827 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2091 - acc: 0.8913 - auc_1: 0.9731 - val_loss: 0.7116 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2087 - acc: 0.8913 - auc_1: 0.9743 - val_loss: 0.6756 - val_acc: 0.8333 - val_auc_1: 0.8500\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2070 - acc: 0.8804 - auc_1: 0.9745 - val_loss: 0.7958 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2199 - acc: 0.8913 - auc_1: 0.9710 - val_loss: 0.6702 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2096 - acc: 0.9130 - auc_1: 0.9736 - val_loss: 0.6479 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2046 - acc: 0.9022 - auc_1: 0.9757 - val_loss: 0.7068 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2035 - acc: 0.9022 - auc_1: 0.9750 - val_loss: 0.6734 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1986 - acc: 0.9130 - auc_1: 0.9767 - val_loss: 0.7432 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2107 - acc: 0.8913 - auc_1: 0.9724 - val_loss: 0.6344 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2059 - acc: 0.8913 - auc_1: 0.9717 - val_loss: 0.7144 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1915 - acc: 0.9022 - auc_1: 0.9788 - val_loss: 0.6535 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2083 - acc: 0.9130 - auc_1: 0.9724 - val_loss: 0.7743 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1991 - acc: 0.9022 - auc_1: 0.9767 - val_loss: 0.8046 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1914 - acc: 0.9130 - auc_1: 0.9802 - val_loss: 0.6723 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2013 - acc: 0.9022 - auc_1: 0.9748 - val_loss: 0.7339 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1920 - acc: 0.9130 - auc_1: 0.9781 - val_loss: 0.7541 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1924 - acc: 0.9022 - auc_1: 0.9776 - val_loss: 0.7797 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2030 - acc: 0.9022 - auc_1: 0.9736 - val_loss: 0.6969 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1922 - acc: 0.8804 - auc_1: 0.9790 - val_loss: 0.7826 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1895 - acc: 0.9239 - auc_1: 0.9771 - val_loss: 0.7671 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2021 - acc: 0.8913 - auc_1: 0.9771 - val_loss: 0.7419 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1976 - acc: 0.9022 - auc_1: 0.9764 - val_loss: 0.7191 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2120 - acc: 0.8696 - auc_1: 0.9683 - val_loss: 0.7718 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1953 - acc: 0.9130 - auc_1: 0.9767 - val_loss: 0.8090 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1990 - acc: 0.9130 - auc_1: 0.9757 - val_loss: 0.8373 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1915 - acc: 0.9130 - auc_1: 0.9779 - val_loss: 0.7884 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1816 - acc: 0.9022 - auc_1: 0.9783 - val_loss: 0.7066 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1934 - acc: 0.8913 - auc_1: 0.9767 - val_loss: 0.7730 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1881 - acc: 0.9130 - auc_1: 0.9774 - val_loss: 0.8104 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1883 - acc: 0.9239 - auc_1: 0.9805 - val_loss: 0.8203 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1946 - acc: 0.9022 - auc_1: 0.9731 - val_loss: 0.7568 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1842 - acc: 0.9022 - auc_1: 0.9790 - val_loss: 0.7144 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1804 - acc: 0.9022 - auc_1: 0.9798 - val_loss: 0.8138 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1669 - acc: 0.9022 - auc_1: 0.9850 - val_loss: 0.6427 - val_acc: 0.8333 - val_auc_1: 0.8286\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2470 - acc: 0.8587 - auc_1: 0.9581 - val_loss: 0.6961 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1937 - acc: 0.9022 - auc_1: 0.9790 - val_loss: 0.7200 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1761 - acc: 0.9022 - auc_1: 0.9814 - val_loss: 0.7874 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1926 - acc: 0.8913 - auc_1: 0.9750 - val_loss: 0.7495 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1701 - acc: 0.9130 - auc_1: 0.9836 - val_loss: 0.7868 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1808 - acc: 0.9022 - auc_1: 0.9790 - val_loss: 0.6963 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1753 - acc: 0.8913 - auc_1: 0.9805 - val_loss: 0.7450 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1776 - acc: 0.9239 - auc_1: 0.9800 - val_loss: 0.7402 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1761 - acc: 0.9130 - auc_1: 0.9821 - val_loss: 0.7040 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1812 - acc: 0.8804 - auc_1: 0.9783 - val_loss: 0.7616 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1908 - acc: 0.9022 - auc_1: 0.9752 - val_loss: 0.7712 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1722 - acc: 0.9130 - auc_1: 0.9810 - val_loss: 0.7274 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 337/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1852 - acc: 0.8913 - auc_1: 0.9762 - val_loss: 0.8240 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 338/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1787 - acc: 0.9239 - auc_1: 0.9810 - val_loss: 0.8235 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1788 - acc: 0.8804 - auc_1: 0.9805 - val_loss: 0.7493 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1749 - acc: 0.8913 - auc_1: 0.9795 - val_loss: 0.8257 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1689 - acc: 0.9022 - auc_1: 0.9833 - val_loss: 0.8131 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1748 - acc: 0.9022 - auc_1: 0.9790 - val_loss: 0.8506 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1809 - acc: 0.8804 - auc_1: 0.9774 - val_loss: 0.7977 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1754 - acc: 0.9022 - auc_1: 0.9786 - val_loss: 0.8401 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1661 - acc: 0.9130 - auc_1: 0.9843 - val_loss: 0.7411 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1751 - acc: 0.9022 - auc_1: 0.9798 - val_loss: 0.7748 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1573 - acc: 0.9130 - auc_1: 0.9867 - val_loss: 0.7391 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1579 - acc: 0.9239 - auc_1: 0.9848 - val_loss: 0.9430 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1770 - acc: 0.8913 - auc_1: 0.9810 - val_loss: 0.8029 - val_acc: 0.8333 - val_auc_1: 0.8464\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1780 - acc: 0.9130 - auc_1: 0.9790 - val_loss: 0.8137 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1563 - acc: 0.9239 - auc_1: 0.9862 - val_loss: 0.7415 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1670 - acc: 0.9239 - auc_1: 0.9843 - val_loss: 0.8691 - val_acc: 0.7917 - val_auc_1: 0.8143\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1649 - acc: 0.9022 - auc_1: 0.9819 - val_loss: 0.8036 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1682 - acc: 0.9130 - auc_1: 0.9824 - val_loss: 0.8684 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1626 - acc: 0.9130 - auc_1: 0.9829 - val_loss: 0.7418 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1724 - acc: 0.9130 - auc_1: 0.9819 - val_loss: 0.7696 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1724 - acc: 0.9239 - auc_1: 0.9821 - val_loss: 0.8200 - val_acc: 0.7917 - val_auc_1: 0.8143\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1589 - acc: 0.9022 - auc_1: 0.9833 - val_loss: 0.7656 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1750 - acc: 0.9022 - auc_1: 0.9798 - val_loss: 0.7580 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1594 - acc: 0.8913 - auc_1: 0.9857 - val_loss: 0.8400 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2108 - acc: 0.8696 - auc_1: 0.9745 - val_loss: 0.8253 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1612 - acc: 0.9130 - auc_1: 0.9831 - val_loss: 0.9140 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1540 - acc: 0.9348 - auc_1: 0.9857 - val_loss: 0.8214 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1690 - acc: 0.9022 - auc_1: 0.9817 - val_loss: 0.8568 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1548 - acc: 0.9022 - auc_1: 0.9857 - val_loss: 0.9183 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1673 - acc: 0.9022 - auc_1: 0.9800 - val_loss: 0.8606 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1724 - acc: 0.8804 - auc_1: 0.9814 - val_loss: 0.8471 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1599 - acc: 0.9239 - auc_1: 0.9836 - val_loss: 0.8185 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1619 - acc: 0.9022 - auc_1: 0.9800 - val_loss: 0.8349 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1552 - acc: 0.8913 - auc_1: 0.9852 - val_loss: 0.8383 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1619 - acc: 0.9130 - auc_1: 0.9838 - val_loss: 0.8269 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1493 - acc: 0.9130 - auc_1: 0.9855 - val_loss: 0.8649 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1549 - acc: 0.9022 - auc_1: 0.9860 - val_loss: 0.8575 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1613 - acc: 0.9130 - auc_1: 0.9838 - val_loss: 0.8341 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1475 - acc: 0.9130 - auc_1: 0.9857 - val_loss: 0.8013 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1560 - acc: 0.9239 - auc_1: 0.9812 - val_loss: 0.8042 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1763 - acc: 0.9022 - auc_1: 0.9788 - val_loss: 0.8903 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1552 - acc: 0.9239 - auc_1: 0.9855 - val_loss: 0.8719 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1536 - acc: 0.9348 - auc_1: 0.9850 - val_loss: 0.8313 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1515 - acc: 0.8913 - auc_1: 0.9843 - val_loss: 0.8275 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1461 - acc: 0.9130 - auc_1: 0.9855 - val_loss: 0.8315 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1611 - acc: 0.8804 - auc_1: 0.9807 - val_loss: 0.8845 - val_acc: 0.7917 - val_auc_1: 0.8071\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1694 - acc: 0.8913 - auc_1: 0.9802 - val_loss: 0.8889 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1660 - acc: 0.9130 - auc_1: 0.9840 - val_loss: 0.8431 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 385/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1474 - acc: 0.9022 - auc_1: 0.9867 - val_loss: 0.8004 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 386/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1640 - acc: 0.9130 - auc_1: 0.9798 - val_loss: 0.9083 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1445 - acc: 0.9239 - auc_1: 0.9888 - val_loss: 0.8109 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1552 - acc: 0.8913 - auc_1: 0.9819 - val_loss: 0.8078 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1477 - acc: 0.9022 - auc_1: 0.9862 - val_loss: 0.7893 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1410 - acc: 0.9239 - auc_1: 0.9883 - val_loss: 0.8947 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1703 - acc: 0.9239 - auc_1: 0.9833 - val_loss: 0.8904 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1442 - acc: 0.9130 - auc_1: 0.9871 - val_loss: 0.8517 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1636 - acc: 0.9022 - auc_1: 0.9802 - val_loss: 0.8310 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1510 - acc: 0.9239 - auc_1: 0.9855 - val_loss: 0.8569 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1523 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 0.9000 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1370 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 0.9240 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1462 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 0.8162 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1416 - acc: 0.9022 - auc_1: 0.9852 - val_loss: 0.8816 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1538 - acc: 0.9130 - auc_1: 0.9852 - val_loss: 0.8089 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1495 - acc: 0.9348 - auc_1: 0.9860 - val_loss: 0.8405 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1486 - acc: 0.9239 - auc_1: 0.9848 - val_loss: 0.8602 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1349 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.8828 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1425 - acc: 0.9348 - auc_1: 0.9879 - val_loss: 0.8203 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1891 - acc: 0.8913 - auc_1: 0.9731 - val_loss: 0.8166 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1464 - acc: 0.9239 - auc_1: 0.9852 - val_loss: 0.8293 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1376 - acc: 0.9239 - auc_1: 0.9869 - val_loss: 0.8723 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1348 - acc: 0.9239 - auc_1: 0.9871 - val_loss: 0.9366 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1362 - acc: 0.9239 - auc_1: 0.9886 - val_loss: 0.8518 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1353 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.8412 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1505 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 0.7248 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1306 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.9085 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1395 - acc: 0.9239 - auc_1: 0.9860 - val_loss: 0.9311 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1554 - acc: 0.9348 - auc_1: 0.9836 - val_loss: 0.9102 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1443 - acc: 0.9239 - auc_1: 0.9886 - val_loss: 0.8806 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1446 - acc: 0.9565 - auc_1: 0.9864 - val_loss: 0.9821 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1270 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 0.7729 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1310 - acc: 0.9239 - auc_1: 0.9890 - val_loss: 0.8563 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1299 - acc: 0.9348 - auc_1: 0.9905 - val_loss: 0.9382 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1297 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 0.8625 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1331 - acc: 0.9457 - auc_1: 0.9890 - val_loss: 0.8481 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1409 - acc: 0.9239 - auc_1: 0.9857 - val_loss: 0.8500 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1529 - acc: 0.9348 - auc_1: 0.9886 - val_loss: 0.9368 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1216 - acc: 0.9457 - auc_1: 0.9917 - val_loss: 0.7765 - val_acc: 0.8333 - val_auc_1: 0.8321\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1737 - acc: 0.9348 - auc_1: 0.9812 - val_loss: 0.8616 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1375 - acc: 0.9565 - auc_1: 0.9881 - val_loss: 0.9246 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1257 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 0.8854 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1311 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 0.9336 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1341 - acc: 0.9239 - auc_1: 0.9895 - val_loss: 0.8173 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1241 - acc: 0.9565 - auc_1: 0.9914 - val_loss: 0.8050 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1300 - acc: 0.9457 - auc_1: 0.9883 - val_loss: 0.9252 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1371 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 0.8508 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1200 - acc: 0.9565 - auc_1: 0.9900 - val_loss: 0.9325 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 433/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1589 - acc: 0.9348 - auc_1: 0.9843 - val_loss: 0.9417 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 434/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1212 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 0.8984 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1226 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.8133 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1249 - acc: 0.9565 - auc_1: 0.9898 - val_loss: 0.8286 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1219 - acc: 0.9348 - auc_1: 0.9926 - val_loss: 0.9019 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1338 - acc: 0.9348 - auc_1: 0.9862 - val_loss: 0.8905 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1339 - acc: 0.9348 - auc_1: 0.9905 - val_loss: 0.8222 - val_acc: 0.8333 - val_auc_1: 0.8464\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1338 - acc: 0.9348 - auc_1: 0.9879 - val_loss: 0.8580 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1129 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 0.8396 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1285 - acc: 0.9457 - auc_1: 0.9910 - val_loss: 0.8365 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1069 - acc: 0.9783 - auc_1: 0.9957 - val_loss: 0.8546 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1457 - acc: 0.9348 - auc_1: 0.9867 - val_loss: 0.9205 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1330 - acc: 0.9565 - auc_1: 0.9890 - val_loss: 0.7872 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1308 - acc: 0.9239 - auc_1: 0.9893 - val_loss: 0.8676 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1197 - acc: 0.9348 - auc_1: 0.9924 - val_loss: 0.7784 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1195 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.7892 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1136 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.8464 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1335 - acc: 0.9457 - auc_1: 0.9871 - val_loss: 0.9209 - val_acc: 0.8333 - val_auc_1: 0.8321\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1237 - acc: 0.9565 - auc_1: 0.9919 - val_loss: 0.8544 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1167 - acc: 0.9565 - auc_1: 0.9912 - val_loss: 0.8611 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1212 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 0.9017 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1384 - acc: 0.9348 - auc_1: 0.9867 - val_loss: 0.9118 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1259 - acc: 0.9348 - auc_1: 0.9900 - val_loss: 0.8424 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1100 - acc: 0.9457 - auc_1: 0.9952 - val_loss: 0.8602 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1181 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 0.8357 - val_acc: 0.8333 - val_auc_1: 0.8393\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1078 - acc: 0.9783 - auc_1: 0.9938 - val_loss: 0.8039 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1149 - acc: 0.9565 - auc_1: 0.9902 - val_loss: 0.7720 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1282 - acc: 0.9457 - auc_1: 0.9874 - val_loss: 0.8699 - val_acc: 0.7917 - val_auc_1: 0.7893\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1197 - acc: 0.9565 - auc_1: 0.9921 - val_loss: 0.8608 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1153 - acc: 0.9457 - auc_1: 0.9936 - val_loss: 0.8232 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1083 - acc: 0.9674 - auc_1: 0.9940 - val_loss: 0.9098 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1220 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 0.9218 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1397 - acc: 0.9457 - auc_1: 0.9881 - val_loss: 0.9278 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1286 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 0.8181 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1176 - acc: 0.9348 - auc_1: 0.9914 - val_loss: 0.8632 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1085 - acc: 0.9565 - auc_1: 0.9943 - val_loss: 0.8961 - val_acc: 0.8333 - val_auc_1: 0.8321\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1251 - acc: 0.9348 - auc_1: 0.9900 - val_loss: 0.9073 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1045 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 1.0012 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1045 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.8925 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1042 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.8150 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1029 - acc: 0.9674 - auc_1: 0.9924 - val_loss: 0.8989 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1041 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.8902 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1040 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 0.9657 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1285 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 0.8350 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1236 - acc: 0.9565 - auc_1: 0.9914 - val_loss: 0.7952 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1199 - acc: 0.9565 - auc_1: 0.9867 - val_loss: 0.7464 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1131 - acc: 0.9457 - auc_1: 0.9936 - val_loss: 0.8398 - val_acc: 0.8333 - val_auc_1: 0.8464\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1129 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 1.0640 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 481/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1155 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.8269 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 482/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1230 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.9457 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1113 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.8183 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1142 - acc: 0.9565 - auc_1: 0.9943 - val_loss: 0.7765 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1380 - acc: 0.9348 - auc_1: 0.9871 - val_loss: 0.8804 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1091 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 0.8236 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0952 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.8384 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1002 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.8578 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1006 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.8414 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0997 - acc: 0.9565 - auc_1: 0.9950 - val_loss: 0.8326 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1185 - acc: 0.9239 - auc_1: 0.9919 - val_loss: 0.7515 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1072 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 0.8573 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0975 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.8970 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1054 - acc: 0.9674 - auc_1: 0.9933 - val_loss: 0.8720 - val_acc: 0.8333 - val_auc_1: 0.8357\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1093 - acc: 0.9565 - auc_1: 0.9943 - val_loss: 0.8907 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1249 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 0.9506 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0923 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 0.8596 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1163 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.8323 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0904 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 0.9274 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1111 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.9139 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1082 - acc: 0.9457 - auc_1: 0.9948 - val_loss: 0.8057 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1123 - acc: 0.9565 - auc_1: 0.9914 - val_loss: 0.8415 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0806 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.8333 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0872 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.8576 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0897 - acc: 0.9674 - auc_1: 0.9969 - val_loss: 0.9308 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0993 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.8941 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0929 - acc: 0.9783 - auc_1: 0.9957 - val_loss: 0.8056 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0849 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.8312 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1150 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 0.8189 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0928 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.8342 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1092 - acc: 0.9674 - auc_1: 0.9917 - val_loss: 0.8074 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0877 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 0.8075 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0782 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.8968 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1517 - acc: 0.9239 - auc_1: 0.9852 - val_loss: 0.8325 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0894 - acc: 0.9674 - auc_1: 0.9969 - val_loss: 0.9186 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1048 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.8510 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0917 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 0.8067 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0921 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.8384 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1295 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 0.7983 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0997 - acc: 0.9565 - auc_1: 0.9914 - val_loss: 0.8809 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1080 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.8877 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0961 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.9072 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0859 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.8963 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0851 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.8299 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0863 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.8878 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0914 - acc: 0.9783 - auc_1: 0.9969 - val_loss: 0.9640 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0944 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.9138 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0966 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.8975 - val_acc: 0.8333 - val_auc_1: 0.8500\n",
      "Epoch 529/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0796 - acc: 0.9783 - auc_1: 0.9979 - val_loss: 0.9109 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 530/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0790 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.8067 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1441 - acc: 0.9457 - auc_1: 0.9867 - val_loss: 0.8714 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0988 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.8496 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0787 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.8827 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0723 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.8692 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0982 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 0.7831 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0910 - acc: 0.9674 - auc_1: 0.9950 - val_loss: 0.9008 - val_acc: 0.8333 - val_auc_1: 0.8393\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0960 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.8455 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0960 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 0.8545 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0905 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.9707 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0810 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.9183 - val_acc: 0.8333 - val_auc_1: 0.8393\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0804 - acc: 0.9565 - auc_1: 0.9960 - val_loss: 0.8747 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1072 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 0.9184 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0821 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.9951 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0852 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 0.9363 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0726 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8414 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0831 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.9682 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0821 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.9502 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0783 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.9726 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0931 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.8449 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0923 - acc: 0.9674 - auc_1: 0.9950 - val_loss: 0.9717 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0832 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.9085 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0784 - acc: 0.9783 - auc_1: 0.9983 - val_loss: 0.8921 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0938 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 0.9873 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0707 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.8753 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0809 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 1.0402 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0821 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.9188 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1082 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 0.9656 - val_acc: 0.8333 - val_auc_1: 0.8357\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1017 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 0.8514 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0768 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.8580 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0745 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.9364 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0689 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 1.0382 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0662 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.9102 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0895 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.9558 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0710 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.9294 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0820 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.0017 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0723 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.9515 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0856 - acc: 0.9565 - auc_1: 0.9964 - val_loss: 0.8979 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0719 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.8348 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0963 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.8706 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0672 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.9014 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0850 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.9959 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0599 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8792 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0715 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 0.9907 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0778 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.8220 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0703 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.9740 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0809 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 1.0388 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 577/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0660 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.9357 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 578/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0668 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.9791 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0962 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 1.0246 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1272 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 0.9397 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0684 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.9204 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1007 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.9071 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0989 - acc: 0.9565 - auc_1: 0.9943 - val_loss: 0.9428 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0739 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.9042 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0678 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.8842 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0806 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.9772 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0736 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.9558 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0678 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.9207 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0772 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.1048 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0677 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.9404 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0580 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.9109 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0809 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.9668 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1111 - acc: 0.9457 - auc_1: 0.9933 - val_loss: 1.0281 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0684 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.9143 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0999 - acc: 0.9565 - auc_1: 0.9936 - val_loss: 0.8618 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0732 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 0.9380 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0947 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 0.8762 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0748 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 0.9898 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0800 - acc: 0.9783 - auc_1: 0.9945 - val_loss: 1.0964 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0731 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 0.9780 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0712 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 0.9677 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0542 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.9292 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0648 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.9397 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0809 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 1.0504 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0728 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.0383 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0580 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.9052 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0600 - acc: 0.9783 - auc_1: 0.9983 - val_loss: 1.1565 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1091 - acc: 0.9565 - auc_1: 0.9921 - val_loss: 0.9918 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0991 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.8925 - val_acc: 0.7917 - val_auc_1: 0.88210  \n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0669 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 0.9402 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0592 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.0743 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0618 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.0079 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0795 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.9952 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0579 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.9790 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0621 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.9181 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0598 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.0712 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0572 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 0.9182 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0589 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.0098 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0818 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 1.1664 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0647 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 0.9410 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0652 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.1759 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0708 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 0.9722 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0864 - acc: 0.9674 - auc_1: 0.9955 - val_loss: 1.0532 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0658 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.0409 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 625/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0678 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 1.0026 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 626/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0659 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.9848 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0641 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 1.0396 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0670 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 1.1444 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0671 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 1.1122 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0767 - acc: 0.9565 - auc_1: 0.9969 - val_loss: 1.0299 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0550 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.0356 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0629 - acc: 0.9565 - auc_1: 0.9974 - val_loss: 0.9838 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0613 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.0826 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0707 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.1491 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0618 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.1976 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0941 - acc: 0.9239 - auc_1: 0.9943 - val_loss: 1.0363 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0633 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.2134 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0479 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.0541 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0716 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.9495 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0575 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.3354 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0623 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.9970 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0904 - acc: 0.9457 - auc_1: 0.9952 - val_loss: 1.0987 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0765 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.2955 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0532 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.1311 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0605 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 1.2307 - val_acc: 0.7917 - val_auc_1: 0.8071\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0642 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 1.1739 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0562 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 1.2346 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0592 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.2758 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0574 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.1830 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0500 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.1363 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0725 - acc: 0.9457 - auc_1: 0.9962 - val_loss: 1.1330 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0516 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.1746 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0507 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.1969 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0483 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.1615 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0649 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 1.3982 - val_acc: 0.7917 - val_auc_1: 0.7714\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0511 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.0296 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0673 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.3512 - val_acc: 0.7917 - val_auc_1: 0.7714\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0972 - acc: 0.9348 - auc_1: 0.9929 - val_loss: 1.1784 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0478 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.1055 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0579 - acc: 0.9674 - auc_1: 0.9979 - val_loss: 1.2510 - val_acc: 0.7917 - val_auc_1: 0.8143\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0467 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1395 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0622 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.1328 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0580 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.3801 - val_acc: 0.7917 - val_auc_1: 0.7714\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0739 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 1.2704 - val_acc: 0.7917 - val_auc_1: 0.7893\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0626 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.0922 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0599 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.2241 - val_acc: 0.7917 - val_auc_1: 0.8143\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0580 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.1494 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0459 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.1441 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0496 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.1049 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0789 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.1585 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0488 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.3628 - val_acc: 0.7917 - val_auc_1: 0.7821\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0528 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.2210 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 673/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0482 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1070 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 674/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0864 - acc: 0.9674 - auc_1: 0.9945 - val_loss: 1.3190 - val_acc: 0.7917 - val_auc_1: 0.7929\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0603 - acc: 0.9565 - auc_1: 0.9986 - val_loss: 1.2985 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0413 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.2620 - val_acc: 0.7917 - val_auc_1: 0.7821\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0420 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1379 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0459 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.2088 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0471 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4320 - val_acc: 0.7917 - val_auc_1: 0.7750\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0540 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.2868 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0630 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.2605 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0425 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0589 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0519 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.5616 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0491 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3637 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0382 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3178 - val_acc: 0.7917 - val_auc_1: 0.7929\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0434 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0726 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1686 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.9204 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0703 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.2470 - val_acc: 0.7917 - val_auc_1: 0.8071\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0790 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.2546 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0510 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1470 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0415 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.3173 - val_acc: 0.7917 - val_auc_1: 0.8036\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0527 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.2992 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0359 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1754 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0375 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1999 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0357 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4547 - val_acc: 0.7917 - val_auc_1: 0.7750\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0544 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.2418 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0306 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1470 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0478 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3218 - val_acc: 0.7917 - val_auc_1: 0.8107\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0490 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.3442 - val_acc: 0.7917 - val_auc_1: 0.7857\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0385 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3102 - val_acc: 0.7917 - val_auc_1: 0.8179\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydeXhU1fn4P+9MJnsI+yIBwo6yuIAKrohaca9iFapWWy3u+/LVtlprF21rbWvrz7q2dV9otbiiokitooIKioDsEtlC2ELIPuf3x7k3c2fmTjKBTBKY9/M8eebec889953JzHnPed/3vEeMMSiKoijpS6CtBVAURVHaFlUEiqIoaY4qAkVRlDRHFYGiKEqao4pAURQlzVFFoCiKkuaoIlDSHhEJisgOEembovYHiMiOVLStKC2BKgJlj8PptN2/sIhUes7PbW57xph6Y0y+MeabXZBlkIjELcYRkSdF5A6n/RXGmPwk2rpYRGY1VwZF2V0y2loARWku3k5VRFYBFxtj3k5UX0QyjDF1rSFbW5Iu71NpeXRGoOx1iMivROQ5EXlGRMqB80RknIjMEZGtIrJORO4TkZBTP0NEjIgUO+dPOtdfF5FyEflQRPrvhjxRswYRuUhEVjltrxCRySIyEvgrcKQzs9nk1O3oyFPq3HOriIhz7WIRme3Iuhn4lfP+9vU8q5eI7BSRLrsqv7L3o4pA2Vs5A3gaKASeA+qAa4CuwOHAROCSRu7/PnAb0Bn4BvhlSwglIh2Ae4HjjTEFjiwLjDFfAFcC/3XMVF2dW/4fkAsMACYAFwE/8DR5GLAI6Ab8AngeOC/mfcwwxpS1hPzK3okqAmVv5X1jzMvGmLAxptIY84kx5iNjTJ0xZgXwEHB0I/dPM8bMNcbUAk8BBzT2MGck3vAHnN1IdQOMEJFsY8w6Y8xXCdoMOe3cYowpd+T+I3C+p9o3xpgHHD9HJfBP4PvurMGp+0RjsiuKKgJlb2WN90REhonIqyKyXkS2A3diZweJWO853gk06uw1xnT0/mFH5n71tgNTgCuA9SLyiogMSdBsdyAIrPaUrQZ6e86j3qcx5n/Y2c8RIjIC6Au82pjsiqKKQNlbiY3keRD4EhhkjOkA3A5I3F2tgDHmdWPMcUAvYJkjG8TLvBGoB/p5yvoC33qb83nE41jz0PnA88aY6paQW9l7UUWgpAsFwDagwnGmNuYfSBmO8/ZUEckFaoAKbGcPsAEocp3YjllqGvAbEcl3HNbXAU828ZgngLOw/oHHU/A2lL0MVQRKunADcAFQjh2BP9dGcgSBm4B1QBnW2Xulc+0tYCmwQURc09TlWIWxEngP6wNotHM3xqwCvgBqjDEftLD8yl6I6MY0irL3ISKPAyuMMXe0tSxK+0cXlCnKXoaIDABOB0a2tSzKnoGahhRlL0JE7gLmA7/ZlZQZSnqipiFFUZQ0R2cEiqIoac4e5yPo2rWrKS4ubmsxFEVR9ijmzZu3yRjTze/aHqcIiouLmTt3bluLoSiKskchIqsTXVPTkKIoSpqjikBRFCXNUUWgKIqS5uxxPgJFUfYuamtrKSkpoaqqqq1F2SvIzs6mqKiIUCiU9D2qCBRFaVNKSkooKCiguLiYyDYKyq5gjKGsrIySkhL6909+U72UmYZE5DER2SgiXya4Ls4We8tEZIGIHJQqWRRFab9UVVXRpUsXVQItgIjQpUuXZs+uUukj+Ad2O8BEnAgMdv6mAg+kUBZFUdoxqgRajl35LFNmGjLGzHY3A0/A6cDjxua4mONs0t3LGLMuVTIpirL3EjYGIXFHaIzBAAHP9dh7mmrDrRMQwRhDXdgQCgZs2wYCAaGuPkxd2BAQyAgGGrYOCgRsmzV19YQN7KiuIycUZGdNnb0uggjUhQ1d8rKoqq2nvLqOjIAQNob6sKFTbibZoeDuflRxtKWPoDfR2+yVOGVxikBEpmJnDfTt27dVhFMUJTFVtfVkBgMNndvmihpmLFzPoO75PDlnNZnBAAf370xlTT1DehTw8oK1XHvcYLJDQTpkhyjZspNvt1RigPqKGkq27CQchqJOOYSdTvWbzTupqKmjc24mWaEAW3bW0ik3k1BQ2Li9mqq6erIygoSCwo5q25lmZQTJzAhQHzbkhALkZ2Wws7aeqtow5VW1BANCflYGHXJChMOG9durCAYEQcgJBamqq6eqtp5gQAgFbTuFOSHCxlBbb3v08qrahmdV19U3fCYBsW1UOB17LKFggIBI1D2J2Li9mrBPHrjMYGCvUwR+Ktc3A54x5iHsZuOMGTNGs+QpSjMxxvCLl7/ilFG9GFPcuaF8W2Utz33yDT88vD+hYICq2nqyQ0E27ajmrtcWs6qsgrId1fz8tOEcM7Q7m3ZUs3TDDu56fRHfbqnk2uMGM2fFZt5ftoltlbVRz3xhXknU+dMf2WSoPzlpGL95bXFD+cOn9WJzRQ0AWytr4mTfvDNStm5bZdS16rp6qutiz21Hu7MGyiqi26sPG7ZV1kbJWh82Dfd6y+rD9nzTDv+dPmM79LAx1IbDDeciwm3XX8HsmTPo3KUrL70zh7BYxeJ9/j4dc6gPGyqq68jNDLKx3CqB7FCQ3h1zKK+qo64+TLeCLLJSoASgbRVBCdDHc14ErG0jWRRlj2Te6s3884PV/O6sUQAsL93B8H0KAfh8zVbWbq0kNzPItHklvLJgHS/PX8u4gV34cHkZ0y47jOfnruGBWcv5zWuLOfOg3vz70285cURPXv9yfdRz/jJzKVc/8xnlVdGj3dv+s9BXrl6F2azb5u+wdJVAp9wQdeHGx3WDuuWzpbKWspjOOC8zg5zMIFkZAQywdmslnfMy6dEhm1WbKqisjXTSHbJD9CrMJhAQFq3bHtVO94JsCnMyKK+uY70j76Du+WRlBKmqrefbrZV0ys2kpq6+ocN2RV68fjsF2SG6FWSxdmslxV3yyMwIUFsfZntlLZ3zMpk0+VymXPhjfnHj5ezXqwMQMR+VVdSwYXsVHbJDZGZYd2192LCx3L7X/l3zCAUD5GWlvptuS0UwHbhSRJ4FDgW2qX9AUeKZt3oLnXJDDOiWz7zVW3jps2+ZNLqIfp1zmfTAhwBMnx89hrr62MHcN3NpXFtlFTW8ssD+zI65Z1bUtX9/+i1AnBIA+PSbrXFlf5lyIFc985mvzL87axQdskOcfv//GspyQsGGDvqlKw7ngD4dAXjrg08BGNA1j9/NWMLiddvZWVtPRiBAVkYknsU1lVTXhcnKCETZ+mOprQ9TUxcmKxRkZO9C7jhtOAB9O+eyuaKG7gVZZDpmJRHhnO9NYtnK1dTX1nDDddcydepUenTpyI4dOwCYNm0ar7zyCv/4xz/YsGEDl156KcuXr0AEHnjgAQ477LCGZ4eCAbrkZwEw6eTj+WTBEgIiDWY0sL6D7gVZdM7NJOR5j54qBAOt50BPmSIQkWeA8UBXESkBfg64m3L/DXgNOAlYBuwEfpgqWRQllYTD1gm5Oz/c/y4tZerj8zh8UFdOGdWL8uo6/vz217x9/dFMesBuO/zc1LGc89AcAJ6YkzB/GICvEkjEQX07NnT0JwzvwYyFGwAY1rOAl686gnMf+YiPV26Ou+/EET2ZdeN49umYw+MfrqJDTogTR/Tkra82cPjArnYEfudEHn1/Bfe8+TU9C7Oprq1nRO/CBiXgJS8rw9rrRcjLjO+a3I4/JwnzSCgYICMYcBy/kfKOuZl0zM2Mq/+Pv/+dgsKO1NVUc/DBBzNp0qSEbV999dUcffTRvPjii9TX1zcoCz9yMzPo1zXP95qIEMqQuDKXxhRdS5PKqKEpTVw3wBWper6i7C6L128nLzODPp1zE9apDxumPDyH7ZW1dMwNMfWoAUwY1oOaujC/eW0RWaEA7y/dxJ2nD6e23vDY+yv5cHkZ543rR0bAOj2H9izgzle+AuDtRRt4e9GGhvYP/vXbDceuEvAyoGseHXJCfL7GduT7FGYzsqiwoTM/eWQvXv3CzgAGd89n6cYdvHTF4XzXM1I/Zmh39umYw5tfbeCqCYOpDxvuOG04vTvmICI8duHBjPj5DABW3X0yh/7mbTZsryYjGKDY6eQuPnJAQ3tnHlTUcJyTGeT4/Xpyz5tfIwL/vvxwOuT4dzsiws9PHZ7ws04l9913Hy+++CIAa9asYenSxIr0nXfe4fHHHwcgGAxSWFjYKjKmEl1ZrCgJmPin/wJw79n7s3h9ORcd0Z/8rAzysjJYuqGcv3+wipWlFVGj5TkrNnPVhEE8/uHqKIega8JxeWDW8iaff9jALnywvCyq7J0bjuZv7y3n+bnWEfvK1Ucw++tNXPrkPABO3X8fbjphKMf/cTYrN1Xw46MGMLRnAReMK6a6rp41Wyo5oE9H5v3sOPKyMnh/6SbGD+2GiFAXDpOVEeSRCw6OemZ+VgZvX39Uw2h15g3jfSNaElHUKQeA648fQs/C7LjrPQuzGNyjIOn2WppZs2bx9ttv8+GHH5Kbm8v48eOpqqqKGp3v7ekvVBEoacn6bVUsWredY4Z1j7u2ZH057y/b1HB+/fPzAXho9goAuuZnJYwkAfjLO8sSXssICKP7deIjH1NLLE9dfCgiwvT5a7nascUP6JbPXWeOomt+FmceVERuZgYTR/TkphOG8vsZS+hWkEVGMMCb1x3FJ6s2c0Cfjh4zTIjuHWxH7Nqwj9uvR8PzgoHEJpdB3SMddX4znZd5WRmsuvvkhNczAqkJiUyWbdu20alTJ3Jzc1m8eDFz5tiZV48ePVi0aBFDhw7lxRdfpKDAfgbHHnssDzzwANdeey319fVUVFTQoUOHFpNnQNe8aHtWK6DZR5W0whjDz176grF3zeSH//iE8x/9iNG/fIvZX5eyo7qOO6Yv5IQ/zeaXjqnGj8aUwMM/GMO/Lz+MTrmRhF+Du+c3HD9x0aH8/YeREfffzhtNQXakY51/+3c4cnBXjh3WvWFE6r0frC/i5onDGOQpv/CwYq44ZiDnje0HWBv5YQO7NvVxKMDEiROpq6tj1KhR3HbbbYwdOxaAu+++m1NOOYUJEybQq1evhvp//vOfeffddxk5ciSjR49m4UL/yCmAKVOmMG7cOJYsWUJRURGPPvpok/LkZ4earWx3lz1u8/oxY8YY3aFMSZYd1XVsr6wlMyPA795Y3GBS2RV++d0R3PaSTZ01pl8nOuaG+N+yMh48fzSDuuczd/UWTtt/H8AuuBp22xsArLzrJKrrbHy5O/KduWgDIjBhmB2Rb6usJSMgvqGC67dVMfaumQCNjqz3VBYtWsS+++7b1mLsVfh9piIyzxgzxq++moaUPZ6N5VVs3F7N4B75TP98Ld0KsujXJY973lzCFyXb+GbzzqTbGtgtj/37dGwIpXS55cRhTDqoN7e99CW5mUH+37kH0TU/i/KqOgqd0f9pHXMa6ntNHSISZ/o4dt8eUeeFOYlTBnfMTT6dsKLsCqoIlD2WDdurqA8bfvDYxyzbGB3CV9Qph5ItlXH3eBc6Pf6jQ1hdVkFeVkaDH+DJiw8lPyuDz9dsZVN5Ndur6vi/icO45KgBiEjciLywkU76o58cS01dOOH1ZMkOBdm3Vwd+eHjxbreltDxlZWUce+yxceUzZ86kS5cubSBR81FFoLR7XGfpXWeOpLyqlgFd8ymvruUvM5exYlNFVN1fnj6c389YQsmWSnJCQU4c0ZMbTxjKPz9cxdAeBRw9pBtvfrWBo4d0Y5+OOUA3IOIQ7lFgV6C+c8N4Lvz7x8xaUkr3gqxdyujYo0N8hMyu8vo1R7ZYW0rL0qVLFz7//PO2FmO3UEWgtAuMMWyuqCEvK4OSLZUM6p5Pfdjw709LuOfNJQDc+u8vEt5/0wlDufCwYvKyMpi5eCOzlpRy/fFD+PFRNr791hMj9tIph8QnLvzD9/Zn7uotUas/3Rw0rbHEX1HaEv2GK23Gv+aV0K9LLmOKO/PIf1fy69cWMW5AFz5cUcbfzjuINxdu4N+ffdt0Q8AVxwxqOL7rzJH87o0lfPfA3knLMml0EZNGF0WVubHyOZltF9qoKK2BKgIl5RhjWF5aQf+ueVTW1rN84w62V9VywwvWHDOmXyfmrt4CwIcr7AKq2/+zsCH5FsCRg7syZ0UZtfWGKYf0ZVtlDa99sZ6bThjKqKLolZ29CnP44zkH7Lbc7owgqJumKHs5qgiU3WJLRQ23T1/InacNp1NeZkPZx6s2c8Lwnlzx9Ke8uXA9tfWGjrkhtu6sjWvDVQIunfMyG5TAs1PHUh82jBvQhUBAGjYAqakPc/ekMB2yUxdR42YUDuhqG2UvRxWBsls88N5yXp6/lpfnr2VYzwIWry9vuPbKVUfw6oJIQtlYJXDOmD48N9fuTfSvy8bxwbIyNpZXc/kxAzn697MwxjCyd2GUjV6cXZyyA8GUr0b94eHFfLxqM0PbMP2B0v7Iz89vNNFcKpk4cSJz5szhiCOO4JVXXmmxdlURKI1SXVfPph019HZi5DdX1LBpRzWDu+dz/qMfR6Vi8CoBgGc+/sa3zV+fMYLvH9KX+SXbGhTB6H6dGd0vsmHKf28+hpq6cJs6ak8c2WuvXMCl7LncdNNN7Ny5kwcffLBF21VFoDTKJU/MY9aSUpb/5iSCAeGwu2dSVRtmxrVHRSkBP5766BsyAsKXvziB2176khfmlXD4oC6cuv8+iEiDcvGjJUMvlT2I12+B9Ymjw3aJniPhxLsTXv6///s/+vXrx+WXXw7AHXfcgYgwe/ZstmzZQm1tLb/61a84/fTTm3zUjh07OP300+PuW7VqFaeccgpffmlXpt9zzz3s2LGDO+64g2XLlnHppZdSWlpKMBjkhRdeYODAgb7tH3vsscyaNav5n0ETqCJQEmKMYdaSUsBuEVhbb6iqtYbzE/40O67+xUf0Z2RRIdc8G4mpHtyjgOxQkN9/b39+/739o+p3zc9kVFEhFx3RP4XvQlEaZ/LkyVx77bUNiuD555/njTfe4LrrrqNDhw5s2rSJsWPHctpppzW5niQ7O5sXX3wx7r7GOPfcc7nllls444wzqKqqIhze/UWIzUUVgRJHZU092ypro1IzPDR7Bd0Lshq9b9zALhw9pBv5WRnc+u8v2FhezW8njUxYX0SYfuURLSa3shfQyMg9VRx44IFs3LiRtWvXUlpaSqdOnejVqxfXXXcds2fPJhAI8O2337JhwwZ69uzZaFvGGH7yk5/E3ZeI8vJyvv32W8444wzAKpK2QBWB0oAxhq/WbeeqZz5jRWn0it3HP4zeEevsMUWcPaYPZ/0tkme/Y24mGcEAx+7bg2mXFrB6cwWjiuJ3olKU9sZZZ53FtGnTWL9+PZMnT+app56itLSUefPmEQqFKC4uTmpPgkT3ZWRkRI303bbaS9JPDYxTALv591XPfMbJ970fpQQmDOvOHafuR4Znxe0D5x7EnaePYGC36PTI3sRpfbvkcuTgbqkXXFFagMmTJ/Pss88ybdo0zjrrLLZt20b37t0JhUK8++67rF7d+NagLonu69GjBxs3bqSsrIzq6uqGiJ8OHTpQVFTESy+9BEB1dTU7dyafJLGl0BlBmrJ1Zw0H3PkWv/ruCGrrwzw0e0VDMjYvB/XtyIWH9+d7Y/ow/OczOP2AfThxpM3Nnh0KsurukymvqmXGwg0M7Oa/N6uitHeGDx9OeXk5vXv3plevXpx77rmceuqpjBkzhgMOOIBhw4Yl1U6i+0KhELfffjuHHnoo/fv3j2rviSee4JJLLuH2228nFArxwgsvMGDAAN/2jzzySBYvXsyOHTsa9jc44YQTdvv9634EaUZlTT1hY3j1i3XcPG2Bb52TRvbk/aWbGN2vEw+cN7ohXn97VS3ZGUEyM3QiqbQcuh9By6P7ESiNMuEPs3xH/gD79+nIc1PHJlyolcpVvIqitB2qCNIEd+aXSAmEgsK0S8cRCupoX1Ga4osvvuD888+PKsvKyuKjjz5q120nQhXBXs7y0h0c+4f34sovPqI/7yzeyIpNFUw+uA8/O2U/VQJKm2GM2aU9H9qKkSNHpmwPgt1te1fM/frL3wv5dmsl3/nje3y+Zitvf+UfwzygW37D6t2RRYWtvlm2orhkZ2dTVlbWbkIp92SMMZSVlTV7PYL++vcSjDGsLttJcdc8nvv4G77esIPv3v8/37rXHTeEcw7uQ3lVLR+uKCMrQ/PtK21HUVERJSUllJaWtrUoewXZ2dkUFRU1XdGDKoI9mK83lDO4ez4iwhtfrueypz5lyiF9eObjNVH1jh7SjZ+fuh/H3fseYQNXTRhEICBcfOQAunfI4pRR+7TRO1AUG1rZv7+mGWlLVBHsLvV1EK6FQAiCjXyclVugajuIQIei3U5yP2dFGZMfmsNdZ45kyiF9G/bujVUCJ43syb1nH0B2KMhb1x/NitKKhu0YgwHhjAObN3JQFGXvQxXB7vLIsbDuc9jnQJg6y79ORRncuy/UOztujb8Vxt+yW4918wDdM2MJA7rmMWPhet961x03pCEcdGC3/LjVwIqiKKoImsuK9+CzJ6GwN2xeYZUAwNrPEt+z8SurBI64DuY/C6WLd/nx5VW1/OTFL3l5/loAyipqOOehOXH13rnhaL74dhuDureDjt8YeOdXMOaHUKgzEEVpb6giaA71dfDq9VC2rPF6FZsglAuhHJtbfcW7tnzMRbDmEyhfbzvHdfOhvgaCmdCxL2RkQWZ8moZ12yrpVWhz9988bQGvf+k/+geYetQAThjegwHd8hkQO/ov3wC5naFmB1RtA8Q+b8dGqK2EYAjyu8PWb+xxhyLYuQnqqqFDb9iyCvK6QiAIBfvAhi+t3CKQ08k+wxgoXwcdPH6H9V/Af++BVe/DRTOa+JAVRWltVBE0h+lXNa4EjAETht8PhEHHwSGXwNPfs9eyCm1nWtATvp0Hi6bD8z+Ivr+wL1wXvSnHv+aVcMML83nx8sM4sG8n3l8avRlMp9wQW3bW8tzUsXTOy2Rwom0Va6vgr2OsSWrGT5r7zuMpOhhKPomc37HNvn78MLx+E1z2IfTYz5aZevtaV7n7z1UUpcVRRbB5JTx+GoTyoGIjdPbZGaimAipK7fXGeOQ4CNfZ42Vvw8ZFVgGc9Rh06mcdxAU97Yj79Vsgtwuc8seIQtgWv7Xj7KU2pG55aQUH9OlIXTg61nrOT45l3dYqirs2kfBty0qo3m5nIU1xwLmw4LnIe/HDqwS8LHjWvj5/Plz+UWIHevl6mPFTOO0+31mQoiitR0oXlInIRBFZIiLLRCTOOyoi/URkpogsEJFZItL6BuR3fmk75tJFsLPMjugz86L/Ni70VwJjL4d+h0N+D+gzFrLyIceTfz+vGxzzExh8HHQdbMv2+y4MGA/dhsAxP4VhpwCeFZWrP4St3xAOG65//nM+Wbm54VLJlkoqa+u55cRhzLpxPG+eXUDWxi8oDq+xpp1NS60C2uSZtezcbH0ZX7xgz1e93/RnMnACdGpmON+il21k1FZHmZUtgzn3Q7jezpRimXknfDkNvvx3856jKEqLk7IZgYgEgfuB44ES4BMRmW6M+cpT7R7gcWPMP0VkAnAXcH58aynEtW27TH4aCnpEl91R6H/vmB9FOngvs+6GWXfB+S9am7yXPgfD+TGdXyAYGX3/fSIAG6/bwL8//bahyo0vREbyQ3sWULztI5h+RqSNoSfD8plQ5+QSck01fzsCtkfaiTpOROcB0GUglC2NLj/gPPj8Sf97njsPDr3Mzpxc3rrd+hcGHRtfX1eRKkq7IZUzgkOAZcaYFcaYGuBZIHb35/2Amc7xuz7XU09OTEed373x+pMehVtL4JoF/koA4Kib4OaV8UqgGeyork147cA+HaFseXThklcjSgCgxtncIpmOP5a8bpDVIb78tPvgRo9yuHIeHHZ15HzjV/H3rJtvnewJcRTC67dY01pt07tAKYrSsqTSR9Ab8K5uKgEOjakzH5gE/Bk4AygQkS7GmDJvJRGZCkwF6Nu3b8tK6TowT/yd7fz8El9d+CpsWGjNLPt919q9sxI4ZcGO8HdDCQA8Pu1FuhNgI9EzlgkDcum4+NmIqScR20rgmw+aftCp94EEoMdwePgYW5bb2UYyeTnzEfu+vIqyU3F0dNDK+OR2BDNtZJRL5RbrO3GpdxTeRw/Y1x3rbbuKorQaqVQEfqkEY+0BNwJ/FZELgdnAt0Dc8NEY8xDwENiNaVpUyuodkNsVDr0kcZ3iI+xfqhh+RlzHfufGq7gmq4DR1Q82lK26+2T47Cn4z1VNt/nxQ/DJw9Fl/Q6H1U7+of5HwcrZMPqC+HtDuZDhUQQH/xhGfS++XjAD+o5z2jvaXxFkZEUrgifOhLWfwoiz7Hn19uj6OiNQlFYnlYqgBOjjOS8C1norGGPWAmcCiEg+MMkYsy2FMkWoLoe72n5x0/OfrKFw6J1c/8lEBsm3/Cfr9oZrXaQcgDtPH85BfZ2ZQeWW5Br+Zg5k5MD1X9lReSjHjujB2ucbS/krEpkRfOfXcNiVievucwD8fCt8eH+CGUEoMuoHqwTAfv5g0254qUtCEdRWwt194YwHYcSZTddXFKVRUukj+AQYLCL9RSQTmAxM91YQka4i4spwK/BYCuWJZsuqVntUIiqq67j5Xwu45MnPqCCH+WYQy8O9ouqcE3yXyQd0Y0Rvx2FdsyO5xjd8CV0GWTNPVn5ECUDjSsDFVQTe0bzLxTPhh29Et5eVYAWzMf5tLHUWlq2bD197Fpm5imDZ2/F+EJfta22bM+9s/D0o6cXK2bBugTXjLn/Xv059Hcz7R+N+K2Pg86etKbi1CdfDB3+x0YOtSMoUgTGmDrgSmAEsAp43xiwUkTtF5DSn2nhgiYh8DfQAfp0qeeJwR6RtyKYd1XFlT9QfH3X+29DDZL4TmSUkLbcEYOD45gk07BQY5Dx/1DlO2cnx9YrGQL9x0WWZjiKI9S3UVPgrApflM+HpsyPnriJ4chL85SD/expb36CkH3U1dtb5z1PhwSPhofHwxHdteWy9z5+Cl6+BD/5sy8LheHPk8nfgpcts9J9LbSVUbrVKomqbvQ9aPvpt41fw5s/g2Skt224TpHRBmTHmNUkNMNwAACAASURBVOC1mLLbPcfTgGmplCEhbaHtY/BTBFVkxlfc4InGqanwb+zH79iwz98W2/Of78L7m/xU5LjniEgIajK4zvOgxyfQ6wA7g2lOx92Yj6BkHjwyAU66J/n2lL2b2ir4w1Co2hopc79/386DDr3gz/vD95+Hl6+Fcsc6PfNO2P/78Mp18PXrtmzCbXDUjbDaCbL4+EHY9xSrYFwycmyAybBT4MyH4DdOsMQ+B8HUBLMQN/x84ASrZIqPhFX/tW31PwrOfT5e9mRNwC1E+q4srnQ6yvG3RhyXrUhNXZi1WyOdXkFWBuXVdVQaH0WwfgFMu8g6Xj9/Kv46WAdvZhsmmHNXB2dkgjsQyyqApW/acFRIblXze3dDt6H+19wf7MKXdktUZQ/jq/9Afk/A2HUq+3o65lX/jVYCXl6cCtuc8OnPnogoAZclr0W+U2AXl2Z1sHmxXJ46O/oeN8pw80o7Q3BxfV+xuDMHsErAldlta2lM7q02Wl+TvorAtT+PuzKxfTuFXPH0p7zl2UbyZ6fsy0kje3HfXxdCrBugZoddhdsYoRzrmO07Dg6+uOUFbgo/05Bblkh5FfSyCeq8rP0MHjjcv344JmdRbMSR0j4J10dMflXb7Sg9Wepq4nNyuTPV7eusLykRWz0pW/xMqt4wZpfXb4p5foL8WOHaSA6tuGthqK2wA6HY73dThH3aNMb2AY2FrO8m6blnsTHwvz/Z41bOc7Ozpo79f/FmlBIAGFPcmYLsED89dWRyDd2xLdp0k2Gzk/KjN2Bk689wIoogFClrSsH2PwrOeCi+vDaB+cs1Mbnmo51lsOR1/7pK+2H61daE8shxcO8w6+xPlr+O8S/f+o1t66O/JdfOilnxZbU7k5cDrNnTpa7av9MG+N8fbUTil/+CP+7XvGf4KZf377XtVWyKv9ZCpKcicO3sIyYlF0HTAixcu40l68sZ+5uZbKuMXjXcMTfEADdp3M4yn7uTINS8zapbnIaoJM/nmYySbUpZeP0jxplme3/AfsnvqndY229lApOBsuvU18JrN9vReCI2LrYJBV0zh5uWxF157lUE9bXw0uXw0YPw/h/h0RNsziyXravj21/zCTw2cffeB5J8BJ5LXtfIcX1tYkWw2HGLzv1789r/4C8R/wTAm7fBqzdEouNSGOCSnqah0iX2dcAxKX3MvNVb2L+okMXryznlL/7J3rrmZzL3Z55IoX1PtXb1UefY6IaBE6ydc/0C2Pc0a9M84a5I/YvfgU//4Z8SojXp2NfmIjr0Ehu5AdZv0RRN+TVeuBDOecI6zzYstGVbVkau5zkrnTevgI7FNsPrZ0/C3Mds29/5ZXPfye5hjJWv84CWaW/zSrvSuiUGLNu+tZ1ZRlbTdcGaOLZ9E73Se9V/rRN162r4/nOR8rpqa78P5cL/cxIIHHyR//eyalskWKOi1JoOvebDJ8+Ea79IHBgx+/eJU6eE8hLPKL1kF9r9ORJx4PnWr+Alt0vkufXVsG1N/H1gMwxDtGkqGd78WfT5B/dFn6dw0JqeiuCRCfZ1N9NANMa81VuY9MAHfG90Ef+Z7z8V/tV3R/Cd4TEJ7rIL4ezH7bFf6GYsRaPtX1sTCMJ3748p9PniHnQBfPpPe2xM0zOCTUvg/kMSXw/XWr/CQ+PhxN/DoVMjs5Oq1lmbGMWnj8PLV8OPZkDfsbvX1vovbNLAphb1JYMx1kyx76lwToLEgbH89x5499dw1ac2CSGAOJ9tdcxo+qXL4/1Y9x3o3271dvidk932wlfjr5c7Gy89cpz//Ws+ii8be4XNdpvpowjcSB8v2YWwJn5nvwZO/6v1P3ht/LldIsf1tTZE1Q+3nt9sZndINANpAdLTNOQSm3CuBVldZr+ML8wroaYu7Ftn7IAudC9oY5NOa5Mdk8nV9W3sKjUVsOZje7zRmTG4DuvaNtgIZ72zsdDaz3e/LXfR4zctsLiozglVXvxa4/W8rHBWintH364PKHZtyJJmtOtV0N5stS5u235JDCHyXry4o2W/gYVfWez30I/YGa1XEfjJsPBFeOMnja+b8ePTx+G/f2i6XgrXz6S5IujUdJ1dZGdN09q7c55PqOjewMl/iB7pDfekgegy0JqRwP54uw6B/afA0JOa94wpz9kf6uoPrCkNbKI9iNh+d6y3oabe0ev2tTaMrzzxdp++rP4gOhTQpXx99Apot4NJ1WykvtbayJt9n9NxBZpjBHBDGT0zO7eTq4/pCAMhksbrX0jkAP0mZtSf7dnno7Gd7vzMkX6+Ku++IYmIXRwZNSPwUQQvXGhnJc215U+/KrlV8qoIUkRTKad3g8okFEFhTjN+PHsSB18cnaSv92hrEgIbDjje2SrTGJu47oy/wZRnmveMgROsD2Dle5EQwmVv2xGv2wmvnA0vXBBt6713X3jiDLsIKVkWPA9/PxG+eD7+2h+GRq+AznZs4qkKbX37Dnj0uGgnejK4I1hvqpGmcJ29Xtu0G7EVu2o30U50fqz3bMfqNyMAeOw7keORZ1tTTSL6HxU59lN0fn6oZGYEsTb5ZO6B5juhk0UVQQsjQTj00pT6CCpqIv+0gmz/H0kw0DoRS22G2ylm5kZszPU1ds0DJP/D8iMYioz0Rl8YKd+yMj6RXXNH/7F89R/7msxIz431TtWMwI2SSrSIKhFuHL8koQgePArmP9t4O/XVds+LP+9vTUixo+fG2Lwicryjie1fATCJTYhT34PzXox02n5y+CqCJGYEsT6uzCSCHyDef9JSpFARpJ+zuL7Oxup6p3ktwM6aOq5+5jN+eHh/lm3cwdINkS9DeVUd/7psHF+tK+e2l74E4NrjEmxqszdx+DW2wz7wfCf5XK2NJAlmwnF3NL3w7YKXo5f3e/GO1rz7TM/5G+R3i65budl2VrErm5e8blNzZ8dEtmxfazur4iPs1p5ulNnyd2HICRHTlq9cztgqVTMC1zTTHFMMREbwgSbGfvW19nN68ZJIinFv9tg6z4ygbKn1Y7x6fbRTNXahYFYhVDuKMZRrt4V12bYGug61QQGJMCYyeIglMz96NuKrCHxMQ0nNCGI+q1CSa45SNiNInbM4/RSB+0XO2D0nbThs2FZZy/vLNjFhWHdemLuGtxdt5O1F/iOc0f06M7pfZ56as5rvHtibS48e6FtvryKUA0feEDk/6sbI8RHXNX1/38OaqOCYLrwzu23f2D8vOzfDvy6KN0M8MxlGTYYzH4wu/8fJVhHcvtkeuyx51f755WByU3u7o7aWGBUaH5+E2yn7XWsM93vflI/Ab9bjdX667WwviXSUZcui68eOwA/5cSRtQ2Z+9DqQzSugQ2/rr0sUxWPC0QsVvTSUS8y5h9EX2OSGXtwZQa8DYF0Cx37shD3ZGcGurgVqCp0RtCAtpAjueXMJ/2+WdRKecWBvNlckFynwxrVHNV0pXSnYJzofTFN2Z/fHHBv9dcs3toN5aLw937zCKoFAyIabeomN9b7voIjporSRUSpE54Wpq7KKryErZQuM3mLt8JDYWdtkW079pkxDf/KsbHffnzdCxpsU8JXr/duITYVQ2DtyHBtRs3kF9NofvvePxHuDm3D86NzF7filEUUw6DjoUGSVl4s7C2x0Xw7PM8+dlrwTOJHfY3dRH0EL4iqC3VyJ++JnkZC6lZsqmLsqOtvnr88YsVvtpyU/nmmzRF78Dlwyu+n67kzAz6nXxWN6c8MQe/r8TyRgV3B+6qzd2OyJACr52P+5xsCOUvjfnyNl7gzA/bGumBWJYkqWLavhC08svl9n73akddU2kik2b70xNt9+RcyotL4JZ/H856xJLMqsYaKfCdEbByX6fLzhmsVHRgIFwL8zy+sWXxaFwX/DQ+JNQbHn5zzlbxpqmLU05qfzXJNAq6ejiUMVQQtS2zIzgtr6yNT88zVbqYiJEvr+IS28t3I60GEfa4MvGm1HiU0x/lbb6ff2yUeTlQ89R0WX9fNJZrf6fbuCc/pV8Z3nmgQd3Y6N8M9T4O2fR8qqt9tO2Ptj/fuJjcsfG4764JHWhNWQXM8nJbc7S6irsu3/PSbVwtpP7Yp0b/I0YyJrKlzTkDGR5+8otZk6n/2+v5x11da3VrU9ItO+CXw3EL2a+NBLo5XPaffF13dX4ibChKHbEP9rDaYuiTl32PcU53Ks4zfPv9yLd0YQyEhupXwqaWwznd0k/RTBbpqGXvtiHXe9vsh3kdjJIyNZFaWVchilNX0OsWagWOewy6X/jaTjGHFWdKoEP8qWRp/7rWAFaxMvXRxd9peD4MVLoxVBYykGlr8Ld3aKdmC7kUY1FdYX8OoN8fd5ZwQuXhPVZif9htfB+9eDbdoGiHRub/7MPv+r6XDPIFsWm5vJbbe+2iq+3xbb9oOZ1oyXCK+PINZMNGKS9bFc6km50mVQ4rZcObIKYOJv46+5MwD3f9uxT3wdID4CKD/SdiK8v+FAMHkfQarQGUEL4oYCNkMRvDB3DXe9biMdLn/qUx58bwV14fgv0I+O6O97/+M/aiRFgpJavGaKRJEnLo+dEH3uOkEPuxqKPP/D2b/3v3/Bs9GmJbDft3C9XXE67x+waRk88/1IeoIHj4rvjJ6ZYrdK9MPt4L2KwBse65qjOnjs8l4FV1cNb/0cPnTi8j/0pAXxfj4SoME09OqNdnWzqbfKLSOn8VF8ViOKwK88GUUA/it2XZ/A6AvhvH/ZNQd+xDl+nRlBo74cr2komHzUEKQma4E6i1uIumqY/Tt7nCgKwYebpi0AYFN55Ivot3K4f9foL8rfLzyYqtp6jhrSlA1UScgxP7X/N+9mIX4c+3OY+Qubb8jLvqfadMATfmpzErn0P9quOdj6DQyZCF+/QULGXWlDYF+5zpqSSuYmrvtZTB6f539gV1nPcTrc/J52xbOXrd9Ed3Kr37d/LiZsV+OGsiO2fq//oGJjJMf/DieRWqLEcjvWR1KwQ3SYp9eE41VO3s5y5ybbifc/2r99iLalJ0qG6C3v2C9xW1YA+7L/ZHjrtuhLrilIxDqFvYvVGsNVeo2FZO7OjCC7MLL5VUuhM4IW4l+euPUYe98Ds5Zz0wvRceYzF22g+JZIqoR/fZrY+ffujePjUkYcM6w7J3rMRcoucPTNcOxtsE+CBGYuR15vTQ6HTo0uz+kEP/iPzQbqzgKHnAgXTI84MXO7wtH/F31f9+HRbXQbAj981a6NqGlmCgHvngmxSgDgz6MS590Hm8fn3mHWNOPOBLzhqV7bsbuYzs+/4Ic3MZrXvh4I+ptNtq6xs4FGEx16OtBEM4Io85FzPHCCf93ezsrt/O7xCijWBJtwfVBMPdek5Ne5NiipGEXgzghCeTYKqTGau+AvGXQdQQuxaLp9LToY+h7aUBwOG377hrX5/v57ESflX96JiY9OwIe3TqBXoR1h3Hn6cDKD6aVfW4ULXrZ5aTKyojcIaQ4NoZNOB+cuKgoE46fyhb0jSewyPArezzwQyGh8tPb1jMTX/MjMb2RRkiO7d2TshsSWLY/k/m/upisQPWMK5fmbTeoqk3PuuiRSBBk+C7/OeQrmP2MXqLmc+69oBdFUiowO+8AVHzeesRY8TvMYX98Fr0APZxDgdRaLZ0Zgwk0vzEvFnsM6I2gh3LjzSY9EFX+7NZLEqviWV/ndG4s57K6ZfL4mOa3uKgGAH4wrZrJGDLU8WQXQub/9oeft4qpw94ft/vjdEVYgIz4BYX5MenAXP/NAU6vUy5bCYVc5++4mQVO+jFg2LrIj9Sc9yf1qk5wRQPye3cVH2pXA7v4PYGdRLq4iuPA1uzBw4m9tuO4gZ18Nb4flvpfJT8MJv2lcjsxca/4ZdU6kbJ8DozvdU++DA89rvB2/Pa9jZw5dBtmV7Wc/Yc2KLoVF/mHJgaCdUY670s4Mk0nV0dKoj6AFqK+z07Xxt8ZFj6zcFJ2/3F0o5uXuM0cSNpCXFeSaZ+1KxIfOH82Rg9X+v8fg/rBdReCGqA44Ov5HliiYwC+EMJmNXooOgTE/Spyj30tzZzyvXBtf5s4I/Mw7satpD/qBTd7nLoQaMtFuQOP6LYqPtCY6d6P3Qicyp/hw+wcw9lL4+GFY9pY1S/UZa1cKu595or01usZ02pl5cOZD1jzzycPxSrFjHzj9/nhfTJPEKIJAwGbJBeg+zPqXIHrGETsjEIETfh1fr7VQRdACuNNnnx/tqrLGdzSaduk4RhYVkpVh//lzV23hiTmr2adjDjmZbfCFUHYN1y7sdvL9xsENX0NBD1j0cnTdRCtZXUdodmEk3DOZCLQug5Jwijrkdnb2ADBw5sM2YV/l1ugRf1PUVdkQVTcEddRku7Bu/QIYeAyc7yRqK18P3YZFr4b1bsl44Hlw8r3R20ceeqn/M11TmwSsKa+pnDu3fJM4Wd2Jv7WDtpYK2WxqAySXqJF+zIwgYT3sjCg2/LilUUXQArhmAJ8p3YrSeEXws5P35Vev2pDRMcXR9uM7Tx/OBYf1Y1D3BPZPpX1SfCQcdRMcckmkrMAxAQ2ZCGMugk1fW7PQgefZdQqxJiN3RtB1SCQTaDIzgm5DbWdy1E2Jw087FNm8OKPOsesSwnU2oV7v0f7pJhpj2dvW5OWGs/Y+KLIuoseIiPkj9v116g/Dz4DXb7aKrmOx45fxRNklWpU//AyrbA6/xvoAMpoIoWws8Vsg2LgJ8EczoveBaIrJT8OC5+xn2Zj9PmpG4FUEGYnrgV0dnXJFoM7i3cc1B/iM9GJNQyeN7MlFR/RvUASxiIgqgT2RQAAm/Mz/WjAEp9wbXdZrVHw9VxG4s4CDL47Pauri7nt7wLmRjuOI6xMrgkDQmmAg8j11O92MTBsKu+hlOOkeeO1G/za8eENiQ7mRSKJEDlyAiXfbjj+UZxWBm5MnmXDrYMhmlW0N+o5t3lagHftaJdwUkkARxPYbsQPK5uzHsKuos7gFcCMgYjT5H95cwntfl0ZF+hwztHvDyuC9dhcxZRdxbO7BENy+xXbKhQlWs7r2ba+dOzPXZjX1I9YmDdFmp+/9E25e6Z8q46zHGhc7My+iCPzy87u40Tyxe0Y0N+31noq3f8jr7l8OkXUbDddjPp9EpsXdQRVBC+DmVXF+YLX1YW54fn5DiOijF44hz7H3ZwStEvjkp8fx7o3jW11UpR3j/hgDGXaGIQKn/skqhFjcWWiswzORo7HzgMix25F4FUEgaE06fsnP3L0DAH78bmQldH4POwsZOCESSdRY8jTXUe2u9nXfb3M2ntmT8Xbg3hli7AzgjJjU5d4Z0wWv2BDWlubdX0eH+LYg6aMI3BmBM9L/ekN5wwKxi47oz5GDu/Hezcfw/UP7cuIIq+27FWTtvdtJKrtGrwPsq9fPkF1oc+7H4i7+SrS7FkR3sMf8NHIc8JkRuLhbrHrNXB32sU7fsVdYf8BxdwBiwx2P+7ndozcZ05Dr7xjvLLDr46y3acZK/D0aryLILiRhMrvY3Q3d6/k9oP+R0DUFG0/V18DaBHsn7Cbp5yMIuDOCSFhdtwL75e+an8VvzhgZd6uiNNChl//GNL51nXw/je1olt/D7tK1//ejV+t238+GX/otvArlWBkqyuCdX0XKr/AkySs+3JqgohY+Od/5xkxDrmLqPTr6faaLIkg0W/MrL+wb2QSptT6f5q4xSZL0mRHERA1tr4xkZ+yWv4srVRXFy9We0dr3X7CO37Mes87iWC770GbgdBdnxTobpzxjV9U2NnpvqvNJtPq1sVDKRBFQaWMaSqAI/Gz+F78Ng0+Ivp4om6k3bfe1SeZD8iOZCLVdIH0UQYyzeJtHERR1So2WVdKMzp7ss0O+Y79rIyb5d8g99oOeIyMrmGOdjbmdYfBxjT9vV0ehjeXVT9Thp6OzuKnygh7Q391xsIm0826ajJzOjc8Qm6IxM+NukFJFICITRWSJiCwTkVt8rvcVkXdF5DMRWSAiJ6VMmIYZgX3LriK4/vghHNI/BSljFSUZ3BlBU3sJ+9HcUbrrAG5sr4xEI86mcuvsLcTOCNzPqqmUEm6Yb1GC5IEtlZIiRTOClPkIRCQI3A8cD5QAn4jIdGPMV55qPwOeN8Y8ICL7Aa8BxSkRyERHDbmKYOpRA3QTGaXtcE0/uzK6b26ag4veit67wI9dTejX3rhm/q4p11iF55p6mmorqwNMnWUXGvq228z/1Q/+A4+fHl+eIh9BKp3FhwDLjDErAETkWeB0wKsIDODmfC0E1pIqPM7i95du4t63vqYgO4PskKaIUNqQ5mx2srvkdo6PdonFzzm9J9LUbnTNJZmOvLFU6bGZb5ui/9E2GWDZsui8UHugj6A3sMZzXuKUebkDOE9ESrCzgatSJo3HNHTeox9RHzZcctSAxu9RlFTj5tLxbi3ZluwtM4KWwk2Wl9CJnKQ1wbtXdDKIwFmPenwQDinyEaRyRuD3CcV+ClOAfxhj/iAi44AnRGSEMdFJwkVkKjAVoG/fXXS0OM5i4/H+TxiWINWwouwqN69sXn13nYDfNoxtQbqEiSbLpEdtQr7d9ZG0lI9lT/MRYGcA3rX3RcSbfi4CJgIYYz4UkWygK7DRW8kY8xDwEMCYMWOSVKkxOLplp7NQcnD3fPbtpfmClBamKdNLLK7Dt70ogsZGuBPvhu77tp4s7YFQtk19vbu0lLN4D1xH8AkwWET6i0gmMBmYHlPnG+BYABHZF8gGSkkFjmloW5VVCFdOGKROYqXtaQlFUNTEblwtxdjLYMD41nnWnkJvJ0qo+MjG67XU/gV72ozAGFMnIlcCM4Ag8JgxZqGI3AnMNcZMB24AHhaR67BmowuNSdaI1lyBXEVgX3URmdIuyNhNRfCTdWrOaUv6Hmr3VWgspTZ4oo6S6N5+6MkaG1t/D/QRYIx5DesE9pbd7jn+CvBJpZgCnKRzriLo3kEVgdIOaJgR7KKzuKU2bpn6HpQuaZm20o2mlABETEPJOOPd1N9+7IFRQ+0Lx0ewtWFGkMSuUoqSatyOoa19BPscAPuf03S9vZWRZ6e2fddZ3Fjm14a6jczwUmTOTiNFYBXAlsowmcEAHXLSJ9+e0o7J6Whfc7s2Xk9JLZMeTj6Z4K7gzghi8zz5JQD0M/Udf2dK5Uuf3jDsKoI6uhVkqaNYaR/0Hg2n/7/opGTK3ocbtu52/D9+15oDC3rCi5fCNx9E6raBzyd9FIEzI9haWU+X/L1k9aSy5yMCB/pkJ1X2Lty9KVzTUO+DItcGHx+jCHz6pxTF0Lg0qQhEJAuYhM0B1FDfGHNn6sRKAY6PYFt1mE6FqggURWlFanbYVz8fgZt40MWb18jdBrXDPqmRyyGZGcF/gG3APKA6pdKkknDEWdypl4bbKYrSitRU2Fc/n8D+UyC7Izx/vt0a1DsjOPjHNm31kIkpFS8ZRVBkjEmtFK2BYxraXh2mV67OCBRFSTFH3wLv3Q3jb4WhJ9o9qQ+/Nr6eCAw7KWL+8foIAgF7b4pJRhF8ICIjjTG7sa1OO8BxFpdXh+mkikBRlFRzzK32z+XqJjae738krJjVJpsAJaMIjgAuFJGVWNOQAMYYMyqlkrU0jo8gTIBOeWoaUhSlnXHOU7CtpE02AUpGEaR+XtIaOKahegIU5qgiUBSlnZGVD92HtcmjEyoCEelgjNkOlLeiPKnDMQ2FCZCVkT7r6BRFUZqisRnB08Ap2GghQ/T+AgbYs3Z1aTANCZmqCBRFURpIqAiMMac4r/1bT5wU4iiCegKEgqoIFEVRXJJaWSwinYDB2P0CADDGzE6VUCkhHPERZKoiUBRFaSCZlcUXA9dgdxj7HBgLfAhMSK1oLYy7VSUBQmoaUhRFaSCZHvEa4GBgtTHmGOBAUrWLWCpxZwRGZwSKoihekukRq4wxVWDzDhljFgNDUytWCvD4CNRZrCiKEiEZH0GJiHQEXgLeEpEtxG9C3/4xkfBRnREoiqJEaFIRGGPOcA7vEJF3gULgjUZuaZ+ENXxUURTFj0YVgYgEgAXGmBEAxpj3WkWqVOBZWazho4qiKBEa7RGNMWFgvoj0bSV5Uocn15DOCBRFUSIk4yPoBSwUkY+BCrfQGHNayqRKBQ0pJkR9BIqiKB6SUQT52FQTLgL8NjXipJCcjmzO6UddVVBnBIqiKB6SUQQZsb4BEclJkTyp46Af8FjpodTOWkYwoBvXK4qiuDSWffQy4HJggIgs8FwqAP6XasFSQU19WGcDiqIoMTSVffR14C7gFk95uTFmc0qlShE1dWH1DyiKosTQWPbRbdhN66e0njippbY+rKGjiqIoMaRVr1hXb8gIqn9AURTFS3opgrAhow32A1UURWnPpFWvWBcO64xAURQlhjRTBIYMDR1VFEWJIr0UQX1YTUOKoigxpLRXFJGJIrJERJaJyC0+1/8oIp87f1+LyNZUylMfNrqYTFEUJYak9izeFUQkCNwPHA+UAJ+IyHRjzFduHWPMdZ76V2F3P0sZdWFDSH0EiqIoUaRyRnAIsMwYs8IYUwM8C5zeSP0pwDMplIe6ep0RKIqixJJKRdAbWOM5L3HK4hCRfkB/4J0E16eKyFwRmVtauuvbJduoIfURKIqieEllr+g39DYJ6k4Gphnj7B4Te5MxDxljxhhjxnTr1m2XBaqr16ghRVGUWFKpCEqAPp7zIhLvdTyZFJuFwAkf1RmBoihKFKnsFT8BBotIfxHJxHb202MrichQoBPwYQplARzTkM4IFEVRokiZIjDG1AFXAjOARcDzxpiFInKniHh3N5sCPGuMSWQ2ajHUWawoihJPysJHAYwxrwGvxZTdHnN+Rypl8FKv4aOKoihxpJXBvC5sCOrKYkVRlCjSqlesC4cJqWlIURQlivRSBOojUBRFiSO9FIGGjyqKosSRVr2izT6qMwJFURQv6aUINPuooihKHGmlCDR8VFEUJZ60UgTWWZxWb1lRFKVJ0qpXrAuHdUagiCgt8wAACyJJREFUKIoSQ9oognDYEDaoj0BRFCWGtFEEdWGbykijhhRFUaJJG0UQdnLaiagiUBRF8ZI2isAloIpAURQlirRRBO6MQC1DiqIo0aSRIrCvOiNQFEWJJo0UgesjaGNBFEVR2hlpowhM2L7qjEBRFCWatFEE6iNQFEXxJ/0UgWoCRVGUKNJIEdhXVQOKoijRpI0iMOiCMkVRFD/SRxFo+KiiKIovaaMI1FmsKIriTxopAvuqMwJFUZRo0kcRhHVBmaIoih9powjUR6AoiuJP2iiCyDqCNhZEURSlnZE23WJDriFdSaAoihJFGikC+6qWIUVRlGjSRhGAGz6qmkBRFMVL2igCDR9VFEXxJ40UgS4oUxRF8SOlikBEJorIEhFZJiK3JKhztoh8JSILReTpVMkSDjc8L1WPUBRF2SPJSFXDIhIE7geOB0qAT0RkujHmK0+dwcCtwOHGmC0i0j1V8uiMQFEUxZ9UzggOAZYZY1YYY2qAZ4HTY+r8GLjfGLMFwBizMVXC6IIyRVEUf1KpCHoDazznJU6ZlyHAEBH5n4jMEZGJfg2JyFQRmSsic0tLS3dJGN2zWFEUxZ9UKgK/LtfEnGcAg4HxwBTgERHpGHeTMQ8ZY8YYY8Z069Ztl4SJmIZUEyiKonhJpSIoAfp4zouAtT51/mOMqTXGrASWYBVDi+NqINUDiqIo0aRSEXwCDBaR/iKSCUwGpsfUeQk4BkBEumJNRStSIYzRGYGiKIovKVMExpg64EpgBrAIeN4Ys1BE7hSR05xqM4AyEfkKeBe4yRhTlgp5dEGZoiiKPykLHwUwxrwGvBZTdrvn2ADXO38pxd2PQMNHFUVRokmjlcX2VReUKYqiRJM2isDogjJFURRf0kYR6IxAURTFnzRSBDojUBRF8SNtFEFkHYFqAkVRFC9powh0RqAoiuJP2igCXVCmKIriT9ooAnc/AlUEiqIo0aSPItDso4qiKL6kkSKwrzojUBRFiSZtFIHRGYGiKIovaaMIdEagKIriT9ooAoOGjyqKoviRNopAU0woiqL4kzaKQJPOKYqi+JM2ikD3LFYURfEnfRSBLihTFEXxJX0UgYaPKoqi+JI2isA0OIvbVg5FUZT2RtooAvURKIqi+JM2isDdj0AVgaIoSjRpowh0PwJFURR/0kgR2FddUKYoihJN2igCXVCmKIriT9oognBYncWKoih+pI8i0OyjiqIovqSRInCdBG0rh6IoSnsjbRSBaZgRtK0ciqIo7Y30UQSoj0BRFMWPtFEE/bvmc/LIXgR1SqAoihJFRlsL0Focv18Pjt+vR1uLoSiK0u5I6YxARCaKyBIRWSYit/hcv1BESkXkc+fv4lTKoyiKosSTshmBiASB+4HjgRLgExGZboz5Kqbqc8aYK1Mlh6IoitI4qZwRHAIsM8asMMbUAM8Cp6fweYqiKMoukEpF0BtY4zkvccpimSQiC0Rkmoj08WtIRKaKyFwRmVtaWpoKWRVFUdKWVCoCv/AcE3P+MlBsjBkFvA38068hY8xDxpgxxpgx3bp1a2ExFUVR0ptUKoISwDvCLwLWeisYY8qMMdXO6cPA6BTKoyiKoviQSkXwCTBYRPqLSCYwGZjurSAivTynpwGLUiiPoiiK4kPKooaMMXUiciUwAwgCjxljForIncBcY8x04GoROQ2oAzYDF6ZKHkVRFMUfcfP07ymISCmwehdv7wpsakFxUs2eJO+eJCvsWfLuSbKCyptKdkfWfsYYXyfrHqcIdgcRmWuMGdPWciTLniTvniQr7Fny7kmygsqbSlIla9rkGlIURVH8UUWgKIqS5qSbIniorQVoJnuSvHuSrLBnybsnyQoqbypJiaxp5SNQFEVR4km3GYGiKIoSgyoCRVGUNCdtFEFTeyO0BSLymIhsFJEvPWWdReQtEVnqvHZyykVE7nPkXyAiB7WyrH1E5F0RWSQiC0XkmvYqr4hki8jHIjLfkfUXTnl/EfnIkfU5Z8U7IpLlnC9zrhe3lqwxcgdF5DMReaU9yysiq0TkC2cPkblOWbv7Hnjk7egktVzsfH/HtUd5RWSoRPZm+VxEtovIta0iqzFmr//DrmxeDgwAMoH5wH7tQK6jgIOALz1lvwNucY5vAX7rHJ8EvI5N5jcW+KiVZe0FHOQcFwBfA/u1R3mdZ+Y7xyHgI0eG54HJTvnfgMuc48uBvznHk7F7ZLTF9+F64GngFee8XcoLrAK6xpS1u++BR7Z/Ahc7x5lAx/YsryNHEFgP9GsNWVv9DbbRhzoOmOE5vxW4ta3lcmQpjlEES4BeznEvYIlz/CAwxa9eG8n9H+ymQ+1aXiAX+BQ4FLsiMyP2O4FNgzLOOc5w6kkry1kEzAQmAK84P+52KW8CRdAuvwdAB2Bl7OfTXuX1PPc7wP9aS9Z0MQ0luzdCe6CHMWYdgPPa3SlvN+/BMUUciB1pt0t5HTPL58BG4C3sjHCrMabOR54GWZ3r24AurSWrw5+Am4Gwc96F9iuvAd4UkXkiMtUpa5ffA6wVoBT4u2N2e0RE8tqxvC6TgWec45TLmi6KIJm9Edo77eI9iEg+8C/gWmPM9saq+pS1mrzGmHpjzAHYkfYhwL6NyNOmsorIKcBGY8w8b7FP1XYhL3C4MeYg4ETgChE5qpG6bS1rBtb8+oAx5kCgAmteSURby4vjCzoNeKGpqj5luyRruiiCJvdGaEdsECc9t/O60Slv8/cgIiGsEnjKGPNvp7jdygtgjNkKzMLaUDuKiJtx1ytPg6zO9UJsNtzW4nDgNBFZhd3SdQJ2htAu5TXGrHVeNwIvYhVte/0elAAlxpiPnPNpWMXQXuUFq2A/NcZscM5TLmu6KIIm90ZoR0wHLnCOL8Da4t3yHziRAmOBbe50sTUQEQEeBRYZY+5tz/KKSDcR6egc5wDHYfe6eBc4K4Gs7ns4C3jHOEbX1sAYc6sxpsgYU4z9br5jjDm3PcorInkiUuAeY23ZX9IOvwcAxpj1wBoRGeoUHQt81V7ldZhCxCzkypRaWVvbCdJWf1gP+9dYW/FP21oeR6ZngHVALVa7X4S19c4EljqvnZ26AtzvyP8FMKaVZT0CO+1cAHzu/J3UHuUFRgGfObJ+CdzulA8APgaWYafdWU55tnO+zLk+oA2/E+OJRA21O3kdmeY7fwvd31J7/B54ZD4AmOt8H14COrVXebHBDWVAoacs5bJqiglFUZQ0J11MQ4qiKEoCVBEoiqKkOaoIFEVR0hxVBIqiKGmOKgJFUZQ0RxWBosQgIvUxWSBbLFutiBSLJ9usorQHMpquoihpR6Wx6SkUJS3QGYGiJImTh/+3Yvc6+FhEBjnl/URkppMTfqaI9HXKe4jIi2L3RZgvIoc5TQVF5GGxeyW86ax+VpQ2QxWBosSTE2MaOsdzbbsx5hDgr9h8QDjHjxtjRgFPAfc55fcB7xlj9sfmt1nolA8G7jfGDAe2ApNS/H4UpVF0ZbGixCAiO4wx+T7lq4AJxpgVTgK+9caYLiKyCZsHvtYpX2eM6SoipUCRMaba00Yx8JYxZrBz/n9AyBjzq9S/M0XxR2cEitI8TILjRHX8qPYc16O+OqWNUUWgKM3jHM/rh87xB9isoQDnAu87xzOBy6Bho5wOrSWkojQHHYkoSjw5zu5mLm8YY9wQ0iwR+Qg7iJrilF0NPCYiN2F3w/qhU34N8JCIXIQd+V+GzTarKO0K9REoSpI4PoIxxphNbS2LorQkahpSFEVJc3RGoCiKkubojEBRlP/fXh0IAAAAAAjytx7kkog5EQDMiQBgTgQAcyIAmAuR7EkhmLKBZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.5258158 ,  0.7512111 , -1.6176167 , -1.2120553 , -0.43434674,\n",
      "         1.7929729 , -1.3028594 , -0.53494656, -0.93162704],\n",
      "       [ 0.00486184,  2.264636  , -1.666974  , -0.35257047, -0.31253713,\n",
      "         2.419005  ,  0.7649636 , -3.3618329 , -2.06478   ],\n",
      "       [-0.12173834,  0.53659   ,  1.4628364 , -0.3293292 , -0.8125591 ,\n",
      "        -0.86116683,  0.8001096 , -0.38993713, -0.9389843 ],\n",
      "       [-0.02106684,  0.27245805, -0.4095522 ,  0.9461973 , -1.0870667 ,\n",
      "         0.17185646,  0.6918251 ,  0.19359648,  0.667095  ],\n",
      "       [-4.0050564 ,  0.3285139 ,  0.30702436, -1.9746796 , -0.8437208 ,\n",
      "        -0.7576544 ,  0.5725485 ,  0.36492938, -0.26690194]],\n",
      "      dtype=float32), array([ 0.29762268, -1.0011543 ,  0.2023002 ,  0.20757166,  0.6108017 ,\n",
      "       -0.10912645, -0.4810885 ,  0.51580876,  0.4634142 ], dtype=float32), array([[-4.9334106e-01, -3.4537694e+00,  3.0799047e-03, -2.9132038e-01,\n",
      "        -2.7020553e-02,  1.2756766e+00,  3.9851182e+00,  2.1080067e+00,\n",
      "         1.3788030e-01],\n",
      "       [ 8.8237190e-01,  8.4977973e-01, -1.3721247e+00,  4.5297068e-01,\n",
      "         1.7289754e+00, -7.3648453e-01, -3.1484811e+00, -7.6558790e-03,\n",
      "        -3.0031173e+00],\n",
      "       [-9.7385132e-01, -8.7899280e-01,  5.8090138e-01, -4.3220224e+00,\n",
      "        -2.4044826e+00, -1.2798082e+00,  6.9382977e+00, -5.4137931e+00,\n",
      "        -4.9442828e-01],\n",
      "       [-9.6772385e-01, -3.1373668e-01,  4.2485261e-01,  2.5889027e-01,\n",
      "         3.9652660e-03,  2.5171087e+00,  1.8348790e+00,  2.8934960e+00,\n",
      "         3.2215706e-01],\n",
      "       [ 5.2696943e-01, -5.3830200e-01, -1.3176343e+00,  1.6159275e+00,\n",
      "        -5.9531122e-01,  7.1289462e-01,  1.0378881e+00,  7.8302306e-01,\n",
      "         6.5632331e-01],\n",
      "       [ 7.5906992e-01,  3.1646285e-02, -2.8865439e-01,  5.1354015e-01,\n",
      "         4.9286952e+00,  3.9492124e-01, -1.1557803e+00,  5.8693051e+00,\n",
      "         5.5183566e-01],\n",
      "       [-1.5927140e+00,  7.5501865e-01, -1.5020441e-01, -1.9966716e+00,\n",
      "        -2.4280784e-01, -7.4326611e-01,  2.1407889e-01, -1.3292502e+00,\n",
      "        -1.9946607e+00],\n",
      "       [ 2.4294452e-01,  1.4603480e+00,  1.3810822e+00,  9.6454364e-01,\n",
      "        -1.6337678e+00,  2.0963836e+00, -6.2800395e-01, -1.7529294e+00,\n",
      "         2.0093615e+00],\n",
      "       [-9.7937232e-01,  1.3989785e-01, -3.7019018e-02,  2.9063234e+00,\n",
      "        -7.8392202e-01,  3.1146634e+00, -1.6976901e+00,  9.4702131e-01,\n",
      "         1.3914423e+00]], dtype=float32), array([-0.33185875, -0.21545827,  0.44314712, -0.78865564,  0.03693524,\n",
      "       -0.0136522 ,  0.86865276, -0.1411518 ,  0.75329673], dtype=float32), array([[ 0.58468264, -1.2144263 , -0.33609024, -0.4725084 , -0.22779849,\n",
      "        -1.2975497 ,  2.610445  ,  1.3188217 ,  0.10827389],\n",
      "       [-0.8523826 , -0.5447596 , -0.81069696, -1.2307018 ,  0.4065548 ,\n",
      "        -3.3807678 ,  3.3581784 , -0.38153052,  0.5984313 ],\n",
      "       [-0.7572848 ,  0.15648937,  0.25263008, -0.5932738 ,  0.14112668,\n",
      "         3.1074462 , -3.9199917 , -0.9774876 , -0.04665953],\n",
      "       [ 2.939642  , -0.03572326, -0.21705717, -0.7878073 , -3.1273227 ,\n",
      "         0.08871812, -1.0054504 , -0.5893904 ,  0.24273747],\n",
      "       [-3.309157  , -3.59595   , -4.1332316 ,  1.75363   ,  3.9200227 ,\n",
      "        -0.32177746, -0.3131652 ,  1.7885017 ,  0.22966321],\n",
      "       [ 4.1378455 , -0.322436  ,  0.38981053,  0.3358085 , -4.204344  ,\n",
      "         1.311228  , -1.1980945 , -0.936795  , -0.9886245 ],\n",
      "       [-1.2588971 ,  1.6205689 ,  0.6024543 ,  1.153874  ,  1.2206823 ,\n",
      "         1.1343733 , -0.12918198,  1.1710371 , -0.60273737],\n",
      "       [-1.4749792 , -1.955006  , -0.64708334, -1.0562843 ,  1.3063939 ,\n",
      "         1.2209971 , -0.20811294, -0.24022314, -2.6928663 ],\n",
      "       [ 1.4633614 ,  1.574642  ,  1.7874409 ,  2.6017594 , -0.7789161 ,\n",
      "        -2.241655  ,  3.3913627 ,  2.2676885 ,  0.8614566 ]],\n",
      "      dtype=float32), array([-0.5405643 ,  0.00275383, -0.21022046, -0.64496326,  0.42571995,\n",
      "        0.7528747 , -0.75320536, -0.01650837, -0.4936742 ], dtype=float32), array([[-1.9278855],\n",
      "       [-2.0513978],\n",
      "       [-1.8477043],\n",
      "       [ 2.788646 ],\n",
      "       [ 1.4387445],\n",
      "       [-2.2879186],\n",
      "       [ 2.450174 ],\n",
      "       [ 3.4069648],\n",
      "       [ 3.2343006]], dtype=float32), array([-0.9403449], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2516094e-07]\n",
      " [9.9689782e-01]\n",
      " [9.3458229e-01]\n",
      " [5.4217813e-05]\n",
      " [3.1583089e-02]\n",
      " [9.9999964e-01]\n",
      " [9.9910152e-01]\n",
      " [9.9999738e-01]\n",
      " [9.5749772e-01]\n",
      " [9.8916024e-01]\n",
      " [3.3008859e-03]\n",
      " [5.2252417e-05]\n",
      " [9.9999464e-01]\n",
      " [1.0216925e-02]\n",
      " [1.3019159e-01]\n",
      " [9.9949050e-01]\n",
      " [4.5265727e-02]\n",
      " [8.2252824e-01]\n",
      " [9.9971718e-01]\n",
      " [9.9991357e-01]\n",
      " [1.3681491e-04]\n",
      " [4.8895535e-04]\n",
      " [5.7522231e-03]\n",
      " [9.8847371e-01]\n",
      " [9.9517906e-01]\n",
      " [9.9818569e-01]\n",
      " [9.7150707e-01]\n",
      " [9.9412704e-01]\n",
      " [4.8311883e-01]\n",
      " [1.0000000e+00]\n",
      " [1.4779520e-03]\n",
      " [5.3134626e-01]\n",
      " [6.5334346e-03]\n",
      " [9.4629563e-02]\n",
      " [3.3503493e-05]\n",
      " [9.9975532e-01]\n",
      " [9.9493921e-01]\n",
      " [9.6898198e-01]\n",
      " [9.7326773e-01]\n",
      " [9.9973863e-01]\n",
      " [9.8640603e-01]\n",
      " [9.9834287e-01]\n",
      " [1.3076254e-02]\n",
      " [1.6932259e-03]\n",
      " [3.8647464e-08]\n",
      " [9.5079750e-01]\n",
      " [9.7890419e-01]\n",
      " [9.9997962e-01]\n",
      " [9.9535888e-01]\n",
      " [4.4633006e-03]\n",
      " [4.6527465e-03]\n",
      " [9.9886858e-01]\n",
      " [4.6593201e-04]\n",
      " [8.9070993e-05]\n",
      " [3.9262715e-05]\n",
      " [8.1602540e-03]\n",
      " [1.1054511e-02]\n",
      " [9.9982870e-01]\n",
      " [1.1501494e-04]\n",
      " [2.8059945e-01]\n",
      " [5.4544613e-02]\n",
      " [9.8833698e-01]\n",
      " [9.8825562e-01]\n",
      " [9.9997807e-01]\n",
      " [6.9272486e-05]\n",
      " [1.1214096e-05]\n",
      " [3.8224321e-06]\n",
      " [9.9999595e-01]\n",
      " [1.4455478e-03]\n",
      " [1.2700141e-02]\n",
      " [2.4308365e-02]\n",
      " [9.9999154e-01]\n",
      " [9.9955183e-01]\n",
      " [9.9931753e-01]\n",
      " [9.9846727e-01]\n",
      " [4.3431824e-04]\n",
      " [9.9975878e-01]\n",
      " [5.2608840e-07]\n",
      " [9.9309278e-01]\n",
      " [3.6783425e-05]\n",
      " [5.1425246e-04]\n",
      " [4.8312922e-05]\n",
      " [1.0000000e+00]\n",
      " [9.8565859e-01]\n",
      " [8.1981409e-01]\n",
      " [9.9965656e-01]\n",
      " [1.0000000e+00]\n",
      " [9.2790413e-01]\n",
      " [7.2200717e-03]\n",
      " [9.9639171e-01]\n",
      " [9.9926215e-01]\n",
      " [9.9966908e-01]\n",
      " [8.7569412e-03]\n",
      " [9.9976295e-01]\n",
      " [9.9993432e-01]\n",
      " [5.3658532e-03]\n",
      " [7.2212787e-03]\n",
      " [3.9652493e-02]\n",
      " [8.2890812e-04]\n",
      " [9.9910152e-01]\n",
      " [8.7749046e-01]\n",
      " [2.4437895e-07]\n",
      " [9.9987590e-01]\n",
      " [9.9881905e-01]\n",
      " [6.4195874e-03]\n",
      " [9.9999964e-01]\n",
      " [6.7226676e-05]\n",
      " [5.1274333e-07]\n",
      " [9.9976140e-01]\n",
      " [1.3986125e-02]\n",
      " [9.3577801e-05]\n",
      " [9.5478159e-01]\n",
      " [9.9919564e-01]\n",
      " [9.8555553e-01]\n",
      " [7.8998469e-02]\n",
      " [7.7145249e-03]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
