{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,5:6] #Leptin\n",
    "X2 = dataset[:,6:7] #Adiponectin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,7:8] #Resistin\n",
    "X5 = dataset[:,2:3] #Glucose\n",
    "X6 = dataset[:,4:5] #HOMA\n",
    "X7 = dataset[:,8:9] #MCP.1\n",
    "X8 = dataset[:,3:4] #Insulin\n",
    "X9 = dataset[:,1:2] #BMI\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "X6 = normalization(X6)\n",
    "X7 = normalization(X7)\n",
    "X8 = normalization(X8)\n",
    "X9 = normalization(X9)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X6 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X7 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X8 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X9 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 9)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "                                                                 input_layer_X6[0][0]             \n",
      "                                                                 input_layer_X7[0][0]             \n",
      "                                                                 input_layer_X8[0][0]             \n",
      "                                                                 input_layer_X9[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            90          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 280\n",
      "Trainable params: 280\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "input_layer_X6 = keras.layers.Input(shape=(1, ), name='input_layer_X6')\n",
    "input_layer_X7 = keras.layers.Input(shape=(1, ), name='input_layer_X7')\n",
    "input_layer_X8 = keras.layers.Input(shape=(1, ), name='input_layer_X8')\n",
    "input_layer_X9 = keras.layers.Input(shape=(1, ), name='input_layer_X9')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7, input_layer_X8, input_layer_X9], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7, input_layer_X8, input_layer_X9], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.7051 - acc: 0.5761 - auc_1: 0.5226 - val_loss: 0.6572 - val_acc: 0.7083 - val_auc_1: 0.6857\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6647 - acc: 0.6196 - auc_1: 0.6702 - val_loss: 0.6154 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6372 - acc: 0.6848 - auc_1: 0.7202 - val_loss: 0.5824 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6063 - acc: 0.6739 - auc_1: 0.7519 - val_loss: 0.5567 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5811 - acc: 0.7174 - auc_1: 0.7633 - val_loss: 0.5159 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5677 - acc: 0.6304 - auc_1: 0.7736 - val_loss: 0.5371 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5522 - acc: 0.6957 - auc_1: 0.7824 - val_loss: 0.5092 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5466 - acc: 0.6739 - auc_1: 0.7843 - val_loss: 0.5584 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5418 - acc: 0.7174 - auc_1: 0.7907 - val_loss: 0.5291 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5375 - acc: 0.6957 - auc_1: 0.7810 - val_loss: 0.5799 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5292 - acc: 0.7609 - auc_1: 0.8010 - val_loss: 0.5068 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5254 - acc: 0.7174 - auc_1: 0.8014 - val_loss: 0.5325 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5221 - acc: 0.7500 - auc_1: 0.8038 - val_loss: 0.5481 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5166 - acc: 0.7391 - auc_1: 0.8100 - val_loss: 0.6216 - val_acc: 0.6667 - val_auc_1: 0.8929\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5131 - acc: 0.7500 - auc_1: 0.8217 - val_loss: 0.4878 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5190 - acc: 0.7283 - auc_1: 0.8086 - val_loss: 0.5443 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5091 - acc: 0.7826 - auc_1: 0.8195 - val_loss: 0.5263 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5008 - acc: 0.8043 - auc_1: 0.8271 - val_loss: 0.4806 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5043 - acc: 0.7391 - auc_1: 0.8314 - val_loss: 0.6162 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5083 - acc: 0.7609 - auc_1: 0.8150 - val_loss: 0.5575 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4985 - acc: 0.7609 - auc_1: 0.8274 - val_loss: 0.6114 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5040 - acc: 0.7609 - auc_1: 0.8102 - val_loss: 0.5627 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4960 - acc: 0.7826 - auc_1: 0.8310 - val_loss: 0.5089 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4985 - acc: 0.7826 - auc_1: 0.8231 - val_loss: 0.5743 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4915 - acc: 0.7717 - auc_1: 0.8207 - val_loss: 0.5640 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4867 - acc: 0.7609 - auc_1: 0.8305 - val_loss: 0.5295 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4923 - acc: 0.7609 - auc_1: 0.8288 - val_loss: 0.5568 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4838 - acc: 0.7609 - auc_1: 0.8367 - val_loss: 0.5932 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4780 - acc: 0.7717 - auc_1: 0.8307 - val_loss: 0.6322 - val_acc: 0.6250 - val_auc_1: 0.8964\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4880 - acc: 0.7500 - auc_1: 0.8302 - val_loss: 0.5900 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4646 - acc: 0.7826 - auc_1: 0.8524 - val_loss: 0.6566 - val_acc: 0.6250 - val_auc_1: 0.8964\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4774 - acc: 0.7717 - auc_1: 0.8421 - val_loss: 0.5584 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4724 - acc: 0.7500 - auc_1: 0.8452 - val_loss: 0.5819 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4684 - acc: 0.7609 - auc_1: 0.8474 - val_loss: 0.5453 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4658 - acc: 0.7500 - auc_1: 0.8595 - val_loss: 0.5936 - val_acc: 0.7083 - val_auc_1: 0.9036\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4799 - acc: 0.7935 - auc_1: 0.8524 - val_loss: 0.5336 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4629 - acc: 0.7500 - auc_1: 0.8600 - val_loss: 0.6050 - val_acc: 0.7083 - val_auc_1: 0.9036\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4531 - acc: 0.7935 - auc_1: 0.8626 - val_loss: 0.6232 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4556 - acc: 0.7609 - auc_1: 0.8581 - val_loss: 0.5757 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4518 - acc: 0.7717 - auc_1: 0.8574 - val_loss: 0.5848 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4365 - acc: 0.7717 - auc_1: 0.8795 - val_loss: 0.6970 - val_acc: 0.6250 - val_auc_1: 0.8929\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4400 - acc: 0.8043 - auc_1: 0.8698 - val_loss: 0.5569 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4392 - acc: 0.7935 - auc_1: 0.8671 - val_loss: 0.5541 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4421 - acc: 0.7826 - auc_1: 0.8779 - val_loss: 0.7112 - val_acc: 0.6250 - val_auc_1: 0.8964\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4426 - acc: 0.7935 - auc_1: 0.8650 - val_loss: 0.6271 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4344 - acc: 0.7826 - auc_1: 0.8786 - val_loss: 0.5979 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4164 - acc: 0.7935 - auc_1: 0.8876 - val_loss: 0.5599 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4295 - acc: 0.7826 - auc_1: 0.8769 - val_loss: 0.5984 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4248 - acc: 0.7935 - auc_1: 0.8752 - val_loss: 0.6606 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4091 - acc: 0.8043 - auc_1: 0.9040 - val_loss: 0.5804 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4293 - acc: 0.7826 - auc_1: 0.8790 - val_loss: 0.6335 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4193 - acc: 0.8152 - auc_1: 0.8798 - val_loss: 0.6632 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4142 - acc: 0.8043 - auc_1: 0.8924 - val_loss: 0.6088 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4046 - acc: 0.8261 - auc_1: 0.8886 - val_loss: 0.6337 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4024 - acc: 0.8043 - auc_1: 0.8988 - val_loss: 0.5974 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3829 - acc: 0.8478 - auc_1: 0.9102 - val_loss: 0.6723 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4070 - acc: 0.8043 - auc_1: 0.8907 - val_loss: 0.6021 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3937 - acc: 0.8370 - auc_1: 0.8929 - val_loss: 0.6305 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3864 - acc: 0.8043 - auc_1: 0.9026 - val_loss: 0.5860 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3981 - acc: 0.8152 - auc_1: 0.9069 - val_loss: 0.6637 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3902 - acc: 0.8152 - auc_1: 0.8995 - val_loss: 0.5847 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3797 - acc: 0.8370 - auc_1: 0.9081 - val_loss: 0.5500 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3711 - acc: 0.8370 - auc_1: 0.9145 - val_loss: 0.6588 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3876 - acc: 0.8152 - auc_1: 0.9002 - val_loss: 0.5737 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3767 - acc: 0.8261 - auc_1: 0.9098 - val_loss: 0.5887 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3711 - acc: 0.8152 - auc_1: 0.9267 - val_loss: 0.6359 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3839 - acc: 0.8152 - auc_1: 0.8950 - val_loss: 0.6237 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3734 - acc: 0.8478 - auc_1: 0.9079 - val_loss: 0.5549 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3695 - acc: 0.8152 - auc_1: 0.9067 - val_loss: 0.5437 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3625 - acc: 0.8043 - auc_1: 0.9148 - val_loss: 0.5155 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3565 - acc: 0.8043 - auc_1: 0.9312 - val_loss: 0.5797 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3533 - acc: 0.8370 - auc_1: 0.9205 - val_loss: 0.5677 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3594 - acc: 0.8370 - auc_1: 0.9221 - val_loss: 0.5171 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3659 - acc: 0.8043 - auc_1: 0.9152 - val_loss: 0.5404 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3459 - acc: 0.8152 - auc_1: 0.9267 - val_loss: 0.5854 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3646 - acc: 0.8043 - auc_1: 0.9160 - val_loss: 0.5496 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3494 - acc: 0.8261 - auc_1: 0.9200 - val_loss: 0.5265 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3506 - acc: 0.8696 - auc_1: 0.9224 - val_loss: 0.5400 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3493 - acc: 0.8261 - auc_1: 0.9317 - val_loss: 0.5200 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3370 - acc: 0.8478 - auc_1: 0.9279 - val_loss: 0.5721 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3374 - acc: 0.8152 - auc_1: 0.9324 - val_loss: 0.5745 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3445 - acc: 0.8261 - auc_1: 0.9321 - val_loss: 0.5204 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3321 - acc: 0.8261 - auc_1: 0.9369 - val_loss: 0.5640 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3243 - acc: 0.8370 - auc_1: 0.9431 - val_loss: 0.4804 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3309 - acc: 0.8261 - auc_1: 0.9324 - val_loss: 0.5004 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3168 - acc: 0.8696 - auc_1: 0.9493 - val_loss: 0.6712 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3506 - acc: 0.8152 - auc_1: 0.9267 - val_loss: 0.4962 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3319 - acc: 0.8587 - auc_1: 0.9302 - val_loss: 0.5217 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3252 - acc: 0.8478 - auc_1: 0.9348 - val_loss: 0.5218 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3318 - acc: 0.8370 - auc_1: 0.9429 - val_loss: 0.5411 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3161 - acc: 0.8587 - auc_1: 0.9457 - val_loss: 0.5385 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3226 - acc: 0.8261 - auc_1: 0.9410 - val_loss: 0.5155 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3074 - acc: 0.8478 - auc_1: 0.9431 - val_loss: 0.5371 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3186 - acc: 0.8261 - auc_1: 0.9421 - val_loss: 0.5283 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3077 - acc: 0.8804 - auc_1: 0.9471 - val_loss: 0.5054 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3275 - acc: 0.8696 - auc_1: 0.9333 - val_loss: 0.5747 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 97/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3115 - acc: 0.8152 - auc_1: 0.9431 - val_loss: 0.5638 - val_acc: 0.7917 - val_auc_1: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3160 - acc: 0.8152 - auc_1: 0.9350 - val_loss: 0.5744 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3022 - acc: 0.8478 - auc_1: 0.9498 - val_loss: 0.5498 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3016 - acc: 0.8370 - auc_1: 0.9490 - val_loss: 0.5639 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3076 - acc: 0.8261 - auc_1: 0.9445 - val_loss: 0.5240 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3028 - acc: 0.8587 - auc_1: 0.9417 - val_loss: 0.5867 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2750 - acc: 0.9022 - auc_1: 0.9593 - val_loss: 0.6650 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3135 - acc: 0.8370 - auc_1: 0.9364 - val_loss: 0.6602 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2948 - acc: 0.8478 - auc_1: 0.9593 - val_loss: 0.5248 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2961 - acc: 0.8913 - auc_1: 0.9493 - val_loss: 0.5637 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2759 - acc: 0.8913 - auc_1: 0.9545 - val_loss: 0.5793 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2879 - acc: 0.8587 - auc_1: 0.9562 - val_loss: 0.5585 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2934 - acc: 0.8478 - auc_1: 0.9490 - val_loss: 0.5600 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2802 - acc: 0.8913 - auc_1: 0.9552 - val_loss: 0.5534 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2897 - acc: 0.8370 - auc_1: 0.9464 - val_loss: 0.5328 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2926 - acc: 0.8370 - auc_1: 0.9460 - val_loss: 0.5844 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2726 - acc: 0.9022 - auc_1: 0.9538 - val_loss: 0.6453 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2845 - acc: 0.8587 - auc_1: 0.9540 - val_loss: 0.5780 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2817 - acc: 0.8478 - auc_1: 0.9543 - val_loss: 0.6737 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2854 - acc: 0.8587 - auc_1: 0.9517 - val_loss: 0.5546 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2732 - acc: 0.9022 - auc_1: 0.9574 - val_loss: 0.5669 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2788 - acc: 0.8587 - auc_1: 0.9545 - val_loss: 0.5842 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2775 - acc: 0.8587 - auc_1: 0.9560 - val_loss: 0.5627 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2773 - acc: 0.8696 - auc_1: 0.9538 - val_loss: 0.5951 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2466 - acc: 0.8587 - auc_1: 0.9686 - val_loss: 0.5591 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2946 - acc: 0.8696 - auc_1: 0.9505 - val_loss: 0.5667 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2685 - acc: 0.8696 - auc_1: 0.9567 - val_loss: 0.5456 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2645 - acc: 0.8804 - auc_1: 0.9600 - val_loss: 0.5911 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2631 - acc: 0.8804 - auc_1: 0.9617 - val_loss: 0.6079 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2778 - acc: 0.8696 - auc_1: 0.9536 - val_loss: 0.5808 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2508 - acc: 0.9239 - auc_1: 0.9681 - val_loss: 0.6196 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2710 - acc: 0.8478 - auc_1: 0.9595 - val_loss: 0.5690 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2619 - acc: 0.9022 - auc_1: 0.9605 - val_loss: 0.5655 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2492 - acc: 0.9130 - auc_1: 0.9629 - val_loss: 0.5759 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2498 - acc: 0.8587 - auc_1: 0.9655 - val_loss: 0.5669 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2593 - acc: 0.8913 - auc_1: 0.9583 - val_loss: 0.5713 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2491 - acc: 0.8696 - auc_1: 0.9614 - val_loss: 0.5838 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2474 - acc: 0.9022 - auc_1: 0.9660 - val_loss: 0.5751 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2460 - acc: 0.9239 - auc_1: 0.9645 - val_loss: 0.5664 - val_acc: 0.8333 - val_auc_1: 0.8500\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2462 - acc: 0.9022 - auc_1: 0.9652 - val_loss: 0.5813 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2448 - acc: 0.8913 - auc_1: 0.9648 - val_loss: 0.5593 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2572 - acc: 0.9130 - auc_1: 0.9607 - val_loss: 0.5733 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2392 - acc: 0.9022 - auc_1: 0.9676 - val_loss: 0.5891 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2394 - acc: 0.9130 - auc_1: 0.9660 - val_loss: 0.5712 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2345 - acc: 0.9348 - auc_1: 0.9686 - val_loss: 0.6000 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2407 - acc: 0.8913 - auc_1: 0.9657 - val_loss: 0.5747 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2284 - acc: 0.9239 - auc_1: 0.9702 - val_loss: 0.6034 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2396 - acc: 0.9130 - auc_1: 0.9657 - val_loss: 0.5501 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 145/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2222 - acc: 0.9022 - auc_1: 0.9738 - val_loss: 0.5774 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 146/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2262 - acc: 0.9130 - auc_1: 0.9707 - val_loss: 0.5540 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2293 - acc: 0.9130 - auc_1: 0.9667 - val_loss: 0.5397 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2169 - acc: 0.9348 - auc_1: 0.9755 - val_loss: 0.5649 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2036 - acc: 0.9130 - auc_1: 0.9790 - val_loss: 0.5407 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2240 - acc: 0.9348 - auc_1: 0.9721 - val_loss: 0.5712 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2194 - acc: 0.9239 - auc_1: 0.9700 - val_loss: 0.5809 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2076 - acc: 0.9348 - auc_1: 0.9788 - val_loss: 0.5879 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2151 - acc: 0.9022 - auc_1: 0.9757 - val_loss: 0.6076 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2108 - acc: 0.9457 - auc_1: 0.9726 - val_loss: 0.5799 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2018 - acc: 0.9239 - auc_1: 0.9810 - val_loss: 0.5843 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2142 - acc: 0.9239 - auc_1: 0.9752 - val_loss: 0.5820 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1941 - acc: 0.9348 - auc_1: 0.9819 - val_loss: 0.6025 - val_acc: 0.8333 - val_auc_1: 0.8357\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2073 - acc: 0.9239 - auc_1: 0.9776 - val_loss: 0.6027 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1919 - acc: 0.9348 - auc_1: 0.9805 - val_loss: 0.6227 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2186 - acc: 0.9130 - auc_1: 0.9726 - val_loss: 0.6330 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1880 - acc: 0.9457 - auc_1: 0.9807 - val_loss: 0.6370 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1984 - acc: 0.9130 - auc_1: 0.9810 - val_loss: 0.6231 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1800 - acc: 0.9457 - auc_1: 0.9833 - val_loss: 0.6130 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1968 - acc: 0.9457 - auc_1: 0.9798 - val_loss: 0.5931 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1779 - acc: 0.9457 - auc_1: 0.9817 - val_loss: 0.5994 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1842 - acc: 0.9239 - auc_1: 0.9814 - val_loss: 0.6333 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1809 - acc: 0.9565 - auc_1: 0.9838 - val_loss: 0.6020 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1769 - acc: 0.9457 - auc_1: 0.9819 - val_loss: 0.6848 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1774 - acc: 0.9565 - auc_1: 0.9819 - val_loss: 0.6292 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1846 - acc: 0.9565 - auc_1: 0.9793 - val_loss: 0.6425 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1743 - acc: 0.9457 - auc_1: 0.9798 - val_loss: 0.6532 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1753 - acc: 0.9674 - auc_1: 0.9850 - val_loss: 0.7093 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1590 - acc: 0.9674 - auc_1: 0.9893 - val_loss: 0.6338 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1706 - acc: 0.9783 - auc_1: 0.9833 - val_loss: 0.6537 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1773 - acc: 0.9565 - auc_1: 0.9814 - val_loss: 0.6488 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1627 - acc: 0.9565 - auc_1: 0.9845 - val_loss: 0.7157 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1698 - acc: 0.9565 - auc_1: 0.9810 - val_loss: 0.6485 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1660 - acc: 0.9565 - auc_1: 0.9819 - val_loss: 0.6531 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1569 - acc: 0.9565 - auc_1: 0.9838 - val_loss: 0.7051 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1484 - acc: 0.9565 - auc_1: 0.9874 - val_loss: 0.6369 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1671 - acc: 0.9674 - auc_1: 0.9855 - val_loss: 0.7209 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1799 - acc: 0.9565 - auc_1: 0.9824 - val_loss: 0.6712 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1666 - acc: 0.9457 - auc_1: 0.9829 - val_loss: 0.6372 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1598 - acc: 0.9565 - auc_1: 0.9824 - val_loss: 0.6403 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1425 - acc: 0.9565 - auc_1: 0.9848 - val_loss: 0.6414 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1587 - acc: 0.9348 - auc_1: 0.9848 - val_loss: 0.6532 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1592 - acc: 0.9565 - auc_1: 0.9848 - val_loss: 0.6656 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1448 - acc: 0.9457 - auc_1: 0.9879 - val_loss: 0.6445 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1465 - acc: 0.9674 - auc_1: 0.9867 - val_loss: 0.7478 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1484 - acc: 0.9565 - auc_1: 0.9869 - val_loss: 0.6590 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1434 - acc: 0.9674 - auc_1: 0.9881 - val_loss: 0.7222 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1523 - acc: 0.9565 - auc_1: 0.9867 - val_loss: 0.7143 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1606 - acc: 0.9457 - auc_1: 0.9829 - val_loss: 0.6822 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 194/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1479 - acc: 0.9457 - auc_1: 0.9852 - val_loss: 0.7371 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1399 - acc: 0.9674 - auc_1: 0.9876 - val_loss: 0.6961 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1362 - acc: 0.9674 - auc_1: 0.9869 - val_loss: 0.7029 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1447 - acc: 0.9565 - auc_1: 0.9888 - val_loss: 0.7634 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1368 - acc: 0.9674 - auc_1: 0.9845 - val_loss: 0.6922 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1343 - acc: 0.9565 - auc_1: 0.9910 - val_loss: 0.7730 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1241 - acc: 0.9783 - auc_1: 0.9917 - val_loss: 0.6760 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1978 - acc: 0.9348 - auc_1: 0.9740 - val_loss: 0.7696 - val_acc: 0.7917 - val_auc_1: 0.7750\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1529 - acc: 0.9674 - auc_1: 0.9867 - val_loss: 0.7585 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1425 - acc: 0.9348 - auc_1: 0.9876 - val_loss: 0.7266 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1309 - acc: 0.9674 - auc_1: 0.9900 - val_loss: 0.7829 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1179 - acc: 0.9674 - auc_1: 0.9907 - val_loss: 0.6873 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1437 - acc: 0.9565 - auc_1: 0.9876 - val_loss: 0.7101 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1447 - acc: 0.9457 - auc_1: 0.9876 - val_loss: 0.7764 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1210 - acc: 0.9565 - auc_1: 0.9931 - val_loss: 0.7574 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1315 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.7426 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1173 - acc: 0.9674 - auc_1: 0.9933 - val_loss: 0.7022 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1124 - acc: 0.9783 - auc_1: 0.9914 - val_loss: 0.7274 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1093 - acc: 0.9674 - auc_1: 0.9940 - val_loss: 0.6963 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1158 - acc: 0.9674 - auc_1: 0.9910 - val_loss: 0.7285 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1070 - acc: 0.9565 - auc_1: 0.9940 - val_loss: 0.7314 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1085 - acc: 0.9783 - auc_1: 0.9960 - val_loss: 0.7820 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1230 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 0.7876 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1196 - acc: 0.9674 - auc_1: 0.9929 - val_loss: 0.7529 - val_acc: 0.7917 - val_auc_1: 0.7964\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1015 - acc: 0.9783 - auc_1: 0.9945 - val_loss: 0.7636 - val_acc: 0.7917 - val_auc_1: 0.7964\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0939 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.7637 - val_acc: 0.7917 - val_auc_1: 0.7929\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0997 - acc: 0.9674 - auc_1: 0.9945 - val_loss: 0.7124 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1772 - acc: 0.9022 - auc_1: 0.9807 - val_loss: 0.7767 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0964 - acc: 0.9674 - auc_1: 0.9955 - val_loss: 0.7616 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0915 - acc: 0.9783 - auc_1: 0.9957 - val_loss: 0.8276 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1237 - acc: 0.9783 - auc_1: 0.9914 - val_loss: 0.8064 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1038 - acc: 0.9783 - auc_1: 0.9938 - val_loss: 0.8178 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0982 - acc: 0.9783 - auc_1: 0.9952 - val_loss: 0.8308 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0977 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.8689 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0969 - acc: 0.9783 - auc_1: 0.9948 - val_loss: 0.8444 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0933 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.8485 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0981 - acc: 0.9783 - auc_1: 0.9948 - val_loss: 0.8594 - val_acc: 0.7500 - val_auc_1: 0.7821\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0888 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.8681 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0865 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 0.9093 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0983 - acc: 0.9783 - auc_1: 0.9945 - val_loss: 0.8855 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0948 - acc: 0.9565 - auc_1: 0.9969 - val_loss: 0.8223 - val_acc: 0.7917 - val_auc_1: 0.7964\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1147 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 0.8333 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0788 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8794 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0849 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.7951 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0744 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 0.8668 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0990 - acc: 0.9457 - auc_1: 0.9957 - val_loss: 0.8362 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0794 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8381 - val_acc: 0.7917 - val_auc_1: 0.7786\n",
      "Epoch 241/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1019 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.9013 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0822 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 0.8726 - val_acc: 0.7083 - val_auc_1: 0.7643\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0683 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 0.8254 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0739 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8494 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0667 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8702 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0845 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 0.9035 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0930 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.8499 - val_acc: 0.7917 - val_auc_1: 0.7643\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0637 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8634 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0727 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.8679 - val_acc: 0.7917 - val_auc_1: 0.7750\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0628 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 0.9252 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0798 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.9568 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1424 - acc: 0.9457 - auc_1: 0.9888 - val_loss: 0.8643 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0590 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.8617 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0552 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 0.8703 - val_acc: 0.7917 - val_auc_1: 0.7679\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0548 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8434 - val_acc: 0.8333 - val_auc_1: 0.7643\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0953 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.9086 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0743 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.9207 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0527 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9215 - val_acc: 0.7917 - val_auc_1: 0.7714\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0513 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.9338 - val_acc: 0.7917 - val_auc_1: 0.7643\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0452 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9473 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0521 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9574 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0526 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.9379 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0566 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.9735 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0418 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0224 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0468 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9819 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0430 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9797 - val_acc: 0.7917 - val_auc_1: 0.7679\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0448 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9741 - val_acc: 0.7500 - val_auc_1: 0.7607\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0617 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.9641 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0657 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.9521 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0410 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0552 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0434 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0046 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0520 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.9726 - val_acc: 0.7917 - val_auc_1: 0.7929\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0415 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0099 - val_acc: 0.7917 - val_auc_1: 0.7643\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0459 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0325 - val_acc: 0.7917 - val_auc_1: 0.7750\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0341 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0079 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0366 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0396 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0408 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0327 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0284 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0744 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0502 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.0433 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0389 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0302 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0306 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0415 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0311 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0271 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0458 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.0412 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0339 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0787 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0314 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0860 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0243 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0949 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0300 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1397 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0503 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.1784 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 289/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0555 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0875 - val_acc: 0.7917 - val_auc_1: 0.7214\n",
      "Epoch 290/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0325 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1564 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0281 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1365 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0459 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1628 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0273 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1774 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1076 - acc: 0.9783 - auc_1: 0.9914 - val_loss: 1.0725 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0269 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0588 - val_acc: 0.7917 - val_auc_1: 0.7893\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0349 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0780 - val_acc: 0.7917 - val_auc_1: 0.7750\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0228 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1052 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0196 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1178 - val_acc: 0.7917 - val_auc_1: 0.7607\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0231 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1230 - val_acc: 0.7917 - val_auc_1: 0.7607\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0286 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1336 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0218 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1435 - val_acc: 0.7917 - val_auc_1: 0.7607\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0195 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1514 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0181 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1710 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0187 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1279 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0189 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2229 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0181 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2291 - val_acc: 0.7917 - val_auc_1: 0.7607\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0162 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2311 - val_acc: 0.7917 - val_auc_1: 0.7607\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0203 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2471 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0138 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2733 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0267 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2027 - val_acc: 0.7917 - val_auc_1: 0.7714\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0843 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 1.3568 - val_acc: 0.7083 - val_auc_1: 0.7429\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2330 - acc: 0.9130 - auc_1: 0.9738 - val_loss: 1.1357 - val_acc: 0.7917 - val_auc_1: 0.7643\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0204 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2059 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0180 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2198 - val_acc: 0.7917 - val_auc_1: 0.7643\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0193 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2229 - val_acc: 0.7917 - val_auc_1: 0.7607\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0149 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2293 - val_acc: 0.7917 - val_auc_1: 0.7607\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0140 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2408 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0218 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2599 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0147 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2655 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0194 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2553 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0157 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2565 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0130 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2787 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0112 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2906 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0103 - acc: 1.0000 - auc_1: 1.000 - 0s 5ms/step - loss: 0.0110 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2923 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0314 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.2736 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0164 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2888 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0119 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2949 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0125 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2615 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3073 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0265 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.3163 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0408 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.3085 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0120 - acc: 1.0000 - auc_1: 1.000 - 0s 5ms/step - loss: 0.0116 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2980 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0141 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3164 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3296 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0113 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3538 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0112 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3479 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 337/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1141 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 1.2528 - val_acc: 0.7917 - val_auc_1: 0.7321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3188 - acc: 0.9239 - auc_1: 0.9512 - val_loss: 1.2121 - val_acc: 0.7917 - val_auc_1: 0.7857\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0943 - acc: 0.9783 - auc_1: 0.9921 - val_loss: 1.2752 - val_acc: 0.7500 - val_auc_1: 0.7607\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0569 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.2956 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0158 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3133 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0134 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3159 - val_acc: 0.7917 - val_auc_1: 0.7214\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0128 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3219 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0111 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3308 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0106 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3384 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3423 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3527 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3649 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3620 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3739 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0108 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3705 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3910 - val_acc: 0.7917 - val_auc_1: 0.7214\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0098 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3977 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4015 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4132 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4234 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4289 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4390 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0108 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4342 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4473 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0408 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.5018 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.1303 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 1.6106 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2782 - acc: 0.8913 - auc_1: 0.9729 - val_loss: 1.3997 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0845 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.3607 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0357 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.3316 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0112 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3405 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0093 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3533 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3595 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3680 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3755 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3882 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3939 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4005 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4040 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4123 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4191 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4279 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4344 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4437 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4520 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4583 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4736 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4771 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4853 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 385/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4965 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 386/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4979 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5041 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5117 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5306 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5334 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5420 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5497 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5597 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5700 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5663 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5812 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6406 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2163 - acc: 0.9457 - auc_1: 0.9814 - val_loss: 1.4890 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0439 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 1.3374 - val_acc: 0.8333 - val_auc_1: 0.7464\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1073 - acc: 0.9783 - auc_1: 0.9833 - val_loss: 1.5142 - val_acc: 0.7500 - val_auc_1: 0.7321\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0129 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4858 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4774 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4730 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4872 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4941 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4957 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5082 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5059 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5067 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5121 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5332 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5266 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5443 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5455 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5599 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0045 - acc: 1.0000 - auc_1: 1.000 - 0s 4ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5638 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5774 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5860 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5936 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6007 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6047 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6153 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6166 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6225 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6299 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6418 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6511 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6623 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6778 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6801 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6894 - val_acc: 0.7917 - val_auc_1: 0.7321\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7107 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 433/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7085 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 434/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7215 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7177 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8167 - val_acc: 0.7500 - val_auc_1: 0.7071\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3106 - acc: 0.9457 - auc_1: 0.9655 - val_loss: 1.5223 - val_acc: 0.7083 - val_auc_1: 0.7464\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3509 - acc: 0.8913 - auc_1: 0.9593 - val_loss: 1.6494 - val_acc: 0.7500 - val_auc_1: 0.7179\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0187 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6511 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0093 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6145 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6343 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6235 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6283 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6299 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6274 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6345 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6449 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6422 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6451 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6516 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6582 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6547 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6625 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6653 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6751 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6796 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6848 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6941 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6922 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7091 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7070 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7158 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7232 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7334 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7377 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7494 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7520 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7613 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7671 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7745 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7842 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8051 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8099 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8279 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8278 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8172 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8402 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8450 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8509 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8794 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 481/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8744 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 482/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8894 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1912 - acc: 0.9674 - auc_1: 0.9752 - val_loss: 2.1588 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2943 - acc: 0.9239 - auc_1: 0.9638 - val_loss: 1.7006 - val_acc: 0.7500 - val_auc_1: 0.7071\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2746 - acc: 0.9130 - auc_1: 0.9667 - val_loss: 1.5335 - val_acc: 0.7917 - val_auc_1: 0.7607\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0534 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.3346 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0604 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.4128 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0313 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5552 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5076 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5108 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5134 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5197 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5258 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5313 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5405 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5458 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5532 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5610 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5685 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5765 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5863 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5939 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6012 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6086 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6180 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6294 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6348 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6440 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6561 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6668 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6694 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6856 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6927 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6979 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7113 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7157 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7299 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7362 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7476 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7602 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7688 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000   - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7792 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7868 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7938 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8043 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8149 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8258 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8330 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 529/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8510 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 530/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8597 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8770 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8852 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8929 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8893 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9045 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9103 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9235 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9629 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9696 - val_acc: 0.7917 - val_auc_1: 0.7286\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9502 - val_acc: 0.7917 - val_auc_1: 0.7179\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0563 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.8027 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5873 - acc: 0.8587 - auc_1: 0.9214 - val_loss: 1.3985 - val_acc: 0.8333 - val_auc_1: 0.7893\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4238 - acc: 0.8913 - auc_1: 0.9538 - val_loss: 1.0538 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0354 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.0652 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0242 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0660 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0841 - acc: 0.9783 - auc_1: 0.9948 - val_loss: 1.1913 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1066 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 1.2184 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0515 - acc: 0.9783 - auc_1: 0.9979 - val_loss: 1.2385 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0136 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2676 - val_acc: 0.7917 - val_auc_1: 0.8107\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3019 - val_acc: 0.7917 - val_auc_1: 0.8107\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3169 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3419 - val_acc: 0.7917 - val_auc_1: 0.7786\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3545 - val_acc: 0.7917 - val_auc_1: 0.7786\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3691 - val_acc: 0.7917 - val_auc_1: 0.7786\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3844 - val_acc: 0.7917 - val_auc_1: 0.7786\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3968 - val_acc: 0.7917 - val_auc_1: 0.7893\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4099 - val_acc: 0.7917 - val_auc_1: 0.7893\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4220 - val_acc: 0.7917 - val_auc_1: 0.7893\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4279 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4485 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4527 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4657 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4824 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4905 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5047 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5161 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5259 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5423 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5550 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5584 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5710 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5864 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5971 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6034 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6219 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6301 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 577/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6406 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 578/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6482 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6615 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6787 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6907 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6933 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7113 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7158 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7315 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7397 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7578 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7645 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7758 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7967 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7919 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8065 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8197 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8198 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8406 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8548 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8597 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8736 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8876 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9050 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9160 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9192 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9383 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9379 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9613 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9784 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9737 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9862 - val_acc: 0.7917 - val_auc_1: 0.7393\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9996 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2585 - acc: 0.9457 - auc_1: 0.9729 - val_loss: 1.5128 - val_acc: 0.8333 - val_auc_1: 0.7607\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3550 - acc: 0.9457 - auc_1: 0.9586 - val_loss: 1.9860 - val_acc: 0.7500 - val_auc_1: 0.7464\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0132 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1268 - val_acc: 0.7083 - val_auc_1: 0.7143\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9937 - val_acc: 0.7500 - val_auc_1: 0.7250\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9624 - val_acc: 0.7500 - val_auc_1: 0.7250\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0451 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.7997 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8237 - val_acc: 0.7917 - val_auc_1: 0.7250\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8326 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8380 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8444 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8489 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8540 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8579 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8618 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8667 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 625/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8705 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 626/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8737 - val_acc: 0.7917 - val_auc_1: 0.7357\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8791 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8835 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8890 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8926 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8970 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9010 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9066 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9120 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9150 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9193 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9238 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9320 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9349 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9407 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9471 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9523 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9582 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9643 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9702 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9767 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9818 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9889 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9968 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0024 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0102 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0150 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.8735e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0241 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.8854e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0312 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 9.7547e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0381 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.5049e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0488 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 9.5428e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0540 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.5002e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0616 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.1174e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0719 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.9250e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0738 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.9075e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0841 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.7302e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0899 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 8.6946e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1057 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 8.7314e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1149 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 8.6196e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1275 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.6451e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1303 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.9310e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1400 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 8.0144e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1457 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 7.9234e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1531 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 7.8939e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1679 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 7.4689e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1733 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 7.2263e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1908 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 673/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 7.3879e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1974 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 674/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 7.1659e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2150 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 6.7490e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2188 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 6.8836e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2292 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.1674e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2447 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.6963e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2543 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.4065e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2627 - val_acc: 0.7500 - val_auc_1: 0.7464\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.0129e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2710 - val_acc: 0.7500 - val_auc_1: 0.7464\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 6.2325e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2755 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 6.2077e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2796 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3089 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3855 - acc: 0.9565 - auc_1: 0.9638 - val_loss: 1.7147 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3060 - acc: 0.8913 - auc_1: 0.9743 - val_loss: 1.4994 - val_acc: 0.7917 - val_auc_1: 0.7714\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1166 - acc: 0.9674 - auc_1: 0.9869 - val_loss: 1.7437 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0200 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.5657 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5817 - val_acc: 0.7500 - val_auc_1: 0.7429\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5847 - val_acc: 0.7500 - val_auc_1: 0.7500\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5893 - val_acc: 0.7500 - val_auc_1: 0.7536\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5977 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6032 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6085 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6133 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6238 - val_acc: 0.7500 - val_auc_1: 0.7286\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6375 - val_acc: 0.7500 - val_auc_1: 0.7393\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6370 - val_acc: 0.7500 - val_auc_1: 0.7393\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6448 - val_acc: 0.7500 - val_auc_1: 0.7393\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6495 - val_acc: 0.7500 - val_auc_1: 0.7393\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6567 - val_acc: 0.7500 - val_auc_1: 0.7393\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5, X6, X7, X8, X9], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.9734497 ,  1.0721098 , -0.73662454, -1.8177592 , -0.778409  ,\n",
      "         0.33488172,  0.8140833 , -0.276615  , -0.18442324],\n",
      "       [ 0.32345772, -0.60317785, -0.43707845,  0.33604324,  0.36595893,\n",
      "         1.0007935 ,  1.1869309 , -1.8085326 ,  0.08096401],\n",
      "       [ 0.17306775,  0.4155604 ,  0.82757926, -0.02547674, -0.09393729,\n",
      "        -1.3838017 ,  1.7368501 ,  0.2596948 , -0.35657588],\n",
      "       [-0.17568742,  1.9046465 , -2.1183496 , -0.5574882 , -2.1486504 ,\n",
      "        -0.27503362,  0.13903147,  0.7472016 ,  1.6877944 ],\n",
      "       [-1.1701248 ,  0.19686744, -1.6147951 , -0.7546039 , -1.0058459 ,\n",
      "         0.9801385 , -0.46932554, -0.15867043,  1.3618879 ],\n",
      "       [-0.7044733 ,  0.7291656 ,  0.03576811,  0.57487136,  0.21304533,\n",
      "        -1.1341861 , -0.42042556,  0.6126313 ,  1.0218407 ],\n",
      "       [-0.25085   ,  0.32000142, -0.28401583,  0.12142867,  0.38654226,\n",
      "         0.6045966 , -1.9478116 ,  0.1886006 , -0.30461374],\n",
      "       [-0.59565693,  0.39079762,  0.75795954,  1.3514132 ,  0.95028156,\n",
      "        -0.6810112 , -0.21265607,  0.38388386,  0.5919471 ],\n",
      "       [ 0.6764679 , -0.80217034, -0.03526448, -0.09646246,  0.49204898,\n",
      "         0.42189574,  0.8199695 , -0.07087678, -0.4561331 ]],\n",
      "      dtype=float32), array([-0.19919996, -0.33280763,  0.179584  ,  0.3156652 ,  0.11265953,\n",
      "        0.02127167,  0.05975534,  0.06914751, -0.05507854], dtype=float32), array([[-0.08799682, -1.0743253 ,  1.0114951 , -0.01458379, -0.02749437,\n",
      "        -0.33136603, -0.20874724, -2.2201045 ,  0.9570238 ],\n",
      "       [ 0.9766358 ,  1.0241035 , -0.4344192 ,  2.0679383 ,  0.35530362,\n",
      "         0.4612998 , -0.60644674, -1.8506764 , -0.5596344 ],\n",
      "       [-1.2055854 , -1.1361443 ,  0.34367746,  0.21015824, -4.3472157 ,\n",
      "        -0.8116867 ,  0.48756975, -0.24211447,  0.4975662 ],\n",
      "       [-1.0817857 , -0.63199675, -0.05868426, -0.58760136, -0.900444  ,\n",
      "         0.6204416 ,  1.0617516 ,  1.8584435 , -0.83110607],\n",
      "       [-1.025824  ,  0.33509603,  0.9473708 , -1.0407014 , -1.605426  ,\n",
      "         0.31342998,  2.2594497 ,  0.98654246,  0.33347234],\n",
      "       [ 0.47230318,  0.65391797,  1.2694259 , -1.7600937 ,  1.8186889 ,\n",
      "        -0.59590405,  1.3230108 ,  1.4923564 , -0.18802203],\n",
      "       [-1.6779232 , -0.8724715 ,  0.719467  ,  1.4880189 , -0.03056238,\n",
      "        -1.1791248 , -0.8430132 , -1.5245594 ,  1.2784854 ],\n",
      "       [ 1.9111476 ,  0.2847982 , -1.0280166 ,  0.51185566, -0.57834005,\n",
      "         0.6640628 , -0.68478405, -0.399182  , -0.48776737],\n",
      "       [-0.02274471,  1.0640061 , -1.9883137 , -0.0257653 ,  1.5869433 ,\n",
      "         1.4221144 , -0.5749834 ,  0.5011058 , -1.0327457 ]],\n",
      "      dtype=float32), array([-0.30968034,  0.03192294,  0.041525  ,  0.03768697,  0.098941  ,\n",
      "       -0.09217981,  0.24549085,  0.37344337,  0.18596242], dtype=float32), array([[ 1.7078918 ,  3.0134823 ,  1.7993783 , -0.9154477 , -1.2962133 ,\n",
      "         0.8711994 ,  1.0543573 ,  0.5945813 , -0.41549176],\n",
      "       [-0.6457448 ,  1.1780218 ,  0.75609326, -0.25477943, -1.2068813 ,\n",
      "        -1.8467541 ,  1.5462991 ,  0.7725688 ,  0.8564814 ],\n",
      "       [-0.15187538, -1.2154207 , -0.5466209 , -1.2704885 ,  2.5418382 ,\n",
      "         0.5675421 , -2.9069755 , -1.4973295 , -1.2064135 ],\n",
      "       [ 0.15718894, -0.20501179, -0.4944875 ,  0.59233695, -0.70274216,\n",
      "        -4.2656536 , -0.16468538,  0.8453437 ,  0.92598337],\n",
      "       [-1.9298927 , -1.7522163 , -1.3111897 ,  1.4616628 ,  0.6673623 ,\n",
      "        -0.3247869 , -0.7750482 ,  2.551353  ,  2.2303245 ],\n",
      "       [ 0.19518985, -0.3652363 , -0.29943866,  1.101198  , -2.9888315 ,\n",
      "         0.35052615,  2.3606453 ,  0.07586506,  0.71150666],\n",
      "       [-1.8547442 , -0.27962515, -0.6361034 ,  0.39035702,  0.40535942,\n",
      "         2.2677996 , -0.48998818, -0.1360695 , -1.1388282 ],\n",
      "       [-1.2532752 , -1.4807078 , -0.17405075, -1.3930972 , -2.597431  ,\n",
      "         2.3284674 ,  2.3229651 , -1.2833935 , -0.3968991 ],\n",
      "       [ 0.7558008 ,  0.41670075,  0.69328475, -0.7704413 ,  2.9369528 ,\n",
      "        -0.04939462, -3.003352  , -0.22034182, -0.88295925]],\n",
      "      dtype=float32), array([-0.18233529, -0.5248605 ,  0.29540765, -0.5523227 ,  0.13871978,\n",
      "       -0.3416917 , -0.11385939, -0.2500839 , -0.33708987], dtype=float32), array([[-3.4921217],\n",
      "       [-3.3620234],\n",
      "       [-2.9528866],\n",
      "       [ 2.743818 ],\n",
      "       [-2.676594 ],\n",
      "       [-3.3949444],\n",
      "       [ 3.2455738],\n",
      "       [ 2.5190995],\n",
      "       [ 2.7023075]], dtype=float32), array([-0.9604072], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.93632242e-04]\n",
      " [9.99999285e-01]\n",
      " [9.92938697e-01]\n",
      " [1.94972672e-05]\n",
      " [6.22753100e-03]\n",
      " [9.99878407e-01]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [9.86297846e-01]\n",
      " [9.99966979e-01]\n",
      " [7.36546644e-05]\n",
      " [1.86170859e-03]\n",
      " [1.00000000e+00]\n",
      " [2.29376121e-04]\n",
      " [1.59051258e-03]\n",
      " [9.99296904e-01]\n",
      " [2.70792923e-04]\n",
      " [9.94830310e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99950051e-01]\n",
      " [3.38958111e-04]\n",
      " [3.13201715e-04]\n",
      " [4.47022589e-03]\n",
      " [9.99229431e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99337018e-01]\n",
      " [9.98989999e-01]\n",
      " [9.99494910e-01]\n",
      " [1.25662073e-05]\n",
      " [1.00000000e+00]\n",
      " [2.35542189e-04]\n",
      " [1.18295808e-04]\n",
      " [7.84595904e-05]\n",
      " [2.15926149e-04]\n",
      " [4.63903234e-06]\n",
      " [9.99999881e-01]\n",
      " [9.99932170e-01]\n",
      " [9.93600368e-01]\n",
      " [9.84981179e-01]\n",
      " [9.99998689e-01]\n",
      " [9.99637008e-01]\n",
      " [9.99997973e-01]\n",
      " [6.17916696e-04]\n",
      " [1.73325505e-04]\n",
      " [2.79384025e-04]\n",
      " [9.99978065e-01]\n",
      " [9.98687685e-01]\n",
      " [9.98632133e-01]\n",
      " [9.98804808e-01]\n",
      " [1.75083740e-04]\n",
      " [2.58285786e-06]\n",
      " [9.97218370e-01]\n",
      " [1.98775233e-05]\n",
      " [7.36561415e-05]\n",
      " [3.10311884e-06]\n",
      " [4.44674352e-03]\n",
      " [4.73294687e-03]\n",
      " [1.00000000e+00]\n",
      " [2.78195912e-05]\n",
      " [1.30268764e-02]\n",
      " [3.02057457e-03]\n",
      " [9.99992251e-01]\n",
      " [9.98813152e-01]\n",
      " [9.99719560e-01]\n",
      " [1.06090134e-04]\n",
      " [1.62870232e-02]\n",
      " [3.40944898e-05]\n",
      " [9.99997735e-01]\n",
      " [2.88505162e-05]\n",
      " [2.11800318e-04]\n",
      " [8.45349277e-04]\n",
      " [9.99999285e-01]\n",
      " [9.99944448e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99806106e-01]\n",
      " [2.89985546e-05]\n",
      " [9.98736084e-01]\n",
      " [3.14457138e-04]\n",
      " [9.99999762e-01]\n",
      " [3.58651974e-04]\n",
      " [3.03499575e-04]\n",
      " [7.23436779e-06]\n",
      " [9.99686718e-01]\n",
      " [9.99209225e-01]\n",
      " [9.91544127e-01]\n",
      " [9.99247551e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99903321e-01]\n",
      " [2.88262963e-04]\n",
      " [9.99868274e-01]\n",
      " [9.99999642e-01]\n",
      " [9.98869479e-01]\n",
      " [9.99500513e-01]\n",
      " [5.87871730e-01]\n",
      " [9.99807775e-01]\n",
      " [9.49740112e-01]\n",
      " [9.97284889e-01]\n",
      " [9.92971480e-01]\n",
      " [5.94140256e-05]\n",
      " [1.00000000e+00]\n",
      " [9.99366701e-01]\n",
      " [2.30670499e-04]\n",
      " [9.96679664e-01]\n",
      " [9.99998331e-01]\n",
      " [1.06140855e-03]\n",
      " [9.99118626e-01]\n",
      " [8.40114953e-05]\n",
      " [3.16291233e-04]\n",
      " [9.99074101e-01]\n",
      " [1.66260961e-05]\n",
      " [7.61347337e-06]\n",
      " [9.59825635e-01]\n",
      " [9.99365747e-01]\n",
      " [9.98360693e-01]\n",
      " [4.02036931e-05]\n",
      " [9.98669147e-01]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5, X6, X7, X8, X9])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
