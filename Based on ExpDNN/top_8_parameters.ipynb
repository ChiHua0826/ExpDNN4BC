{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,5:6] #Leptin\n",
    "X2 = dataset[:,6:7] #Adiponectin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,7:8] #Resistin\n",
    "X5 = dataset[:,2:3] #Glucose\n",
    "X6 = dataset[:,4:5] #HOMA\n",
    "X7 = dataset[:,8:9] #MCP.1\n",
    "X8 = dataset[:,3:4] #Insulin\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "X6 = normalization(X6)\n",
    "X7 = normalization(X7)\n",
    "X8 = normalization(X8)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X6 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X7 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X8 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 8)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "                                                                 input_layer_X6[0][0]             \n",
      "                                                                 input_layer_X7[0][0]             \n",
      "                                                                 input_layer_X8[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            81          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 271\n",
      "Trainable params: 271\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "input_layer_X6 = keras.layers.Input(shape=(1, ), name='input_layer_X6')\n",
    "input_layer_X7 = keras.layers.Input(shape=(1, ), name='input_layer_X7')\n",
    "input_layer_X8 = keras.layers.Input(shape=(1, ), name='input_layer_X8')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7, input_layer_X8], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7, input_layer_X8], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.7035 - acc: 0.5652 - auc_1: 0.5543 - val_loss: 0.6541 - val_acc: 0.7083 - val_auc_1: 0.6607\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6646 - acc: 0.6848 - auc_1: 0.6626 - val_loss: 0.6233 - val_acc: 0.7500 - val_auc_1: 0.7357\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6452 - acc: 0.6522 - auc_1: 0.6926 - val_loss: 0.6019 - val_acc: 0.7500 - val_auc_1: 0.7500\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6260 - acc: 0.6848 - auc_1: 0.7110 - val_loss: 0.5809 - val_acc: 0.6667 - val_auc_1: 0.7536\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6094 - acc: 0.6522 - auc_1: 0.7210 - val_loss: 0.5556 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5985 - acc: 0.6630 - auc_1: 0.7331 - val_loss: 0.5544 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5874 - acc: 0.6196 - auc_1: 0.7450 - val_loss: 0.5352 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5792 - acc: 0.6957 - auc_1: 0.7626 - val_loss: 0.5566 - val_acc: 0.5833 - val_auc_1: 0.8607\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5704 - acc: 0.6413 - auc_1: 0.7671 - val_loss: 0.5220 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5678 - acc: 0.6957 - auc_1: 0.7650 - val_loss: 0.5369 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5574 - acc: 0.6739 - auc_1: 0.7776 - val_loss: 0.5156 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5476 - acc: 0.6848 - auc_1: 0.7864 - val_loss: 0.5062 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5446 - acc: 0.6957 - auc_1: 0.7926 - val_loss: 0.5310 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5354 - acc: 0.7065 - auc_1: 0.7938 - val_loss: 0.5983 - val_acc: 0.5833 - val_auc_1: 0.8964\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5332 - acc: 0.7283 - auc_1: 0.8000 - val_loss: 0.4865 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5341 - acc: 0.7065 - auc_1: 0.8007 - val_loss: 0.5260 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5272 - acc: 0.7283 - auc_1: 0.8076 - val_loss: 0.5103 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5174 - acc: 0.7391 - auc_1: 0.8183 - val_loss: 0.5017 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5131 - acc: 0.7391 - auc_1: 0.8248 - val_loss: 0.5785 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5101 - acc: 0.7500 - auc_1: 0.8212 - val_loss: 0.5491 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5108 - acc: 0.6957 - auc_1: 0.8155 - val_loss: 0.5470 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5034 - acc: 0.7500 - auc_1: 0.8214 - val_loss: 0.5379 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4958 - acc: 0.7500 - auc_1: 0.8390 - val_loss: 0.4833 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4973 - acc: 0.7609 - auc_1: 0.8317 - val_loss: 0.5365 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4876 - acc: 0.7391 - auc_1: 0.8286 - val_loss: 0.5138 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4826 - acc: 0.7609 - auc_1: 0.8438 - val_loss: 0.5313 - val_acc: 0.7083 - val_auc_1: 0.9179\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4853 - acc: 0.7174 - auc_1: 0.8350 - val_loss: 0.5255 - val_acc: 0.7083 - val_auc_1: 0.9179\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4799 - acc: 0.7174 - auc_1: 0.8398 - val_loss: 0.5372 - val_acc: 0.7083 - val_auc_1: 0.9143\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4692 - acc: 0.7283 - auc_1: 0.8498 - val_loss: 0.5841 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4744 - acc: 0.7500 - auc_1: 0.8440 - val_loss: 0.5478 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4615 - acc: 0.7826 - auc_1: 0.8619 - val_loss: 0.5455 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4574 - acc: 0.7935 - auc_1: 0.8610 - val_loss: 0.4814 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4611 - acc: 0.7391 - auc_1: 0.8545 - val_loss: 0.4959 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4594 - acc: 0.7609 - auc_1: 0.8576 - val_loss: 0.5044 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4558 - acc: 0.7391 - auc_1: 0.8610 - val_loss: 0.4870 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4536 - acc: 0.7717 - auc_1: 0.8674 - val_loss: 0.4468 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4597 - acc: 0.7609 - auc_1: 0.8624 - val_loss: 0.4802 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4460 - acc: 0.7826 - auc_1: 0.8707 - val_loss: 0.5353 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4467 - acc: 0.7609 - auc_1: 0.8674 - val_loss: 0.4947 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4473 - acc: 0.7500 - auc_1: 0.8640 - val_loss: 0.4830 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4363 - acc: 0.7826 - auc_1: 0.8752 - val_loss: 0.5369 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4207 - acc: 0.7391 - auc_1: 0.8802 - val_loss: 0.4545 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4370 - acc: 0.7717 - auc_1: 0.8652 - val_loss: 0.4543 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4279 - acc: 0.8152 - auc_1: 0.8855 - val_loss: 0.6270 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4407 - acc: 0.7826 - auc_1: 0.8693 - val_loss: 0.5046 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4323 - acc: 0.7500 - auc_1: 0.8745 - val_loss: 0.4572 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4208 - acc: 0.8043 - auc_1: 0.8902 - val_loss: 0.4495 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4249 - acc: 0.7717 - auc_1: 0.8807 - val_loss: 0.4418 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4099 - acc: 0.8043 - auc_1: 0.8950 - val_loss: 0.5603 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4083 - acc: 0.7717 - auc_1: 0.8938 - val_loss: 0.4172 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4334 - acc: 0.7717 - auc_1: 0.8740 - val_loss: 0.4793 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4229 - acc: 0.7717 - auc_1: 0.8800 - val_loss: 0.4871 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4192 - acc: 0.7935 - auc_1: 0.8802 - val_loss: 0.4258 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4204 - acc: 0.7500 - auc_1: 0.8812 - val_loss: 0.4199 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4144 - acc: 0.7500 - auc_1: 0.8876 - val_loss: 0.4522 - val_acc: 0.7500 - val_auc_1: 0.9179\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4037 - acc: 0.8261 - auc_1: 0.9007 - val_loss: 0.5330 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4269 - acc: 0.7826 - auc_1: 0.8848 - val_loss: 0.4263 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4167 - acc: 0.7609 - auc_1: 0.8857 - val_loss: 0.4143 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4031 - acc: 0.7609 - auc_1: 0.8967 - val_loss: 0.4227 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4111 - acc: 0.7935 - auc_1: 0.8952 - val_loss: 0.4625 - val_acc: 0.7500 - val_auc_1: 0.9179\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4020 - acc: 0.7935 - auc_1: 0.8971 - val_loss: 0.3941 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4048 - acc: 0.7826 - auc_1: 0.8902 - val_loss: 0.3731 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3887 - acc: 0.7935 - auc_1: 0.9038 - val_loss: 0.4889 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4099 - acc: 0.7826 - auc_1: 0.8874 - val_loss: 0.4422 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4126 - acc: 0.7717 - auc_1: 0.8945 - val_loss: 0.4047 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3969 - acc: 0.7826 - auc_1: 0.8983 - val_loss: 0.4599 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4031 - acc: 0.7935 - auc_1: 0.8914 - val_loss: 0.4362 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3872 - acc: 0.7935 - auc_1: 0.9040 - val_loss: 0.3786 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3944 - acc: 0.7935 - auc_1: 0.8950 - val_loss: 0.4359 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4004 - acc: 0.8152 - auc_1: 0.8938 - val_loss: 0.3872 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3999 - acc: 0.7935 - auc_1: 0.8967 - val_loss: 0.4083 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3873 - acc: 0.8152 - auc_1: 0.9029 - val_loss: 0.4131 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4074 - acc: 0.7935 - auc_1: 0.8883 - val_loss: 0.3784 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3736 - acc: 0.7935 - auc_1: 0.9138 - val_loss: 0.4802 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3778 - acc: 0.7935 - auc_1: 0.9071 - val_loss: 0.4084 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3954 - acc: 0.8261 - auc_1: 0.8960 - val_loss: 0.3866 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3909 - acc: 0.8043 - auc_1: 0.8990 - val_loss: 0.3988 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3838 - acc: 0.8043 - auc_1: 0.9057 - val_loss: 0.4234 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3777 - acc: 0.8370 - auc_1: 0.9086 - val_loss: 0.3739 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3805 - acc: 0.8152 - auc_1: 0.9052 - val_loss: 0.4439 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3812 - acc: 0.8261 - auc_1: 0.9076 - val_loss: 0.4392 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3860 - acc: 0.8152 - auc_1: 0.9005 - val_loss: 0.4451 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3808 - acc: 0.8261 - auc_1: 0.9110 - val_loss: 0.4145 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3700 - acc: 0.8261 - auc_1: 0.9155 - val_loss: 0.3618 - val_acc: 0.8333 - val_auc_1: 0.9250\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3690 - acc: 0.8152 - auc_1: 0.9133 - val_loss: 0.3602 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3772 - acc: 0.8370 - auc_1: 0.9069 - val_loss: 0.4789 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3627 - acc: 0.8043 - auc_1: 0.9219 - val_loss: 0.3730 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3777 - acc: 0.8261 - auc_1: 0.9088 - val_loss: 0.4148 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3726 - acc: 0.8152 - auc_1: 0.9102 - val_loss: 0.4103 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3671 - acc: 0.8261 - auc_1: 0.9136 - val_loss: 0.3937 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3665 - acc: 0.8043 - auc_1: 0.9102 - val_loss: 0.4215 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3833 - acc: 0.8152 - auc_1: 0.9048 - val_loss: 0.4416 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3595 - acc: 0.8261 - auc_1: 0.9202 - val_loss: 0.3842 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3792 - acc: 0.8043 - auc_1: 0.9055 - val_loss: 0.4015 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3694 - acc: 0.8261 - auc_1: 0.9107 - val_loss: 0.4111 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3677 - acc: 0.8370 - auc_1: 0.9150 - val_loss: 0.4459 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 97/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3701 - acc: 0.8370 - auc_1: 0.9083 - val_loss: 0.4010 - val_acc: 0.7917 - val_auc_1: 0.8964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3634 - acc: 0.8370 - auc_1: 0.9148 - val_loss: 0.4062 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3538 - acc: 0.8152 - auc_1: 0.9252 - val_loss: 0.4748 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3666 - acc: 0.8261 - auc_1: 0.9138 - val_loss: 0.4369 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3621 - acc: 0.8043 - auc_1: 0.9145 - val_loss: 0.4700 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3633 - acc: 0.8370 - auc_1: 0.9155 - val_loss: 0.4468 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3545 - acc: 0.8152 - auc_1: 0.9190 - val_loss: 0.4761 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3697 - acc: 0.8261 - auc_1: 0.9110 - val_loss: 0.4475 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3481 - acc: 0.8261 - auc_1: 0.9233 - val_loss: 0.4117 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3637 - acc: 0.8370 - auc_1: 0.9183 - val_loss: 0.4234 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3313 - acc: 0.8587 - auc_1: 0.9319 - val_loss: 0.5440 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3649 - acc: 0.8478 - auc_1: 0.9133 - val_loss: 0.4185 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3630 - acc: 0.8261 - auc_1: 0.9140 - val_loss: 0.4183 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3469 - acc: 0.8152 - auc_1: 0.9262 - val_loss: 0.4772 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3631 - acc: 0.8478 - auc_1: 0.9143 - val_loss: 0.4244 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3448 - acc: 0.8370 - auc_1: 0.9210 - val_loss: 0.4397 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3438 - acc: 0.8152 - auc_1: 0.9202 - val_loss: 0.4761 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3413 - acc: 0.8370 - auc_1: 0.9248 - val_loss: 0.4857 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3575 - acc: 0.8261 - auc_1: 0.9152 - val_loss: 0.5055 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3487 - acc: 0.8261 - auc_1: 0.9238 - val_loss: 0.4367 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3443 - acc: 0.8478 - auc_1: 0.9262 - val_loss: 0.4361 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3409 - acc: 0.8261 - auc_1: 0.9260 - val_loss: 0.4796 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3411 - acc: 0.8043 - auc_1: 0.9274 - val_loss: 0.4327 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3453 - acc: 0.7935 - auc_1: 0.9226 - val_loss: 0.4497 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3448 - acc: 0.8370 - auc_1: 0.9190 - val_loss: 0.4664 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3335 - acc: 0.8587 - auc_1: 0.9338 - val_loss: 0.4827 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3259 - acc: 0.8696 - auc_1: 0.9338 - val_loss: 0.4607 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3554 - acc: 0.8152 - auc_1: 0.9179 - val_loss: 0.4569 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3345 - acc: 0.8370 - auc_1: 0.9276 - val_loss: 0.4634 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3323 - acc: 0.8478 - auc_1: 0.9317 - val_loss: 0.4427 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3226 - acc: 0.8261 - auc_1: 0.9364 - val_loss: 0.5150 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3288 - acc: 0.8478 - auc_1: 0.9336 - val_loss: 0.4637 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3312 - acc: 0.8478 - auc_1: 0.9288 - val_loss: 0.4698 - val_acc: 0.7917 - val_auc_1: 0.8071\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3156 - acc: 0.8696 - auc_1: 0.9395 - val_loss: 0.5356 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3318 - acc: 0.8370 - auc_1: 0.9324 - val_loss: 0.4394 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3257 - acc: 0.8587 - auc_1: 0.9333 - val_loss: 0.4588 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3228 - acc: 0.8370 - auc_1: 0.9340 - val_loss: 0.4652 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3232 - acc: 0.8370 - auc_1: 0.9350 - val_loss: 0.4621 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3244 - acc: 0.8370 - auc_1: 0.9345 - val_loss: 0.4724 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3267 - acc: 0.8261 - auc_1: 0.9312 - val_loss: 0.4749 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3053 - acc: 0.8478 - auc_1: 0.9431 - val_loss: 0.4955 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3244 - acc: 0.8152 - auc_1: 0.9371 - val_loss: 0.4478 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3065 - acc: 0.8587 - auc_1: 0.9400 - val_loss: 0.5111 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3091 - acc: 0.8152 - auc_1: 0.9393 - val_loss: 0.4396 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3250 - acc: 0.8587 - auc_1: 0.9300 - val_loss: 0.4562 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3080 - acc: 0.8696 - auc_1: 0.9412 - val_loss: 0.4948 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2953 - acc: 0.8696 - auc_1: 0.9455 - val_loss: 0.5672 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2971 - acc: 0.8696 - auc_1: 0.9483 - val_loss: 0.5156 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 145/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3021 - acc: 0.8696 - auc_1: 0.9412 - val_loss: 0.5345 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 146/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3040 - acc: 0.8696 - auc_1: 0.9414 - val_loss: 0.4460 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2997 - acc: 0.8587 - auc_1: 0.9436 - val_loss: 0.5152 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2846 - acc: 0.8804 - auc_1: 0.9486 - val_loss: 0.4822 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2825 - acc: 0.8804 - auc_1: 0.9526 - val_loss: 0.4899 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2956 - acc: 0.8696 - auc_1: 0.9457 - val_loss: 0.4665 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2846 - acc: 0.8696 - auc_1: 0.9500 - val_loss: 0.4401 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2844 - acc: 0.9022 - auc_1: 0.9524 - val_loss: 0.4531 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2821 - acc: 0.8587 - auc_1: 0.9545 - val_loss: 0.4850 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2824 - acc: 0.8804 - auc_1: 0.9524 - val_loss: 0.4599 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2716 - acc: 0.8696 - auc_1: 0.9583 - val_loss: 0.4950 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3018 - acc: 0.8478 - auc_1: 0.9464 - val_loss: 0.4422 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2812 - acc: 0.8587 - auc_1: 0.9510 - val_loss: 0.4985 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2636 - acc: 0.8804 - auc_1: 0.9569 - val_loss: 0.4486 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2741 - acc: 0.8696 - auc_1: 0.9555 - val_loss: 0.5463 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2856 - acc: 0.8804 - auc_1: 0.9531 - val_loss: 0.4697 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2696 - acc: 0.8804 - auc_1: 0.9569 - val_loss: 0.4968 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2703 - acc: 0.8587 - auc_1: 0.9574 - val_loss: 0.5515 - val_acc: 0.5417 - val_auc_1: 0.7500\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2712 - acc: 0.8804 - auc_1: 0.9569 - val_loss: 0.5211 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2693 - acc: 0.9022 - auc_1: 0.9555 - val_loss: 0.5454 - val_acc: 0.7083 - val_auc_1: 0.7714\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2847 - acc: 0.8696 - auc_1: 0.9512 - val_loss: 0.5139 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2533 - acc: 0.8804 - auc_1: 0.9600 - val_loss: 0.5063 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2654 - acc: 0.8913 - auc_1: 0.9579 - val_loss: 0.5046 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2511 - acc: 0.8913 - auc_1: 0.9664 - val_loss: 0.5663 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2594 - acc: 0.8696 - auc_1: 0.9586 - val_loss: 0.4425 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2629 - acc: 0.8804 - auc_1: 0.9588 - val_loss: 0.4633 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2517 - acc: 0.9022 - auc_1: 0.9676 - val_loss: 0.4906 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2611 - acc: 0.8587 - auc_1: 0.9576 - val_loss: 0.4605 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2448 - acc: 0.8913 - auc_1: 0.9669 - val_loss: 0.5407 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2571 - acc: 0.8804 - auc_1: 0.9629 - val_loss: 0.4989 - val_acc: 0.6250 - val_auc_1: 0.8000\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2395 - acc: 0.8913 - auc_1: 0.9657 - val_loss: 0.5102 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2648 - acc: 0.8587 - auc_1: 0.9579 - val_loss: 0.5388 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2615 - acc: 0.8804 - auc_1: 0.9602 - val_loss: 0.4756 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2449 - acc: 0.9130 - auc_1: 0.9657 - val_loss: 0.4669 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2413 - acc: 0.9022 - auc_1: 0.9669 - val_loss: 0.5463 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2556 - acc: 0.8696 - auc_1: 0.9595 - val_loss: 0.4920 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2375 - acc: 0.8913 - auc_1: 0.9662 - val_loss: 0.4614 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2333 - acc: 0.9022 - auc_1: 0.9695 - val_loss: 0.5505 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2546 - acc: 0.8696 - auc_1: 0.9598 - val_loss: 0.4803 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2428 - acc: 0.8696 - auc_1: 0.9686 - val_loss: 0.5567 - val_acc: 0.6250 - val_auc_1: 0.8071\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2597 - acc: 0.8587 - auc_1: 0.9579 - val_loss: 0.4815 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2566 - acc: 0.8696 - auc_1: 0.9581 - val_loss: 0.5167 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2475 - acc: 0.8478 - auc_1: 0.9633 - val_loss: 0.5092 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2514 - acc: 0.8804 - auc_1: 0.9602 - val_loss: 0.4597 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2185 - acc: 0.8913 - auc_1: 0.9760 - val_loss: 0.4617 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2439 - acc: 0.8804 - auc_1: 0.9643 - val_loss: 0.4668 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2384 - acc: 0.8696 - auc_1: 0.9655 - val_loss: 0.4802 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2226 - acc: 0.9130 - auc_1: 0.9700 - val_loss: 0.4541 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2238 - acc: 0.9022 - auc_1: 0.9724 - val_loss: 0.5133 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 194/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2316 - acc: 0.9130 - auc_1: 0.9683 - val_loss: 0.4918 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2254 - acc: 0.8696 - auc_1: 0.9698 - val_loss: 0.4687 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2272 - acc: 0.9022 - auc_1: 0.9710 - val_loss: 0.4894 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2580 - acc: 0.8478 - auc_1: 0.9588 - val_loss: 0.4506 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2011 - acc: 0.8913 - auc_1: 0.9757 - val_loss: 0.6216 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2397 - acc: 0.9022 - auc_1: 0.9640 - val_loss: 0.5924 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2210 - acc: 0.8804 - auc_1: 0.9724 - val_loss: 0.6015 - val_acc: 0.6667 - val_auc_1: 0.7714\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2840 - acc: 0.8478 - auc_1: 0.9507 - val_loss: 0.5435 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2382 - acc: 0.8913 - auc_1: 0.9681 - val_loss: 0.4795 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2181 - acc: 0.8913 - auc_1: 0.9731 - val_loss: 0.5574 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2224 - acc: 0.9022 - auc_1: 0.9690 - val_loss: 0.4776 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2036 - acc: 0.9022 - auc_1: 0.9788 - val_loss: 0.5073 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2269 - acc: 0.9022 - auc_1: 0.9702 - val_loss: 0.5061 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2095 - acc: 0.8696 - auc_1: 0.9762 - val_loss: 0.5529 - val_acc: 0.6250 - val_auc_1: 0.7929\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2241 - acc: 0.8913 - auc_1: 0.9721 - val_loss: 0.5329 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2350 - acc: 0.8370 - auc_1: 0.9662 - val_loss: 0.5665 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1972 - acc: 0.9130 - auc_1: 0.9802 - val_loss: 0.4973 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2084 - acc: 0.9130 - auc_1: 0.9752 - val_loss: 0.4977 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2222 - acc: 0.8804 - auc_1: 0.9726 - val_loss: 0.4974 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2046 - acc: 0.9239 - auc_1: 0.9783 - val_loss: 0.5484 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2232 - acc: 0.8804 - auc_1: 0.9705 - val_loss: 0.5125 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2046 - acc: 0.9239 - auc_1: 0.9788 - val_loss: 0.4812 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2226 - acc: 0.8804 - auc_1: 0.9683 - val_loss: 0.5072 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2274 - acc: 0.8804 - auc_1: 0.9698 - val_loss: 0.4797 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2150 - acc: 0.8913 - auc_1: 0.9731 - val_loss: 0.4873 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2105 - acc: 0.9130 - auc_1: 0.9748 - val_loss: 0.5036 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2181 - acc: 0.8913 - auc_1: 0.9743 - val_loss: 0.5810 - val_acc: 0.6250 - val_auc_1: 0.7893\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1886 - acc: 0.9239 - auc_1: 0.9838 - val_loss: 0.5089 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2046 - acc: 0.9348 - auc_1: 0.9745 - val_loss: 0.5175 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2050 - acc: 0.8913 - auc_1: 0.9750 - val_loss: 0.5543 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2040 - acc: 0.8913 - auc_1: 0.9750 - val_loss: 0.5556 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2025 - acc: 0.9239 - auc_1: 0.9755 - val_loss: 0.5377 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2023 - acc: 0.8913 - auc_1: 0.9760 - val_loss: 0.4848 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1903 - acc: 0.9130 - auc_1: 0.9738 - val_loss: 0.6415 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2623 - acc: 0.8261 - auc_1: 0.9557 - val_loss: 0.4891 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2148 - acc: 0.8913 - auc_1: 0.9721 - val_loss: 0.4925 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2020 - acc: 0.9022 - auc_1: 0.9786 - val_loss: 0.4999 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1840 - acc: 0.9130 - auc_1: 0.9800 - val_loss: 0.5162 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1913 - acc: 0.9239 - auc_1: 0.9786 - val_loss: 0.5292 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1969 - acc: 0.8913 - auc_1: 0.9748 - val_loss: 0.6029 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1780 - acc: 0.9130 - auc_1: 0.9860 - val_loss: 0.5364 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2045 - acc: 0.8804 - auc_1: 0.9740 - val_loss: 0.5689 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1926 - acc: 0.9239 - auc_1: 0.9798 - val_loss: 0.6399 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2109 - acc: 0.8696 - auc_1: 0.9726 - val_loss: 0.5508 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1927 - acc: 0.9022 - auc_1: 0.9764 - val_loss: 0.5491 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1932 - acc: 0.9239 - auc_1: 0.9795 - val_loss: 0.5672 - val_acc: 0.6667 - val_auc_1: 0.8179\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1745 - acc: 0.9348 - auc_1: 0.9817 - val_loss: 0.4663 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 241/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1918 - acc: 0.9022 - auc_1: 0.9783 - val_loss: 0.5116 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1855 - acc: 0.9130 - auc_1: 0.9807 - val_loss: 0.5574 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1754 - acc: 0.9130 - auc_1: 0.9814 - val_loss: 0.5611 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1933 - acc: 0.9239 - auc_1: 0.9771 - val_loss: 0.4908 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1762 - acc: 0.9239 - auc_1: 0.9798 - val_loss: 0.5332 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1882 - acc: 0.9239 - auc_1: 0.9814 - val_loss: 0.4718 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1911 - acc: 0.9022 - auc_1: 0.9781 - val_loss: 0.5800 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1945 - acc: 0.8913 - auc_1: 0.9781 - val_loss: 0.5261 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1761 - acc: 0.9130 - auc_1: 0.9829 - val_loss: 0.5279 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1771 - acc: 0.9022 - auc_1: 0.9821 - val_loss: 0.5610 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1763 - acc: 0.9348 - auc_1: 0.9833 - val_loss: 0.5616 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1805 - acc: 0.9022 - auc_1: 0.9800 - val_loss: 0.5807 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2064 - acc: 0.9022 - auc_1: 0.9738 - val_loss: 0.5395 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1866 - acc: 0.9130 - auc_1: 0.9786 - val_loss: 0.5458 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1791 - acc: 0.9239 - auc_1: 0.9807 - val_loss: 0.5735 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1532 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 0.5308 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1925 - acc: 0.8913 - auc_1: 0.9781 - val_loss: 0.5077 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1765 - acc: 0.9239 - auc_1: 0.9798 - val_loss: 0.5297 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1846 - acc: 0.9130 - auc_1: 0.9786 - val_loss: 0.5075 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1629 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 0.4967 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1856 - acc: 0.8913 - auc_1: 0.9786 - val_loss: 0.5135 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1725 - acc: 0.9022 - auc_1: 0.9814 - val_loss: 0.5663 - val_acc: 0.6667 - val_auc_1: 0.8179\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1715 - acc: 0.9348 - auc_1: 0.9817 - val_loss: 0.4924 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1520 - acc: 0.9348 - auc_1: 0.9902 - val_loss: 0.6830 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1832 - acc: 0.9130 - auc_1: 0.9767 - val_loss: 0.6396 - val_acc: 0.6250 - val_auc_1: 0.7964\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1937 - acc: 0.8913 - auc_1: 0.9743 - val_loss: 0.5617 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1741 - acc: 0.9239 - auc_1: 0.9840 - val_loss: 0.6059 - val_acc: 0.6250 - val_auc_1: 0.8071\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1663 - acc: 0.9022 - auc_1: 0.9852 - val_loss: 0.5938 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1741 - acc: 0.9239 - auc_1: 0.9810 - val_loss: 0.5171 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1373 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 0.6937 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1683 - acc: 0.9348 - auc_1: 0.9845 - val_loss: 0.5799 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1712 - acc: 0.9130 - auc_1: 0.9831 - val_loss: 0.6029 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1653 - acc: 0.9457 - auc_1: 0.9881 - val_loss: 0.5101 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1640 - acc: 0.9239 - auc_1: 0.9814 - val_loss: 0.5370 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1594 - acc: 0.9239 - auc_1: 0.9862 - val_loss: 0.6266 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1616 - acc: 0.9348 - auc_1: 0.9869 - val_loss: 0.5652 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1704 - acc: 0.9348 - auc_1: 0.9829 - val_loss: 0.5688 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1860 - acc: 0.9022 - auc_1: 0.9795 - val_loss: 0.5531 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1531 - acc: 0.9239 - auc_1: 0.9869 - val_loss: 0.6344 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1660 - acc: 0.9022 - auc_1: 0.9850 - val_loss: 0.5556 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1647 - acc: 0.9022 - auc_1: 0.9821 - val_loss: 0.7582 - val_acc: 0.6250 - val_auc_1: 0.7786\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1671 - acc: 0.9348 - auc_1: 0.9848 - val_loss: 0.6114 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1772 - acc: 0.9130 - auc_1: 0.9798 - val_loss: 0.5812 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1611 - acc: 0.9348 - auc_1: 0.9852 - val_loss: 0.6195 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1749 - acc: 0.9130 - auc_1: 0.9807 - val_loss: 0.7134 - val_acc: 0.6250 - val_auc_1: 0.7786\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1599 - acc: 0.9022 - auc_1: 0.9850 - val_loss: 0.7426 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1714 - acc: 0.9022 - auc_1: 0.9840 - val_loss: 0.6203 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1505 - acc: 0.9130 - auc_1: 0.9869 - val_loss: 0.5689 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 289/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1510 - acc: 0.9239 - auc_1: 0.9857 - val_loss: 0.5948 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 290/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1532 - acc: 0.9457 - auc_1: 0.9852 - val_loss: 0.6485 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1620 - acc: 0.9130 - auc_1: 0.9848 - val_loss: 0.5797 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1637 - acc: 0.9457 - auc_1: 0.9845 - val_loss: 0.5492 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1524 - acc: 0.9348 - auc_1: 0.9867 - val_loss: 0.6591 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1664 - acc: 0.9022 - auc_1: 0.9829 - val_loss: 0.6450 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1359 - acc: 0.9348 - auc_1: 0.9905 - val_loss: 0.5872 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1497 - acc: 0.9565 - auc_1: 0.9852 - val_loss: 0.6111 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1580 - acc: 0.9239 - auc_1: 0.9852 - val_loss: 0.5570 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1581 - acc: 0.9239 - auc_1: 0.9855 - val_loss: 0.5615 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1578 - acc: 0.9239 - auc_1: 0.9852 - val_loss: 0.5947 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1489 - acc: 0.9348 - auc_1: 0.9874 - val_loss: 0.6196 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1503 - acc: 0.9457 - auc_1: 0.9871 - val_loss: 0.5294 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1565 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.5949 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1482 - acc: 0.9130 - auc_1: 0.9864 - val_loss: 0.5786 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1544 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 0.6470 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1580 - acc: 0.9239 - auc_1: 0.9852 - val_loss: 0.6478 - val_acc: 0.6667 - val_auc_1: 0.8179\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1498 - acc: 0.9130 - auc_1: 0.9888 - val_loss: 0.5477 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.1364 - acc: 0.9348 - auc_1: 0.9900 - val_loss: 0.5617 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1391 - acc: 0.9130 - auc_1: 0.9886 - val_loss: 0.5415 - val_acc: 0.6250 - val_auc_1: 0.8071\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1433 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.6558 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1574 - acc: 0.9348 - auc_1: 0.9852 - val_loss: 0.6787 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1599 - acc: 0.9130 - auc_1: 0.9838 - val_loss: 0.5661 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1291 - acc: 0.9565 - auc_1: 0.9876 - val_loss: 0.5121 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1445 - acc: 0.9565 - auc_1: 0.9874 - val_loss: 0.6589 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2090 - acc: 0.9239 - auc_1: 0.9750 - val_loss: 0.5175 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1658 - acc: 0.9348 - auc_1: 0.9819 - val_loss: 0.4893 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1465 - acc: 0.9239 - auc_1: 0.9876 - val_loss: 0.6154 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1483 - acc: 0.9348 - auc_1: 0.9864 - val_loss: 0.6786 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1402 - acc: 0.9348 - auc_1: 0.9893 - val_loss: 0.6463 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1401 - acc: 0.9348 - auc_1: 0.9900 - val_loss: 0.5518 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1622 - acc: 0.9348 - auc_1: 0.9857 - val_loss: 0.6603 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1719 - acc: 0.9130 - auc_1: 0.9812 - val_loss: 0.5427 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1332 - acc: 0.9457 - auc_1: 0.9898 - val_loss: 0.5813 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1242 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 0.6757 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1411 - acc: 0.9130 - auc_1: 0.9907 - val_loss: 0.7479 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1343 - acc: 0.9348 - auc_1: 0.9895 - val_loss: 0.5569 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1413 - acc: 0.9348 - auc_1: 0.9876 - val_loss: 0.5458 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1328 - acc: 0.9674 - auc_1: 0.9907 - val_loss: 0.5417 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1455 - acc: 0.9348 - auc_1: 0.9867 - val_loss: 0.7188 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1229 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 0.6088 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1262 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 0.6419 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1381 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.5592 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1496 - acc: 0.9239 - auc_1: 0.9838 - val_loss: 0.5663 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1298 - acc: 0.9239 - auc_1: 0.9898 - val_loss: 0.6113 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1222 - acc: 0.9348 - auc_1: 0.9933 - val_loss: 0.5970 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1281 - acc: 0.9565 - auc_1: 0.9910 - val_loss: 0.6544 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1157 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 0.6685 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 337/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1358 - acc: 0.9239 - auc_1: 0.9900 - val_loss: 0.5055 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 338/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1452 - acc: 0.9457 - auc_1: 0.9888 - val_loss: 0.5253 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2138 - acc: 0.9022 - auc_1: 0.9738 - val_loss: 0.5642 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1461 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 0.7652 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1428 - acc: 0.9239 - auc_1: 0.9888 - val_loss: 0.6373 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1237 - acc: 0.9239 - auc_1: 0.9912 - val_loss: 0.6473 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1236 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.6172 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1268 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6071 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1279 - acc: 0.9457 - auc_1: 0.9890 - val_loss: 0.6569 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1225 - acc: 0.9348 - auc_1: 0.9919 - val_loss: 0.7061 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1162 - acc: 0.9783 - auc_1: 0.9926 - val_loss: 0.7066 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1247 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 0.5912 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1274 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.6786 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1450 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 0.8686 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1256 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 0.7458 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1444 - acc: 0.9348 - auc_1: 0.9857 - val_loss: 0.6588 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1271 - acc: 0.9565 - auc_1: 0.9917 - val_loss: 0.5906 - val_acc: 0.6250 - val_auc_1: 0.8214\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1408 - acc: 0.9565 - auc_1: 0.9893 - val_loss: 0.6210 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1171 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 0.6245 - val_acc: 0.6250 - val_auc_1: 0.8286\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1526 - acc: 0.9239 - auc_1: 0.9869 - val_loss: 0.6948 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1047 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.4799 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1325 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 0.6302 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1224 - acc: 0.9348 - auc_1: 0.9905 - val_loss: 0.7086 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1159 - acc: 0.9457 - auc_1: 0.9933 - val_loss: 0.6744 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1065 - acc: 0.9783 - auc_1: 0.9943 - val_loss: 0.7945 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1123 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 0.6919 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1168 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 0.6913 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1281 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.7684 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1159 - acc: 0.9457 - auc_1: 0.9940 - val_loss: 0.5934 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1154 - acc: 0.9674 - auc_1: 0.9921 - val_loss: 0.6640 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1209 - acc: 0.9239 - auc_1: 0.9910 - val_loss: 0.6986 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1045 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 0.8837 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1316 - acc: 0.9565 - auc_1: 0.9917 - val_loss: 0.7498 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1095 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.7727 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1143 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.7608 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1157 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 0.6965 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1040 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 0.7173 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1261 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 0.6407 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0961 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.8181 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1236 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.7460 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1142 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.6891 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1173 - acc: 0.9565 - auc_1: 0.9919 - val_loss: 0.8048 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0993 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.6924 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1248 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 0.7805 - val_acc: 0.6250 - val_auc_1: 0.7929\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1062 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 0.8241 - val_acc: 0.6250 - val_auc_1: 0.8036\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1027 - acc: 0.9457 - auc_1: 0.9957 - val_loss: 0.6701 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0958 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 0.8913 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0939 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.9132 - val_acc: 0.6667 - val_auc_1: 0.8179\n",
      "Epoch 385/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1065 - acc: 0.9565 - auc_1: 0.9943 - val_loss: 0.8068 - val_acc: 0.6250 - val_auc_1: 0.7964\n",
      "Epoch 386/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0947 - acc: 0.9674 - auc_1: 0.9969 - val_loss: 0.7136 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1077 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 0.7814 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1052 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 0.8243 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0973 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.9260 - val_acc: 0.6250 - val_auc_1: 0.7857\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1029 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 0.6333 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1138 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.7645 - val_acc: 0.6250 - val_auc_1: 0.7964\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1083 - acc: 0.9457 - auc_1: 0.9952 - val_loss: 0.8279 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0921 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 0.8446 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0874 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.7675 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1038 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 0.9275 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0967 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.8571 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0790 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8965 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0806 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.8028 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0897 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.9061 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0948 - acc: 0.9565 - auc_1: 0.9955 - val_loss: 0.8457 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0818 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 0.7905 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1066 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 0.8663 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0797 - acc: 0.9565 - auc_1: 0.9986 - val_loss: 0.8327 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0908 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.7673 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0866 - acc: 0.9783 - auc_1: 0.9955 - val_loss: 0.9125 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1083 - acc: 0.9674 - auc_1: 0.9929 - val_loss: 0.8072 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1231 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.8240 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0892 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.9018 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0849 - acc: 0.9891 - auc_1: 0.9976 - val_loss: 0.9904 - val_acc: 0.6250 - val_auc_1: 0.7857\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0989 - acc: 0.9457 - auc_1: 0.9967 - val_loss: 1.0131 - val_acc: 0.6250 - val_auc_1: 0.7893\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0840 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.8815 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0763 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 0.7150 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0780 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.9358 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0753 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.9351 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0900 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 0.7950 - val_acc: 0.7083 - val_auc_1: 0.7714\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0816 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.7964 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0691 - acc: 0.9783 - auc_1: 0.9983 - val_loss: 0.8708 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0849 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.8340 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0649 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.8294 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0751 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.9870 - val_acc: 0.6667 - val_auc_1: 0.7714\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0692 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.0150 - val_acc: 0.6250 - val_auc_1: 0.7750\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0739 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.9766 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0692 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.7709 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0632 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8532 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0597 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.9499 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0707 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7565 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0682 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.8709 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0637 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.9310 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0810 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.9637 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0568 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.0116 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0703 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.9420 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0930 - acc: 0.9457 - auc_1: 0.9957 - val_loss: 0.7306 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 433/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0581 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.9855 - val_acc: 0.6667 - val_auc_1: 0.7750\n",
      "Epoch 434/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0636 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.7931 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0515 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.9110 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0659 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.9741 - val_acc: 0.7083 - val_auc_1: 0.7714\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0575 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.0227 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0652 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7306 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0676 - acc: 0.9540 - auc_1: 0.997 - 1s 7ms/step - loss: 0.0648 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 0.9543 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0525 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 0.8767 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0532 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8916 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0803 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.5793 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0726 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.6762 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0522 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 0.6806 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0580 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7540 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0423 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.9355 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0479 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.7559 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0359 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9038 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0566 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.8019 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0368 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.7998 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0647 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.9379 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0331 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0696 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0801 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.8125 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0646 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8392 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0960 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 1.0502 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0463 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.9292 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0441 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.9026 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0307 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0518 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0283 - acc: 1.0000 - auc_1: 1.000 - 0s 4ms/step - loss: 0.0351 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8579 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0386 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.0030 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0330 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0066 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0338 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0457 - val_acc: 0.7083 - val_auc_1: 0.7643\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0330 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0336 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0299 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8785 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0278 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0142 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0279 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1738 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0381 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.9934 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0298 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0552 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0314 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0444 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0384 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8629 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1024 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 0.9591 - val_acc: 0.6250 - val_auc_1: 0.7679\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0497 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.2101 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0590 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.2089 - val_acc: 0.7083 - val_auc_1: 0.7714\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0235 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2379 - val_acc: 0.6667 - val_auc_1: 0.7679\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0236 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1744 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0165 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3195 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0311 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.2952 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0373 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.4086 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0255 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3709 - val_acc: 0.6667 - val_auc_1: 0.7536\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0175 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2354 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 481/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0213 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1927 - val_acc: 0.7083 - val_auc_1: 0.7643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0156 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2287 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0174 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2291 - val_acc: 0.7083 - val_auc_1: 0.7393\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0161 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3130 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0171 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1820 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0161 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2649 - val_acc: 0.7083 - val_auc_1: 0.7357\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0211 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4911 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0119 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3440 - val_acc: 0.7083 - val_auc_1: 0.7357\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0181 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2003 - val_acc: 0.7083 - val_auc_1: 0.7429\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0170 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4033 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0120 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2498 - val_acc: 0.7083 - val_auc_1: 0.7393\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0215 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1947 - val_acc: 0.7083 - val_auc_1: 0.7643\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0343 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 1.6484 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3484 - acc: 0.9130 - auc_1: 0.9495 - val_loss: 0.4153 - val_acc: 0.8333 - val_auc_1: 0.9250\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0530 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.3226 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0156 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1231 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0134 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1910 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0130 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1464 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0120 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1883 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0110 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1572 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0106 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1775 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2285 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0094 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2236 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1833 - val_acc: 0.7500 - val_auc_1: 0.7464\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1860 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0104 - acc: 1.0000 - auc_1: 1.000 - 0s 5ms/step - loss: 0.0103 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0946 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1853 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2584 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2506 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0111 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1833 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1645 - val_acc: 0.7500 - val_auc_1: 0.7536\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0088 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1531 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1733 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2334 - val_acc: 0.7500 - val_auc_1: 0.7464\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0462 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0106 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3777 - val_acc: 0.7083 - val_auc_1: 0.7393\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3014 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2994 - val_acc: 0.7083 - val_auc_1: 0.7607\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2570 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3183 - val_acc: 0.7083 - val_auc_1: 0.7393\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2975 - val_acc: 0.7083 - val_auc_1: 0.7393\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2315 - val_acc: 0.7500 - val_auc_1: 0.7464\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2499 - val_acc: 0.7500 - val_auc_1: 0.7464\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2977 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3095 - val_acc: 0.7083 - val_auc_1: 0.7393\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3417 - val_acc: 0.7083 - val_auc_1: 0.7393\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0132 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7011 - val_acc: 0.7083 - val_auc_1: 0.7179\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3988 - acc: 0.8913 - auc_1: 0.9419 - val_loss: 1.0884 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 529/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1062 - acc: 0.9457 - auc_1: 0.9952 - val_loss: 1.6363 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 530/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0222 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4687 - val_acc: 0.6667 - val_auc_1: 0.7429\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3747 - val_acc: 0.6667 - val_auc_1: 0.7571\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3552 - val_acc: 0.6667 - val_auc_1: 0.7607\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3603 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3313 - val_acc: 0.6667 - val_auc_1: 0.7679\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3245 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2973 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3238 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3171 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3086 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3074 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3175 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3072 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3147 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3258 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3201 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3171 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3488 - val_acc: 0.7500 - val_auc_1: 0.7607\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3277 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3139 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3148 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3103 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3302 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3474 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3221 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3394 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3762 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3386 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3795 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3643 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3812 - val_acc: 0.7500 - val_auc_1: 0.7607\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4058 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4076 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4055 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3563 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3833 - val_acc: 0.7500 - val_auc_1: 0.7536\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4427 - val_acc: 0.7500 - val_auc_1: 0.7429\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4728 - val_acc: 0.7500 - val_auc_1: 0.7464\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3696 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3919 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3777 - val_acc: 0.7500 - val_auc_1: 0.7536\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4296 - val_acc: 0.7500 - val_auc_1: 0.7500\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4999 - val_acc: 0.7500 - val_auc_1: 0.7143\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2486 - val_acc: 0.7500 - val_auc_1: 0.7821\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0278 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.9025 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2467 - acc: 0.9239 - auc_1: 0.9724 - val_loss: 1.0815 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1194 - acc: 0.9674 - auc_1: 0.9845 - val_loss: 0.9423 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 577/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0651 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.1830 - val_acc: 0.8333 - val_auc_1: 0.7964\n",
      "Epoch 578/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0155 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1214 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1131 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1164 - val_acc: 0.7500 - val_auc_1: 0.7821\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1050 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1224 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1201 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1219 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1299 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1353 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1383 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1520 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1716 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1816 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1853 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2003 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1894 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2062 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2109 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2143 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2147 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2348 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2439 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2505 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2533 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2482 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2733 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2606 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2702 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2910 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2834 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2646 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3177 - val_acc: 0.7500 - val_auc_1: 0.7821\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2987 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3168 - val_acc: 0.7500 - val_auc_1: 0.7821\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3392 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3366 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3587 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3792 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3342 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3893 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3675 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3913 - val_acc: 0.7500 - val_auc_1: 0.7821\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3825 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3989 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4258 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4204 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4415 - val_acc: 0.7500 - val_auc_1: 0.7607\n",
      "Epoch 625/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4690 - val_acc: 0.7500 - val_auc_1: 0.7607\n",
      "Epoch 626/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4411 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4701 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.5738e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4516 - val_acc: 0.7500 - val_auc_1: 0.7607\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.6017e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4362 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.3109e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4642 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.4726e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4803 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.4491e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5048 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.7662e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5157 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.8556e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4966 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.1002e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4850 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.8094e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5309 - val_acc: 0.7500 - val_auc_1: 0.7536\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.0962e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5568 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.8787e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5628 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.4918e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5640 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.5170e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6042 - val_acc: 0.7500 - val_auc_1: 0.7536\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.9797e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6207 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.6792e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5356 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6246 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2462 - acc: 0.9130 - auc_1: 0.9845 - val_loss: 1.0115 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1036 - acc: 0.9674 - auc_1: 0.9960 - val_loss: 0.7447 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0735 - acc: 0.9891 - auc_1: 0.9867 - val_loss: 1.2920 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2723 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2608 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2617 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2590 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2600 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2664 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2637 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2663 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2645 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.6613e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2638 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 9.5190e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2641 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 9.2139e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2745 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.0647e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2814 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.7722e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2809 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.5660e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2854 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.3724e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2815 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 8.3277e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2935 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.2460e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2971 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.0434e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2982 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.7436e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3038 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.5658e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3123 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.6446e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3144 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.3758e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3191 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.1635e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3123 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.0393e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3236 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.9423e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3251 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 673/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.8513e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3331 - val_acc: 0.7500 - val_auc_1: 0.7964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 674/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.6887e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3432 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.6598e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3484 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.4711e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3405 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.4545e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3497 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.1842e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3652 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.2444e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3641 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.9422e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3746 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.0362e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3646 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.8653e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3656 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.8811e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3794 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.5670e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3955 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.5781e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3781 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.5832e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4090 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.2876e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4233 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.2463e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4174 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.0452e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4133 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.0215e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4285 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 5.0533e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4628 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.9525e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4465 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 4.8708e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4656 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 4.6463e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4388 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.6509e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4797 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.5359e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4828 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.5313e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4489 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.4078e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5004 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.3125e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4678 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4.2983e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5152 - val_acc: 0.7083 - val_auc_1: 0.7893\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5, X6, X7, X8], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.11047665,  2.0753841 ,  0.03018923, -1.5484679 ,  0.17149904,\n",
      "        -0.07472192, -0.59424573,  0.65693545, -0.39313248],\n",
      "       [-0.37748563, -0.62340385, -0.25698486, -0.16568704,  1.1133446 ,\n",
      "        -0.6710895 ,  2.790142  , -1.5015608 ,  0.08242103],\n",
      "       [ 0.46166742, -0.07402916,  1.1335173 ,  0.5076177 , -0.6003938 ,\n",
      "        -0.44103456,  0.16447042, -0.6040523 , -0.0946009 ],\n",
      "       [-1.9799584 ,  1.8385764 , -2.2508314 ,  2.589592  , -2.4997993 ,\n",
      "         2.1759813 , -0.00947241, -0.22048865,  0.967752  ],\n",
      "       [-1.3375978 ,  0.08171265, -0.98298496, -0.69924927, -1.0858915 ,\n",
      "         1.379075  , -0.2112374 , -0.8188787 ,  1.5200362 ],\n",
      "       [ 0.6818679 , -0.3549123 , -0.38143793,  2.1019487 ,  0.5173405 ,\n",
      "        -1.2119459 , -0.09994353,  0.57335055,  1.4363058 ],\n",
      "       [ 0.56871   , -0.39957538, -0.3564451 ,  0.6329253 , -0.1694097 ,\n",
      "         0.28638726, -0.9833265 , -0.5724897 , -0.3539923 ],\n",
      "       [ 1.3435671 , -0.06477709, -0.03414082,  1.7671821 ,  1.6962906 ,\n",
      "        -1.1288894 , -0.07138483,  0.9125133 ,  0.7722216 ]],\n",
      "      dtype=float32), array([ 0.12861076, -0.19359495,  0.161465  , -0.5253926 ,  0.2041561 ,\n",
      "       -0.09593739, -0.13173553,  0.15072794, -0.26399675], dtype=float32), array([[ 0.4538797 ,  0.21710986,  2.1941366 , -0.8660759 ,  0.47651327,\n",
      "         2.3110561 ,  2.3501892 ,  1.5076715 ,  1.7129288 ],\n",
      "       [ 0.14164557,  0.33030644, -0.8386808 ,  0.1302501 , -1.3477407 ,\n",
      "         0.60342836, -0.42002106,  0.04399706, -1.8849815 ],\n",
      "       [ 0.49864244, -1.609784  ,  1.1629668 , -0.44084737, -1.2706145 ,\n",
      "         1.0331081 ,  2.6324656 , -0.9069864 ,  1.119578  ],\n",
      "       [-1.239554  , -1.2075799 ,  1.4523362 , -1.476255  ,  0.6122213 ,\n",
      "        -0.30604905, -1.634651  ,  4.6045995 , -0.5700004 ],\n",
      "       [ 0.01407563,  1.1109962 ,  1.6512626 ,  3.2141616 , -0.03241792,\n",
      "         1.2652339 ,  0.21527563, -0.9454129 ,  1.9976934 ],\n",
      "       [-0.01074025,  0.36122593, -1.7738483 , -1.3191358 ,  0.57303363,\n",
      "        -2.0446703 , -0.26204482,  0.85026187, -1.700446  ],\n",
      "       [-1.6328161 , -0.41971448,  0.860666  ,  1.557904  , -0.60090417,\n",
      "        -0.62220573, -1.4523084 , -2.5673082 ,  0.63511485],\n",
      "       [ 1.0406166 ,  0.40559593,  0.30791143,  1.0143614 , -0.27891767,\n",
      "         0.752225  , -0.08220156,  1.549741  , -0.42788848],\n",
      "       [-0.91069317, -1.447782  , -0.56754816,  0.28449   ,  0.92596555,\n",
      "         0.2863406 , -1.1669803 ,  0.91579413, -0.9373957 ]],\n",
      "      dtype=float32), array([ 0.0101891 ,  0.13599706, -0.16327415, -0.48475236, -0.14165226,\n",
      "       -0.24155119,  0.2401023 , -0.6186716 ,  0.06655525], dtype=float32), array([[ 0.47506663,  1.0345912 ,  1.1095436 , -1.28197   , -1.2738172 ,\n",
      "         1.3459629 ,  1.6029515 , -0.3942254 , -0.9757509 ],\n",
      "       [ 0.12311313,  1.7264737 ,  0.75292456, -1.9013537 , -0.46926406,\n",
      "        -0.6429631 , -0.48222405, -0.8479718 , -0.7694608 ],\n",
      "       [ 1.283618  , -0.21387884,  0.6593485 , -0.6412773 ,  0.4797389 ,\n",
      "         0.99482954, -1.3730181 , -1.398566  , -0.6504761 ],\n",
      "       [-0.42104787, -0.8357993 , -1.1604396 , -0.09116445, -3.1364913 ,\n",
      "        -1.7692944 , -1.2645772 ,  1.2042023 ,  1.1928855 ],\n",
      "       [ 2.5516312 , -2.341503  , -0.6206154 , -0.4579243 ,  1.4714276 ,\n",
      "        -1.5522317 ,  0.66176677,  0.8315529 ,  0.89578277],\n",
      "       [ 0.57342976, -1.0605593 , -0.5047357 ,  1.6571591 , -2.8245041 ,\n",
      "         0.25286388, -0.37654632,  0.5318883 ,  0.5169552 ],\n",
      "       [ 1.9718999 , -2.1458337 , -0.8521515 ,  0.38463417,  1.1103446 ,\n",
      "         0.35442364, -3.0587878 ,  1.1452417 ,  0.69504863],\n",
      "       [-1.9912882 , -0.63676363,  0.5805525 , -1.2491009 , -0.3488083 ,\n",
      "         1.8810998 ,  3.533938  , -0.9451336 , -0.6982667 ],\n",
      "       [ 2.4096227 ,  0.5759575 ,  1.3692436 , -1.0870779 ,  2.054172  ,\n",
      "         0.70519614, -3.0177867 , -0.9191106 , -1.300253  ]],\n",
      "      dtype=float32), array([-0.35701618,  0.27676153,  0.25940895, -0.17575169, -0.13097386,\n",
      "        0.14100963, -0.01117768, -0.31170443, -0.23962793], dtype=float32), array([[-2.1287594],\n",
      "       [-3.302966 ],\n",
      "       [-4.562121 ],\n",
      "       [ 3.3675883],\n",
      "       [-2.061475 ],\n",
      "       [-3.0756822],\n",
      "       [ 2.7888787],\n",
      "       [ 3.1492631],\n",
      "       [ 4.071694 ]], dtype=float32), array([-0.11616697], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.53608867e-04]\n",
      " [9.99912858e-01]\n",
      " [9.99773920e-01]\n",
      " [1.81082112e-04]\n",
      " [6.54138043e-04]\n",
      " [9.99995589e-01]\n",
      " [9.99875188e-01]\n",
      " [1.00000000e+00]\n",
      " [9.98507440e-01]\n",
      " [9.99433935e-01]\n",
      " [2.06841669e-05]\n",
      " [9.95177470e-06]\n",
      " [9.99999642e-01]\n",
      " [2.77314225e-08]\n",
      " [9.07506852e-04]\n",
      " [1.00000000e+00]\n",
      " [1.00277221e-05]\n",
      " [9.99829531e-01]\n",
      " [9.99997020e-01]\n",
      " [9.99986053e-01]\n",
      " [1.05765004e-07]\n",
      " [4.04327061e-09]\n",
      " [1.17274548e-03]\n",
      " [9.99909401e-01]\n",
      " [9.99858379e-01]\n",
      " [9.99998450e-01]\n",
      " [9.99985099e-01]\n",
      " [9.99998331e-01]\n",
      " [1.95409739e-05]\n",
      " [1.00000000e+00]\n",
      " [6.01720940e-09]\n",
      " [7.22129198e-06]\n",
      " [4.05679430e-06]\n",
      " [5.24513634e-05]\n",
      " [1.46580144e-08]\n",
      " [9.99999762e-01]\n",
      " [1.00000000e+00]\n",
      " [9.98088658e-01]\n",
      " [9.99992609e-01]\n",
      " [9.99995112e-01]\n",
      " [9.99548137e-01]\n",
      " [1.00000000e+00]\n",
      " [1.23533956e-03]\n",
      " [6.10768388e-04]\n",
      " [4.32194611e-07]\n",
      " [9.97468829e-01]\n",
      " [9.97586250e-01]\n",
      " [9.99656439e-01]\n",
      " [9.99847054e-01]\n",
      " [1.00091956e-05]\n",
      " [1.43463126e-06]\n",
      " [9.99135673e-01]\n",
      " [1.33401099e-05]\n",
      " [5.82997163e-05]\n",
      " [7.68588507e-05]\n",
      " [4.63571014e-05]\n",
      " [3.04301807e-06]\n",
      " [1.00000000e+00]\n",
      " [4.14950279e-08]\n",
      " [7.73701526e-04]\n",
      " [2.05930206e-03]\n",
      " [9.99974132e-01]\n",
      " [9.96710896e-01]\n",
      " [9.99826610e-01]\n",
      " [4.44696404e-08]\n",
      " [1.17599178e-04]\n",
      " [2.58745104e-06]\n",
      " [9.99994755e-01]\n",
      " [1.93878025e-09]\n",
      " [8.24416522e-04]\n",
      " [1.87369401e-03]\n",
      " [9.99985218e-01]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [9.99999523e-01]\n",
      " [1.10534811e-03]\n",
      " [9.99734223e-01]\n",
      " [5.85924226e-07]\n",
      " [9.99941468e-01]\n",
      " [2.53803682e-06]\n",
      " [1.18976436e-03]\n",
      " [8.41435627e-04]\n",
      " [9.99814093e-01]\n",
      " [9.99998093e-01]\n",
      " [9.99950171e-01]\n",
      " [9.99460518e-01]\n",
      " [9.99576747e-01]\n",
      " [1.00000000e+00]\n",
      " [1.52743922e-03]\n",
      " [9.99995947e-01]\n",
      " [9.98509228e-01]\n",
      " [9.99994397e-01]\n",
      " [6.24880083e-02]\n",
      " [1.75689068e-02]\n",
      " [4.40561771e-01]\n",
      " [4.29795218e-05]\n",
      " [3.01557392e-01]\n",
      " [9.99915242e-01]\n",
      " [9.99911547e-01]\n",
      " [9.99982238e-01]\n",
      " [5.41840494e-03]\n",
      " [2.15681926e-08]\n",
      " [9.99999881e-01]\n",
      " [1.00000000e+00]\n",
      " [2.67139107e-01]\n",
      " [1.00000000e+00]\n",
      " [1.12914167e-08]\n",
      " [2.20904360e-03]\n",
      " [1.00000000e+00]\n",
      " [2.57815791e-05]\n",
      " [9.99907255e-01]\n",
      " [4.07020748e-03]\n",
      " [1.00000000e+00]\n",
      " [9.98568773e-01]\n",
      " [4.21678618e-04]\n",
      " [9.74538267e-01]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5, X6, X7, X8])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
