{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,5:6] #Leptin\n",
    "X2 = dataset[:,6:7] #Adiponectin\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 2)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            27          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 217\n",
      "Trainable params: 217\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.7007 - acc: 0.4891 - auc_1: 0.4510 - val_loss: 0.6820 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6951 - acc: 0.5326 - auc_1: 0.3836 - val_loss: 0.6808 - val_acc: 0.5833 - val_auc_1: 0.5929\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6954 - acc: 0.5435 - auc_1: 0.3857 - val_loss: 0.6813 - val_acc: 0.5833 - val_auc_1: 0.4929\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.5435 - auc_1: 0.3836 - val_loss: 0.6817 - val_acc: 0.5833 - val_auc_1: 0.4679\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6933 - acc: 0.5435 - auc_1: 0.3881 - val_loss: 0.6823 - val_acc: 0.5833 - val_auc_1: 0.4643\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6937 - acc: 0.5326 - auc_1: 0.4357 - val_loss: 0.6825 - val_acc: 0.5833 - val_auc_1: 0.4321\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6945 - acc: 0.5326 - auc_1: 0.4345 - val_loss: 0.6840 - val_acc: 0.5833 - val_auc_1: 0.4464\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.5435 - auc_1: 0.3962 - val_loss: 0.6844 - val_acc: 0.5833 - val_auc_1: 0.4643\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6934 - acc: 0.5435 - auc_1: 0.4533 - val_loss: 0.6838 - val_acc: 0.5833 - val_auc_1: 0.4857\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.5435 - auc_1: 0.3921 - val_loss: 0.6837 - val_acc: 0.5833 - val_auc_1: 0.4607\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.5435 - auc_1: 0.4221 - val_loss: 0.6844 - val_acc: 0.5833 - val_auc_1: 0.4643\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6919 - acc: 0.5435 - auc_1: 0.4667 - val_loss: 0.6836 - val_acc: 0.5833 - val_auc_1: 0.4393\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6923 - acc: 0.5435 - auc_1: 0.4700 - val_loss: 0.6835 - val_acc: 0.5833 - val_auc_1: 0.3929\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6927 - acc: 0.5435 - auc_1: 0.4119 - val_loss: 0.6841 - val_acc: 0.5833 - val_auc_1: 0.4429\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6934 - acc: 0.5435 - auc_1: 0.4381 - val_loss: 0.6842 - val_acc: 0.5833 - val_auc_1: 0.4286\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6920 - acc: 0.5435 - auc_1: 0.4164 - val_loss: 0.6842 - val_acc: 0.5833 - val_auc_1: 0.4750\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.5435 - auc_1: 0.4471 - val_loss: 0.6838 - val_acc: 0.5833 - val_auc_1: 0.3929\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6916 - acc: 0.5435 - auc_1: 0.4643 - val_loss: 0.6843 - val_acc: 0.5833 - val_auc_1: 0.4107\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.5435 - auc_1: 0.4417 - val_loss: 0.6841 - val_acc: 0.5833 - val_auc_1: 0.4214\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.6929 - acc: 0.5325 - auc_1: 0.4919     - 0s 3ms/step - loss: 0.6919 - acc: 0.5435 - auc_1: 0.4581 - val_loss: 0.6844 - val_acc: 0.5833 - val_auc_1: 0.4643\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.5435 - auc_1: 0.4445 - val_loss: 0.6850 - val_acc: 0.5833 - val_auc_1: 0.3929\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6920 - acc: 0.5435 - auc_1: 0.4398 - val_loss: 0.6847 - val_acc: 0.5833 - val_auc_1: 0.4464\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.5435 - auc_1: 0.4405 - val_loss: 0.6848 - val_acc: 0.5833 - val_auc_1: 0.4179\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6919 - acc: 0.5435 - auc_1: 0.4110 - val_loss: 0.6840 - val_acc: 0.5833 - val_auc_1: 0.4607\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 0.5435 - auc_1: 0.4712 - val_loss: 0.6841 - val_acc: 0.5833 - val_auc_1: 0.4000\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6909 - acc: 0.5435 - auc_1: 0.4548 - val_loss: 0.6845 - val_acc: 0.5833 - val_auc_1: 0.4393\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6911 - acc: 0.5435 - auc_1: 0.4357 - val_loss: 0.6841 - val_acc: 0.5833 - val_auc_1: 0.4321\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6919 - acc: 0.5435 - auc_1: 0.4405 - val_loss: 0.6843 - val_acc: 0.5833 - val_auc_1: 0.4321\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 0.5435 - auc_1: 0.4179 - val_loss: 0.6841 - val_acc: 0.5833 - val_auc_1: 0.4036\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6917 - acc: 0.5435 - auc_1: 0.4602 - val_loss: 0.6850 - val_acc: 0.5833 - val_auc_1: 0.4321\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6914 - acc: 0.5435 - auc_1: 0.4488 - val_loss: 0.6843 - val_acc: 0.5833 - val_auc_1: 0.4464\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6906 - acc: 0.5435 - auc_1: 0.4748 - val_loss: 0.6845 - val_acc: 0.5833 - val_auc_1: 0.4214\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6914 - acc: 0.5435 - auc_1: 0.4802 - val_loss: 0.6845 - val_acc: 0.5833 - val_auc_1: 0.3750\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.5435 - auc_1: 0.4645 - val_loss: 0.6845 - val_acc: 0.5833 - val_auc_1: 0.4071\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6910 - acc: 0.5435 - auc_1: 0.4581 - val_loss: 0.6841 - val_acc: 0.5833 - val_auc_1: 0.4286\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6919 - acc: 0.5435 - auc_1: 0.4479 - val_loss: 0.6845 - val_acc: 0.5833 - val_auc_1: 0.4107\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6911 - acc: 0.5435 - auc_1: 0.4724 - val_loss: 0.6844 - val_acc: 0.5833 - val_auc_1: 0.3786\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6896 - acc: 0.5435 - auc_1: 0.5176 - val_loss: 0.6858 - val_acc: 0.5833 - val_auc_1: 0.3536\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 0.5217 - auc_1: 0.4890 - val_loss: 0.6848 - val_acc: 0.5833 - val_auc_1: 0.4000\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6887 - acc: 0.5543 - auc_1: 0.4843 - val_loss: 0.6845 - val_acc: 0.5833 - val_auc_1: 0.4536\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6894 - acc: 0.5326 - auc_1: 0.5048 - val_loss: 0.6856 - val_acc: 0.5833 - val_auc_1: 0.4071\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6898 - acc: 0.5217 - auc_1: 0.4974 - val_loss: 0.6854 - val_acc: 0.5833 - val_auc_1: 0.3607\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6888 - acc: 0.5435 - auc_1: 0.4957 - val_loss: 0.6867 - val_acc: 0.5833 - val_auc_1: 0.3786\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6906 - acc: 0.5435 - auc_1: 0.5062 - val_loss: 0.6863 - val_acc: 0.5833 - val_auc_1: 0.4071\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6875 - acc: 0.5652 - auc_1: 0.5033 - val_loss: 0.6887 - val_acc: 0.5417 - val_auc_1: 0.4321\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6861 - acc: 0.5435 - auc_1: 0.5552 - val_loss: 0.6881 - val_acc: 0.5833 - val_auc_1: 0.4071\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6853 - acc: 0.5435 - auc_1: 0.5588 - val_loss: 0.6900 - val_acc: 0.6250 - val_auc_1: 0.4179\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6849 - acc: 0.5543 - auc_1: 0.5486 - val_loss: 0.6896 - val_acc: 0.6250 - val_auc_1: 0.4357\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6845 - acc: 0.5543 - auc_1: 0.5476 - val_loss: 0.6923 - val_acc: 0.6250 - val_auc_1: 0.4214\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6847 - acc: 0.5435 - auc_1: 0.5564 - val_loss: 0.6917 - val_acc: 0.6250 - val_auc_1: 0.4286\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6862 - acc: 0.5543 - auc_1: 0.5410 - val_loss: 0.6902 - val_acc: 0.6667 - val_auc_1: 0.4071\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6852 - acc: 0.5543 - auc_1: 0.5526 - val_loss: 0.6954 - val_acc: 0.5833 - val_auc_1: 0.4214\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6831 - acc: 0.5435 - auc_1: 0.5640 - val_loss: 0.6974 - val_acc: 0.5000 - val_auc_1: 0.4357\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6821 - acc: 0.5543 - auc_1: 0.5645 - val_loss: 0.6989 - val_acc: 0.5417 - val_auc_1: 0.4214\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6825 - acc: 0.5761 - auc_1: 0.5705 - val_loss: 0.7005 - val_acc: 0.5000 - val_auc_1: 0.4286\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6826 - acc: 0.5652 - auc_1: 0.5643 - val_loss: 0.6963 - val_acc: 0.5417 - val_auc_1: 0.4286\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6823 - acc: 0.5326 - auc_1: 0.5740 - val_loss: 0.6995 - val_acc: 0.5000 - val_auc_1: 0.4464\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6803 - acc: 0.5652 - auc_1: 0.5862 - val_loss: 0.6997 - val_acc: 0.5000 - val_auc_1: 0.4429\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6817 - acc: 0.5543 - auc_1: 0.5698 - val_loss: 0.7004 - val_acc: 0.5000 - val_auc_1: 0.4536\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6790 - acc: 0.5870 - auc_1: 0.5819 - val_loss: 0.7014 - val_acc: 0.5000 - val_auc_1: 0.4536\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6798 - acc: 0.5761 - auc_1: 0.5757 - val_loss: 0.7031 - val_acc: 0.5000 - val_auc_1: 0.4500\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6785 - acc: 0.5652 - auc_1: 0.5843 - val_loss: 0.7060 - val_acc: 0.5417 - val_auc_1: 0.4500\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6778 - acc: 0.5652 - auc_1: 0.5855 - val_loss: 0.7046 - val_acc: 0.5000 - val_auc_1: 0.4536\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6763 - acc: 0.5652 - auc_1: 0.5962 - val_loss: 0.7054 - val_acc: 0.5000 - val_auc_1: 0.4357\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6769 - acc: 0.5870 - auc_1: 0.5860 - val_loss: 0.7036 - val_acc: 0.5000 - val_auc_1: 0.4214\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6789 - acc: 0.5652 - auc_1: 0.5855 - val_loss: 0.7079 - val_acc: 0.5417 - val_auc_1: 0.4500\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6771 - acc: 0.5543 - auc_1: 0.5952 - val_loss: 0.7053 - val_acc: 0.5000 - val_auc_1: 0.4429\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6773 - acc: 0.5543 - auc_1: 0.5924 - val_loss: 0.7052 - val_acc: 0.5000 - val_auc_1: 0.4500\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6769 - acc: 0.5870 - auc_1: 0.5821 - val_loss: 0.7079 - val_acc: 0.5000 - val_auc_1: 0.4536\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6747 - acc: 0.5652 - auc_1: 0.5993 - val_loss: 0.7111 - val_acc: 0.5417 - val_auc_1: 0.4500\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6712 - acc: 0.5870 - auc_1: 0.6033 - val_loss: 0.7083 - val_acc: 0.5000 - val_auc_1: 0.4429\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6736 - acc: 0.5761 - auc_1: 0.6052 - val_loss: 0.7100 - val_acc: 0.5000 - val_auc_1: 0.4357\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6764 - acc: 0.5870 - auc_1: 0.5919 - val_loss: 0.7185 - val_acc: 0.4583 - val_auc_1: 0.4607\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6688 - acc: 0.5543 - auc_1: 0.6176 - val_loss: 0.7118 - val_acc: 0.5000 - val_auc_1: 0.4357\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6736 - acc: 0.5870 - auc_1: 0.6045 - val_loss: 0.7139 - val_acc: 0.5417 - val_auc_1: 0.4500\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6707 - acc: 0.5870 - auc_1: 0.6064 - val_loss: 0.7197 - val_acc: 0.4167 - val_auc_1: 0.4679\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6747 - acc: 0.5543 - auc_1: 0.5952 - val_loss: 0.7198 - val_acc: 0.4167 - val_auc_1: 0.4679\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6689 - acc: 0.5761 - auc_1: 0.6169 - val_loss: 0.7216 - val_acc: 0.4583 - val_auc_1: 0.4679\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6705 - acc: 0.5435 - auc_1: 0.6133 - val_loss: 0.7235 - val_acc: 0.4167 - val_auc_1: 0.4643\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6697 - acc: 0.5543 - auc_1: 0.6048 - val_loss: 0.7245 - val_acc: 0.4167 - val_auc_1: 0.4607\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6678 - acc: 0.5652 - auc_1: 0.6152 - val_loss: 0.7220 - val_acc: 0.4167 - val_auc_1: 0.4500\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6682 - acc: 0.5761 - auc_1: 0.6107 - val_loss: 0.7233 - val_acc: 0.4167 - val_auc_1: 0.4679\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6729 - acc: 0.5652 - auc_1: 0.6007 - val_loss: 0.7220 - val_acc: 0.3750 - val_auc_1: 0.4679\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6681 - acc: 0.5978 - auc_1: 0.6183 - val_loss: 0.7253 - val_acc: 0.3750 - val_auc_1: 0.4643\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6616 - acc: 0.6087 - auc_1: 0.6295 - val_loss: 0.7225 - val_acc: 0.3750 - val_auc_1: 0.4286\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6694 - acc: 0.5652 - auc_1: 0.6160 - val_loss: 0.7204 - val_acc: 0.3750 - val_auc_1: 0.4464\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6645 - acc: 0.5978 - auc_1: 0.6145 - val_loss: 0.7268 - val_acc: 0.3750 - val_auc_1: 0.4714\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6662 - acc: 0.5761 - auc_1: 0.6117 - val_loss: 0.7277 - val_acc: 0.3750 - val_auc_1: 0.4750\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.6585 - acc: 0.5765 - auc_1: 0.634 - 0s 4ms/step - loss: 0.6627 - acc: 0.5543 - auc_1: 0.6214 - val_loss: 0.7318 - val_acc: 0.3333 - val_auc_1: 0.4571\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6666 - acc: 0.5870 - auc_1: 0.6064 - val_loss: 0.7245 - val_acc: 0.3750 - val_auc_1: 0.4714\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6629 - acc: 0.6196 - auc_1: 0.6293 - val_loss: 0.7257 - val_acc: 0.3750 - val_auc_1: 0.4571\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6602 - acc: 0.6196 - auc_1: 0.6243 - val_loss: 0.7362 - val_acc: 0.2917 - val_auc_1: 0.4536\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6608 - acc: 0.5652 - auc_1: 0.6279 - val_loss: 0.7210 - val_acc: 0.3750 - val_auc_1: 0.4536\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6611 - acc: 0.6087 - auc_1: 0.6302 - val_loss: 0.7313 - val_acc: 0.3750 - val_auc_1: 0.4536\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6597 - acc: 0.5870 - auc_1: 0.6307 - val_loss: 0.7329 - val_acc: 0.4167 - val_auc_1: 0.4571\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6610 - acc: 0.5761 - auc_1: 0.6250 - val_loss: 0.7316 - val_acc: 0.4167 - val_auc_1: 0.4607\n",
      "Epoch 97/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6585 - acc: 0.6196 - auc_1: 0.6352 - val_loss: 0.7331 - val_acc: 0.3333 - val_auc_1: 0.4607\n",
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6589 - acc: 0.6087 - auc_1: 0.6312 - val_loss: 0.7307 - val_acc: 0.3333 - val_auc_1: 0.4607\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6579 - acc: 0.5870 - auc_1: 0.6240 - val_loss: 0.7289 - val_acc: 0.4167 - val_auc_1: 0.4571\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6616 - acc: 0.5761 - auc_1: 0.6195 - val_loss: 0.7275 - val_acc: 0.3333 - val_auc_1: 0.4643\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6538 - acc: 0.5543 - auc_1: 0.6343 - val_loss: 0.7214 - val_acc: 0.3750 - val_auc_1: 0.4607\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6554 - acc: 0.5217 - auc_1: 0.6150 - val_loss: 0.7289 - val_acc: 0.3333 - val_auc_1: 0.4750\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6565 - acc: 0.5870 - auc_1: 0.6343 - val_loss: 0.7271 - val_acc: 0.3333 - val_auc_1: 0.4786\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6561 - acc: 0.6087 - auc_1: 0.6310 - val_loss: 0.7265 - val_acc: 0.3750 - val_auc_1: 0.4821\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6552 - acc: 0.5543 - auc_1: 0.6169 - val_loss: 0.7287 - val_acc: 0.3750 - val_auc_1: 0.4643\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6568 - acc: 0.5870 - auc_1: 0.6233 - val_loss: 0.7217 - val_acc: 0.4167 - val_auc_1: 0.4536\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6549 - acc: 0.6087 - auc_1: 0.6381 - val_loss: 0.7306 - val_acc: 0.3333 - val_auc_1: 0.4464\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6524 - acc: 0.5761 - auc_1: 0.6400 - val_loss: 0.7246 - val_acc: 0.4167 - val_auc_1: 0.4929\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6525 - acc: 0.6413 - auc_1: 0.6505 - val_loss: 0.7267 - val_acc: 0.4167 - val_auc_1: 0.4786\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6510 - acc: 0.6196 - auc_1: 0.6264 - val_loss: 0.7354 - val_acc: 0.3750 - val_auc_1: 0.4536\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6529 - acc: 0.5217 - auc_1: 0.6038 - val_loss: 0.7282 - val_acc: 0.3750 - val_auc_1: 0.4607\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6531 - acc: 0.6087 - auc_1: 0.6426 - val_loss: 0.7263 - val_acc: 0.3750 - val_auc_1: 0.4929\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6496 - acc: 0.5435 - auc_1: 0.6236 - val_loss: 0.7235 - val_acc: 0.4167 - val_auc_1: 0.5000\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6487 - acc: 0.5870 - auc_1: 0.6348 - val_loss: 0.7228 - val_acc: 0.4167 - val_auc_1: 0.5000\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6461 - acc: 0.5978 - auc_1: 0.6526 - val_loss: 0.7222 - val_acc: 0.3333 - val_auc_1: 0.5000\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6514 - acc: 0.5652 - auc_1: 0.6255 - val_loss: 0.7210 - val_acc: 0.4583 - val_auc_1: 0.4964\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6435 - acc: 0.5761 - auc_1: 0.6395 - val_loss: 0.7258 - val_acc: 0.3333 - val_auc_1: 0.4893\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6451 - acc: 0.5652 - auc_1: 0.6371 - val_loss: 0.7241 - val_acc: 0.3333 - val_auc_1: 0.4893\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6447 - acc: 0.6087 - auc_1: 0.6443 - val_loss: 0.7243 - val_acc: 0.4167 - val_auc_1: 0.4893\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6413 - acc: 0.6196 - auc_1: 0.6395 - val_loss: 0.7246 - val_acc: 0.5000 - val_auc_1: 0.4929\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6476 - acc: 0.6087 - auc_1: 0.6376 - val_loss: 0.7215 - val_acc: 0.4167 - val_auc_1: 0.5000\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6426 - acc: 0.6196 - auc_1: 0.6440 - val_loss: 0.7243 - val_acc: 0.4583 - val_auc_1: 0.4857\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6405 - acc: 0.5870 - auc_1: 0.6510 - val_loss: 0.7235 - val_acc: 0.4583 - val_auc_1: 0.4857\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6403 - acc: 0.5761 - auc_1: 0.6410 - val_loss: 0.7226 - val_acc: 0.4583 - val_auc_1: 0.4964\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6391 - acc: 0.6196 - auc_1: 0.6483 - val_loss: 0.7158 - val_acc: 0.4583 - val_auc_1: 0.4964\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6371 - acc: 0.6087 - auc_1: 0.6495 - val_loss: 0.7204 - val_acc: 0.5000 - val_auc_1: 0.4893\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6408 - acc: 0.6087 - auc_1: 0.6381 - val_loss: 0.7218 - val_acc: 0.4583 - val_auc_1: 0.4929\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6395 - acc: 0.5761 - auc_1: 0.6376 - val_loss: 0.7262 - val_acc: 0.4583 - val_auc_1: 0.5036\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6370 - acc: 0.6087 - auc_1: 0.6519 - val_loss: 0.7256 - val_acc: 0.4583 - val_auc_1: 0.4964\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6394 - acc: 0.5870 - auc_1: 0.6555 - val_loss: 0.7234 - val_acc: 0.4583 - val_auc_1: 0.4893\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6436 - acc: 0.5870 - auc_1: 0.6338 - val_loss: 0.7167 - val_acc: 0.4583 - val_auc_1: 0.4857\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6338 - acc: 0.5978 - auc_1: 0.6583 - val_loss: 0.7185 - val_acc: 0.5000 - val_auc_1: 0.4857\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6386 - acc: 0.6087 - auc_1: 0.6502 - val_loss: 0.7199 - val_acc: 0.5000 - val_auc_1: 0.4893\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6332 - acc: 0.6087 - auc_1: 0.6683 - val_loss: 0.7238 - val_acc: 0.5833 - val_auc_1: 0.4893\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6366 - acc: 0.6087 - auc_1: 0.6471 - val_loss: 0.7154 - val_acc: 0.5417 - val_auc_1: 0.5036\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6346 - acc: 0.6087 - auc_1: 0.6443 - val_loss: 0.7247 - val_acc: 0.5000 - val_auc_1: 0.5000\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6389 - acc: 0.5761 - auc_1: 0.6533 - val_loss: 0.7171 - val_acc: 0.5417 - val_auc_1: 0.4964\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6359 - acc: 0.6196 - auc_1: 0.6571 - val_loss: 0.7267 - val_acc: 0.5000 - val_auc_1: 0.4929\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6370 - acc: 0.6196 - auc_1: 0.6460 - val_loss: 0.7182 - val_acc: 0.5000 - val_auc_1: 0.5071\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6331 - acc: 0.6413 - auc_1: 0.6545 - val_loss: 0.7212 - val_acc: 0.5000 - val_auc_1: 0.4964\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6306 - acc: 0.6087 - auc_1: 0.6564 - val_loss: 0.7138 - val_acc: 0.5417 - val_auc_1: 0.5036\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6329 - acc: 0.5870 - auc_1: 0.6543 - val_loss: 0.7129 - val_acc: 0.5417 - val_auc_1: 0.5071\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6316 - acc: 0.6196 - auc_1: 0.6498 - val_loss: 0.7134 - val_acc: 0.5000 - val_auc_1: 0.4821\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6326 - acc: 0.5761 - auc_1: 0.6552 - val_loss: 0.7209 - val_acc: 0.5000 - val_auc_1: 0.5107\n",
      "Epoch 145/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6380 - acc: 0.6413 - auc_1: 0.6440 - val_loss: 0.7152 - val_acc: 0.5417 - val_auc_1: 0.5036\n",
      "Epoch 146/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6304 - acc: 0.5978 - auc_1: 0.6545 - val_loss: 0.7160 - val_acc: 0.5000 - val_auc_1: 0.4821\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6332 - acc: 0.5761 - auc_1: 0.6450 - val_loss: 0.7127 - val_acc: 0.5417 - val_auc_1: 0.5036\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6358 - acc: 0.5870 - auc_1: 0.6431 - val_loss: 0.7229 - val_acc: 0.5000 - val_auc_1: 0.5143\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6325 - acc: 0.6087 - auc_1: 0.6493 - val_loss: 0.7136 - val_acc: 0.5417 - val_auc_1: 0.4893\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6321 - acc: 0.6196 - auc_1: 0.6579 - val_loss: 0.7139 - val_acc: 0.5000 - val_auc_1: 0.4893\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6305 - acc: 0.5870 - auc_1: 0.6514 - val_loss: 0.7084 - val_acc: 0.5417 - val_auc_1: 0.4821\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6289 - acc: 0.5978 - auc_1: 0.6531 - val_loss: 0.7069 - val_acc: 0.5417 - val_auc_1: 0.4964\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6271 - acc: 0.5978 - auc_1: 0.6619 - val_loss: 0.7116 - val_acc: 0.5417 - val_auc_1: 0.5071\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6280 - acc: 0.6304 - auc_1: 0.6621 - val_loss: 0.7040 - val_acc: 0.5417 - val_auc_1: 0.5107\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6318 - acc: 0.6196 - auc_1: 0.6486 - val_loss: 0.7082 - val_acc: 0.5833 - val_auc_1: 0.4821\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6315 - acc: 0.6196 - auc_1: 0.6474 - val_loss: 0.7113 - val_acc: 0.5833 - val_auc_1: 0.4893\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6317 - acc: 0.6413 - auc_1: 0.6500 - val_loss: 0.7017 - val_acc: 0.5417 - val_auc_1: 0.5143\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6272 - acc: 0.6304 - auc_1: 0.6631 - val_loss: 0.7073 - val_acc: 0.5833 - val_auc_1: 0.5000\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6278 - acc: 0.6630 - auc_1: 0.6640 - val_loss: 0.7034 - val_acc: 0.5833 - val_auc_1: 0.5071\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6263 - acc: 0.5978 - auc_1: 0.6548 - val_loss: 0.7029 - val_acc: 0.5833 - val_auc_1: 0.5071\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6294 - acc: 0.5978 - auc_1: 0.6574 - val_loss: 0.7099 - val_acc: 0.5000 - val_auc_1: 0.5143\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6276 - acc: 0.5978 - auc_1: 0.6593 - val_loss: 0.7042 - val_acc: 0.5417 - val_auc_1: 0.5214\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6293 - acc: 0.5870 - auc_1: 0.6543 - val_loss: 0.7089 - val_acc: 0.4583 - val_auc_1: 0.5107\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6261 - acc: 0.6196 - auc_1: 0.6686 - val_loss: 0.7099 - val_acc: 0.5000 - val_auc_1: 0.5143\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6300 - acc: 0.6413 - auc_1: 0.6557 - val_loss: 0.7044 - val_acc: 0.5417 - val_auc_1: 0.5250\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6301 - acc: 0.6413 - auc_1: 0.6600 - val_loss: 0.7053 - val_acc: 0.5833 - val_auc_1: 0.5071\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6258 - acc: 0.5978 - auc_1: 0.6583 - val_loss: 0.7104 - val_acc: 0.5417 - val_auc_1: 0.5107\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6269 - acc: 0.6196 - auc_1: 0.6695 - val_loss: 0.7062 - val_acc: 0.5833 - val_auc_1: 0.5143\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6281 - acc: 0.6087 - auc_1: 0.6621 - val_loss: 0.7114 - val_acc: 0.5000 - val_auc_1: 0.5250\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6279 - acc: 0.6087 - auc_1: 0.6531 - val_loss: 0.7126 - val_acc: 0.5417 - val_auc_1: 0.5143\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6238 - acc: 0.6413 - auc_1: 0.6640 - val_loss: 0.7091 - val_acc: 0.5833 - val_auc_1: 0.5179\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6267 - acc: 0.6413 - auc_1: 0.6621 - val_loss: 0.7084 - val_acc: 0.5833 - val_auc_1: 0.5071\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6262 - acc: 0.6196 - auc_1: 0.6588 - val_loss: 0.7086 - val_acc: 0.5833 - val_auc_1: 0.5179\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6273 - acc: 0.6304 - auc_1: 0.6643 - val_loss: 0.7001 - val_acc: 0.5417 - val_auc_1: 0.5250\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6266 - acc: 0.5978 - auc_1: 0.6619 - val_loss: 0.7000 - val_acc: 0.5417 - val_auc_1: 0.5321\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6265 - acc: 0.6196 - auc_1: 0.6633 - val_loss: 0.7036 - val_acc: 0.5417 - val_auc_1: 0.5250\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6285 - acc: 0.6196 - auc_1: 0.6514 - val_loss: 0.7054 - val_acc: 0.5833 - val_auc_1: 0.5107\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6222 - acc: 0.6196 - auc_1: 0.6505 - val_loss: 0.7083 - val_acc: 0.5833 - val_auc_1: 0.5393\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6268 - acc: 0.6522 - auc_1: 0.6602 - val_loss: 0.7078 - val_acc: 0.5833 - val_auc_1: 0.5393\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6251 - acc: 0.5978 - auc_1: 0.6638 - val_loss: 0.7088 - val_acc: 0.5833 - val_auc_1: 0.5107\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6270 - acc: 0.5870 - auc_1: 0.6569 - val_loss: 0.7105 - val_acc: 0.5417 - val_auc_1: 0.5214\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6281 - acc: 0.6413 - auc_1: 0.6614 - val_loss: 0.7023 - val_acc: 0.5417 - val_auc_1: 0.5464\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6257 - acc: 0.5652 - auc_1: 0.6579 - val_loss: 0.7026 - val_acc: 0.5417 - val_auc_1: 0.5286\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6203 - acc: 0.6196 - auc_1: 0.6626 - val_loss: 0.6974 - val_acc: 0.5417 - val_auc_1: 0.5393\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6231 - acc: 0.5978 - auc_1: 0.6638 - val_loss: 0.7207 - val_acc: 0.5833 - val_auc_1: 0.5036\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6282 - acc: 0.5978 - auc_1: 0.6500 - val_loss: 0.6984 - val_acc: 0.5833 - val_auc_1: 0.5607\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6248 - acc: 0.6087 - auc_1: 0.6702 - val_loss: 0.6967 - val_acc: 0.5417 - val_auc_1: 0.5286\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6259 - acc: 0.6413 - auc_1: 0.6710 - val_loss: 0.6962 - val_acc: 0.5417 - val_auc_1: 0.5429\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6235 - acc: 0.6304 - auc_1: 0.6767 - val_loss: 0.6966 - val_acc: 0.5417 - val_auc_1: 0.5464\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6218 - acc: 0.6196 - auc_1: 0.6695 - val_loss: 0.7015 - val_acc: 0.5833 - val_auc_1: 0.5429\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6213 - acc: 0.5870 - auc_1: 0.6626 - val_loss: 0.6976 - val_acc: 0.5833 - val_auc_1: 0.5464\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6214 - acc: 0.5870 - auc_1: 0.6664 - val_loss: 0.7032 - val_acc: 0.5833 - val_auc_1: 0.5321\n",
      "Epoch 193/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6230 - acc: 0.6413 - auc_1: 0.6848 - val_loss: 0.7037 - val_acc: 0.5833 - val_auc_1: 0.5429\n",
      "Epoch 194/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6207 - acc: 0.6304 - auc_1: 0.6783 - val_loss: 0.7069 - val_acc: 0.5833 - val_auc_1: 0.5107\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6239 - acc: 0.6196 - auc_1: 0.6538 - val_loss: 0.6916 - val_acc: 0.5417 - val_auc_1: 0.5714\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6271 - acc: 0.6087 - auc_1: 0.6500 - val_loss: 0.6909 - val_acc: 0.5833 - val_auc_1: 0.5679\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6263 - acc: 0.6304 - auc_1: 0.6819 - val_loss: 0.6946 - val_acc: 0.5833 - val_auc_1: 0.5357\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6179 - acc: 0.6196 - auc_1: 0.6681 - val_loss: 0.6991 - val_acc: 0.5833 - val_auc_1: 0.5679\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6240 - acc: 0.6087 - auc_1: 0.6693 - val_loss: 0.6993 - val_acc: 0.5833 - val_auc_1: 0.5464\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6215 - acc: 0.5870 - auc_1: 0.6555 - val_loss: 0.6956 - val_acc: 0.5833 - val_auc_1: 0.5500\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6260 - acc: 0.6087 - auc_1: 0.6655 - val_loss: 0.7059 - val_acc: 0.5833 - val_auc_1: 0.5500\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6237 - acc: 0.6196 - auc_1: 0.6576 - val_loss: 0.7008 - val_acc: 0.5833 - val_auc_1: 0.5429\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6158 - acc: 0.5761 - auc_1: 0.6512 - val_loss: 0.7074 - val_acc: 0.5417 - val_auc_1: 0.5607\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6197 - acc: 0.6304 - auc_1: 0.6888 - val_loss: 0.6937 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6194 - acc: 0.5761 - auc_1: 0.6648 - val_loss: 0.6969 - val_acc: 0.5833 - val_auc_1: 0.5429\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6262 - acc: 0.6413 - auc_1: 0.6679 - val_loss: 0.7004 - val_acc: 0.5833 - val_auc_1: 0.5500\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6212 - acc: 0.6304 - auc_1: 0.6798 - val_loss: 0.6959 - val_acc: 0.5417 - val_auc_1: 0.5500\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6183 - acc: 0.6087 - auc_1: 0.6729 - val_loss: 0.7013 - val_acc: 0.5833 - val_auc_1: 0.5250\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6267 - acc: 0.6196 - auc_1: 0.6614 - val_loss: 0.7028 - val_acc: 0.5833 - val_auc_1: 0.5500\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6198 - acc: 0.6304 - auc_1: 0.6852 - val_loss: 0.6964 - val_acc: 0.5833 - val_auc_1: 0.5500\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6183 - acc: 0.6304 - auc_1: 0.6748 - val_loss: 0.6957 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6192 - acc: 0.5761 - auc_1: 0.6764 - val_loss: 0.6965 - val_acc: 0.5833 - val_auc_1: 0.5429\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6179 - acc: 0.6413 - auc_1: 0.6845 - val_loss: 0.6922 - val_acc: 0.5833 - val_auc_1: 0.5536\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6207 - acc: 0.6304 - auc_1: 0.6643 - val_loss: 0.6951 - val_acc: 0.5833 - val_auc_1: 0.5821\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6243 - acc: 0.5870 - auc_1: 0.6614 - val_loss: 0.6952 - val_acc: 0.5833 - val_auc_1: 0.5500\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6242 - acc: 0.5978 - auc_1: 0.6693 - val_loss: 0.6972 - val_acc: 0.5833 - val_auc_1: 0.5607\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6135 - acc: 0.6087 - auc_1: 0.6995 - val_loss: 0.7074 - val_acc: 0.5833 - val_auc_1: 0.5286\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6213 - acc: 0.6304 - auc_1: 0.6493 - val_loss: 0.6913 - val_acc: 0.5833 - val_auc_1: 0.5607\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6222 - acc: 0.6522 - auc_1: 0.6752 - val_loss: 0.6923 - val_acc: 0.5833 - val_auc_1: 0.5536\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6205 - acc: 0.5978 - auc_1: 0.6605 - val_loss: 0.6938 - val_acc: 0.6250 - val_auc_1: 0.5679\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6179 - acc: 0.5761 - auc_1: 0.6674 - val_loss: 0.6955 - val_acc: 0.5833 - val_auc_1: 0.5464\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6208 - acc: 0.6304 - auc_1: 0.6831 - val_loss: 0.6930 - val_acc: 0.5833 - val_auc_1: 0.5571\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6168 - acc: 0.6304 - auc_1: 0.6781 - val_loss: 0.6931 - val_acc: 0.5833 - val_auc_1: 0.5643\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6174 - acc: 0.6196 - auc_1: 0.6807 - val_loss: 0.7029 - val_acc: 0.5833 - val_auc_1: 0.5357\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6166 - acc: 0.6304 - auc_1: 0.6721 - val_loss: 0.6987 - val_acc: 0.5833 - val_auc_1: 0.5679\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6146 - acc: 0.6087 - auc_1: 0.6843 - val_loss: 0.6928 - val_acc: 0.5417 - val_auc_1: 0.5643\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6138 - acc: 0.6196 - auc_1: 0.6738 - val_loss: 0.6973 - val_acc: 0.5833 - val_auc_1: 0.5679\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6177 - acc: 0.6196 - auc_1: 0.6729 - val_loss: 0.7060 - val_acc: 0.5833 - val_auc_1: 0.5464\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6248 - acc: 0.6087 - auc_1: 0.6707 - val_loss: 0.7026 - val_acc: 0.5833 - val_auc_1: 0.5607\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6181 - acc: 0.6196 - auc_1: 0.6862 - val_loss: 0.7055 - val_acc: 0.5833 - val_auc_1: 0.5429\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6123 - acc: 0.6087 - auc_1: 0.6760 - val_loss: 0.6968 - val_acc: 0.5833 - val_auc_1: 0.5714\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6128 - acc: 0.6522 - auc_1: 0.6702 - val_loss: 0.6937 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6218 - acc: 0.6087 - auc_1: 0.6824 - val_loss: 0.6998 - val_acc: 0.5417 - val_auc_1: 0.5571\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6166 - acc: 0.6413 - auc_1: 0.6848 - val_loss: 0.6992 - val_acc: 0.5833 - val_auc_1: 0.5536\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6129 - acc: 0.6196 - auc_1: 0.6776 - val_loss: 0.7002 - val_acc: 0.5417 - val_auc_1: 0.5464\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6115 - acc: 0.6304 - auc_1: 0.6936 - val_loss: 0.6992 - val_acc: 0.5833 - val_auc_1: 0.5607\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6217 - acc: 0.6196 - auc_1: 0.6598 - val_loss: 0.7084 - val_acc: 0.5833 - val_auc_1: 0.5464\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6178 - acc: 0.6087 - auc_1: 0.6783 - val_loss: 0.7022 - val_acc: 0.5833 - val_auc_1: 0.5571\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6136 - acc: 0.5870 - auc_1: 0.6574 - val_loss: 0.6976 - val_acc: 0.5000 - val_auc_1: 0.5607\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6122 - acc: 0.6196 - auc_1: 0.6926 - val_loss: 0.7317 - val_acc: 0.5833 - val_auc_1: 0.5179\n",
      "Epoch 241/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6108 - acc: 0.6087 - auc_1: 0.6671 - val_loss: 0.6979 - val_acc: 0.5833 - val_auc_1: 0.5714\n",
      "Epoch 242/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6114 - acc: 0.6413 - auc_1: 0.6831 - val_loss: 0.7141 - val_acc: 0.5000 - val_auc_1: 0.5536\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6117 - acc: 0.6304 - auc_1: 0.6890 - val_loss: 0.6990 - val_acc: 0.5417 - val_auc_1: 0.5500\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6096 - acc: 0.6304 - auc_1: 0.6874 - val_loss: 0.7082 - val_acc: 0.5417 - val_auc_1: 0.5607\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6215 - acc: 0.6087 - auc_1: 0.6790 - val_loss: 0.7076 - val_acc: 0.5833 - val_auc_1: 0.5500\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6066 - acc: 0.6304 - auc_1: 0.6824 - val_loss: 0.7079 - val_acc: 0.5000 - val_auc_1: 0.5500\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6084 - acc: 0.5978 - auc_1: 0.6860 - val_loss: 0.7140 - val_acc: 0.5000 - val_auc_1: 0.5571\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6107 - acc: 0.5978 - auc_1: 0.6845 - val_loss: 0.7006 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6125 - acc: 0.5978 - auc_1: 0.6817 - val_loss: 0.7172 - val_acc: 0.5000 - val_auc_1: 0.5464\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6067 - acc: 0.6304 - auc_1: 0.6986 - val_loss: 0.7102 - val_acc: 0.4583 - val_auc_1: 0.5571\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6122 - acc: 0.6413 - auc_1: 0.6907 - val_loss: 0.7043 - val_acc: 0.5417 - val_auc_1: 0.5500\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6115 - acc: 0.6413 - auc_1: 0.6893 - val_loss: 0.7009 - val_acc: 0.5417 - val_auc_1: 0.5500\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6075 - acc: 0.6196 - auc_1: 0.6857 - val_loss: 0.7038 - val_acc: 0.5000 - val_auc_1: 0.5464\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6031 - acc: 0.6304 - auc_1: 0.6795 - val_loss: 0.7015 - val_acc: 0.5000 - val_auc_1: 0.5607\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6066 - acc: 0.6196 - auc_1: 0.6960 - val_loss: 0.6966 - val_acc: 0.5417 - val_auc_1: 0.5500\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6077 - acc: 0.6196 - auc_1: 0.7112 - val_loss: 0.7156 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6088 - acc: 0.6304 - auc_1: 0.6767 - val_loss: 0.7060 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6100 - acc: 0.5978 - auc_1: 0.6838 - val_loss: 0.7048 - val_acc: 0.5417 - val_auc_1: 0.5500\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6023 - acc: 0.6196 - auc_1: 0.7031 - val_loss: 0.7063 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6041 - acc: 0.6304 - auc_1: 0.6907 - val_loss: 0.7014 - val_acc: 0.5833 - val_auc_1: 0.5571\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6025 - acc: 0.5978 - auc_1: 0.6833 - val_loss: 0.6967 - val_acc: 0.5417 - val_auc_1: 0.5679\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6080 - acc: 0.6087 - auc_1: 0.6824 - val_loss: 0.7032 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6079 - acc: 0.6522 - auc_1: 0.6971 - val_loss: 0.7005 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6056 - acc: 0.6413 - auc_1: 0.6774 - val_loss: 0.6918 - val_acc: 0.5833 - val_auc_1: 0.5607\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6027 - acc: 0.6413 - auc_1: 0.6995 - val_loss: 0.7047 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5991 - acc: 0.6304 - auc_1: 0.7140 - val_loss: 0.7238 - val_acc: 0.5833 - val_auc_1: 0.5429\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6039 - acc: 0.5978 - auc_1: 0.6802 - val_loss: 0.7015 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5967 - acc: 0.6087 - auc_1: 0.6864 - val_loss: 0.6986 - val_acc: 0.5417 - val_auc_1: 0.5464\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6234 - acc: 0.5870 - auc_1: 0.6486 - val_loss: 0.7106 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5989 - acc: 0.6304 - auc_1: 0.7052 - val_loss: 0.7032 - val_acc: 0.5417 - val_auc_1: 0.5393\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6050 - acc: 0.6196 - auc_1: 0.6786 - val_loss: 0.7099 - val_acc: 0.5417 - val_auc_1: 0.5393\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5975 - acc: 0.6522 - auc_1: 0.6974 - val_loss: 0.7066 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6038 - acc: 0.6087 - auc_1: 0.7076 - val_loss: 0.7143 - val_acc: 0.5417 - val_auc_1: 0.5464\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5938 - acc: 0.6304 - auc_1: 0.7048 - val_loss: 0.6957 - val_acc: 0.4583 - val_auc_1: 0.5500\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6071 - acc: 0.6304 - auc_1: 0.6867 - val_loss: 0.7069 - val_acc: 0.5417 - val_auc_1: 0.5500\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6009 - acc: 0.6413 - auc_1: 0.6929 - val_loss: 0.7126 - val_acc: 0.5417 - val_auc_1: 0.5357\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6006 - acc: 0.6087 - auc_1: 0.6843 - val_loss: 0.7090 - val_acc: 0.5417 - val_auc_1: 0.5357\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6037 - acc: 0.5978 - auc_1: 0.6824 - val_loss: 0.7032 - val_acc: 0.5417 - val_auc_1: 0.5357\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6020 - acc: 0.6087 - auc_1: 0.6821 - val_loss: 0.7002 - val_acc: 0.5000 - val_auc_1: 0.5500\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5985 - acc: 0.6522 - auc_1: 0.6998 - val_loss: 0.7059 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5978 - acc: 0.6304 - auc_1: 0.7007 - val_loss: 0.7062 - val_acc: 0.5000 - val_auc_1: 0.5393\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5928 - acc: 0.6087 - auc_1: 0.7007 - val_loss: 0.6948 - val_acc: 0.5000 - val_auc_1: 0.5536\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5960 - acc: 0.6304 - auc_1: 0.7055 - val_loss: 0.7114 - val_acc: 0.5417 - val_auc_1: 0.5321\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6004 - acc: 0.6196 - auc_1: 0.7050 - val_loss: 0.6962 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5965 - acc: 0.6304 - auc_1: 0.7043 - val_loss: 0.7056 - val_acc: 0.5417 - val_auc_1: 0.5464\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5865 - acc: 0.6304 - auc_1: 0.7198 - val_loss: 0.6995 - val_acc: 0.5417 - val_auc_1: 0.5429\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6085 - acc: 0.6413 - auc_1: 0.6862 - val_loss: 0.6987 - val_acc: 0.5417 - val_auc_1: 0.5464\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5900 - acc: 0.6413 - auc_1: 0.7083 - val_loss: 0.6936 - val_acc: 0.5000 - val_auc_1: 0.5500\n",
      "Epoch 289/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6069 - acc: 0.6522 - auc_1: 0.7026 - val_loss: 0.6959 - val_acc: 0.5417 - val_auc_1: 0.5357\n",
      "Epoch 290/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5970 - acc: 0.6413 - auc_1: 0.6860 - val_loss: 0.7009 - val_acc: 0.5417 - val_auc_1: 0.5536\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5976 - acc: 0.6413 - auc_1: 0.7033 - val_loss: 0.6959 - val_acc: 0.5417 - val_auc_1: 0.5429\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5927 - acc: 0.6087 - auc_1: 0.7002 - val_loss: 0.7005 - val_acc: 0.5417 - val_auc_1: 0.5393\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5968 - acc: 0.6304 - auc_1: 0.7074 - val_loss: 0.6989 - val_acc: 0.5000 - val_auc_1: 0.5464\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6039 - acc: 0.5978 - auc_1: 0.7060 - val_loss: 0.7009 - val_acc: 0.6250 - val_auc_1: 0.5571\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5899 - acc: 0.6413 - auc_1: 0.7079 - val_loss: 0.6912 - val_acc: 0.5000 - val_auc_1: 0.5536\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5902 - acc: 0.6304 - auc_1: 0.7098 - val_loss: 0.6998 - val_acc: 0.5417 - val_auc_1: 0.5429\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5907 - acc: 0.6196 - auc_1: 0.7076 - val_loss: 0.6866 - val_acc: 0.4583 - val_auc_1: 0.5607\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5903 - acc: 0.6304 - auc_1: 0.7267 - val_loss: 0.7287 - val_acc: 0.5417 - val_auc_1: 0.5393\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5857 - acc: 0.6413 - auc_1: 0.7188 - val_loss: 0.6923 - val_acc: 0.5000 - val_auc_1: 0.5500\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5906 - acc: 0.6087 - auc_1: 0.7143 - val_loss: 0.7018 - val_acc: 0.5417 - val_auc_1: 0.5357\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5897 - acc: 0.6304 - auc_1: 0.7169 - val_loss: 0.7060 - val_acc: 0.5833 - val_auc_1: 0.5500\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5961 - acc: 0.6098 - auc_1: 0.694 - 0s 4ms/step - loss: 0.5981 - acc: 0.6087 - auc_1: 0.6907 - val_loss: 0.6868 - val_acc: 0.5000 - val_auc_1: 0.5536\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5958 - acc: 0.6196 - auc_1: 0.6952 - val_loss: 0.7020 - val_acc: 0.5833 - val_auc_1: 0.5357\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5849 - acc: 0.6196 - auc_1: 0.7200 - val_loss: 0.7207 - val_acc: 0.5833 - val_auc_1: 0.5571\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5924 - acc: 0.6196 - auc_1: 0.7014 - val_loss: 0.6920 - val_acc: 0.5000 - val_auc_1: 0.5429\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5891 - acc: 0.6304 - auc_1: 0.7200 - val_loss: 0.7087 - val_acc: 0.5417 - val_auc_1: 0.5464\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5790 - acc: 0.6522 - auc_1: 0.7255 - val_loss: 0.6921 - val_acc: 0.5000 - val_auc_1: 0.5429\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5892 - acc: 0.6413 - auc_1: 0.7217 - val_loss: 0.6944 - val_acc: 0.5417 - val_auc_1: 0.5357\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5852 - acc: 0.6304 - auc_1: 0.7267 - val_loss: 0.7027 - val_acc: 0.5417 - val_auc_1: 0.5321\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5878 - acc: 0.6630 - auc_1: 0.7060 - val_loss: 0.7112 - val_acc: 0.5833 - val_auc_1: 0.5464\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5851 - acc: 0.6413 - auc_1: 0.7217 - val_loss: 0.6964 - val_acc: 0.5000 - val_auc_1: 0.5321\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5972 - acc: 0.6304 - auc_1: 0.7145 - val_loss: 0.7168 - val_acc: 0.5833 - val_auc_1: 0.5464\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5891 - acc: 0.6413 - auc_1: 0.6981 - val_loss: 0.6923 - val_acc: 0.5000 - val_auc_1: 0.5393\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5833 - acc: 0.6413 - auc_1: 0.7107 - val_loss: 0.6918 - val_acc: 0.5000 - val_auc_1: 0.5357\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6002 - acc: 0.5870 - auc_1: 0.6843 - val_loss: 0.6946 - val_acc: 0.5417 - val_auc_1: 0.5429\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5807 - acc: 0.6630 - auc_1: 0.7221 - val_loss: 0.6900 - val_acc: 0.5000 - val_auc_1: 0.5536\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5890 - acc: 0.6087 - auc_1: 0.7155 - val_loss: 0.6921 - val_acc: 0.5417 - val_auc_1: 0.5464\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5868 - acc: 0.6739 - auc_1: 0.7252 - val_loss: 0.6999 - val_acc: 0.5417 - val_auc_1: 0.5250\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5866 - acc: 0.6522 - auc_1: 0.7276 - val_loss: 0.6867 - val_acc: 0.5000 - val_auc_1: 0.5500\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5809 - acc: 0.6522 - auc_1: 0.7188 - val_loss: 0.7121 - val_acc: 0.5833 - val_auc_1: 0.5500\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5817 - acc: 0.6087 - auc_1: 0.7133 - val_loss: 0.6930 - val_acc: 0.5000 - val_auc_1: 0.5429\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5978 - acc: 0.6413 - auc_1: 0.7136 - val_loss: 0.6932 - val_acc: 0.5833 - val_auc_1: 0.5500\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5829 - acc: 0.6630 - auc_1: 0.7219 - val_loss: 0.6884 - val_acc: 0.5000 - val_auc_1: 0.5607\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5816 - acc: 0.6413 - auc_1: 0.7252 - val_loss: 0.6924 - val_acc: 0.5000 - val_auc_1: 0.5464\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5818 - acc: 0.6522 - auc_1: 0.7212 - val_loss: 0.6966 - val_acc: 0.5417 - val_auc_1: 0.5571\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5820 - acc: 0.6304 - auc_1: 0.7219 - val_loss: 0.7028 - val_acc: 0.5417 - val_auc_1: 0.5357\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5827 - acc: 0.6413 - auc_1: 0.7293 - val_loss: 0.7166 - val_acc: 0.5833 - val_auc_1: 0.5464\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5803 - acc: 0.6304 - auc_1: 0.7214 - val_loss: 0.6887 - val_acc: 0.5000 - val_auc_1: 0.5643\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5903 - acc: 0.6413 - auc_1: 0.7305 - val_loss: 0.6912 - val_acc: 0.5833 - val_auc_1: 0.5929\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5863 - acc: 0.6630 - auc_1: 0.7329 - val_loss: 0.6941 - val_acc: 0.5833 - val_auc_1: 0.5571\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5790 - acc: 0.6522 - auc_1: 0.7317 - val_loss: 0.7101 - val_acc: 0.5833 - val_auc_1: 0.5679\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5778 - acc: 0.6413 - auc_1: 0.7336 - val_loss: 0.6888 - val_acc: 0.5417 - val_auc_1: 0.5357\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5838 - acc: 0.6630 - auc_1: 0.7243 - val_loss: 0.6931 - val_acc: 0.5417 - val_auc_1: 0.5679\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5778 - acc: 0.6413 - auc_1: 0.7326 - val_loss: 0.6881 - val_acc: 0.5000 - val_auc_1: 0.5679\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5819 - acc: 0.6413 - auc_1: 0.7186 - val_loss: 0.6956 - val_acc: 0.5417 - val_auc_1: 0.5857\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5772 - acc: 0.6087 - auc_1: 0.7219 - val_loss: 0.7192 - val_acc: 0.5833 - val_auc_1: 0.5750\n",
      "Epoch 337/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5817 - acc: 0.6413 - auc_1: 0.7286 - val_loss: 0.7067 - val_acc: 0.5000 - val_auc_1: 0.5464\n",
      "Epoch 338/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5813 - acc: 0.6196 - auc_1: 0.7233 - val_loss: 0.6927 - val_acc: 0.5417 - val_auc_1: 0.5714\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5927 - acc: 0.6413 - auc_1: 0.7076 - val_loss: 0.7077 - val_acc: 0.5000 - val_auc_1: 0.5500\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5751 - acc: 0.6196 - auc_1: 0.7362 - val_loss: 0.7012 - val_acc: 0.5000 - val_auc_1: 0.5679\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5729 - acc: 0.6522 - auc_1: 0.7319 - val_loss: 0.6952 - val_acc: 0.5000 - val_auc_1: 0.5536\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5760 - acc: 0.6630 - auc_1: 0.7393 - val_loss: 0.6965 - val_acc: 0.6250 - val_auc_1: 0.5714\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5944 - acc: 0.6957 - auc_1: 0.7367 - val_loss: 0.7009 - val_acc: 0.5417 - val_auc_1: 0.5571\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5840 - acc: 0.6087 - auc_1: 0.7169 - val_loss: 0.6917 - val_acc: 0.5000 - val_auc_1: 0.5607\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5765 - acc: 0.6630 - auc_1: 0.7367 - val_loss: 0.7050 - val_acc: 0.5417 - val_auc_1: 0.5786\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5757 - acc: 0.5761 - auc_1: 0.7248 - val_loss: 0.6954 - val_acc: 0.4583 - val_auc_1: 0.5786\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5702 - acc: 0.6522 - auc_1: 0.7414 - val_loss: 0.6996 - val_acc: 0.5000 - val_auc_1: 0.5643\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5690 - acc: 0.6630 - auc_1: 0.7462 - val_loss: 0.6904 - val_acc: 0.4583 - val_auc_1: 0.5643\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5688 - acc: 0.6848 - auc_1: 0.7393 - val_loss: 0.7058 - val_acc: 0.5000 - val_auc_1: 0.5500\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5743 - acc: 0.6957 - auc_1: 0.7440 - val_loss: 0.7257 - val_acc: 0.5417 - val_auc_1: 0.5607\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5693 - acc: 0.6739 - auc_1: 0.7524 - val_loss: 0.6989 - val_acc: 0.4583 - val_auc_1: 0.5786\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5703 - acc: 0.6196 - auc_1: 0.7445 - val_loss: 0.7228 - val_acc: 0.5833 - val_auc_1: 0.5750\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5719 - acc: 0.6196 - auc_1: 0.7348 - val_loss: 0.7010 - val_acc: 0.5000 - val_auc_1: 0.5821\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5630 - acc: 0.6848 - auc_1: 0.7543 - val_loss: 0.6930 - val_acc: 0.5000 - val_auc_1: 0.5643\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5758 - acc: 0.6739 - auc_1: 0.7319 - val_loss: 0.6931 - val_acc: 0.4583 - val_auc_1: 0.5536\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5687 - acc: 0.6413 - auc_1: 0.7357 - val_loss: 0.6859 - val_acc: 0.4583 - val_auc_1: 0.6000\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5718 - acc: 0.6522 - auc_1: 0.7531 - val_loss: 0.7193 - val_acc: 0.5417 - val_auc_1: 0.5643\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5691 - acc: 0.6413 - auc_1: 0.7433 - val_loss: 0.6979 - val_acc: 0.4583 - val_auc_1: 0.5750\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5632 - acc: 0.6522 - auc_1: 0.7581 - val_loss: 0.7125 - val_acc: 0.5000 - val_auc_1: 0.5750\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5661 - acc: 0.6522 - auc_1: 0.7479 - val_loss: 0.7016 - val_acc: 0.4583 - val_auc_1: 0.5929\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5637 - acc: 0.6413 - auc_1: 0.7476 - val_loss: 0.6895 - val_acc: 0.4583 - val_auc_1: 0.6071\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5610 - acc: 0.6522 - auc_1: 0.7576 - val_loss: 0.7075 - val_acc: 0.5000 - val_auc_1: 0.5679\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5659 - acc: 0.6304 - auc_1: 0.7540 - val_loss: 0.6988 - val_acc: 0.4583 - val_auc_1: 0.5857\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5670 - acc: 0.6196 - auc_1: 0.7590 - val_loss: 0.6956 - val_acc: 0.4583 - val_auc_1: 0.5929\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5577 - acc: 0.6522 - auc_1: 0.7538 - val_loss: 0.6894 - val_acc: 0.4583 - val_auc_1: 0.6107\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5719 - acc: 0.6304 - auc_1: 0.7410 - val_loss: 0.7018 - val_acc: 0.4583 - val_auc_1: 0.6071\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5589 - acc: 0.6739 - auc_1: 0.7550 - val_loss: 0.7006 - val_acc: 0.5000 - val_auc_1: 0.5857\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5606 - acc: 0.6522 - auc_1: 0.7605 - val_loss: 0.6910 - val_acc: 0.5000 - val_auc_1: 0.6286\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5604 - acc: 0.6413 - auc_1: 0.7476 - val_loss: 0.6993 - val_acc: 0.4583 - val_auc_1: 0.6107\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5548 - acc: 0.6630 - auc_1: 0.7764 - val_loss: 0.7210 - val_acc: 0.4583 - val_auc_1: 0.5964\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5636 - acc: 0.6522 - auc_1: 0.7643 - val_loss: 0.7025 - val_acc: 0.4583 - val_auc_1: 0.5607\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5633 - acc: 0.6413 - auc_1: 0.7579 - val_loss: 0.7152 - val_acc: 0.5000 - val_auc_1: 0.5857\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5563 - acc: 0.6739 - auc_1: 0.7681 - val_loss: 0.7049 - val_acc: 0.4583 - val_auc_1: 0.5929\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5565 - acc: 0.6630 - auc_1: 0.7571 - val_loss: 0.7120 - val_acc: 0.4583 - val_auc_1: 0.6107\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5508 - acc: 0.6630 - auc_1: 0.7771 - val_loss: 0.7077 - val_acc: 0.4583 - val_auc_1: 0.5929\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5520 - acc: 0.6739 - auc_1: 0.7702 - val_loss: 0.7159 - val_acc: 0.4583 - val_auc_1: 0.6000\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5521 - acc: 0.6848 - auc_1: 0.7843 - val_loss: 0.7310 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5536 - acc: 0.6739 - auc_1: 0.7714 - val_loss: 0.7404 - val_acc: 0.5000 - val_auc_1: 0.5929\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5665 - acc: 0.6522 - auc_1: 0.7455 - val_loss: 0.7222 - val_acc: 0.4583 - val_auc_1: 0.6107\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5501 - acc: 0.6739 - auc_1: 0.7740 - val_loss: 0.7308 - val_acc: 0.5000 - val_auc_1: 0.6036\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5617 - acc: 0.6739 - auc_1: 0.7550 - val_loss: 0.7152 - val_acc: 0.5833 - val_auc_1: 0.6107\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5614 - acc: 0.6739 - auc_1: 0.7710 - val_loss: 0.7038 - val_acc: 0.6667 - val_auc_1: 0.6107\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5463 - acc: 0.6957 - auc_1: 0.7917 - val_loss: 0.7016 - val_acc: 0.5417 - val_auc_1: 0.5714\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5547 - acc: 0.6304 - auc_1: 0.7617 - val_loss: 0.7058 - val_acc: 0.6250 - val_auc_1: 0.6000\n",
      "Epoch 385/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5403 - acc: 0.6957 - auc_1: 0.7902 - val_loss: 0.7260 - val_acc: 0.5417 - val_auc_1: 0.5964\n",
      "Epoch 386/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5519 - acc: 0.6957 - auc_1: 0.7802 - val_loss: 0.7270 - val_acc: 0.5000 - val_auc_1: 0.6143\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5576 - acc: 0.6739 - auc_1: 0.7836 - val_loss: 0.7219 - val_acc: 0.6250 - val_auc_1: 0.6214\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5474 - acc: 0.6739 - auc_1: 0.7812 - val_loss: 0.7095 - val_acc: 0.5833 - val_auc_1: 0.6036\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5491 - acc: 0.7174 - auc_1: 0.7867 - val_loss: 0.7310 - val_acc: 0.5000 - val_auc_1: 0.5821\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5536 - acc: 0.6739 - auc_1: 0.7702 - val_loss: 0.7329 - val_acc: 0.5417 - val_auc_1: 0.5929\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5413 - acc: 0.6739 - auc_1: 0.7840 - val_loss: 0.7192 - val_acc: 0.5417 - val_auc_1: 0.5929\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5352 - acc: 0.6739 - auc_1: 0.7924 - val_loss: 0.7195 - val_acc: 0.5417 - val_auc_1: 0.6107\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5518 - acc: 0.6739 - auc_1: 0.7767 - val_loss: 0.7323 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5499 - acc: 0.6739 - auc_1: 0.7755 - val_loss: 0.7439 - val_acc: 0.5417 - val_auc_1: 0.5929\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.5408 - acc: 0.6522 - auc_1: 0.7810 - val_loss: 0.7302 - val_acc: 0.5417 - val_auc_1: 0.5857\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5395 - acc: 0.6739 - auc_1: 0.7931 - val_loss: 0.7421 - val_acc: 0.5417 - val_auc_1: 0.5786\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5380 - acc: 0.6957 - auc_1: 0.7850 - val_loss: 0.7191 - val_acc: 0.5417 - val_auc_1: 0.5857\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5430 - acc: 0.6957 - auc_1: 0.7890 - val_loss: 0.7382 - val_acc: 0.6250 - val_auc_1: 0.5929\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5362 - acc: 0.6957 - auc_1: 0.7945 - val_loss: 0.7360 - val_acc: 0.6250 - val_auc_1: 0.5929\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5404 - acc: 0.6739 - auc_1: 0.7821 - val_loss: 0.7279 - val_acc: 0.5000 - val_auc_1: 0.6179\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5385 - acc: 0.7065 - auc_1: 0.7862 - val_loss: 0.7307 - val_acc: 0.5833 - val_auc_1: 0.6036\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5413 - acc: 0.6848 - auc_1: 0.7831 - val_loss: 0.7305 - val_acc: 0.5000 - val_auc_1: 0.6036\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5357 - acc: 0.6848 - auc_1: 0.7826 - val_loss: 0.7414 - val_acc: 0.5833 - val_auc_1: 0.5929\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5352 - acc: 0.7174 - auc_1: 0.7998 - val_loss: 0.7390 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5442 - acc: 0.6957 - auc_1: 0.7881 - val_loss: 0.7477 - val_acc: 0.5417 - val_auc_1: 0.6107\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5429 - acc: 0.6739 - auc_1: 0.7910 - val_loss: 0.7490 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5286 - acc: 0.6739 - auc_1: 0.8052 - val_loss: 0.7561 - val_acc: 0.5417 - val_auc_1: 0.5679\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5417 - acc: 0.6739 - auc_1: 0.7812 - val_loss: 0.7437 - val_acc: 0.5000 - val_auc_1: 0.6036\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5389 - acc: 0.7174 - auc_1: 0.7900 - val_loss: 0.7364 - val_acc: 0.5833 - val_auc_1: 0.6214\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5336 - acc: 0.7065 - auc_1: 0.7950 - val_loss: 0.7475 - val_acc: 0.5000 - val_auc_1: 0.5857\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5259 - acc: 0.6848 - auc_1: 0.7993 - val_loss: 0.7487 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5354 - acc: 0.7174 - auc_1: 0.7845 - val_loss: 0.7438 - val_acc: 0.5000 - val_auc_1: 0.5964\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5360 - acc: 0.7065 - auc_1: 0.7893 - val_loss: 0.7412 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5386 - acc: 0.6848 - auc_1: 0.7917 - val_loss: 0.7598 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5354 - acc: 0.6848 - auc_1: 0.7810 - val_loss: 0.7685 - val_acc: 0.5417 - val_auc_1: 0.6000\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5341 - acc: 0.6848 - auc_1: 0.7921 - val_loss: 0.7531 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5253 - acc: 0.7174 - auc_1: 0.7990 - val_loss: 0.7441 - val_acc: 0.5000 - val_auc_1: 0.6107\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5280 - acc: 0.7065 - auc_1: 0.8038 - val_loss: 0.7619 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5242 - acc: 0.6848 - auc_1: 0.7957 - val_loss: 0.7480 - val_acc: 0.4583 - val_auc_1: 0.6107\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5237 - acc: 0.7174 - auc_1: 0.8060 - val_loss: 0.7709 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5172 - acc: 0.7065 - auc_1: 0.8038 - val_loss: 0.7750 - val_acc: 0.5000 - val_auc_1: 0.5786\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5225 - acc: 0.6848 - auc_1: 0.8090 - val_loss: 0.7777 - val_acc: 0.5000 - val_auc_1: 0.5964\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5207 - acc: 0.6957 - auc_1: 0.8079 - val_loss: 0.7690 - val_acc: 0.5000 - val_auc_1: 0.6036\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5262 - acc: 0.6957 - auc_1: 0.7998 - val_loss: 0.7763 - val_acc: 0.5000 - val_auc_1: 0.5821\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5281 - acc: 0.7065 - auc_1: 0.8040 - val_loss: 0.8144 - val_acc: 0.5417 - val_auc_1: 0.5750\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5303 - acc: 0.6739 - auc_1: 0.7848 - val_loss: 0.7955 - val_acc: 0.5000 - val_auc_1: 0.5643\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5115 - acc: 0.6848 - auc_1: 0.8062 - val_loss: 0.7739 - val_acc: 0.5000 - val_auc_1: 0.6214\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5254 - acc: 0.6739 - auc_1: 0.7857 - val_loss: 0.7982 - val_acc: 0.5417 - val_auc_1: 0.6000\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5173 - acc: 0.7391 - auc_1: 0.8076 - val_loss: 0.7835 - val_acc: 0.5000 - val_auc_1: 0.6107\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5286 - acc: 0.7174 - auc_1: 0.8010 - val_loss: 0.7868 - val_acc: 0.5000 - val_auc_1: 0.5786\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5302 - acc: 0.6957 - auc_1: 0.7895 - val_loss: 0.8072 - val_acc: 0.5417 - val_auc_1: 0.6000\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5168 - acc: 0.6957 - auc_1: 0.8088 - val_loss: 0.7757 - val_acc: 0.5000 - val_auc_1: 0.6179\n",
      "Epoch 433/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5145 - acc: 0.7065 - auc_1: 0.8171 - val_loss: 0.8232 - val_acc: 0.5417 - val_auc_1: 0.6107\n",
      "Epoch 434/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5245 - acc: 0.7065 - auc_1: 0.7979 - val_loss: 0.7844 - val_acc: 0.5000 - val_auc_1: 0.6107\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5147 - acc: 0.7283 - auc_1: 0.8136 - val_loss: 0.8098 - val_acc: 0.5000 - val_auc_1: 0.5964\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5247 - acc: 0.7174 - auc_1: 0.7926 - val_loss: 0.8380 - val_acc: 0.5417 - val_auc_1: 0.5964\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5218 - acc: 0.7065 - auc_1: 0.8005 - val_loss: 0.7893 - val_acc: 0.4583 - val_auc_1: 0.6107\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5118 - acc: 0.7065 - auc_1: 0.8098 - val_loss: 0.7952 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5108 - acc: 0.7065 - auc_1: 0.8090 - val_loss: 0.8012 - val_acc: 0.5000 - val_auc_1: 0.6179\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5038 - acc: 0.7717 - auc_1: 0.8243 - val_loss: 0.7893 - val_acc: 0.4167 - val_auc_1: 0.5571\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5114 - acc: 0.6739 - auc_1: 0.8202 - val_loss: 0.8029 - val_acc: 0.5417 - val_auc_1: 0.5964\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5107 - acc: 0.7500 - auc_1: 0.8217 - val_loss: 0.7912 - val_acc: 0.4583 - val_auc_1: 0.6107\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5174 - acc: 0.7065 - auc_1: 0.8031 - val_loss: 0.7782 - val_acc: 0.4583 - val_auc_1: 0.6179\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5068 - acc: 0.7391 - auc_1: 0.8274 - val_loss: 0.8031 - val_acc: 0.5417 - val_auc_1: 0.6250\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5132 - acc: 0.7174 - auc_1: 0.8138 - val_loss: 0.8199 - val_acc: 0.5417 - val_auc_1: 0.6179\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5087 - acc: 0.7391 - auc_1: 0.8162 - val_loss: 0.8176 - val_acc: 0.5417 - val_auc_1: 0.6107\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5161 - acc: 0.7283 - auc_1: 0.8129 - val_loss: 0.7986 - val_acc: 0.5417 - val_auc_1: 0.6179\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5090 - acc: 0.7174 - auc_1: 0.8198 - val_loss: 0.8268 - val_acc: 0.5417 - val_auc_1: 0.5893\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5172 - acc: 0.7174 - auc_1: 0.8050 - val_loss: 0.8255 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5118 - acc: 0.7174 - auc_1: 0.8067 - val_loss: 0.8179 - val_acc: 0.5417 - val_auc_1: 0.6000\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5073 - acc: 0.7500 - auc_1: 0.8179 - val_loss: 0.8253 - val_acc: 0.5417 - val_auc_1: 0.6036\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5113 - acc: 0.6957 - auc_1: 0.8157 - val_loss: 0.8197 - val_acc: 0.5417 - val_auc_1: 0.6107\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5146 - acc: 0.7174 - auc_1: 0.8090 - val_loss: 0.8201 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5018 - acc: 0.7283 - auc_1: 0.8181 - val_loss: 0.8249 - val_acc: 0.5417 - val_auc_1: 0.6000\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5024 - acc: 0.7174 - auc_1: 0.8200 - val_loss: 0.8053 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5064 - acc: 0.7283 - auc_1: 0.8224 - val_loss: 0.8357 - val_acc: 0.5417 - val_auc_1: 0.6000\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5087 - acc: 0.7065 - auc_1: 0.8262 - val_loss: 0.7750 - val_acc: 0.5833 - val_auc_1: 0.6107\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5087 - acc: 0.7065 - auc_1: 0.8140 - val_loss: 0.8328 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5027 - acc: 0.7174 - auc_1: 0.8212 - val_loss: 0.8187 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5016 - acc: 0.7283 - auc_1: 0.8179 - val_loss: 0.8074 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5017 - acc: 0.6957 - auc_1: 0.8217 - val_loss: 0.8209 - val_acc: 0.5000 - val_auc_1: 0.5929\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5086 - acc: 0.7174 - auc_1: 0.8157 - val_loss: 0.8282 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5175 - acc: 0.7143 - auc_1: 0.8056    - 0s 4ms/step - loss: 0.5117 - acc: 0.7283 - auc_1: 0.8150 - val_loss: 0.8160 - val_acc: 0.5000 - val_auc_1: 0.6036\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5026 - acc: 0.7391 - auc_1: 0.8226 - val_loss: 0.8227 - val_acc: 0.5000 - val_auc_1: 0.6143\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4965 - acc: 0.6957 - auc_1: 0.8207 - val_loss: 0.8340 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5005 - acc: 0.7391 - auc_1: 0.8276 - val_loss: 0.8135 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5013 - acc: 0.7283 - auc_1: 0.8198 - val_loss: 0.8027 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4966 - acc: 0.7717 - auc_1: 0.8331 - val_loss: 0.7874 - val_acc: 0.4583 - val_auc_1: 0.6214\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4954 - acc: 0.7174 - auc_1: 0.8298 - val_loss: 0.7902 - val_acc: 0.4583 - val_auc_1: 0.6143\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5254 - acc: 0.7065 - auc_1: 0.7924 - val_loss: 0.8308 - val_acc: 0.5000 - val_auc_1: 0.6179\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5017 - acc: 0.7283 - auc_1: 0.8205 - val_loss: 0.7906 - val_acc: 0.5000 - val_auc_1: 0.6107\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5028 - acc: 0.6739 - auc_1: 0.8126 - val_loss: 0.8177 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5015 - acc: 0.7391 - auc_1: 0.8240 - val_loss: 0.8189 - val_acc: 0.5417 - val_auc_1: 0.6036\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4951 - acc: 0.7174 - auc_1: 0.8300 - val_loss: 0.7796 - val_acc: 0.5000 - val_auc_1: 0.6250\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5093 - acc: 0.7065 - auc_1: 0.8033 - val_loss: 0.7575 - val_acc: 0.5833 - val_auc_1: 0.6071\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4960 - acc: 0.7065 - auc_1: 0.8279 - val_loss: 0.8696 - val_acc: 0.5000 - val_auc_1: 0.6143\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5055 - acc: 0.7500 - auc_1: 0.8150 - val_loss: 0.8101 - val_acc: 0.5833 - val_auc_1: 0.6036\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4827 - acc: 0.7283 - auc_1: 0.8464 - val_loss: 0.8676 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4964 - acc: 0.6957 - auc_1: 0.8250 - val_loss: 0.7821 - val_acc: 0.4583 - val_auc_1: 0.6107\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4956 - acc: 0.6957 - auc_1: 0.8314 - val_loss: 0.8109 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 481/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4918 - acc: 0.7283 - auc_1: 0.8293 - val_loss: 0.8346 - val_acc: 0.5000 - val_auc_1: 0.6143\n",
      "Epoch 482/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5004 - acc: 0.6957 - auc_1: 0.8205 - val_loss: 0.8713 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4976 - acc: 0.6957 - auc_1: 0.8219 - val_loss: 0.8107 - val_acc: 0.5000 - val_auc_1: 0.6143\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4857 - acc: 0.7500 - auc_1: 0.8343 - val_loss: 0.8480 - val_acc: 0.5000 - val_auc_1: 0.6214\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4901 - acc: 0.7065 - auc_1: 0.8288 - val_loss: 0.7816 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4905 - acc: 0.6848 - auc_1: 0.8260 - val_loss: 0.8618 - val_acc: 0.5000 - val_auc_1: 0.6107\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4963 - acc: 0.7391 - auc_1: 0.8252 - val_loss: 0.7973 - val_acc: 0.5417 - val_auc_1: 0.6107\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4847 - acc: 0.6739 - auc_1: 0.8274 - val_loss: 0.8220 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4917 - acc: 0.7391 - auc_1: 0.8310 - val_loss: 0.7884 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4953 - acc: 0.7500 - auc_1: 0.8345 - val_loss: 0.7709 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4853 - acc: 0.7065 - auc_1: 0.8331 - val_loss: 0.7931 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4869 - acc: 0.7174 - auc_1: 0.8329 - val_loss: 0.8034 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4881 - acc: 0.7283 - auc_1: 0.8319 - val_loss: 0.8505 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4933 - acc: 0.7500 - auc_1: 0.8295 - val_loss: 0.8081 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4817 - acc: 0.7391 - auc_1: 0.8388 - val_loss: 0.8064 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4754 - acc: 0.7391 - auc_1: 0.8455 - val_loss: 0.7817 - val_acc: 0.5000 - val_auc_1: 0.6107\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4800 - acc: 0.7500 - auc_1: 0.8405 - val_loss: 0.8858 - val_acc: 0.5000 - val_auc_1: 0.6107\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5004 - acc: 0.7283 - auc_1: 0.8224 - val_loss: 0.8994 - val_acc: 0.5000 - val_auc_1: 0.6214\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4967 - acc: 0.7283 - auc_1: 0.8288 - val_loss: 0.7787 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4866 - acc: 0.7391 - auc_1: 0.8381 - val_loss: 0.8353 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4901 - acc: 0.6957 - auc_1: 0.8255 - val_loss: 0.8485 - val_acc: 0.5000 - val_auc_1: 0.6143\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4842 - acc: 0.7391 - auc_1: 0.8352 - val_loss: 0.7683 - val_acc: 0.5417 - val_auc_1: 0.6286\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4828 - acc: 0.7174 - auc_1: 0.8357 - val_loss: 0.8062 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4820 - acc: 0.7065 - auc_1: 0.8386 - val_loss: 0.8168 - val_acc: 0.5417 - val_auc_1: 0.6036\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4837 - acc: 0.7283 - auc_1: 0.8314 - val_loss: 0.8187 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4868 - acc: 0.7717 - auc_1: 0.8362 - val_loss: 0.8527 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4868 - acc: 0.7391 - auc_1: 0.8343 - val_loss: 0.8308 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4758 - acc: 0.7174 - auc_1: 0.8417 - val_loss: 0.7789 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4859 - acc: 0.7391 - auc_1: 0.8307 - val_loss: 0.7886 - val_acc: 0.5417 - val_auc_1: 0.5929\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4784 - acc: 0.7065 - auc_1: 0.8367 - val_loss: 0.8719 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4954 - acc: 0.7174 - auc_1: 0.8171 - val_loss: 0.8545 - val_acc: 0.5417 - val_auc_1: 0.6286\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4845 - acc: 0.7391 - auc_1: 0.8369 - val_loss: 0.8302 - val_acc: 0.5417 - val_auc_1: 0.6214\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4839 - acc: 0.7500 - auc_1: 0.8381 - val_loss: 0.8138 - val_acc: 0.5417 - val_auc_1: 0.6036\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4823 - acc: 0.7391 - auc_1: 0.8376 - val_loss: 0.8345 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4837 - acc: 0.7174 - auc_1: 0.8376 - val_loss: 0.8491 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4744 - acc: 0.7500 - auc_1: 0.8429 - val_loss: 0.8383 - val_acc: 0.5000 - val_auc_1: 0.5929\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4828 - acc: 0.7283 - auc_1: 0.8329 - val_loss: 0.7795 - val_acc: 0.5833 - val_auc_1: 0.6286\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4954 - acc: 0.7283 - auc_1: 0.8295 - val_loss: 0.8559 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4734 - acc: 0.7500 - auc_1: 0.8474 - val_loss: 0.8001 - val_acc: 0.5000 - val_auc_1: 0.6036\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4824 - acc: 0.7391 - auc_1: 0.8355 - val_loss: 0.9043 - val_acc: 0.5000 - val_auc_1: 0.6107\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4860 - acc: 0.7500 - auc_1: 0.8326 - val_loss: 0.8624 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4809 - acc: 0.7283 - auc_1: 0.8305 - val_loss: 0.8129 - val_acc: 0.5000 - val_auc_1: 0.5929\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4808 - acc: 0.7174 - auc_1: 0.8338 - val_loss: 0.8336 - val_acc: 0.5417 - val_auc_1: 0.6321\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.4775 - acc: 0.7283 - auc_1: 0.8405 - val_loss: 0.8416 - val_acc: 0.5000 - val_auc_1: 0.6286\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4838 - acc: 0.7065 - auc_1: 0.8314 - val_loss: 0.8053 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4825 - acc: 0.7609 - auc_1: 0.8364 - val_loss: 0.8555 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4819 - acc: 0.7283 - auc_1: 0.8362 - val_loss: 0.8428 - val_acc: 0.5000 - val_auc_1: 0.5857\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4828 - acc: 0.7283 - auc_1: 0.8395 - val_loss: 0.8013 - val_acc: 0.5000 - val_auc_1: 0.5929\n",
      "Epoch 529/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4827 - acc: 0.7283 - auc_1: 0.8257 - val_loss: 0.8242 - val_acc: 0.5000 - val_auc_1: 0.6214\n",
      "Epoch 530/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4733 - acc: 0.7500 - auc_1: 0.8450 - val_loss: 0.7599 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4835 - acc: 0.7065 - auc_1: 0.8340 - val_loss: 0.8132 - val_acc: 0.5000 - val_auc_1: 0.6286\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4734 - acc: 0.7500 - auc_1: 0.8457 - val_loss: 0.8335 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4926 - acc: 0.7174 - auc_1: 0.8167 - val_loss: 0.8094 - val_acc: 0.5417 - val_auc_1: 0.6250\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4920 - acc: 0.6848 - auc_1: 0.8233 - val_loss: 0.8186 - val_acc: 0.5417 - val_auc_1: 0.6429\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4797 - acc: 0.7174 - auc_1: 0.8357 - val_loss: 0.7975 - val_acc: 0.5000 - val_auc_1: 0.6107\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4741 - acc: 0.7283 - auc_1: 0.8431 - val_loss: 0.7987 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4759 - acc: 0.7065 - auc_1: 0.8381 - val_loss: 0.8090 - val_acc: 0.5833 - val_auc_1: 0.6464\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4733 - acc: 0.7283 - auc_1: 0.8395 - val_loss: 0.8279 - val_acc: 0.5000 - val_auc_1: 0.5964\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4720 - acc: 0.7500 - auc_1: 0.8419 - val_loss: 0.8068 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4777 - acc: 0.7391 - auc_1: 0.8424 - val_loss: 0.7571 - val_acc: 0.5833 - val_auc_1: 0.6036\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4805 - acc: 0.7283 - auc_1: 0.8231 - val_loss: 0.8388 - val_acc: 0.5417 - val_auc_1: 0.6429\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4755 - acc: 0.7174 - auc_1: 0.8417 - val_loss: 0.8521 - val_acc: 0.5000 - val_auc_1: 0.5750\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4725 - acc: 0.7174 - auc_1: 0.8393 - val_loss: 0.7597 - val_acc: 0.5833 - val_auc_1: 0.6071\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4742 - acc: 0.7283 - auc_1: 0.8410 - val_loss: 0.8095 - val_acc: 0.5000 - val_auc_1: 0.5964\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4727 - acc: 0.7174 - auc_1: 0.8440 - val_loss: 0.8238 - val_acc: 0.5833 - val_auc_1: 0.6214\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4722 - acc: 0.7174 - auc_1: 0.8395 - val_loss: 0.8630 - val_acc: 0.5417 - val_auc_1: 0.6000\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4789 - acc: 0.7609 - auc_1: 0.8398 - val_loss: 0.7943 - val_acc: 0.5417 - val_auc_1: 0.6000\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4853 - acc: 0.6848 - auc_1: 0.8219 - val_loss: 0.8178 - val_acc: 0.5000 - val_auc_1: 0.5893\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4729 - acc: 0.7283 - auc_1: 0.8431 - val_loss: 0.7858 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4777 - acc: 0.7174 - auc_1: 0.8329 - val_loss: 0.7964 - val_acc: 0.5417 - val_auc_1: 0.6286\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4766 - acc: 0.7391 - auc_1: 0.8379 - val_loss: 0.8407 - val_acc: 0.5417 - val_auc_1: 0.6357\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4746 - acc: 0.7283 - auc_1: 0.8362 - val_loss: 0.7579 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4785 - acc: 0.7391 - auc_1: 0.8345 - val_loss: 0.7926 - val_acc: 0.5417 - val_auc_1: 0.6250\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4684 - acc: 0.7609 - auc_1: 0.8464 - val_loss: 0.7556 - val_acc: 0.5833 - val_auc_1: 0.6107\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4744 - acc: 0.7500 - auc_1: 0.8421 - val_loss: 0.8927 - val_acc: 0.5833 - val_auc_1: 0.6179\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4730 - acc: 0.7391 - auc_1: 0.8398 - val_loss: 0.7529 - val_acc: 0.5417 - val_auc_1: 0.6250\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4709 - acc: 0.7391 - auc_1: 0.8440 - val_loss: 0.8279 - val_acc: 0.5417 - val_auc_1: 0.6393\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4684 - acc: 0.7391 - auc_1: 0.8429 - val_loss: 0.8002 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4764 - acc: 0.7174 - auc_1: 0.8350 - val_loss: 0.8407 - val_acc: 0.5417 - val_auc_1: 0.6429\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4721 - acc: 0.7174 - auc_1: 0.8367 - val_loss: 0.8159 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4681 - acc: 0.7283 - auc_1: 0.8405 - val_loss: 0.7547 - val_acc: 0.5833 - val_auc_1: 0.6179\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4700 - acc: 0.7717 - auc_1: 0.8529 - val_loss: 0.7701 - val_acc: 0.5417 - val_auc_1: 0.6179\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4713 - acc: 0.7283 - auc_1: 0.8357 - val_loss: 0.8962 - val_acc: 0.5000 - val_auc_1: 0.5643\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4630 - acc: 0.7609 - auc_1: 0.8533 - val_loss: 0.7168 - val_acc: 0.5833 - val_auc_1: 0.6357\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4880 - acc: 0.7174 - auc_1: 0.8314 - val_loss: 0.8100 - val_acc: 0.5417 - val_auc_1: 0.5929\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4763 - acc: 0.7283 - auc_1: 0.8410 - val_loss: 0.7930 - val_acc: 0.5417 - val_auc_1: 0.6286\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4696 - acc: 0.7065 - auc_1: 0.8433 - val_loss: 0.8193 - val_acc: 0.5417 - val_auc_1: 0.6321\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4736 - acc: 0.7391 - auc_1: 0.8498 - val_loss: 0.8466 - val_acc: 0.5417 - val_auc_1: 0.6429\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4731 - acc: 0.6957 - auc_1: 0.8331 - val_loss: 0.8386 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4836 - acc: 0.7065 - auc_1: 0.8300 - val_loss: 0.8026 - val_acc: 0.5833 - val_auc_1: 0.6286\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4743 - acc: 0.7174 - auc_1: 0.8352 - val_loss: 0.7908 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4718 - acc: 0.7283 - auc_1: 0.8414 - val_loss: 0.8544 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4683 - acc: 0.7609 - auc_1: 0.8474 - val_loss: 0.8410 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4711 - acc: 0.7174 - auc_1: 0.8460 - val_loss: 0.7533 - val_acc: 0.5833 - val_auc_1: 0.5964\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4851 - acc: 0.7283 - auc_1: 0.8300 - val_loss: 0.9354 - val_acc: 0.5000 - val_auc_1: 0.5500\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4708 - acc: 0.7174 - auc_1: 0.8393 - val_loss: 0.7508 - val_acc: 0.5417 - val_auc_1: 0.6500\n",
      "Epoch 577/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4701 - acc: 0.7391 - auc_1: 0.8450 - val_loss: 0.7505 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 578/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4824 - acc: 0.7065 - auc_1: 0.8267 - val_loss: 0.7563 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4632 - acc: 0.7065 - auc_1: 0.8486 - val_loss: 0.8059 - val_acc: 0.5417 - val_auc_1: 0.6036\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4674 - acc: 0.7283 - auc_1: 0.8460 - val_loss: 0.7405 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4741 - acc: 0.7391 - auc_1: 0.8390 - val_loss: 0.8184 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4644 - acc: 0.7500 - auc_1: 0.8483 - val_loss: 0.8212 - val_acc: 0.5833 - val_auc_1: 0.6179\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4663 - acc: 0.7500 - auc_1: 0.8481 - val_loss: 0.7523 - val_acc: 0.5833 - val_auc_1: 0.6036\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4657 - acc: 0.7609 - auc_1: 0.8440 - val_loss: 0.8010 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4645 - acc: 0.7391 - auc_1: 0.8510 - val_loss: 0.7813 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4655 - acc: 0.7174 - auc_1: 0.8424 - val_loss: 0.8181 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4619 - acc: 0.7500 - auc_1: 0.8517 - val_loss: 0.7788 - val_acc: 0.5000 - val_auc_1: 0.6071\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4700 - acc: 0.7174 - auc_1: 0.8355 - val_loss: 0.7359 - val_acc: 0.5833 - val_auc_1: 0.6357\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4778 - acc: 0.7609 - auc_1: 0.8355 - val_loss: 0.8279 - val_acc: 0.5417 - val_auc_1: 0.6286\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4630 - acc: 0.7174 - auc_1: 0.8474 - val_loss: 0.8061 - val_acc: 0.5417 - val_auc_1: 0.6214\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4680 - acc: 0.7609 - auc_1: 0.8483 - val_loss: 0.8269 - val_acc: 0.5417 - val_auc_1: 0.6286\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4603 - acc: 0.7391 - auc_1: 0.8548 - val_loss: 0.8481 - val_acc: 0.5417 - val_auc_1: 0.6000\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4617 - acc: 0.7174 - auc_1: 0.8450 - val_loss: 0.7352 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4737 - acc: 0.7283 - auc_1: 0.8364 - val_loss: 0.7852 - val_acc: 0.5833 - val_auc_1: 0.6036\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4746 - acc: 0.7174 - auc_1: 0.8360 - val_loss: 0.8102 - val_acc: 0.5417 - val_auc_1: 0.6214\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4563 - acc: 0.7391 - auc_1: 0.8533 - val_loss: 0.8879 - val_acc: 0.5833 - val_auc_1: 0.6107\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4612 - acc: 0.7283 - auc_1: 0.8460 - val_loss: 0.7562 - val_acc: 0.5833 - val_auc_1: 0.6286\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4702 - acc: 0.7609 - auc_1: 0.8507 - val_loss: 0.7693 - val_acc: 0.5833 - val_auc_1: 0.6071\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4646 - acc: 0.7609 - auc_1: 0.8495 - val_loss: 0.8344 - val_acc: 0.5000 - val_auc_1: 0.5857\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4699 - acc: 0.7174 - auc_1: 0.8431 - val_loss: 0.9289 - val_acc: 0.5417 - val_auc_1: 0.5786\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4703 - acc: 0.7065 - auc_1: 0.8426 - val_loss: 0.8675 - val_acc: 0.5417 - val_auc_1: 0.59640  \n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4595 - acc: 0.7500 - auc_1: 0.8519 - val_loss: 0.9103 - val_acc: 0.5000 - val_auc_1: 0.5714\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4594 - acc: 0.7283 - auc_1: 0.8479 - val_loss: 0.7363 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4643 - acc: 0.7500 - auc_1: 0.8519 - val_loss: 0.8409 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4530 - acc: 0.7500 - auc_1: 0.8631 - val_loss: 0.9366 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4773 - acc: 0.7174 - auc_1: 0.8345 - val_loss: 0.8707 - val_acc: 0.6250 - val_auc_1: 0.6179\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4706 - acc: 0.7500 - auc_1: 0.8479 - val_loss: 0.8966 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4640 - acc: 0.7283 - auc_1: 0.8438 - val_loss: 0.8690 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4759 - acc: 0.7391 - auc_1: 0.8336 - val_loss: 0.8953 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4753 - acc: 0.7500 - auc_1: 0.8421 - val_loss: 0.8335 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4499 - acc: 0.7935 - auc_1: 0.8660 - val_loss: 0.9044 - val_acc: 0.5417 - val_auc_1: 0.5786\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4703 - acc: 0.7391 - auc_1: 0.8455 - val_loss: 0.8301 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4642 - acc: 0.7717 - auc_1: 0.8524 - val_loss: 0.7575 - val_acc: 0.5417 - val_auc_1: 0.6071\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4574 - acc: 0.7500 - auc_1: 0.8512 - val_loss: 0.7777 - val_acc: 0.5833 - val_auc_1: 0.6179\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4613 - acc: 0.7609 - auc_1: 0.8550 - val_loss: 0.8044 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4575 - acc: 0.7717 - auc_1: 0.8493 - val_loss: 0.8446 - val_acc: 0.5833 - val_auc_1: 0.6357\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4694 - acc: 0.7174 - auc_1: 0.8419 - val_loss: 0.9594 - val_acc: 0.5833 - val_auc_1: 0.5786\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4754 - acc: 0.7283 - auc_1: 0.8310 - val_loss: 0.7596 - val_acc: 0.5833 - val_auc_1: 0.6286\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4688 - acc: 0.7065 - auc_1: 0.8467 - val_loss: 0.8260 - val_acc: 0.5833 - val_auc_1: 0.6214\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4627 - acc: 0.7500 - auc_1: 0.8502 - val_loss: 0.7841 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4531 - acc: 0.7391 - auc_1: 0.8579 - val_loss: 0.7724 - val_acc: 0.6250 - val_auc_1: 0.6214\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4638 - acc: 0.7391 - auc_1: 0.8457 - val_loss: 0.9018 - val_acc: 0.5000 - val_auc_1: 0.5714\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4656 - acc: 0.7283 - auc_1: 0.8460 - val_loss: 0.8473 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4707 - acc: 0.7283 - auc_1: 0.8400 - val_loss: 0.8688 - val_acc: 0.5833 - val_auc_1: 0.5964\n",
      "Epoch 625/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4645 - acc: 0.7174 - auc_1: 0.8450 - val_loss: 0.8466 - val_acc: 0.5417 - val_auc_1: 0.6143\n",
      "Epoch 626/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4584 - acc: 0.7283 - auc_1: 0.8462 - val_loss: 0.8430 - val_acc: 0.6250 - val_auc_1: 0.6214\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4636 - acc: 0.7391 - auc_1: 0.8464 - val_loss: 0.9355 - val_acc: 0.6250 - val_auc_1: 0.5821\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4632 - acc: 0.7609 - auc_1: 0.8495 - val_loss: 0.7968 - val_acc: 0.5000 - val_auc_1: 0.6000\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4587 - acc: 0.7174 - auc_1: 0.8514 - val_loss: 0.8193 - val_acc: 0.5833 - val_auc_1: 0.6071\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4558 - acc: 0.7174 - auc_1: 0.8467 - val_loss: 0.8681 - val_acc: 0.6250 - val_auc_1: 0.6036\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4603 - acc: 0.7174 - auc_1: 0.8462 - val_loss: 0.8565 - val_acc: 0.5833 - val_auc_1: 0.6250\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4573 - acc: 0.7717 - auc_1: 0.8567 - val_loss: 0.8319 - val_acc: 0.5417 - val_auc_1: 0.5964\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4505 - acc: 0.7283 - auc_1: 0.8498 - val_loss: 0.8604 - val_acc: 0.6250 - val_auc_1: 0.6036\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4599 - acc: 0.7391 - auc_1: 0.8498 - val_loss: 0.7851 - val_acc: 0.6250 - val_auc_1: 0.6214\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4637 - acc: 0.7283 - auc_1: 0.8393 - val_loss: 0.8665 - val_acc: 0.5000 - val_auc_1: 0.5893\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4487 - acc: 0.7391 - auc_1: 0.8610 - val_loss: 0.9027 - val_acc: 0.5000 - val_auc_1: 0.5536\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4651 - acc: 0.7283 - auc_1: 0.8367 - val_loss: 0.7706 - val_acc: 0.5417 - val_auc_1: 0.6107\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4577 - acc: 0.7283 - auc_1: 0.8521 - val_loss: 0.8089 - val_acc: 0.6250 - val_auc_1: 0.6214\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4581 - acc: 0.7500 - auc_1: 0.8550 - val_loss: 0.7909 - val_acc: 0.5833 - val_auc_1: 0.6071\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4588 - acc: 0.7174 - auc_1: 0.8469 - val_loss: 0.8629 - val_acc: 0.6250 - val_auc_1: 0.6179\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4518 - acc: 0.7391 - auc_1: 0.8569 - val_loss: 0.8578 - val_acc: 0.5833 - val_auc_1: 0.5857\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4561 - acc: 0.7174 - auc_1: 0.8431 - val_loss: 1.0032 - val_acc: 0.5417 - val_auc_1: 0.5357\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4645 - acc: 0.7283 - auc_1: 0.8440 - val_loss: 0.7429 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4559 - acc: 0.7391 - auc_1: 0.8586 - val_loss: 0.7408 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4598 - acc: 0.7391 - auc_1: 0.8500 - val_loss: 0.7399 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4616 - acc: 0.7174 - auc_1: 0.8457 - val_loss: 0.8945 - val_acc: 0.5833 - val_auc_1: 0.5857\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4560 - acc: 0.7391 - auc_1: 0.8517 - val_loss: 0.7612 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4619 - acc: 0.7283 - auc_1: 0.8462 - val_loss: 0.8760 - val_acc: 0.6250 - val_auc_1: 0.6214\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4559 - acc: 0.7500 - auc_1: 0.8583 - val_loss: 0.8331 - val_acc: 0.5417 - val_auc_1: 0.5929\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4556 - acc: 0.7717 - auc_1: 0.8576 - val_loss: 0.7833 - val_acc: 0.6250 - val_auc_1: 0.6179\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4581 - acc: 0.7283 - auc_1: 0.8495 - val_loss: 0.8573 - val_acc: 0.5000 - val_auc_1: 0.5929\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4485 - acc: 0.7283 - auc_1: 0.8536 - val_loss: 0.8081 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4630 - acc: 0.7174 - auc_1: 0.8395 - val_loss: 0.8638 - val_acc: 0.5417 - val_auc_1: 0.5857\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4512 - acc: 0.7174 - auc_1: 0.8555 - val_loss: 0.7927 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4572 - acc: 0.7391 - auc_1: 0.8481 - val_loss: 0.9036 - val_acc: 0.6250 - val_auc_1: 0.6107\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4540 - acc: 0.7500 - auc_1: 0.8543 - val_loss: 0.8809 - val_acc: 0.5833 - val_auc_1: 0.5964\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4580 - acc: 0.7283 - auc_1: 0.8474 - val_loss: 0.9134 - val_acc: 0.6250 - val_auc_1: 0.6071\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4555 - acc: 0.7283 - auc_1: 0.8481 - val_loss: 0.8542 - val_acc: 0.6250 - val_auc_1: 0.6214\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4553 - acc: 0.7609 - auc_1: 0.8531 - val_loss: 0.8006 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4551 - acc: 0.7391 - auc_1: 0.8510 - val_loss: 0.8685 - val_acc: 0.6250 - val_auc_1: 0.6071\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4471 - acc: 0.7609 - auc_1: 0.8631 - val_loss: 0.7833 - val_acc: 0.6250 - val_auc_1: 0.6214\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4525 - acc: 0.7065 - auc_1: 0.8512 - val_loss: 0.7201 - val_acc: 0.6667 - val_auc_1: 0.6357\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4563 - acc: 0.7391 - auc_1: 0.8431 - val_loss: 0.7664 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4568 - acc: 0.7391 - auc_1: 0.8505 - val_loss: 1.0036 - val_acc: 0.6250 - val_auc_1: 0.5464\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4641 - acc: 0.7283 - auc_1: 0.8464 - val_loss: 0.8578 - val_acc: 0.5000 - val_auc_1: 0.5786\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4610 - acc: 0.7391 - auc_1: 0.8481 - val_loss: 0.8345 - val_acc: 0.5833 - val_auc_1: 0.6071\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4524 - acc: 0.7283 - auc_1: 0.8519 - val_loss: 0.9008 - val_acc: 0.6250 - val_auc_1: 0.5964\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4506 - acc: 0.7391 - auc_1: 0.8560 - val_loss: 0.8529 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4604 - acc: 0.7391 - auc_1: 0.8488 - val_loss: 0.8133 - val_acc: 0.5417 - val_auc_1: 0.5929\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4461 - acc: 0.7500 - auc_1: 0.8567 - val_loss: 0.7217 - val_acc: 0.5833 - val_auc_1: 0.6250\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4512 - acc: 0.7391 - auc_1: 0.8524 - val_loss: 0.9071 - val_acc: 0.5417 - val_auc_1: 0.5679\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4592 - acc: 0.7283 - auc_1: 0.8457 - val_loss: 0.8391 - val_acc: 0.5833 - val_auc_1: 0.5821\n",
      "Epoch 673/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4543 - acc: 0.7609 - auc_1: 0.8571 - val_loss: 0.9017 - val_acc: 0.5417 - val_auc_1: 0.5821\n",
      "Epoch 674/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4489 - acc: 0.7174 - auc_1: 0.8524 - val_loss: 0.9165 - val_acc: 0.6250 - val_auc_1: 0.5929\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4549 - acc: 0.7500 - auc_1: 0.8555 - val_loss: 0.8747 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4487 - acc: 0.7500 - auc_1: 0.8488 - val_loss: 0.9877 - val_acc: 0.6250 - val_auc_1: 0.5571\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4564 - acc: 0.7283 - auc_1: 0.8552 - val_loss: 0.9672 - val_acc: 0.5417 - val_auc_1: 0.5393\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4567 - acc: 0.7717 - auc_1: 0.8524 - val_loss: 0.7763 - val_acc: 0.5417 - val_auc_1: 0.6357\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4561 - acc: 0.7609 - auc_1: 0.8517 - val_loss: 0.8561 - val_acc: 0.6250 - val_auc_1: 0.6071\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4547 - acc: 0.7174 - auc_1: 0.8531 - val_loss: 0.8935 - val_acc: 0.5833 - val_auc_1: 0.5750\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4476 - acc: 0.7391 - auc_1: 0.8545 - val_loss: 0.8617 - val_acc: 0.6250 - val_auc_1: 0.6071\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4496 - acc: 0.7283 - auc_1: 0.8519 - val_loss: 0.9400 - val_acc: 0.6250 - val_auc_1: 0.5929\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4479 - acc: 0.7391 - auc_1: 0.8579 - val_loss: 0.7726 - val_acc: 0.5417 - val_auc_1: 0.6286\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4521 - acc: 0.7500 - auc_1: 0.8562 - val_loss: 0.8664 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4464 - acc: 0.7391 - auc_1: 0.8571 - val_loss: 0.9127 - val_acc: 0.5833 - val_auc_1: 0.5786\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4542 - acc: 0.7391 - auc_1: 0.8540 - val_loss: 0.8697 - val_acc: 0.5833 - val_auc_1: 0.5786\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4420 - acc: 0.7283 - auc_1: 0.8567 - val_loss: 0.7364 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4657 - acc: 0.7500 - auc_1: 0.8488 - val_loss: 0.8713 - val_acc: 0.6250 - val_auc_1: 0.6071\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4458 - acc: 0.7174 - auc_1: 0.8540 - val_loss: 0.9689 - val_acc: 0.6250 - val_auc_1: 0.5679\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4569 - acc: 0.7609 - auc_1: 0.8495 - val_loss: 0.8979 - val_acc: 0.6250 - val_auc_1: 0.5786\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4511 - acc: 0.7283 - auc_1: 0.8536 - val_loss: 0.7935 - val_acc: 0.5833 - val_auc_1: 0.6250\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4534 - acc: 0.7283 - auc_1: 0.8517 - val_loss: 0.9023 - val_acc: 0.5000 - val_auc_1: 0.5536\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4477 - acc: 0.7391 - auc_1: 0.8562 - val_loss: 0.9752 - val_acc: 0.6250 - val_auc_1: 0.5571\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4503 - acc: 0.7717 - auc_1: 0.8590 - val_loss: 0.9047 - val_acc: 0.5833 - val_auc_1: 0.5786\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4521 - acc: 0.7609 - auc_1: 0.8567 - val_loss: 0.9405 - val_acc: 0.6250 - val_auc_1: 0.5607\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4571 - acc: 0.7500 - auc_1: 0.8433 - val_loss: 0.8831 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4449 - acc: 0.7500 - auc_1: 0.8588 - val_loss: 0.8183 - val_acc: 0.6250 - val_auc_1: 0.6071\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4582 - acc: 0.7065 - auc_1: 0.8455 - val_loss: 0.8268 - val_acc: 0.6250 - val_auc_1: 0.6036\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4440 - acc: 0.7500 - auc_1: 0.8614 - val_loss: 0.7961 - val_acc: 0.6250 - val_auc_1: 0.6000\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4526 - acc: 0.7391 - auc_1: 0.8512 - val_loss: 0.9531 - val_acc: 0.6250 - val_auc_1: 0.5607\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydZ5hURdaA3+owOcKQhzAEQZGgDLAKKmZUMAfUdcWcddE17qqYdt1dw67hc3XNERXDImLCBIoBEJQgSIYhDgNMTt1d34/q2327+3aY0JO63ufpp2+oW109oU6dUOcIKSUajUajSVxsrT0AjUaj0bQuWhBoNBpNgqMFgUaj0SQ4WhBoNBpNgqMFgUaj0SQ4WhBoNBpNgqMFgSbhEULYhRAVQog+ceq/vxCiIh59azTNgRYEmnaHd9I2Xh4hRLXp/PyG9ieldEspM6SUmxsxloFCiJDNOEKIV4UQ0739r5dSZsTQ16VCiK8aOgaNpqk4WnsAGk1DMU+qQoiNwKVSyrnh2gshHFJKV0uMrTVJlO+paX60RqDpcAgh7hdCvCmEeEMIUQ78XghxiBDieyHEPiHEdiHEY0IIp7e9QwghhRD9vOeveu9/JIQoF0J8J4QoaMJ4ArQGIcQlQoiN3r7XCyGmCCGGAU8Ah3k1m93etjne8RR7n7ldCCG89y4VQszzjnUPcL/3++1v+qweQogqIUTnxo5f0/HRgkDTUTkNeB3IBt4EXMANQB4wDpgIXBHh+fOAO4FOwGbgvuYYlBAiC3gEOFZKmekdyy9SymXAtcB8r5kqz/vI/wFpQH/gKOAS4A+mLg8FfgW6APcAbwG/D/oen0gpS5pj/JqOiRYEmo7KN1LKD6SUHilltZRyoZTyBymlS0q5HngGOCLC8zOllIuklPXAa8DISB/mXYn7XsDZEZpL4EAhRIqUcruUcmWYPp3efm6TUpZ7x/0ocIGp2WYp5VNeP0c18BJwnqE1eNu+EmnsGo0WBJqOyhbziRBiiBDiQyHEDiFEGXAvSjsIxw7TcRUQ0dkrpcwxv1Arc6t2ZcC5wDXADiHEbCHEfmG67QrYgU2ma5uAXqbzgO8ppfwWpf2MF0IcCPQBPow0do1GCwJNRyU4kudpYDkwUEqZBdwFiJCnWgAp5UdSymOAHsBa79ggdMy7ADfQ13StD7DV3J3FR7yMMg9dALwlpaxtjnFrOi5aEGgShUygFKj0OlMj+Qfihtd5O1kIkQbUAZWoyR5gJ5BvOLG9ZqmZwF+FEBleh/U04NUoH/MKcCbKP/ByHL6GpoOhBYEmUbgJuBAoR63A32ylcdiBm4HtQAnK2Xut995nwBpgpxDCME1djRIYG4CvUT6AiJO7lHIjsAyok1IuaObxazogQhem0Wg6HkKIl4H1UsrprT0WTdtHbyjTaDoYQoj+wCnAsNYei6Z9oE1DGk0HQgjxN+Bn4K+NSZmhSUy0aUij0WgSHK0RaDQaTYLT7nwEeXl5sl+/fq09DI1Go2lXLF68eLeUsovVvXYnCPr168eiRYtaexgajUbTrhBCbAp3T5uGNBqNJsHRgkCj0WgSHC0INBqNJsFpdz4CjUbTsaivr6eoqIiamprWHkqHICUlhfz8fJxOZ8zPaEGg0WhalaKiIjIzM+nXrx/+MgqaxiClpKSkhKKiIgoKYi+qp01DGo2mVampqaFz585aCDQDQgg6d+7cYO1KCwKNRtPqaCHQfDTmZ6kFgUaj0XipqHVRU++O3rCDoQWBRqNJaNweD5W1LgDWF1fw287yZv+MihoXbk/bzeumBYFGo0loNpVUsa64osET9d6qOmqjaA8XX3wxXbt2ZeSIYWzdW93oMVbWuthe2vjno6EFgUajSWgqvNqAxyITs9vjocp734yUki17qlizqwKAmno3u8pr8HgkxeU11Ls9AEydOpX3P5gNQHW9K6QPc/Znl1tpJuZxFJfXsHF3JeuKKygur8UTJ61Ch49qNJo2wz0frGDltrJm7fOAnlncPXkooCZbu02EOFT/eMn57CveQWllFedffAX73XgdebnZ/Lx+B5V1LlZ99xlzPvyQF198kWVrNvKnP17Hxg0bAJj+4KMMPXg0AHYh2F5aQ3mNi87pSYwffxgr16wFQKIm/x1lNewur0OiJvU+ndLISnWyvbSGvVV1AHTJTKZrZgrbSwOjf+rdHpJt9mb9+YAWBBqNpp3i8kg8UpJkj82wUetys3pHOV0zkxFC0DUz2XfvnoeeYNR+vVm+uZjzJh3FMSeejAQq67zagmkl/qcbb2TE6EP559Ov4Ha7qaqs8N2rrFOmoopal0/T2GWazGtcHorLawPGtXlPVchYi8trQ9oB1LslybHvE4sZLQg0Gk2bwVi5R6Osup6NJZUA5OemkZnswOkIFQgej2RtcQW/FO2jR3YqALu8E2xlrd+B+/oLT3P13DnUuTzs3L6VzRvWgckK45YSKWFdcQULF8zjgX89BYDdbiczK9vXbp93RW+m3q06qnN52FkaOb4/1WmnOoLfwTA5NTdaEGg0mhZjXXEFndKSyE1PalI/5gmxaK9aUR/YM5vqejfpyQ6Ky2upqXezr6reZ4LZVR44CRsr9oXffcP333zFW7M/p97m5JKzJlFbWwsm81FVVTW1LrcvuqixlNXUW17vkZ1CitNOitPO7gq/NtA9O4UdJuFht8dnv4V2Fms0mqhc+tIiLn85fB2QtxdtYfnW0qj9HP3w15z42PyAa9V1bor2VIVE7QSX0d1RWs264grlZLXou6SyjnXFFewqq2F7aTV7q/x2eCBsVFBFWRlZ2TnU25xsWPsbvyxZRJLdRue8LqxfsxqPx8ObM9+l2mv2GTPucN565XnVp9tNRXlkn4ZNgMNkvspKcSJQE3peRjL5ual0yUwhM8WJ027z+geSGdg1gy4ZyQF9ZaXEwS6EFgQajSYG5v66k09X7rS8V+/2cPPMX5j0+Dch1+tcauVe63LzxBdrAAIcoGt3lVNSWceeqjq27qtmZ1kNlbUuquvcbCutYdX2MvZU1lJeU8+u8loqa10s21pKWXXoytpYre8oa1h6hcmTTsTtcnHmseN48qG/MvygQjJTHNxw+91cN3UKl51zMnlduyFsgoK8dP758CMsXDCfM445lHNPnMCW9b/5+kpx2unXOd13/sCfrmTqacezbs1vHDt6KO/OeIU+ndMY0iOT7FQnXbOS6ZQeONk7bDa6Z6eSluQIcGr37pTWoO/VELRpSKPRNImNuyt9x1JK3+Q1+fFv2LqvmmXTj+e17zfz0Kf+CfPj5dupc6vwSWN6M+zrweKmyCL+vsLCRGM4diOR4rBT43KT7LDTJTOZHaU1dM5K5f9emelrM7BrBh4P9N9dwbEnnUKvnFS27qsmK8VJZoqTYYP68dTLM3xCriAvnd0VdfTMTiHZGRjRM+ONNxBC4PJ4KNpTTc+cVGxCYLML+poERiR65aTitNvISo2PNgBaEGg0miZixNIDXP3aTxwyoDNvLdrCqh1qh+57S4q4d/bKgGeufPUn3/F/T+7RLOOwMv0kOWwM7pbJMq/ZKi1JCQKPlHRKT6JTelKIAzbJbsNt8/eVmeJEUE0XU5RRdoqT4opab58OCvICJ+msFCdlNfU+oeiw2eiXF9vEH0znIPNQPNCCQKPRNIjVO8oZ1DWDvVV1bNhdGRD++NHyHXy0fEdA+2lv/tyg/pPsNurcHnLTkqhzewIctHkZydS6PJSHcbqayUxxkp+bGmBeSUt2sKeqDofNfy04R5vdJrBJ/8Ukh41h+TkBbbpnp1BaXU+d28PePSUcc8wxIZ//6WefRR1jW0ELAo1GE0Cty801r/3EH4/ZjwN7ZQfcW7mtjBMfm8/1Rw9izc7ykEk/HDceux+PfPZb1HZdM1Ooc3moq64j1WlHAJWm++nJDtKTweXxkJeezJa9oTH4BilOG06vk7ZbVgq1Lg+5aU6kTCXFZMKxBUkCIUSIcAhGCMGgbpm4PR6SHHaWLl0a9bu1ZbQg0Gg0AWzYXcncX3cxf81uZl83nnlrdvvuGRE//1u61XLDUzgyUxxkJDssbftmHHaBYeq32QSYJuShPbOw29TEnu21l2/ZW4VdCNwW6SHMl7plpfiOg00tNiEY1iubmnoP1vFI1thtAnscdvm2BjpqSKNJEFZuK+OthVtCrlfUugLs5He+vxyAWpeHYx+dx31B9n1Qidqq6tw8ed7BDOqawf49sgLuz73xcJbedazvPCPZwd/PGA7Av6eM5M8n7s8H144P6ddpExg7uYRJDvTKSfUJATNDumcyuHsm3bNT6JqZHBCx0xCEEKQm2UlL8q+NB3TJYFDXzEb1197QGoFG08Gpd3v4YtUurnhlMQBnFeb77OYej+TAuz/h5BE9eezcg9hbWcfCjXtj7nvC4C6cOKw7G3ZXctTDX/uuD/ROoCPys/m5qJTMFCcTD+zOicNODLDZpycFrqjN8fYCfAb8cOv0JId6vmumf8U/sEsGa4sryEhu2vSW3sTn2xOJ8001mgRlxsItvlU+KA0g07sx6eeifQDM+nkbJw7rwbPz1/vaOe3Clx4hmKsmDGB4r2zfZJmR4p9KXrxotL+hdyLP8t4PTvb28R8PZ3eR/zMdNuETBjYh/JahBiTdTEt2MLRnNnabrnoWK9o0pNF0cOpdgeGRT3+9ni9X7fIdG1z56mIWbfJrA8FC4LLD/MXQb504hBOG+cM+89KTOf3gXrx/zTgmDO4aMobg+HqD3p3SAhy3ToeN7lkp9MpNJTPFQW6aEliZKQ1bs8ZTCGRkZMSt72hMnDiRnJwcJk2a1Kz9ao1Ao+mA7Cqv4dn5G7jl+MEhScye+FKlRU5x2qipjz2JmU0I/nHmcMYWdAq9ZxM8cvbIkOvGdBxrGV2b1zHQ2bvbNjXJwfCg0M1E5uabb6aqqoqnn366WfvVgkCj6YDc9s4yvli1iwFd0i0zYgJhhcBLF4/hxw0lPPnluoDrEji7sHeDxvG304fxz09WM7RnVsR26ckOFdv/0W2wY1mDPiMq3YfBCQ+GvX3rrbfSt29frr76agCmT5+OEIJ58+axd+9e6uvruf/++znllFOiflRFRQWnnHJKyHMbN25k0qRJLF+uTHQPPfQQFRUVTJ8+nbVr13LllVdSXFyM3W7n7bffZsCAAZb9H3300Xz11VcN/xlEQZuGNJoOiFEW8dZ3lkUN87xl4mAAZl83nqsmDGBsQSeSHaGmnGuPGtjgcezfI4vnp4627M/MgC4ZMadcaG6mTJnCm2++6Tt/6623uOiii3jvvff46aef+PLLL7nppptCkuBZkZKS0uDnzj//fK655hp+/vlnFixYQI8ezbPTuiFojUCjaee4PZIXvt3ApOE96Z6tomf2mLSA95duC2ifneqk1JS07aojBnD1BDXJGxvIkoJy+/fKSY1b5ssAIqzc48VBBx3Erl272LZtG8XFxeTm5tKjRw+mTZvGvHnzsNlsbN26lZ07d9K9e/eIfUkpueOOO0KeC0d5eTlbt27ltNNOA5QgaQ20RqDRtHNeXLCR+z/8lTOeWsAXq3bS77YPQ7SAXjmqKIvTLrhkvN/pe8z+XUMieVQ7NTUcNigvjiNvO5x55pnMnDmTN998kylTpvDaa69RXFzM4sWLWbp0Kd26daOmJnpW03DPORwOPB6/Kc7oKxYtoyWIqyAQQkwUQqwWQqwVQtxmcb+PEOJLIcQSIcQvQogT4zkejaY9c87T3zHink8Drs1Ztt234WvrvmouftG6ZsAzfxgFKO3BWO3ffsIQnr1wtGV7g2Rv21idve2VKVOmMGPGDGbOnMmZZ55JaWkpXbt2xel08uWXX7Jp06aY+gn3XLdu3di1axclJSXU1tYye7YqaJ+VlUV+fj7vv/8+ALW1tVRVhU+bES/iZhoSQtiBJ4FjgSJgoRBilpTSvE3xL8BbUsqnhBAHAHOAfvEak0bTnvlhw56A83q3h6tf+ylM60CMHbInDOvBlNG96ZSWxBmj8sO2N2r0dvJWEjvj4PBtOwJDhw6lvLycXr160aNHD84//3wmT55MYWEhI0eOZMiQITH1E+45p9PJXXfdxdixYykoKAjo75VXXuGKK67grrvuwul08vbbb9O/f3/L/g877DBWrVpFRUUF+fn5PPfccxx//PFN/v7x9BGMAdZKKdcDCCFmAKcAZkEgASOcIBsINGZqNBoAxjww13d8/+yVjBuUR26av9zjxKHd+XhF+ARwSQ4bP9xxNDlpTpIdds4eHTn6x8jdk53q5Nd7J5Li7PhW5GXL/NFKeXl5fPfdd5btKioqLK9He+7666/n+uuvD7k+aNAgvvjii5jGOH/+/OiNGkE8f7u9AHNikyLvNTPTgd8LIYpQ2sB1Vh0JIS4XQiwSQiwqLi6Ox1g1mjZLTb3bV3Ad4NlvNnDRCwtZsc1fGvKPxw6K2k+3rJSo0TsGHq8gsNlUDh4rP4Km4xBPjcDqLyfYM3Iu8KKU8mEhxCHAK0KIA6WUAQHOUspngGcACgsL24Z3RaOJE7UuN3UuD/PX7OYv7y/nH95kbWa6ZCazZqd/Zdq3UzqDumYEFIk5cVh35iyLLU10MIYPMzhFs0axbNkyLrjggoBrycnJ/PDDD22673DEUxAUAWb9M59Q088lwEQAKeV3QogUIA/YFcdxaTRthuo6Nxc89wPnje3D6Qfns6yolMlPfEOSw+Yrhfi4dyewmeLyWl5csJHh+dn875pxljn0e2arSKFTR/Zs8Ljyc9WzBY2sqtVQzCUu2wPDhg2LWw2CpvbdmEikeAqChcAgIUQBsBWYApwX1GYzcDTwohBifyAF0LYfTcLw0+a9LNqkXkkOm6/+b50pP1CyPbwF11yBK3j13iMnlS//NMEXOtoQTh7Rky6ZyRzSv3ODn20oKSkplJSU0Llz53YlDNoiUkpKSkoavB8hboJASukSQlwLfALYgeellCuEEPcCi6SUs4CbgP8KIaahzEZTZVsJrNVoWgCXqc7ube8ssyzc8uPGPSHXDMypls2T6MNnjeCUkT0D0jo3BCEEhw5omT0E+fn5FBUVof1/zUNKSgr5+Q2L8orrzmIp5RyUE9h87S7T8UpgXDzHoNG0RS59aRG1LjdTD+3nuxatete1Rw70JYwzMC+bxhZ04tftZdhtImJoaFvD6XRSUFAQvaEmbugUExpNKzD3V5V24LwxfcK2GVPQiSWb91LvlqQl2X05/88uzMcjYebiogBz0J9P2p8pY3ozpHvkBG8aTTBaEGg0LUxVnX/lXx5BCyjsm8vj5x6EyyPJSXUiBGzfV81Nxw/GJgTV9W6mHbufr73TbtNCQNMotCDQaFqIS19aSEayg817/CkESqv8yd+evmCUr5wkwPD8nICi6wD3nHKg7/jJ8w6O42g1iYQWBBpNCzH319Co6Afm/Oo77pHtn/SH52dbFoDRaOKBFgQaTRvBqP/br3Mas64d38qj0SQSHT+BiEbTTuiVk0qfTmncffLQ1h6KJsHQGoFG0wok2W3UuQNLRaY47cy75chWGpEmkdEagUaj0SQ4WiPQaOKI2yPZvKeKhUG1BGRI/kWNpvXQgkCjiQNvLtzMjIVbWLJ5n+X94EQqP999XAuMSqOxRpuGNJpmZO2uCtbuquDWd5ZZCoHu3n0B04McwtmpLVAYXqMJg9YINJpmwOOR/PPT1Tz11bqI7S4ZX8Blh/fH7ZH85f3lALx5+e9aYogaTVi0RqDRNAOb91RFFQIAld70EnabP0fQ2BZI9azRREILAo2mibg90pdELho6ybqmLaIFgUbTRB797Dfu//BXy3uPnXuQ73jS8B5cfnj/lhqWRhMzWhBoNE3ko+XbLa+fOKw7J4/wl4n82+nDfGkkAN656hC++tOEeA9Po4mKFgQaTSP577z1LN9aGlBlzCAvI5lHzh4JwAkHdgcCq4kBjOrbiX4tVBNYo4mEjhrSaBrBt2t3B2QOBRjSPZNVO8oBGNg1nRSnHYB/TzmIB2pduh6vps2iNQKNJgZ2V9Ty0bLtGCW1z3/2h4D7l4wv4NLD/Pb/ZIfdd5zksNEpPallBqrRNAKtEWg0UVi0cQ9n/uc73/nq+yeGtMlOdXLqyJ7c+f5yquvdjOyd05JD1GiahNYINJogqupceLx2/x/WlwQIAYCnv14f8ozdJnDYbcy75Uh+/7s+XHGEjg7StB+0INAkDLUuNze+uZRNJZW+ax/+sp0bZiyhpt4NwL6qOg646xP+76u17Kuq45xnvgegW1ay75lHPvsNUPUD/H2rlNJdMpO5/9RhpCVpZVvTftCCQJMwLCsq5d0lW5n25lIA5v1WzDWv/8T/lm5jxbYyAD74RYWCzlm2g5H3fuZ7Nj05dGLPy/QLh7wM7QPQtF+0INB0WNwWYZ0AxRW11Ls9LFhX4rt2xSuLWLxpL3d68/8U7a0KeCbJbuOywwoCrnU1CYLzx/ZtrmFrNC2OFgSaDsnMxUUMuGMO2/ZV+66V16g8P7vL65j25lL+87U/N9Duijpe+36T77zM2zYvI5nR/XL595SDuGrCwIDPyEpRGUNH5GcH5A7SaNob2pCp6ZC8uXAzoJLB9fTa8stq6gGorncz22sCctiEb0OYYec3882tR/r2A3g8kolDu/PF6l3UuTw+c1B+p7T4fhmNJs5ojUDT7qipd3PUQ18x77fisG2qvc7fZIf/T9zQCMxkpPjXQuuKK0LuG0IAwGYT/OeCURx7QDcADuiZxWPnHsSDpw9r+JfQaNoQWhBo2jzLt5byxxlLfDb/TSVVrN9dyb2zV4Z9prpOCQJz+oe1u0InenPaB2NX8Nc3T6Cwby43HD3Ism9DuNS5PJw8oieZKbqojKZ9owWBps1zxSuLeX/pNrbuVfZ+I6d/epJarX+zZjelVfUBz9TUKzPP3+b8isvt4a1FW3hxwUYAjtivi69dWpKdYHLTk5h51aFMO3Y/y/EYgsDKlKTRtEfiKgiEEBOFEKuFEGuFELdZ3H9UCLHU+/pNCGFd4FWT0Bgx/kaqnrJqNenbbIJXvtvI75/7gVP/71tf+4Ub97DV6yT+afM+Xvh2I7fM/AWAFKctYPIXhDp5k+yR/y0mD1cZRQv75TbuC2k0bYy4CQIhhB14EjgBOAA4VwhxgLmNlHKalHKklHIk8DjwbrzGo2m/GPb+e2evZEdpDXur6gBYsnkfd/5vBQAbdvs3id3tvWZgJId7/NyDWHHPRFKDtIA7ThwScG72K1hx6MA8Nj54EkO6ZzXi22g0bY94agRjgLVSyvVSyjpgBnBKhPbnAm/EcTyaVqDe7WHtrvIm9WFoBJ+t3MmNby1lT2W9ZTspJTMXF7Fyexn9LdI7Tx7RE7tNBGgE/bukc/nhAwLa6SyhmkQjnoKgF7DFdF7kvRaCEKIvUAB8Eeb+5UKIRUKIRcXF4SNFNG2PBz78lWMemcf20urojU243B6OeugrPvh5G+Z9YbvKa/l0xQ7LZ6rq3Pz5vWXkZSRxzylDA+6NLejkO073pn/ITXPyjzOHN2hcGk1HJJ6CwGpZFa5i6xRgppTSbXVTSvmMlLJQSlnYpUsXqyaaNsq3a3cDUFYdGroZiX3V9azfXckNM5YEXF+7q4IfNuyxfGZ7aQ21Lg+XHdaf4b0Cs38+cJo/xNMwDU0a7o/4efGi0Q0an0bTkYinICgCepvO84FtYdpOQZuFOiRGyGe4nbe7K2rpd9uHvLlwM49/vsaX77/U6xAOkyXCkoc/XQ2olNDJzsA/7exUf4inEVqak+a/NmFw19g/SKPpYMRzZ/FCYJAQogDYiprszwtuJIQYDOQC3wXf07QvKmpdpDnt2EyTvlsaM7n1jL50swoUu/WdZQD07pTG5BE9fYKgIXy0XJmMslKdIQ5fsyAw+j64j4760WggjhqBlNIFXAt8AvwKvCWlXCGEuFcIcbKp6bnADCllA9Z+mrZGWU09B979CY/O/S3gusutfq11rsBfb63LTa3LTY0r0Br4xzeXctWri9nnjQxqDNmpzhCHb5JJMNx03GD+fOL+AfsJNJpEJq65hqSUc4A5QdfuCjqfHs8xaOLDnGXb6ZaVwqi+alVtxPa/s7iI4w7ozqvfb+Lgvjm+/D71brX5al9VHat2lHP9G0uodXkCcvobfLpyJ5+u3NnosWVF2enbJTOZyw7XhWM0GgOddE7TKK5+7ScA/j1lJEcN6Yqhz7k8kqtfX8yWPdW8ucgfNLaxpNJX57ei1u84jmYC6pWT6tscFomXLh7Dhc//CPjNQHNvPII6l8cnhKIxuFtmiIai0SQCWhBomsQNM5Zy4rDu3HjsYECFd1ox77fdAQIgVoZ0zwwQBKcf3It3f9oa0u7wQXn84ZC+/FJUSrdsVSdgYNeMBn3WJ9MOb/D4NJqOgBYEmgaxqaSSzXsCi7as2VlBbZSVtAwbOWzNcxcWcsR+XVhbXMGqHeU+YfDI2SNDBEHfzmkIIbj3lAMb9BkajUahBYGmQRz98NcBGT1BbeSqi5KAzWoVH461D5yAw5vvZ0j3LL697SgG/XkO1x+lsoFOO2Y/BnXL8JmnZl83viFfQaPRBKEFgaZBBAsBUNlAmzMTp8Mi6duaB070Hd9wzCDKa/y+BZ0GWqNpGjoNdQejus7d4HQOFbUulm8t5b0lRcxcXBS23cfLt1te31dVz57K0HDPfp1DK3ddf9RAjh/azXfe2AqPyY7Q9NEajaZxaI2ggzH1hR/5YcMeNj54UszPXPPaT3xtqvZ15qh8y3YrtpWF7WPOslAhYa7+ZXDjccqpvKyolH3VdfTITuWYR76OeawGTrtODKfRNBdaEHQwjDw8bo+MWlB97sqduDyS79eXBFx/5LPfKC6v4eA+ufyuf2d+KSplbP9OPPXVOjKTHZRbRP8YNYAjYR7OsPxsyzbvXzMuaj+gM4RqNM2JFgQdlIpaV0BaBYPtpdVc9epPTBjchX/NXQNAqjPQzPLY5+r6Gz9uCXneSgiYueHoQfzb+3xwgZe8jOSo4x7ZOydqG41G07xoQdCBqKrzT9KVFoKgpt7NR8t2sHTLPpZu8ReDMwq/xMpn0w6naG81F724MOTeudks4JgAACAASURBVGP6sGJbGeMHdmb8oDwueWkRm0pUuOmpB1lmIddoNK2MdhZ3EKSUnP20P2/f75/9gUtfWsTjn69hR2kNUkoue3lRxILvZg7p3znsvUHdMjm4r3XCtiSHjWcvLGTquAIGds1kzvWH+e7dOnGI5TOzro3NHKTRaOKDFgTtjPKael8aZTP/+Xo9y7f6nbnrd1cy99edPPzZb/zub59TcPsc5q/ZHbHvqyb4K3W9ftlY3/F+3TJ4+KwRAW2tir5DaJlHp8k8FM5nMTw/h1nXjuOLm46IOD5NB6K+GhY8AR6d0qMtoAVBO6C6zs3iTcoJPGz6p74om/Kaep77ZgMej+TV7zc1qu/pkw/gzkkH8M5Vh3DL8Sqi55j9uwU4Yx88YzinBZl1zBP8inuO9x2HCoLYnLrD83Po36VhKSE07ZivHoRP/wzLZobeqywJvWameh+4ImSnrdoDHg/UlEVu15y4XVC9t2U+Kw5oQdAOuOntpZzx1HeUVKg8Pka6hftn/8p9s1fS/445MSVmMzjdNKlfeGg/LhlfwKi+nRBCsPaBE3jmglEAnFPYm1Snnf556b4aA/27+GsBF3jrAqcnO3juwkImj+gZshnMECjRCsJrEoxKr3bqDspNtXUx/LM//PJ2+Gf/3hdeP9v6XkUx/KMAvvobPNgbXjm1ecYbjTl/gr/3aznB08xoZ3E7wDDpVAWZhNbvroj67F9PG8Yd7y3znf/zzOH075LOu0u2cvKIniFhmOaJ/O9nDuf+0w70rf7n33IkWSYH9OzrxvuSzB29fzeO3r8bVvzrnJGMiEM00FUTBgRoJpp2hNs7YdqT/NdctfDfo9Txhq9h+FkWz3l3lK//0rrfKq+AWfk/9b7p26aPNRZ+eVO9u6rBkRS5bRtEC4J2QHmNigb6Zq3fxj/ink+jpnAe3S+XU0b2DBAE+/fI4sBe2cy98XDyc0N3/gZjnmh7dwpsn57soCA5+p9QvKKFwjmfNe0Aj/dv1+5dWNRXwwd/9N9fPSf0GYDK4tBr+7bAmk9h+DkgvL6r3av994sWQX6hOi5ZB/VV0H1YaD9Nwrugqq+BFIs9MlLCqg9hv4lgb3vTbtsbkSYst7/rn9AjCYHZ142nrKaeQwfkASpX/zuLi1i9o5xB3ZQdfmDXzPgOVqOJhLGyt3mnoDk3wy8z/PerSmD919A/KICgYldgH3YnzJ0Oy2eCMxXyx4R+1rNHw/RSdfz4werdOG9uXGFMtD/PgPevhBMfgjGXxeezm4AWBG2c4jD5/SNxYK/AFckR+3XRZRk1bQuPd8+LETW0c0VoGyvnq1kQ1FeBPRvKd/jv2VrJVChMGoEVW1RRJmTzJWdsTrQgaGOs3lHOnso6RvXNxeXx8KM3ZUQ43r9mHL9uLwvQFjSaNo/hIzA0A7eFk9VmClH+/D51ntPHf61sG3z9D6U9gHoPV/p88YuQ0zfCeFww5yaoq4STn1C+hYpdMPLcGL+QVxCE0whK1qr3DAs/2trPAz9r5f9UfwecHNo2TmhB0MY4/l/zAs6D0z8YXHFEf24+bjAOu42RvXM4p7A3/e8IY1fVaNoaW1UtCZ8AcFlovoa9v6YM5j+kjo/8s//+R7cqp7JB1Z7w+xI+uCHyeNZ+poQFQJ9D4MMb1XGsgiCaRlC2Tb1baQSvnh74WW/9Qb3Hy3xlgRYErcjWfdVkJDvITnWyq7yGWUu3hbQJl/5heK+cgAgfm03w4kWj6ZIZPZ+PRtOq7F4DNd4UJz7NwEIQGBrB7jX+azt+8R/Xlge2r9oNspEb1FxhJvCYiaIRGN+3vZqGhBDJwBlAP3N7KeW98RtWYjDuwS/o0ymNv542jN8/90PYdnabwB1UECY1KdQWOmFw12Yfo6aZ+Pw+2L4Ufv9Oa48kvmz/BV6aDNf8AJndYdMCePcKuOob+PBPkJQOoy70t3fXwad/gX2bQ/vyRQD9Fti/gVmLSMmB3z4ObxoK5ukjYOT5MPZyeOEkqDWlWLebcnTNuRlO/Gf0/owobCuN4JkJfvNVJEGw9A21/6EViMWz8j/gFMAFVJpemiZgTOyb91SxZW9VxLZ5GaFxySlhTEaaNsr8h2Dt3NYdw+41sOL9hj2zb7P17t9wLHhMrX7XeeP8v/wrlG6GLT/Csrdg8QuBm67cdbDgceu+jMm1ypQaZZ9pB71Zi+jrzVe15pPYxrl9KXx0szre9E2gpmEzCYIfnwl8TkpY+JwyV1kNNlgjqN4L25b4zz1ubx/PQm3QPqD/XR34/ZbNhNLwhaKak1hMQ/lSyolxH0mCUVLp/yOuMZl/umelsKMsspp61qh8RvfrFLexaVoBKdUEmmqdzM9HfTUIGzjCmABrK8CRYh2r/s2j8MtbMOSkwFWvFdV71Sr7xZOUMNj/ZP9GKeNecE2ImlI1PvD3n+ZNXlhmMnuaJ/D6CDviXbXq+wRPujl91JjMAiWrZ+TvEw6rFXzwz6Z6H6TmqPedy5X/YMM8OP2/KnIpJdv/s6jep/p0pqhzs1kLlOlq7efw4U2wYxlM/rf/nrAHagzvXAK5BXDD0sZ9twYQi0awQAjR3LsvEp5dZf5/hns+UBlB5918JN/fcTT5uakBbTNMm7YePmsE/zxrhN5R214JN/EteFylKDBCIcPxQHd4YnT4+3/rpSYQK4pXq41cezdG/ozyHWosCx7zm2wM00nxanVv6euBz9SUwYN9YNVsdS68f59J3vxRe9b525pNOpFMITPOU9+ntgyc/tQm9Bip3s0CJSn65khLqizyGtmCtO2/94Ulr6r3okXq2sr34ZEh6tq3//K3/fBGeGR//7kRLWTgcUOt1wkcHB7rsaj1UR694FNzEMtsMh5YLIRYLYT4RQixTAjxS9SnNAF8uWoXM37czOJNe9hVVsOu8tCViOHoDd4xa3YAHzIgfHpoTTsgXGKyhc+q9+Cdsz+9DN8/FXhtX5QEgyvfh+/+Dxa/pM5//K96GavTJ8eqCJtwGJPPZ3f5r9V4J68tP6r34BQPwRNWndfsYThJzd/bKkIoEjVlgZpST68gqNjpvxaLb8CRGnrNShCs+yL0mvH7Kdsa+uzc6YHfr3oPrHhPHQf/PqVbJcSDQBOUuhn6uaJlTMCxmIZOiPsoWoLtP8Om72DM5a2y6SS4iEuvnNA/yhSnGtfkET3509s/U+tSfzAXjyvg+/XqH1cnb2vnVO+zNmMYE2ldkPtt1nXq/XdXBV4vLVKJ24xJEfwTDMAnt6v3UReqhGhmpBuWv6N2uBavVp9ZW6528W5ZGLjD12DD15DeRT0HahJb9AJ0KoD+E0IFQW0F7NkAG+erc7MGYRUhFInqPZCSBYaFqMeIiM3D0m9cqJ/GShD89HLotd3elb2I8f/v7alqj0RZUCSgx+1f+dscfsEajlg/r4mEFQRCiCwpZRlQHq5Nu2L91/DZnTDyPPVH1cpYZQs1J4B77dKxvPHjFh46a3jA9SQtCNo3IeYAr3/ICKMMDokMaGua6B8dqt7NseYei7QjnjBRKuneneZPmlIy3LoRnjvGuv3saWqj0/qv1PnPr6uXzQl3FkPp1sD2teXwmFlIuQLvNYSybZBs+p/tVRjaZvCJypQViTQLbbpmX+g1K+q8Y66OsT3AuxapJKTHJAjs8NyxkftoIUEQ6VMMEb4YWOR9X2w6b18ke3Pr1EXP2NmSnDS8h+X1wn6dePjsESHZQZMdOlqo3fH3Av9xxQ6Yng0/PA2PHgj3doL/jPff37ZE3d/4TWAf8x5SNvhgpmerV225f5eumXvDOJ+rStRzZnatCjxPDrpvCAEznnplww/esFUXYbKPtrkrmLKt/v9fUI7b634KbNP3EDjt6cj9WDnio5mpbEFr5arIxZ2iYtYIrHZTBxPskI8TYQWBlHKS971AStnf+268+rfI6JoT4w8pOGSrlXl8ykENah9roRdNG2DNXJVXv9pkjy9Zr96//juUblHHu0zlQ3/7WL0veTWwry/uizy5rvnMWiMIQMB53jz/xs5ZMy8EBQcOPSVyd6O9K953Lw/97HAhoWaSggoR9TnEul1VidLir10El36urllFTUWLuAr+PEdKdEHgSAk8b2oI8OIX1N4KiBwxZWCzK4f95/eqNBhxIia9QwiRK4QYI4Q43HjF+NxEr5N5rRDitjBtzhZCrBRCrBBCvG7VplnwCYKWt3Q9/82GsPdsNsF+3TLITIltk3ewhqBpw7x2Brx7aeC1aI5eY5VYH3lvSQibFoTao4NJzYFeo2Lrb9hZsH8EQXD4LTDoOHVsCK8+h0L34bH1D6Hpms98IXzb5CzIG+RPJ223yPkfSRD0KoSu+wdec9X4f875Y2DcH0Ofs/qchpLayf+z2v2b2k8BsQkCYVNO+/kPw7rPmz6WMEQVBEKIS4F5wCfAPd736TE8ZweeRDmbDwDOFUIcENRmEHA7ME5KORSw+E00E8ZqINKqKg7U1LtDCsb3yA5cZXx0w+Esveu4iP1MHtHIOGlN28II3awLM9Eb2TVjmSQACo5Q0TAL/wtPHRq5bVpnlarZik4mJf/yr+CMZ6HAu97rdqB6P/R69W5PhqP+DOlBNvfx0+DK+eo9Fsw2+77jIcvaTAqE+vWCTTYQXhCMuQIu+9zvFwHl4Aa/s/j3M+GIW0OfjSYIkmPwNw47E85+JfR6rILA2Fuw5tPo7RtJLBrBDcBoYJOU8kjgIMCiOkQIY4C1Usr1Uso6YAZqh7KZy4AnpZR7AaSUu4gXraQRLNwYGqb3yNkjA87tNhG2sLvBv88ZyZoHOkYAV4fntbNg/iPW9wxBYOxATQqqC2GERNZVxlb2sPOA8JO7Myi2Pq1zqKnDwBAEPQ+Gnl5zpSMJbl4Hl30B01bCEbeo68aEHex8Na4fdSec8qT/+hG3+c1IB5imAPPEnRqlgl1y0M8pFo3g9iL401o4/q/q3Ph55I+GA89Ux0YYrT3ZepNdNEHgTMO/BToM9qTQvQkQm9YnbKrwDsDqj6K3bySx2CNqpJQ1QgiEEMlSylVCiMExPNcL2GI6LwLGBrXZD0AI8S1gB6ZLKT8O7kgIcTlwOUCfPhYOs1hI9moELeQj+Hbtbob2zGL1jlDBk+Sw8cMdRzeoP5tNYIv2B6dpG6z5NPzqrXRL4Hn3YbB5QWi7ip1QHyWTy++uhiPv8MesB5PTB4pNDuC0vMDQ6ZMehq1LIKMrdBuq7N/Boa3pqrgR2d4qc5MehQHecpI5fdUkv2ulMtt09Sr8NjuMOA9mXa9CVe0OlXcIILefv2/z5D45SsRPsOPaatJOMQmTCber/s2fkV8Ixz0AI86Fjd4sv4ue8/aXFOiYzeqlnNTRyk7anV5fQ4TVvSPZej9AbXCaCguE3R9pVrZN7ZeIg3k4FkFQJITIAd4HPhNC7AWiGCMBazEZvGPCAQwCJgD5wHwhxIFSyoAYLSnlM8AzAIWFhTFmlQrCUOFaIGqootbF+c+GTyKX4rTRLSvMykzT9nC71IQWLq1DU0g2OTCTs/27TvdujLzpC9SkZrOF36Q24GjVT1pnNakF2+RHX6p0fYg9B1Hhxf5jIeDI263b2Www7nqV1gL8K2uzw9OYpH93jd/MNPZKlYKhJCg1Q4hpyGr1bprO9p8cel8IOPTawM82j9fM2CtVuLnd4ndeeDEset77nF0Jg0iCYPg51nuXwv3eAsZsM0UXSRVxFC09SCOIahqSUp4mpdwnpZwO3Ak8B5waQ99FQG/TeT6hAqQI+J+Usl5KuQFYjRIMzY/hI2gB09COUutcQYV9c3l+aiFDe1rUNNW0XV6YCPfHKbNrurffzoMg16Ttelzw/tXqOHg1DHD2y9E3Rh78B/jLTv+kGEmQZeer98Zu1rIiz2s46DRAaQwAnfv7BZJh0jKnhzjh73CNaZPV8HPUe3CdAfN3D44Ggug7coNNciF415tWGsGkR+Fo765rKSNPzLdtgS5hDCgxCQIRGNnU5HTZ1kT8SxJC2IQQy41zKeXXUspZXpt/NBYCg4QQBUKIJGAKMCuozfvAkd7PykOZitY35AvEjPHLssrn0czstEgad9G4fjx6zkiOGmJRoUjTtilaGL1NQ7Anq8nu4k9goNfMYrP7NysN9G4yKvpRmR2mLYfLglI6WK2IgzFW0YZjNZx/AJTZ5JLP4LCbYv8e0RgxRX3HoafB4BPg4k+h8BK4bglcs9Cv8QRXDjNP8oa5J9Ju5Bt+Dr1mZZM3E6wRBGOkrLDSCMCfrsLjDv1d/ME0zQX7aQCOb0CqaWFTgsAQbLH4jRpBRNOQlNIjhPhZCNFHSmmRMDzisy4hxLWoKCM78LyUcoUQ4l5gkZRylvfecUKIlYAbuFlKabHnuxkwduiFq2DUDCwrKmV7aTXlNaHC5u7JQ+P2uZoWZMuP0GVI+N3pseS86XuIf5X4q5Gkze7XVn93paqYJT3KqZmSBb0ODuwjFvOAMdkZbY3V7aRHAyNoDHpbFH5vCkJAn9/5z/t4XYTpndXLSEuRE8HvN+E25VQddnb4NoYfI+Czo2hLyRZaRACGIDB+zoIAy7ahXVmZavof4T+2ygKb3Quy+6j03MGkdwnMT2SzKyGYkqU0iIam54iRWHwEPYAVQogfMdUhkFJGLagppZwDzAm6dpfpWAI3el/xRQhAxLVC0OQn1G7QwwZZ/GFq2j/11SolQL/DYOps6zZWGmevQthq2oyfa9ppbKzSbTZ/nqHOg/zOyi77WX9OcEy8FYbJxNAIjNWt2c7fmgw7SxV1N8JTrUjrBKc80fC+owmCaJvPDAzfht0ZuBPYMGtJN9gsorZGnAs/v2HdpyPVWkCYP8+HUJ+b3F0JgtYwDXnJACYB9wIPA48A7dO+YbM3vpRdA5i/ZjcXHtKX729vWGRQh+O1s1R1po6CYboxEqkFU7IO7rNYBOT0hrv2qEgaCNQmjFW6sKtQUIDMHn6bep6FILhzt9+mH4ng6JI4OBmbxJjL4M6S0P0IzUFzmYaMlX/wvgWzRmB81okPwV1eu/+pT/mPg3Gmwp4wFvBgQWDs2Db8RK1hGjLaSCm/Nl8QQoQJXG7jCHtcTUNm9uueSffsFGZeeQg5ac2wO7E9EscNMK2CVabKtZ/Drx/AsffAM0daP+dI9UaXeP/dzLn1jVW6zQ4XvK8KnziSlKN1/VfWgqChE7rxN99CCcwaRLiVcVNpcvpmwzTk/d+1OWHqHH8YrM9H4PH/XG0Ov39DiPBhnuH2fUCoQ9/Yd2IsHuJkGgr7lyGEuEoIsQwY7K1DYLw2AO2zHkEcNQJPUE3hTt7Jv7BfJwZ2jWaP1LQLzPnvDT6+TeWPWTnLH/oZjG/16DVLJqWHthE2tSFrkNdRvP9kGHxSYNx9OE79DwyZ5D8ffg6Mmuo/l21YEMSLaBoBqBV8MAdf6N1rcJ4Sxkb6b5tdpbE2tDazRmAWBLFgFgT5QUWGfnc1dLEw+xkaTENrOcRIpJG/DnwE/A0w5wkql1JGCXBuowh7+LS8TaSkMlBlK9SlJDseFRYb340NiuFUfQi0J0NguKRvkg6auAoOU69YGHmuehnZRA+9Tm1UMzA0glgmx7aE1YQYK7FoBGMuC63VcLJpY9u1P/orxgVP8ubfaUMFgTl6y+y0d6ar+hGjLgzNDGvsg4qTIIiUfbRUSrlRSnmulHKT6dU+hQAotS1OGsFrP/iTiZ05Kj+gqliHZcb5KrtmYyj+DR47GCpMERKvnB5aArEtYdYI5twML58K5d6tMVaCwJiMjH98Y0I2V8oyJo9YnZexEBzOaNi7W6jaVbNw8zqVH6ixNLfQC45MstQIYvxMc0ipYXo6+A9w0yrr9hB301CcDHRtlDj5CGpdbv41178TckxBAmgDUqr6tKtmK2eoOUzQimUzYeAxKiZ/+8+q9uueder5wotUm3Wfq9fI86z7cLtUJMaIc+NnWw7GHA46927/8Y/PBLYz1+Q16D4Mti/1rx7NlakM8kfD0XeriaCpCK/pM9iHYETKtSfTkFVIaEOI9buePzPyBJ7ZHSY+GLpT2byPwPAFxCwITBqB8btK6xy5YJYhPFrBNNTxEPHRCFZs8+cMef2ysRzSPwHqCpvDJJ8/PrBSVjA7V6qC6kMm+YubG1gVUwnHoufho5vVqmj0pdHbNwex/uPtWBZ6bfSlMOta2N8baS0tTDRCwGExRk8PP0f9LMOR3kUVvgmeBLWPIDyGTyYSwWVCweTUlY3wEaSpv4nK3X7tLVhby9tPpawOpqVNQx0SW3w0gn+btIHR/TolRs2AhuzQNkwqwUIA/LHZsfxeyorUe0PKBTaVhtYFMDPoOCUguw5R50211Z/+DFz1Tfj7A7xRS8EaQXv1ETSFeJvBzA5fQxDE+pn2JDjnFbj4I79mG/y7uXYhHHiG6YJXM42lqlkjSCxBIOITNfTr9jJG9c1l1rXjcNo78I90/iOw7gt1HLySL1oEn/zZb0ox338lQmqqukpVoH22qRTFAtMGoopieO8q5ZQ1Yqjn/VPVoG4o67+Gr/4eW9vqvfDelao6lBmrureZpoydRg6bo+6EzDDbbWJdOTaUyf9WKR2C9xi0R9NQLNzwi3pZEW+hZ3b4NlQjMC8UDeFhJUSsVv+tuKGs42Czx5YCIAbeWrSFA+76mIpaF7srajmkf2eG50fJqd7e+fweeOU0dRysEbx+Nnz3hFJ3IfaV9NcPwk8vq5fBp3+GDfOhaLH6zJ9fV74Bo09XDbwcdWN7IDtXqme+8uamr94H2yNEQX/3pPrM188JvJ5q4f8xfBzgn4T7WhSJOeEfcNDvla8kHjiSrX01HdU0lNtXvayI93cNEATeSbwxAt4nRCzGay5cM/ZKVQHOKjVIM9DB/jKiIGzNZhq6ZeYvVNW5OfDuT/BI6JqVAFFCZsLZ9nevVu+xVtgKl/LjpUnw7FGw5BV/f1Y201h5ylQP1+OGV8+Apw8LH05sjL9iR+D1NAtBsL9JKBlOTqvVXHYvVbAlHumsI7GftxaxUeYxEYi3aShAEBjO4kZMp4bwsBpv2Vb1fvbLaoFx8Ucw5KSGf0YMJJazOI4byromQriomWCNwJkGlKjJulchPBxL7aIG8NmdodeMWGubA27fqt4f6O7fln/Zl7D8HVj1YeBzP73sz/1TW+oP3dz6E/z3SLh+Sagt1kgSFpya4Orv/btNQRV42Tg/rjmtGsyQk+Avu1peALUmjZmUG9N/Wl7DTUNmjM2FVgtU42+o4IjQe81MYgmCOKaY6JKZYIVmPEEagVF5a/Y0fzGSeHDc/Sp6yBy373HBq6erKB3zuD66xTqFtNkfUbXHLwiMJGHPHQ+VQZvHMroqQWBeCfYapZK/mc2Nx9yjwkaNKl5thUQSAi3FeW+r3/97V3ovNCJIxFhYWNVSP3eGyl8VrYxnM5BYgqAZNYKMZAcVtf5VcYfWCGorAlfIu9dATYRw0WAHa3PQ82BlWjnkWsjuDW9fGHh/07eh0USx1BEoXqUKpdSU+ifLYCEA/mIq5qRgU7yb34RQobH7TVQx4gf9PrbvpGl+Tv8vLHyuZT5rv+PUu2Eaaszc4qulblE5sfMAf0qLOJNYgqAZfQQCVXu4zqXUtw69k/g/42HvBv/5Ew2wNWfl+8M+reg1CrYu9p+f8RwMOxPevQJ+maGuOdPgclNhluC6ugaGf6IhzAizeS0YQ4U3irwfe1+gSWjKaw3/bE3zM/xs9WpJDNNQY8yBRqrwFiihG4kEcxbbm812W+/xMPXQfr7zFGcHjtE2CwErIpX9M9Ta056Grt7iPGe/4r9/4QfKzm6EZRor7pMfV6GBt2yAPy4ngOBdp2l5gGj+6nNZpjBM45+921C47ieVz0ejAZMgiBKReMsG9TKT3HIldCORWILA1nwaQb1b4rR38I1j1XthwePR23U7AE56RIVHGhxwqoprN+ymGV0hwxv6lpQG570F576pVtpd9/eHxZmraeX2VVE6wfnqcwtUnP5h3oRhuf1UDv9geo8NPLcqaB6OTv3hgves73UeED7FsCbxiFUjSOsUGnXWgrXUI5FYgqCZNpR5PBK3R+Kw2Vhw21F8cVP8vfqtwq8fwKd/Cb0eXFpQShh9CYy9wr8bst/4wFTIzjTTPwyw3/EweKKpE+/EGkuufSHg8D+pOrh4+7IqbnLKk/7jA8+ASf+K3rfBsfe1mH1W085pimmoxwj1PvqS5htPI0gsQdBMKSbqvbHnSQ4bPXNS6d+lg9YbsHJggb9akkG3A0LbGDZ1Y+HsSIGu3nZWsfi+WOwGFF3JL1SVv464BTK8u3jN2/KNaKAhk+DM55VJySwMrIq+mMdv7E7N7u2vMZzRPovzaeKIUTbUatd5NNI6qTQkQ09r3jE1kARzFjePj8DlVrZAh60DmwdWvKd211phDmebcAeMu8F/bthJgyd0m11l2Rx0XGghdqBBGkFwvwAT/67i9wccpfYOgJr4L/oYuptq4o6aqjSa1FzI6QsvTPRvVDvjOfj4dhU1ZAiyy79SgiAlR+0W7jeuYePTdHyOvkvtFm/HG/YSSxDYmkcQ1LtVHx06r9DbU8PfO+4+fy3i/hMC0+pGwpEE/cOY0Qz1OqR4d4zkDVQvgDNf8O/K7HtIYDshYKCplvS5M9Qu437jlDYxd7q6bgiCngf52/af0LixaTo2dmf4v+t2QmIJgmYKH633agQd1lkcLfqhyxBl86+vil4XYNhZKkWzlTPXTENzukfiwNNjb9t5ANywNHQcjgTbIKhJaDrwktaCZtpQ1uE0AlctPNBTZQ+9J1elWgjHqf9RKXiN7fTBJiDDhm6ExR16PdyxLXqhEd+mnOZJCthocrxJzBpqotJo2jFaI2gELp9G0AEEQdUeleGzvlJlDwX4/v/CtzeqKPkEQdCf0NF3QZf9/InOhLAu1h6CoV21siA46yVYOzc0Mkqj6cAkmCBoQY2CowAAFF5JREFUmkZQ7/bgtNuo82oEjo5gGprzJ79z1WD9V+HbGxqAPejdICkNCi9u+Dh8GkHDH21W0jvDiHOit9NoOhAdYEnbAJoQPvrekiIG/fkjNpVU+kxDSR1BI7Aqul61O3x7e5Am0FxFVvodpt6bWqtWo9E0mA4wkzWAJoSPfrRM5aX/dXu5P3y0PQmCTQtgxvl+Qbj6Y5h5Sew7Gn0FMZrRqWvm6Lvh2sXhC41oNJq4kVimoSakmLB79wy4PdJnGmoXUUNSqj0B71+lKntV7YG9G+ENr/kjJTvi4z6y86Gy2FSA3WsSaq603naHP/xTo9G0KO1oSdsMNMFHYAgCl8eDqz1FDa37AmZe5K91WlcOz5lKJQankzbnC8o2OUzTvCYbo6LXuOvVe0bX5h2vRqNpceI6kwkhJgohVgsh1gohbrO4P1UIUSyEWOp9XRrP8TTFR2DsIi6rcfH2YpVWuU0LgmUzVQWvV4Ni6q2Kvp87Azp58+qMmKLeexXCtGVq+/v0Ur8pyBCko6aq60YUkUajabfEzTQkhLADTwLHAkXAQiHELCnlyqCmb0opr43XOAIH1Xgfgc0rCO58358S2dPaMe8GrjpV8H38jWqF/skd8Nsn1m2LV4VeG3iMqqpVsVOZii76SG0aM2PUVI1ThTeNRtN6xNNHMAZYK6VcDyCEmAGcAgQLgpZD2BptGrLKKzS4W4Q8/PGgbDsU/Qj5o1Vxlq0/qRQIG+bBj89A+XY4ejr88J/wfezdGHie2VOFgGbnqxeonDrBTPyrem9rJRg1Gk2TiadtoxewxXRe5L0WzBlCiF+EEDOFEL2tOhJCXC6EWCSEWFRcXNz4Ednsfht3A7EHCYLrjx5Ebnoj8+I0lg9vhLf+oGqk/vaJKrS+5FWV6gGgfCdUlUTuY09QYYzRMcb85/aDc19X+wQ0Gk2HIp4agVVITbAt5QPgDSllrRDiSuAlIGTJKaV8BngGoLCwsPH2mCZoBMGCICe1FVIQ7PSapTZ+40+LPMtkVauriLwHAAI1goLD/cVdNBpNwhJPjaAIMK/w84Ft5gZSyhIpZa339L/AqDiOp0nOYrupIlWyw8aEwV0itG5mVn8Em3+AfVuUWUi6lTAIpqokukbgrvUfZ/XSlbY0Gk1cBcFCYJAQokAIkQRMAWaZGwghzCkpTwZ+jeN4VIpjd12jHq1z+xWRd646tGWL0bwxBZ4/DpDKsQuwy8LVUrETNn+vjodPUeUcIxFTDiCNRtPRiZtpSErpEkJcC3wC2IHnpZQrhBD3AouklLOA64UQJwMuYA8wNV7jAfypkxuBkVYCICulFTNT5g2C5CyoLQu6IQAJS19T3/P0p9XlL+4L31dSB62sptFoGkRcdxZLKecAc4Ku3WU6vh24PZ5jCCApQ2kE7nqYPQ2GnupfYUfBLAgyUlpxQ7YzHS7+BEq3wOtnq2snP6GyfT7k3Zl77L3WzwZvqDOihDQaTUKTWCkmDFNIbTkseUW9ppdGfsZLncskCJJb6Me2b4sKCTXjTFE1grsdAKc+BRu/VcVfnClw3AOwZx2Musi6v/4TYN3n/nMtCDQaDQknCLyhjxU7Y35k6ZZ9zPutmHq3h8HdMnnx4tEkOVpoR/G/Dgy95kj1H488T70MDrXYl3fAKbDyf+p43A1KEBxwKqx8X+0e1mg0CU+CCQKvTbx8R8yPnPrktwAcOqAzqUl2emSnRnmimagJ9gF4ibU+sMHZLweex6gBaTSaxKENJ8uJA84wGsEPz0DRooiP7q6ojU/9gU0L4LsnQ6+vnWvd3tFCgkij0SQMCaYReH0EwRrBRzerd+9qeU9lHZkpjoCkcsXltXTJTG7+Mb1wgnofejpkmaJpd66wbt9QjUCj0WiikFgagWEaMmkE095cGtDE45EcfN9n3DLzl4BIob1V9SQ7mrkYi9vlP34kKMlbuB3CWiPQaDTNTIIJAq9GUFrku/Tekq0BTYyiM+8t2UpVXeAu5PSmRgvNvhEe7Atf/xP+PSIwPUQw4XYIa41Ao9E0M4llGsrtp7SC3z72XcrD7zwtn/8UtoPO951X1bnMT5Oe1ESNYP2XULMPvrxfnQdnAjWoKYVfP1D1gD2BY9AagUajaW4SSyNwpkDvMQFpJm5yvOU7zvz8NhxfPUA61QAhGkFaUhPkZk0pVO+N3KauSqWa/p9XUwgWAuAvHq/RaDTNRGIJAghJq1BDYCrp5EX/YUXKJWRQxaTHAhO7pTVWIyjbDg/2UYJg2Fnh2+1cDo/sD796UzL1GNm4z9NoNJoGkHiCwBloWnFgnY00g2qq69U9oyhNWnIjBYHJJxFxcl/8IgGZui94r3Gfp9FoNA0g8ewMDuVsrc/qR33pdnJEhWUzj0lG9spNZVNJFTlUwqbvoO8h1n17PLB8JuT0VcXi+x8B25bAvk3+NmmdQp9L66ycw0tfg7z94JBrITnDuq1Go9E0MwkjCFZsK2XJ5n2c50jBBqzYZyNfJJNNpWV7O/7Q0e5ZKWwqqWLg1vdg3uNwx3ZwWFQn2/YTvHuZ//zWTfDMhMA2qbmhz104Gz64HooWwvCzYdSF/nvmjKmHXhfbl9VoNJoGkDCC4Js1u/nbR6s4e0IySUCpzKAT5WQLa0HgEC6flSbLW43MU1OuHLjuWmtBULol8PzvfUPbWAmCpDRVML6mVGkHZnL6qILzU+dY1xLWaDSaJpIwPgKj1KTHrkxD5aRRRQo5WJuGHHjoxh6mOWZy6oieAHQyQvjd9aEPSAmzrlfHXYeGH0hqLly/FM54zn8tKUMVkE/PC60Yllug3qtKdDUxjUYTFxJGEBjpIgxBUC2TqCKZvrZdlu0duHks6QlucLzLSd1K+OSPhzOoszfFhFWVs/Lt/mIxJ/4j/EBSc6FTARQc4b8WqUDM8Q+o2sL9jwjfRqPRaJpAwpiGDI3AbVdmnmqSqZLhcwc5cZk2mwkGd88Ej1cTcNWGPmDOFpoawcmbkqPeHabPjrRbuPMAuPCD8Pc1Go2miSSMRmCEgHrq1Wq+hiSqCD8Bz0i6j2RhTPw16t3QBKxMQzX71PsZzwX6Af4wK7Cd4Vtw6FQRGo2mbZAwGoHDaxqqr1URODU4qSV87eEsUY1DeiOH6rwOZSNJnCEQVs6CXgerVBGbvlPXcgsgNcffUaYpo6gZeyvWPdZoNBoTiSMIvBrBtuK95AE1Mok6EXkyThNeE5BPENT532tK4a0LILt3YLRQSnbgpjVnKhwzHeZOh95j/de141ej0bQREkYQGD6C3UkqAmid7EVvWRzbw0YcvyEIVrwH3/5LHQeHjJq1AVD7AMZPUy+NRqNpgySMIHDalSD4qdNknqy1s1gOZpxteWwP//wGlG31+wZWfRi+bXJW4LlRJ1mj0WjaKAkjCOw25SOoqvewWA4GoD7Wr792rnoNOk6dW4WPgkotEbzRLJJT+LgHoOuQ8Pc1Go2mBUgYQWD4CIxEcgB1Df36hgCwSg8NcNSdodci+QIOjVCYRqPRaFqIhAkfNXwENU0RBPWqToFl+CiodBAajUbTzkgcjcDrIzBXHXPJBqaVNspHWpmGxt2git4Y3PAz7Nvc0GFqNBpNi5M4gsDrI6iu92cVlTQwhLPSG2VkpRGMuTzQDJTbT700Go2mjZN4piFT+ckGC4Iab8oJY6exmeCsoRqNRtNOSBhBYISPmp3FjUZa9OHUReU1Gk37JGEEgaERmH0EGo1Go4mzIBBCTBRCrBZCrBVC3Bah3ZlCCCmEKIzXWAwfQU2Aj6CJjJoKw8+Bngc3tSeNRqNpNeLmLBZC2IEngWOBImChEGKWlHJlULtM4Hrgh3iNBfxRQ4GmoSbk++l3GEz+d9MGpdFoNG2AeGoEY4C1Usr1Uso6YAZwikW7+4B/ABYe2ObD0VDTkLCpOgBJmdb3nTp1hEaj6RjEUxD0AswZ2Yq813wIIQ4CekspZ0fqSAhxuRBikRBiUXFxjInigvBvKPNEaYkqEn/pXFUZTIZpr3MIaTSaDkI89xFY2V18ZnkhhA14FJgarSMp5TPAMwCFhYWNMu0bPoLAwYQxDR13v6lRmCgjZ3pjhqHRaDRtjnhqBEVAb9N5PrDNdJ4JHAh8JYTYCPwOmBUvh7HhIwDo30VN4nsIY/Yx4wknCHS4qEaj6RjEUyNYCAwSQhQAW4EpwHnGTSllKZBnnAshvgL+JKVcFI/BGD4CgBSHndcvHcvnK/tA/nAYcBRsWwpZPQmJJQqnEWjTkEaj6SDETRBIKV1CiGuBTwA78LyUcoUQ4l5gkZRyVuQemhe7SRAkO20cOjCPQwfmAcPUxex86wfD+Qi0aUij0XQQ4pprSEo5B5gTdO2uMG0nxHMsTrvfCtY7txlW81oj0Gg0HYSE2VlsFgSnH9wrQssw2ILqG+vwUY1G00FImOyjdptgzQMnAIFCIWaSM6B6r/9cCwKNRtNBSBiNAJQAaJQQgNCNZUnaR6DRaDoGCSUIGkXXoerdGVR7ODWn5cei0Wg0cUALgmhMnQ2XfgG2ICtaSnbrjEej0WiamYTxETSatE7qZQsqa6kFgUaj6SBojSBWgqOGtCDQaDQdBC0IYiXYNJSsBYFGo+kYaEEQK/YgjcAiiZ1Go9G0R7SPIFYMH8Gg48BV27pj0fx/e3ccamddx3H8/WF3m2tT5zaT4Wy31RANTMdYLkPKVpSJ/yS4ISiiKCtICaqNIAz8R/8QGYlmZRSYWZY1BqnjakEad03ddHNOVy0cbt6tmKMI0fXtj9/3zMPZudu9es95ntPzecHh/J7vee69n3N5Lt/z/J5zf8fMppAbwUS1poZW3AxLV1WbxcxsCnl+Y6JmTmDJajOzAeQzgon60l0wbwl85DNVJzEzm1JuBBM1ewGsuq3qFGZmU85TQ2ZmDedGYGbWcG4EZmYN50ZgZtZwbgRmZg3nRmBm1nBuBGZmDedGYGbWcIqIqjNMiqSDwN/f45cvAA5NYZxeG6S8g5QVBivvIGUF5+2l95N1cUSc2e2BgWsE74ekrRGxvOocEzVIeQcpKwxW3kHKCs7bS73K6qkhM7OGcyMwM2u4pjWC+6sOMEmDlHeQssJg5R2krOC8vdSTrI26RmBmZsdr2hmBmZl1cCMwM2u4xjQCSV+QtFvSHknrqs4DIOkBSWOSdrTV5knaLOnVvD8j65K0IfO/IGlZn7OeI+kpSbsk7ZR0S13zSjpF0hZJ2zPrd7P+YUmjmfVhSTOyPjO39+Tjw/3K2pF7mqTnJW2qc15JeyW9KGmbpK1Zq91x0JZ3rqRHJL2cx+/KOuaVdG7+Tlu3I5Ju7UvWiPi/vwHTgL8AS4AZwHbg/BrkuhRYBuxoq90JrMvxOuCOHF8O/A4QcDEw2uesC4FlOT4VeAU4v45582fOyfF0YDQz/AJYnfX7gLU5/gpwX45XAw9XdDx8HfgZsCm3a5kX2Ass6KjV7jhoy/YT4MYczwDm1jlv5pgGHAAW9yNr359gRb/UlcDjbdvrgfVV58oswx2NYDewMMcLgd05/j6wptt+FeX+LfC5uucFPgA8B3yC8h+ZQ53HBPA4sDLHQ7mf+pxzETACXAZsyj/uWuYdpxHU8jgATgP+1vn7qWvetp/7eeDpfmVtytTQ2cBrbdv7slZHZ0XEfoC8/2DWa/McciriIsor7VrmzWmWbcAYsJlyRng4It7pkudY1nz8TWB+v7Kmu4FvAv/N7fnUN28AT0h6VtJNWavlcUCZBTgI/Din3X4oaXaN87asBh7Kcc+zNqURqEtt0N43W4vnIGkO8Cvg1og4cqJdu9T6ljcijkbEhZRX2iuA806Qp9Kskq4AxiLi2fZyl11rkRe4JCKWAV8Evirp0hPsW3XWIcr0670RcRHwb8r0yniqzkteC7oS+OXJdu1Se09Zm9II9gHntG0vAl6vKMvJvCFpIUDej2W98ucgaTqlCTwYEb/Ocm3zAkTEYeD3lDnUuZKGuuQ5ljUfPx34Zx9jXgJcKWkv8HPK9NDddc0bEa/n/RjwKKXR1vU42Afsi4jR3H6E0hjqmhdKg30uIt7I7Z5nbUoj+DOwNN+FMYNy2rWx4kzj2Qhcl+PrKHPxrfq1+U6Bi4E3W6eL/SBJwI+AXRFxV53zSjpT0twczwJWAbuAp4Crxsnaeg5XAU9GTrr2Q0Ssj4hFETFMOTafjIhr6phX0mxJp7bGlLnsHdTwOACIiAPAa5LOzdJngZfqmjet4d1poVam3mbt90WQqm6UK+yvUOaKv111nsz0ELAfeJvS3W+gzPWOAK/m/bzcV8A9mf9FYHmfs36Kctr5ArAtb5fXMS9wAfB8Zt0BfCfrS4AtwB7KaffMrJ+S23vy8SUVHhOf5t13DdUub2banredrb+lOh4HbZkvBLbm8fAb4Iy65qW8ueEfwOlttZ5n9RITZmYN15SpITMzG4cbgZlZw7kRmJk1nBuBmVnDuRGYmTWcG4FZB0lHO1aBnLLVaiUNq221WbM6GDr5LmaN858oy1OYNYLPCMwmKNfhv0Plsw62SPpo1hdLGsk14UckfSjrZ0l6VOVzEbZL+mR+q2mSfqDyWQlP5H8/m1XGjcDseLM6poaubnvsSESsAL5HWQ+IHP80Ii4AHgQ2ZH0D8IeI+DhlfZudWV8K3BMRHwMOA1/u8fMxOyH/Z7FZB0n/iog5Xep7gcsi4q+5AN+BiJgv6RBlHfi3s74/IhZIOggsioi32r7HMLA5Ipbm9reA6RFxe++fmVl3PiMwm5wYZzzePt281TY+iq/VWcXcCMwm5+q2+z/l+BnKqqEA1wB/zPEIsBaOfVDOaf0KaTYZfiVidrxZ+elmLY9FROstpDMljVJeRK3J2teAByR9g/JpWNdn/Rbgfkk3UF75r6WsNmtWK75GYDZBeY1geUQcqjqL2VTy1JCZWcP5jMDMrOF8RmBm1nBuBGZmDedGYGbWcG4EZmYN50ZgZtZw/wOgYNJtTgzywQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.11661641,  2.2787657 ,  1.6072975 , -1.8229865 , -0.1283139 ,\n",
      "         0.55697435, -1.9929711 ,  0.16694292, -2.4900753 ],\n",
      "       [ 1.5763817 , -0.8465356 ,  0.74003   , -0.48852453,  2.0594366 ,\n",
      "         1.7697512 ,  1.17863   , -2.3190103 , -0.10189691]],\n",
      "      dtype=float32), array([-0.2955748 , -0.03789438, -0.6677702 ,  0.5710089 , -0.25751728,\n",
      "       -0.37946373, -0.07156496,  0.2508837 ,  0.4782387 ], dtype=float32), array([[ 4.76859897e-01, -9.22853291e-01, -7.17126876e-02,\n",
      "        -1.98352635e+00,  6.57936037e-01, -1.88258195e+00,\n",
      "         1.24040890e+00, -6.41779065e-01,  8.34517658e-01],\n",
      "       [-5.35944663e-02,  3.30619603e-01, -4.05663401e-01,\n",
      "        -1.28080606e+00, -7.86436653e+00, -6.57834336e-02,\n",
      "        -1.92037866e-01,  2.97807407e+00, -1.26187086e+00],\n",
      "       [ 6.19013667e-01, -2.94540375e-01,  3.45148027e-01,\n",
      "        -1.74140382e+00, -3.60491467e+00, -8.58346403e-01,\n",
      "        -6.25762194e-02, -1.41642347e-01, -6.90046400e-02],\n",
      "       [-5.52924514e-01,  2.49286756e-01,  1.07756734e-01,\n",
      "         2.36344647e+00,  5.40267611e+00,  1.11748660e+00,\n",
      "        -1.70482665e-01, -3.00095677e-01,  4.14816439e-01],\n",
      "       [ 5.56136549e-01, -1.65285373e+00, -5.58548927e-01,\n",
      "        -9.09575343e-01,  6.13683760e-01, -2.09003401e+00,\n",
      "         2.47768331e+00, -7.24864304e-01,  2.26759124e+00],\n",
      "       [ 4.13296282e-01, -1.11812663e+00, -3.55522544e-03,\n",
      "        -2.55444360e+00,  1.21429719e-01, -2.64400387e+00,\n",
      "         1.33533812e+00,  1.10707395e-01,  6.68947041e-01],\n",
      "       [ 3.37977886e-01, -6.26132250e-01,  3.01949054e-01,\n",
      "         1.41925192e+00,  6.48895741e+00, -4.23669130e-01,\n",
      "         3.58579457e-01, -4.27409410e+00,  1.75212669e+00],\n",
      "       [-2.62714237e-01,  2.23482990e+00,  4.77546394e-01,\n",
      "         1.46170628e+00, -1.26647472e+00,  2.68611455e+00,\n",
      "        -2.48973012e+00,  7.98787892e-01, -2.77616048e+00],\n",
      "       [-7.28313088e-01,  3.39509025e-02, -4.30897266e-01,\n",
      "         3.49651289e+00,  6.51594353e+00,  1.18247032e+00,\n",
      "         5.02793081e-02, -1.11089802e+00,  6.50177658e-01]], dtype=float32), array([-0.7021919 ,  0.16842632, -0.25942963,  0.15956132,  0.7648985 ,\n",
      "        0.0871178 ,  0.10628564,  0.40292355,  0.1449287 ], dtype=float32), array([[ 2.36545339e-01, -2.90664345e-01,  1.88862777e+00,\n",
      "        -9.60806489e-01, -1.08924627e+00, -4.28013057e-02,\n",
      "         3.49391818e-01,  8.47552121e-01,  1.93938967e-02],\n",
      "       [-5.21298945e-01,  5.69581330e-01,  1.05916536e+00,\n",
      "        -3.41094971e-01,  2.63419211e-01, -5.95206857e-01,\n",
      "         9.82127309e-01, -1.92252314e+00, -8.86203647e-02],\n",
      "       [-5.91876388e-01, -5.58678329e-01, -1.08285666e+00,\n",
      "        -5.45573175e-01, -1.72114924e-01,  4.65356439e-01,\n",
      "        -7.66789556e-01, -5.26086211e-01, -4.71387208e-02],\n",
      "       [ 2.82639921e-01,  1.27941036e+00, -1.48701036e+00,\n",
      "        -1.14094353e+00, -8.10816526e-01, -1.41478992e+00,\n",
      "        -5.40391922e-01,  7.39244401e-01, -1.11392830e-02],\n",
      "       [-4.53742445e-01, -3.39190453e-01, -1.76872432e+00,\n",
      "         1.04732895e+00,  8.90597403e-01,  3.43038321e-01,\n",
      "        -1.70885181e+00,  2.18120575e+00, -3.13860364e-03],\n",
      "       [ 1.21307172e-01, -1.03285599e+00,  2.35705018e-01,\n",
      "         1.60548043e+00,  7.07594454e-01,  8.91731918e-01,\n",
      "         3.36503714e-01, -1.41801405e+00,  2.85925921e-02],\n",
      "       [-6.43814623e-01,  8.77483413e-02, -7.37060845e-01,\n",
      "        -1.37886271e-01, -7.19783502e-03,  3.86336207e-01,\n",
      "        -7.46139348e-01,  2.78202128e+00, -5.96475229e-02],\n",
      "       [ 3.61235961e-02, -8.81585836e-01, -5.06325662e-02,\n",
      "        -7.87239373e-01, -6.76619709e-01,  1.11646259e+00,\n",
      "         4.01729012e+00, -1.21661127e+00, -4.31145206e-02],\n",
      "       [ 2.05035970e-01,  1.51529104e-01, -2.00172633e-01,\n",
      "         4.31954205e-01,  2.65150398e-01, -4.85785961e-01,\n",
      "        -2.72945738e+00,  2.06256461e+00, -1.03882395e-01]], dtype=float32), array([ 0.06760953,  0.3239948 ,  0.31361496,  0.22845054,  0.00582578,\n",
      "       -0.5100867 ,  0.7856188 ,  0.13812944, -0.02668249], dtype=float32), array([[-4.5971782e-03],\n",
      "       [-1.5926116e+00],\n",
      "       [-1.1844715e+00],\n",
      "       [ 1.3868711e+00],\n",
      "       [ 6.7293292e-01],\n",
      "       [ 1.6957209e+00],\n",
      "       [ 2.4187286e+00],\n",
      "       [ 2.2475972e+00],\n",
      "       [ 1.7561853e-03]], dtype=float32), array([0.06678137], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5577351 ]\n",
      " [0.44335765]\n",
      " [0.83279735]\n",
      " [0.401536  ]\n",
      " [0.3609981 ]\n",
      " [0.20994282]\n",
      " [0.8871356 ]\n",
      " [0.8575561 ]\n",
      " [0.9968829 ]\n",
      " [0.68052137]\n",
      " [0.13783711]\n",
      " [0.50985456]\n",
      " [0.25299326]\n",
      " [0.16628344]\n",
      " [0.5242649 ]\n",
      " [0.9782285 ]\n",
      " [0.41910994]\n",
      " [0.8064297 ]\n",
      " [0.72386867]\n",
      " [0.99841666]\n",
      " [0.27628532]\n",
      " [0.28733054]\n",
      " [0.45465922]\n",
      " [0.4631    ]\n",
      " [0.8213339 ]\n",
      " [0.98467964]\n",
      " [0.9591003 ]\n",
      " [0.38672206]\n",
      " [0.4558287 ]\n",
      " [0.8611358 ]\n",
      " [0.31991306]\n",
      " [0.62047917]\n",
      " [0.56337607]\n",
      " [0.22063778]\n",
      " [0.06619423]\n",
      " [0.51282555]\n",
      " [0.9776522 ]\n",
      " [0.7502224 ]\n",
      " [0.69239515]\n",
      " [0.8789811 ]\n",
      " [0.8566899 ]\n",
      " [0.46694556]\n",
      " [0.61578083]\n",
      " [0.08610243]\n",
      " [0.0070505 ]\n",
      " [0.38965708]\n",
      " [0.7025249 ]\n",
      " [0.97351295]\n",
      " [0.9652673 ]\n",
      " [0.0816251 ]\n",
      " [0.5667458 ]\n",
      " [0.9776853 ]\n",
      " [0.47299072]\n",
      " [0.34604973]\n",
      " [0.18523905]\n",
      " [0.65970653]\n",
      " [0.37846112]\n",
      " [0.63599473]\n",
      " [0.5802743 ]\n",
      " [0.04016976]\n",
      " [0.35181683]\n",
      " [0.4911605 ]\n",
      " [0.7926442 ]\n",
      " [0.9585241 ]\n",
      " [0.45436856]\n",
      " [0.01794287]\n",
      " [0.13324158]\n",
      " [0.55606633]\n",
      " [0.01858916]\n",
      " [0.29208347]\n",
      " [0.01689383]\n",
      " [0.5605171 ]\n",
      " [0.4897315 ]\n",
      " [0.9776372 ]\n",
      " [0.917352  ]\n",
      " [0.07567583]\n",
      " [0.95538926]\n",
      " [0.7238574 ]\n",
      " [0.7049716 ]\n",
      " [0.20403495]\n",
      " [0.81017315]\n",
      " [0.49730244]\n",
      " [0.9736047 ]\n",
      " [0.9740006 ]\n",
      " [0.28775716]\n",
      " [0.9822894 ]\n",
      " [0.6652923 ]\n",
      " [0.7764023 ]\n",
      " [0.6491999 ]\n",
      " [0.47540572]\n",
      " [0.37164247]\n",
      " [0.9757533 ]\n",
      " [0.88699687]\n",
      " [0.10061109]\n",
      " [0.8883187 ]\n",
      " [0.9250329 ]\n",
      " [0.09890789]\n",
      " [0.9658961 ]\n",
      " [0.34136572]\n",
      " [0.1048849 ]\n",
      " [0.81176215]\n",
      " [0.4316156 ]\n",
      " [0.14840361]\n",
      " [0.06208486]\n",
      " [0.41993445]\n",
      " [0.16463193]\n",
      " [0.8824755 ]\n",
      " [0.4882706 ]\n",
      " [0.07361713]\n",
      " [0.889219  ]\n",
      " [0.69261676]\n",
      " [0.6283418 ]\n",
      " [0.88914883]\n",
      " [0.920876  ]\n",
      " [0.43954182]\n",
      " [0.19516999]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
