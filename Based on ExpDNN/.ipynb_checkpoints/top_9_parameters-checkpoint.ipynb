{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,5:6] #Leptin\n",
    "X2 = dataset[:,6:7] #Adiponectin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,7:8] #Resistin\n",
    "X5 = dataset[:,2:3] #Glucose\n",
    "X6 = dataset[:,4:5] #HOMA\n",
    "X7 = dataset[:,8:9] #MCP.1\n",
    "X8 = dataset[:,3:4] #Insulin\n",
    "X9 = dataset[:,1:2] #BMI\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "X6 = normalization(X6)\n",
    "X7 = normalization(X7)\n",
    "X8 = normalization(X8)\n",
    "X9 = normalization(X9)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X6 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X7 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X8 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X9 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 9)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "                                                                 input_layer_X6[0][0]             \n",
      "                                                                 input_layer_X7[0][0]             \n",
      "                                                                 input_layer_X8[0][0]             \n",
      "                                                                 input_layer_X9[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            90          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 280\n",
      "Trainable params: 280\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "input_layer_X6 = keras.layers.Input(shape=(1, ), name='input_layer_X6')\n",
    "input_layer_X7 = keras.layers.Input(shape=(1, ), name='input_layer_X7')\n",
    "input_layer_X8 = keras.layers.Input(shape=(1, ), name='input_layer_X8')\n",
    "input_layer_X9 = keras.layers.Input(shape=(1, ), name='input_layer_X9')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7, input_layer_X8, input_layer_X9], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7, input_layer_X8, input_layer_X9], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.7051 - acc: 0.5761 - auc_1: 0.5226 - val_loss: 0.6572 - val_acc: 0.7083 - val_auc_1: 0.6857\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6647 - acc: 0.6196 - auc_1: 0.6702 - val_loss: 0.6154 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6372 - acc: 0.6848 - auc_1: 0.7202 - val_loss: 0.5824 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6063 - acc: 0.6739 - auc_1: 0.7519 - val_loss: 0.5567 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5811 - acc: 0.7174 - auc_1: 0.7633 - val_loss: 0.5159 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5677 - acc: 0.6304 - auc_1: 0.7736 - val_loss: 0.5371 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5522 - acc: 0.6957 - auc_1: 0.7824 - val_loss: 0.5092 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5466 - acc: 0.6739 - auc_1: 0.7843 - val_loss: 0.5584 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5418 - acc: 0.7174 - auc_1: 0.7907 - val_loss: 0.5291 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5375 - acc: 0.6957 - auc_1: 0.7810 - val_loss: 0.5799 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5292 - acc: 0.7609 - auc_1: 0.8010 - val_loss: 0.5068 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5254 - acc: 0.7174 - auc_1: 0.8014 - val_loss: 0.5325 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5221 - acc: 0.7500 - auc_1: 0.8038 - val_loss: 0.5481 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5166 - acc: 0.7391 - auc_1: 0.8100 - val_loss: 0.6216 - val_acc: 0.6667 - val_auc_1: 0.8929\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5131 - acc: 0.7500 - auc_1: 0.8217 - val_loss: 0.4878 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5190 - acc: 0.7283 - auc_1: 0.8086 - val_loss: 0.5443 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5091 - acc: 0.7826 - auc_1: 0.8195 - val_loss: 0.5263 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5008 - acc: 0.8043 - auc_1: 0.8271 - val_loss: 0.4806 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5043 - acc: 0.7391 - auc_1: 0.8314 - val_loss: 0.6162 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5083 - acc: 0.7609 - auc_1: 0.8150 - val_loss: 0.5575 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4985 - acc: 0.7609 - auc_1: 0.8274 - val_loss: 0.6114 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5040 - acc: 0.7609 - auc_1: 0.8102 - val_loss: 0.5627 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4960 - acc: 0.7826 - auc_1: 0.8310 - val_loss: 0.5089 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4985 - acc: 0.7826 - auc_1: 0.8231 - val_loss: 0.5743 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4915 - acc: 0.7717 - auc_1: 0.8207 - val_loss: 0.5640 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4867 - acc: 0.7609 - auc_1: 0.8305 - val_loss: 0.5295 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4923 - acc: 0.7609 - auc_1: 0.8288 - val_loss: 0.5568 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4838 - acc: 0.7609 - auc_1: 0.8367 - val_loss: 0.5932 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4780 - acc: 0.7717 - auc_1: 0.8307 - val_loss: 0.6322 - val_acc: 0.6250 - val_auc_1: 0.8964\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4880 - acc: 0.7500 - auc_1: 0.8302 - val_loss: 0.5900 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4646 - acc: 0.7826 - auc_1: 0.8524 - val_loss: 0.6566 - val_acc: 0.6250 - val_auc_1: 0.8964\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4774 - acc: 0.7717 - auc_1: 0.8421 - val_loss: 0.5584 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4724 - acc: 0.7500 - auc_1: 0.8452 - val_loss: 0.5819 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4684 - acc: 0.7609 - auc_1: 0.8474 - val_loss: 0.5453 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4658 - acc: 0.7500 - auc_1: 0.8595 - val_loss: 0.5936 - val_acc: 0.7083 - val_auc_1: 0.9036\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4799 - acc: 0.7935 - auc_1: 0.8524 - val_loss: 0.5336 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4629 - acc: 0.7500 - auc_1: 0.8600 - val_loss: 0.6050 - val_acc: 0.7083 - val_auc_1: 0.9036\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4531 - acc: 0.7935 - auc_1: 0.8626 - val_loss: 0.6232 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4556 - acc: 0.7609 - auc_1: 0.8581 - val_loss: 0.5757 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4518 - acc: 0.7717 - auc_1: 0.8574 - val_loss: 0.5848 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4365 - acc: 0.7717 - auc_1: 0.8795 - val_loss: 0.6970 - val_acc: 0.6250 - val_auc_1: 0.8929\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4400 - acc: 0.8043 - auc_1: 0.8698 - val_loss: 0.5569 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4392 - acc: 0.7935 - auc_1: 0.8671 - val_loss: 0.5541 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4421 - acc: 0.7826 - auc_1: 0.8779 - val_loss: 0.7112 - val_acc: 0.6250 - val_auc_1: 0.8964\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4426 - acc: 0.7935 - auc_1: 0.8650 - val_loss: 0.6271 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4344 - acc: 0.7826 - auc_1: 0.8786 - val_loss: 0.5979 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4164 - acc: 0.7935 - auc_1: 0.8876 - val_loss: 0.5599 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4295 - acc: 0.7826 - auc_1: 0.8769 - val_loss: 0.5984 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4248 - acc: 0.7935 - auc_1: 0.8752 - val_loss: 0.6606 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4091 - acc: 0.8043 - auc_1: 0.9040 - val_loss: 0.5804 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4293 - acc: 0.7826 - auc_1: 0.8790 - val_loss: 0.6335 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4193 - acc: 0.8152 - auc_1: 0.8798 - val_loss: 0.6632 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4142 - acc: 0.8043 - auc_1: 0.8924 - val_loss: 0.6088 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4046 - acc: 0.8261 - auc_1: 0.8886 - val_loss: 0.6337 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4024 - acc: 0.8043 - auc_1: 0.8988 - val_loss: 0.5974 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3829 - acc: 0.8478 - auc_1: 0.9102 - val_loss: 0.6723 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4070 - acc: 0.8043 - auc_1: 0.8907 - val_loss: 0.6021 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3937 - acc: 0.8370 - auc_1: 0.8929 - val_loss: 0.6305 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3864 - acc: 0.8043 - auc_1: 0.9026 - val_loss: 0.5860 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3981 - acc: 0.8152 - auc_1: 0.9069 - val_loss: 0.6637 - val_acc: 0.6667 - val_auc_1: 0.9000\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3902 - acc: 0.8152 - auc_1: 0.8995 - val_loss: 0.5847 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3797 - acc: 0.8370 - auc_1: 0.9081 - val_loss: 0.5500 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3711 - acc: 0.8370 - auc_1: 0.9145 - val_loss: 0.6588 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3876 - acc: 0.8152 - auc_1: 0.9002 - val_loss: 0.5737 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3767 - acc: 0.8261 - auc_1: 0.9098 - val_loss: 0.5887 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3711 - acc: 0.8152 - auc_1: 0.9267 - val_loss: 0.6359 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3839 - acc: 0.8152 - auc_1: 0.8950 - val_loss: 0.6237 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3734 - acc: 0.8478 - auc_1: 0.9079 - val_loss: 0.5549 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3695 - acc: 0.8152 - auc_1: 0.9067 - val_loss: 0.5437 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3625 - acc: 0.8043 - auc_1: 0.9148 - val_loss: 0.5155 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3565 - acc: 0.8043 - auc_1: 0.9312 - val_loss: 0.5797 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3533 - acc: 0.8370 - auc_1: 0.9205 - val_loss: 0.5677 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3594 - acc: 0.8370 - auc_1: 0.9221 - val_loss: 0.5171 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3659 - acc: 0.8043 - auc_1: 0.9152 - val_loss: 0.5404 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3459 - acc: 0.8152 - auc_1: 0.9267 - val_loss: 0.5854 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3646 - acc: 0.8043 - auc_1: 0.9160 - val_loss: 0.5496 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3494 - acc: 0.8261 - auc_1: 0.9200 - val_loss: 0.5265 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3506 - acc: 0.8696 - auc_1: 0.9224 - val_loss: 0.5400 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3493 - acc: 0.8261 - auc_1: 0.9317 - val_loss: 0.5200 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3370 - acc: 0.8478 - auc_1: 0.9279 - val_loss: 0.5721 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3374 - acc: 0.8152 - auc_1: 0.9324 - val_loss: 0.5745 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3445 - acc: 0.8261 - auc_1: 0.9321 - val_loss: 0.5204 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3321 - acc: 0.8261 - auc_1: 0.9369 - val_loss: 0.5640 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3243 - acc: 0.8370 - auc_1: 0.9431 - val_loss: 0.4804 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3309 - acc: 0.8261 - auc_1: 0.9324 - val_loss: 0.5004 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3168 - acc: 0.8696 - auc_1: 0.9493 - val_loss: 0.6712 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3506 - acc: 0.8152 - auc_1: 0.9267 - val_loss: 0.4962 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3319 - acc: 0.8587 - auc_1: 0.9302 - val_loss: 0.5217 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3252 - acc: 0.8478 - auc_1: 0.9348 - val_loss: 0.5218 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3318 - acc: 0.8370 - auc_1: 0.9429 - val_loss: 0.5411 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3161 - acc: 0.8587 - auc_1: 0.9457 - val_loss: 0.5385 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3226 - acc: 0.8261 - auc_1: 0.9410 - val_loss: 0.5155 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3074 - acc: 0.8478 - auc_1: 0.9431 - val_loss: 0.5371 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3186 - acc: 0.8261 - auc_1: 0.9421 - val_loss: 0.5283 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3077 - acc: 0.8804 - auc_1: 0.9471 - val_loss: 0.5054 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3275 - acc: 0.8696 - auc_1: 0.9333 - val_loss: 0.5747 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 97/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3115 - acc: 0.8152 - auc_1: 0.9431 - val_loss: 0.5638 - val_acc: 0.7917 - val_auc_1: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3160 - acc: 0.8152 - auc_1: 0.9350 - val_loss: 0.5744 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3022 - acc: 0.8478 - auc_1: 0.9498 - val_loss: 0.5498 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3016 - acc: 0.8370 - auc_1: 0.9490 - val_loss: 0.5639 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3076 - acc: 0.8261 - auc_1: 0.9445 - val_loss: 0.5240 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3028 - acc: 0.8587 - auc_1: 0.9417 - val_loss: 0.5867 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2750 - acc: 0.9022 - auc_1: 0.9593 - val_loss: 0.6650 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3135 - acc: 0.8370 - auc_1: 0.9364 - val_loss: 0.6602 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2948 - acc: 0.8478 - auc_1: 0.9593 - val_loss: 0.5248 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2961 - acc: 0.8913 - auc_1: 0.9493 - val_loss: 0.5637 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2759 - acc: 0.8913 - auc_1: 0.9545 - val_loss: 0.5793 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2879 - acc: 0.8587 - auc_1: 0.9562 - val_loss: 0.5585 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2934 - acc: 0.8478 - auc_1: 0.9490 - val_loss: 0.5600 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2802 - acc: 0.8913 - auc_1: 0.9552 - val_loss: 0.5534 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2897 - acc: 0.8370 - auc_1: 0.9464 - val_loss: 0.5328 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2926 - acc: 0.8370 - auc_1: 0.9460 - val_loss: 0.5844 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2726 - acc: 0.9022 - auc_1: 0.9538 - val_loss: 0.6453 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2845 - acc: 0.8587 - auc_1: 0.9540 - val_loss: 0.5780 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2817 - acc: 0.8478 - auc_1: 0.9543 - val_loss: 0.6737 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2854 - acc: 0.8587 - auc_1: 0.9517 - val_loss: 0.5546 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2732 - acc: 0.9022 - auc_1: 0.9574 - val_loss: 0.5669 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2788 - acc: 0.8587 - auc_1: 0.9545 - val_loss: 0.5842 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2775 - acc: 0.8587 - auc_1: 0.9560 - val_loss: 0.5627 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2773 - acc: 0.8696 - auc_1: 0.9538 - val_loss: 0.5951 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2466 - acc: 0.8587 - auc_1: 0.9686 - val_loss: 0.5591 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2946 - acc: 0.8696 - auc_1: 0.9505 - val_loss: 0.5667 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2685 - acc: 0.8696 - auc_1: 0.9567 - val_loss: 0.5456 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2645 - acc: 0.8804 - auc_1: 0.9600 - val_loss: 0.5911 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2631 - acc: 0.8804 - auc_1: 0.9617 - val_loss: 0.6079 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2778 - acc: 0.8696 - auc_1: 0.9536 - val_loss: 0.5808 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2508 - acc: 0.9239 - auc_1: 0.9681 - val_loss: 0.6196 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2710 - acc: 0.8478 - auc_1: 0.9595 - val_loss: 0.5690 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2619 - acc: 0.9022 - auc_1: 0.9605 - val_loss: 0.5655 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2492 - acc: 0.9130 - auc_1: 0.9629 - val_loss: 0.5759 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2498 - acc: 0.8587 - auc_1: 0.9655 - val_loss: 0.5669 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2593 - acc: 0.8913 - auc_1: 0.9583 - val_loss: 0.5713 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2491 - acc: 0.8696 - auc_1: 0.9614 - val_loss: 0.5838 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2474 - acc: 0.9022 - auc_1: 0.9660 - val_loss: 0.5751 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2460 - acc: 0.9239 - auc_1: 0.9645 - val_loss: 0.5664 - val_acc: 0.8333 - val_auc_1: 0.8500\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2462 - acc: 0.9022 - auc_1: 0.9652 - val_loss: 0.5813 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2448 - acc: 0.8913 - auc_1: 0.9648 - val_loss: 0.5593 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2572 - acc: 0.9130 - auc_1: 0.9607 - val_loss: 0.5733 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2392 - acc: 0.9022 - auc_1: 0.9676 - val_loss: 0.5891 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2394 - acc: 0.9130 - auc_1: 0.9660 - val_loss: 0.5712 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2345 - acc: 0.9348 - auc_1: 0.9686 - val_loss: 0.6000 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2407 - acc: 0.8913 - auc_1: 0.9657 - val_loss: 0.5747 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2284 - acc: 0.9239 - auc_1: 0.9702 - val_loss: 0.6034 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2396 - acc: 0.9130 - auc_1: 0.9657 - val_loss: 0.5501 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 145/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2222 - acc: 0.9022 - auc_1: 0.9738 - val_loss: 0.5774 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 146/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2262 - acc: 0.9130 - auc_1: 0.9707 - val_loss: 0.5540 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2293 - acc: 0.9130 - auc_1: 0.9667 - val_loss: 0.5397 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2169 - acc: 0.9348 - auc_1: 0.9755 - val_loss: 0.5649 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2036 - acc: 0.9130 - auc_1: 0.9790 - val_loss: 0.5407 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2240 - acc: 0.9348 - auc_1: 0.9721 - val_loss: 0.5712 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2194 - acc: 0.9239 - auc_1: 0.9700 - val_loss: 0.5809 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2076 - acc: 0.9348 - auc_1: 0.9788 - val_loss: 0.5879 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2151 - acc: 0.9022 - auc_1: 0.9757 - val_loss: 0.6076 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2108 - acc: 0.9457 - auc_1: 0.9726 - val_loss: 0.5799 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2018 - acc: 0.9239 - auc_1: 0.9810 - val_loss: 0.5843 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2142 - acc: 0.9239 - auc_1: 0.9752 - val_loss: 0.5820 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1941 - acc: 0.9348 - auc_1: 0.9819 - val_loss: 0.6025 - val_acc: 0.8333 - val_auc_1: 0.8357\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2073 - acc: 0.9239 - auc_1: 0.9776 - val_loss: 0.6027 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1919 - acc: 0.9348 - auc_1: 0.9805 - val_loss: 0.6227 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2186 - acc: 0.9130 - auc_1: 0.9726 - val_loss: 0.6330 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1880 - acc: 0.9457 - auc_1: 0.9807 - val_loss: 0.6370 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1984 - acc: 0.9130 - auc_1: 0.9810 - val_loss: 0.6231 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1800 - acc: 0.9457 - auc_1: 0.9833 - val_loss: 0.6130 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1968 - acc: 0.9457 - auc_1: 0.9798 - val_loss: 0.5931 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1779 - acc: 0.9457 - auc_1: 0.9817 - val_loss: 0.5994 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1842 - acc: 0.9239 - auc_1: 0.9814 - val_loss: 0.6333 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1809 - acc: 0.9565 - auc_1: 0.9838 - val_loss: 0.6020 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1769 - acc: 0.9457 - auc_1: 0.9819 - val_loss: 0.6848 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1774 - acc: 0.9565 - auc_1: 0.9819 - val_loss: 0.6292 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1846 - acc: 0.9565 - auc_1: 0.9793 - val_loss: 0.6425 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1743 - acc: 0.9457 - auc_1: 0.9798 - val_loss: 0.6532 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1753 - acc: 0.9674 - auc_1: 0.9850 - val_loss: 0.7093 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1590 - acc: 0.9674 - auc_1: 0.9893 - val_loss: 0.6338 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1706 - acc: 0.9783 - auc_1: 0.9833 - val_loss: 0.6537 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1773 - acc: 0.9565 - auc_1: 0.9814 - val_loss: 0.6488 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1627 - acc: 0.9565 - auc_1: 0.9845 - val_loss: 0.7157 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1698 - acc: 0.9565 - auc_1: 0.9810 - val_loss: 0.6485 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1660 - acc: 0.9565 - auc_1: 0.9819 - val_loss: 0.6531 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1569 - acc: 0.9565 - auc_1: 0.9838 - val_loss: 0.7051 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1484 - acc: 0.9565 - auc_1: 0.9874 - val_loss: 0.6369 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1671 - acc: 0.9674 - auc_1: 0.9855 - val_loss: 0.7209 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1799 - acc: 0.9565 - auc_1: 0.9824 - val_loss: 0.6712 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1666 - acc: 0.9457 - auc_1: 0.9829 - val_loss: 0.6372 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1598 - acc: 0.9565 - auc_1: 0.9824 - val_loss: 0.6403 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1425 - acc: 0.9565 - auc_1: 0.9848 - val_loss: 0.6414 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1587 - acc: 0.9348 - auc_1: 0.9848 - val_loss: 0.6532 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1592 - acc: 0.9565 - auc_1: 0.9848 - val_loss: 0.6656 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1448 - acc: 0.9457 - auc_1: 0.9879 - val_loss: 0.6445 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1465 - acc: 0.9674 - auc_1: 0.9867 - val_loss: 0.7478 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1484 - acc: 0.9565 - auc_1: 0.9869 - val_loss: 0.6590 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1434 - acc: 0.9674 - auc_1: 0.9881 - val_loss: 0.7222 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1523 - acc: 0.9565 - auc_1: 0.9867 - val_loss: 0.7143 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1606 - acc: 0.9457 - auc_1: 0.9829 - val_loss: 0.6822 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 194/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1479 - acc: 0.9457 - auc_1: 0.9852 - val_loss: 0.7371 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1399 - acc: 0.9674 - auc_1: 0.9876 - val_loss: 0.6961 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1362 - acc: 0.9674 - auc_1: 0.9869 - val_loss: 0.7029 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1447 - acc: 0.9565 - auc_1: 0.9888 - val_loss: 0.7634 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1368 - acc: 0.9674 - auc_1: 0.9845 - val_loss: 0.6922 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1343 - acc: 0.9565 - auc_1: 0.9910 - val_loss: 0.7730 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1241 - acc: 0.9783 - auc_1: 0.9917 - val_loss: 0.6760 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1978 - acc: 0.9348 - auc_1: 0.9740 - val_loss: 0.7696 - val_acc: 0.7917 - val_auc_1: 0.7750\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1529 - acc: 0.9674 - auc_1: 0.9867 - val_loss: 0.7585 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1425 - acc: 0.9348 - auc_1: 0.9876 - val_loss: 0.7266 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1309 - acc: 0.9674 - auc_1: 0.9900 - val_loss: 0.7829 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1179 - acc: 0.9674 - auc_1: 0.9907 - val_loss: 0.6873 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1437 - acc: 0.9565 - auc_1: 0.9876 - val_loss: 0.7101 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1447 - acc: 0.9457 - auc_1: 0.9876 - val_loss: 0.7764 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1210 - acc: 0.9565 - auc_1: 0.9931 - val_loss: 0.7574 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1315 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.7426 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1173 - acc: 0.9674 - auc_1: 0.9933 - val_loss: 0.7022 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1124 - acc: 0.9783 - auc_1: 0.9914 - val_loss: 0.7274 - val_acc: 0.7917 - val_auc_1: 0.8000\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1093 - acc: 0.9674 - auc_1: 0.9940 - val_loss: 0.6963 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1158 - acc: 0.9674 - auc_1: 0.9910 - val_loss: 0.7285 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1070 - acc: 0.9565 - auc_1: 0.9940 - val_loss: 0.7314 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1085 - acc: 0.9783 - auc_1: 0.9960 - val_loss: 0.7820 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1230 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 0.7876 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1196 - acc: 0.9674 - auc_1: 0.9929 - val_loss: 0.7529 - val_acc: 0.7917 - val_auc_1: 0.7964\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1015 - acc: 0.9783 - auc_1: 0.9945 - val_loss: 0.7636 - val_acc: 0.7917 - val_auc_1: 0.7964\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0939 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.7637 - val_acc: 0.7917 - val_auc_1: 0.7929\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0997 - acc: 0.9674 - auc_1: 0.9945 - val_loss: 0.7124 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1772 - acc: 0.9022 - auc_1: 0.9807 - val_loss: 0.7767 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0964 - acc: 0.9674 - auc_1: 0.9955 - val_loss: 0.7616 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0915 - acc: 0.9783 - auc_1: 0.9957 - val_loss: 0.8276 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1237 - acc: 0.9783 - auc_1: 0.9914 - val_loss: 0.8064 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1038 - acc: 0.9783 - auc_1: 0.9938 - val_loss: 0.8178 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0982 - acc: 0.9783 - auc_1: 0.9952 - val_loss: 0.8308 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0977 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.8689 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0969 - acc: 0.9783 - auc_1: 0.9948 - val_loss: 0.8444 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0933 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.8485 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0981 - acc: 0.9783 - auc_1: 0.9948 - val_loss: 0.8594 - val_acc: 0.7500 - val_auc_1: 0.7821\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0888 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.8681 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0865 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 0.9093 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0983 - acc: 0.9783 - auc_1: 0.9945 - val_loss: 0.8855 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0948 - acc: 0.9565 - auc_1: 0.9969 - val_loss: 0.8223 - val_acc: 0.7917 - val_auc_1: 0.7964\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1147 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 0.8333 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0788 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8794 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0849 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.7951 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0744 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 0.8668 - val_acc: 0.7500 - val_auc_1: 0.7964\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0990 - acc: 0.9457 - auc_1: 0.9957 - val_loss: 0.8362 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0794 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8381 - val_acc: 0.7917 - val_auc_1: 0.7786\n",
      "Epoch 241/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1019 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.9013 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0822 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 0.8726 - val_acc: 0.7083 - val_auc_1: 0.7643\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0683 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 0.8254 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0739 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8494 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0667 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8702 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0845 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 0.9035 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0930 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.8499 - val_acc: 0.7917 - val_auc_1: 0.7643\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0637 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8634 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0727 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.8679 - val_acc: 0.7917 - val_auc_1: 0.7750\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0628 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 0.9252 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0798 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.9568 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1424 - acc: 0.9457 - auc_1: 0.9888 - val_loss: 0.8643 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0590 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.8617 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0552 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 0.8703 - val_acc: 0.7917 - val_auc_1: 0.7679\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0548 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8434 - val_acc: 0.8333 - val_auc_1: 0.7643\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0953 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.9086 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0743 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.9207 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0527 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9215 - val_acc: 0.7917 - val_auc_1: 0.7714\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0513 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.9338 - val_acc: 0.7917 - val_auc_1: 0.7643\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0452 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9473 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0521 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9574 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0526 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.9379 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0566 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.9735 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0418 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0224 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0468 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9819 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0430 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9797 - val_acc: 0.7917 - val_auc_1: 0.7679\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0448 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9741 - val_acc: 0.7500 - val_auc_1: 0.7607\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0617 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.9641 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0657 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.9521 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0410 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0552 - val_acc: 0.7500 - val_auc_1: 0.7714\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0434 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0046 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0520 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.9726 - val_acc: 0.7917 - val_auc_1: 0.7929\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0415 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0099 - val_acc: 0.7917 - val_auc_1: 0.7643\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0459 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0325 - val_acc: 0.7917 - val_auc_1: 0.7750\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0341 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0079 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0366 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0396 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0408 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0327 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0284 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0744 - val_acc: 0.7500 - val_auc_1: 0.7750\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0502 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.0433 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0389 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0302 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0306 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0415 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0311 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0271 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0458 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.0412 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0339 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0787 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0314 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0860 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0243 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0949 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0300 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1397 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0503 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.1784 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 289/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0555 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0875 - val_acc: 0.7917 - val_auc_1: 0.7214\n",
      "Epoch 290/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0325 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1564 - val_acc: 0.7917 - val_auc_1: 0.7500\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0281 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1365 - val_acc: 0.7917 - val_auc_1: 0.7464\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0459 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1628 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0273 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1774 - val_acc: 0.7917 - val_auc_1: 0.7536\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1076 - acc: 0.9783 - auc_1: 0.9914 - val_loss: 1.0725 - val_acc: 0.7500 - val_auc_1: 0.7571\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0269 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0588 - val_acc: 0.7917 - val_auc_1: 0.7893\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0349 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0780 - val_acc: 0.7917 - val_auc_1: 0.7750\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0228 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1052 - val_acc: 0.7917 - val_auc_1: 0.7571\n",
      "Epoch 298/700\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0203 - acc: 1.0000 - auc_1: 1.0000 "
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5, X6, X7, X8, X9], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5, X6, X7, X8, X9])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
