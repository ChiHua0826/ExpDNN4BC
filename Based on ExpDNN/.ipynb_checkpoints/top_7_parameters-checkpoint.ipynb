{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,5:6] #Leptin\n",
    "X2 = dataset[:,6:7] #Adiponectin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,7:8] #Resistin\n",
    "X5 = dataset[:,2:3] #Glucose\n",
    "X6 = dataset[:,4:5] #HOMA\n",
    "X7 = dataset[:,8:9] #MCP.1\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "X6 = normalization(X6)\n",
    "X7 = normalization(X7)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X6 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X7 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 7)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "                                                                 input_layer_X6[0][0]             \n",
      "                                                                 input_layer_X7[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            72          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 262\n",
      "Trainable params: 262\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "input_layer_X6 = keras.layers.Input(shape=(1, ), name='input_layer_X6')\n",
    "input_layer_X7 = keras.layers.Input(shape=(1, ), name='input_layer_X7')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.7297 - acc: 0.4565 - auc_1: 0.4871 - val_loss: 0.7326 - val_acc: 0.4167 - val_auc_1: 0.5643\n",
      "Epoch 2/3000\n",
      "92/92 [==============================] - 0s 65us/step - loss: 0.7225 - acc: 0.4565 - auc_1: 0.4945 - val_loss: 0.7263 - val_acc: 0.4167 - val_auc_1: 0.5821\n",
      "Epoch 3/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.7177 - acc: 0.4565 - auc_1: 0.5031 - val_loss: 0.7209 - val_acc: 0.4167 - val_auc_1: 0.5929\n",
      "Epoch 4/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.7136 - acc: 0.4674 - auc_1: 0.5102 - val_loss: 0.7157 - val_acc: 0.4167 - val_auc_1: 0.6143\n",
      "Epoch 5/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.7098 - acc: 0.4783 - auc_1: 0.5164 - val_loss: 0.7108 - val_acc: 0.4167 - val_auc_1: 0.6321\n",
      "Epoch 6/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.7062 - acc: 0.4783 - auc_1: 0.5269 - val_loss: 0.7061 - val_acc: 0.4583 - val_auc_1: 0.6464\n",
      "Epoch 7/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.7028 - acc: 0.4783 - auc_1: 0.5426 - val_loss: 0.7016 - val_acc: 0.4583 - val_auc_1: 0.6571\n",
      "Epoch 8/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6996 - acc: 0.5000 - auc_1: 0.5495 - val_loss: 0.6972 - val_acc: 0.5417 - val_auc_1: 0.6571\n",
      "Epoch 9/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6965 - acc: 0.5000 - auc_1: 0.5605 - val_loss: 0.6930 - val_acc: 0.5000 - val_auc_1: 0.6643\n",
      "Epoch 10/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6936 - acc: 0.5326 - auc_1: 0.5817 - val_loss: 0.6890 - val_acc: 0.5000 - val_auc_1: 0.6714\n",
      "Epoch 11/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6909 - acc: 0.5109 - auc_1: 0.5929 - val_loss: 0.6853 - val_acc: 0.5417 - val_auc_1: 0.6643\n",
      "Epoch 12/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6884 - acc: 0.5326 - auc_1: 0.6005 - val_loss: 0.6817 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 13/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.6860 - acc: 0.5761 - auc_1: 0.6098 - val_loss: 0.6783 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 14/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.6838 - acc: 0.5978 - auc_1: 0.6200 - val_loss: 0.6751 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 15/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.6818 - acc: 0.6196 - auc_1: 0.6302 - val_loss: 0.6722 - val_acc: 0.6667 - val_auc_1: 0.6714\n",
      "Epoch 16/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6799 - acc: 0.6413 - auc_1: 0.6469 - val_loss: 0.6694 - val_acc: 0.6667 - val_auc_1: 0.6429\n",
      "Epoch 17/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6781 - acc: 0.6413 - auc_1: 0.6567 - val_loss: 0.6668 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 18/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.6765 - acc: 0.6304 - auc_1: 0.6624 - val_loss: 0.6644 - val_acc: 0.6667 - val_auc_1: 0.6143\n",
      "Epoch 19/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6750 - acc: 0.6304 - auc_1: 0.6771 - val_loss: 0.6622 - val_acc: 0.7083 - val_auc_1: 0.6250\n",
      "Epoch 20/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6735 - acc: 0.6413 - auc_1: 0.6810 - val_loss: 0.6601 - val_acc: 0.7083 - val_auc_1: 0.6286\n",
      "Epoch 21/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6722 - acc: 0.6413 - auc_1: 0.6840 - val_loss: 0.6581 - val_acc: 0.7083 - val_auc_1: 0.6179\n",
      "Epoch 22/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6709 - acc: 0.6304 - auc_1: 0.6886 - val_loss: 0.6563 - val_acc: 0.7083 - val_auc_1: 0.6429\n",
      "Epoch 23/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6697 - acc: 0.6304 - auc_1: 0.6969 - val_loss: 0.6545 - val_acc: 0.7083 - val_auc_1: 0.6464\n",
      "Epoch 24/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6685 - acc: 0.6304 - auc_1: 0.6962 - val_loss: 0.6529 - val_acc: 0.7083 - val_auc_1: 0.6571\n",
      "Epoch 25/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6673 - acc: 0.6304 - auc_1: 0.6960 - val_loss: 0.6513 - val_acc: 0.7083 - val_auc_1: 0.6679\n",
      "Epoch 26/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6661 - acc: 0.6304 - auc_1: 0.7021 - val_loss: 0.6498 - val_acc: 0.7083 - val_auc_1: 0.6679\n",
      "Epoch 27/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6649 - acc: 0.6304 - auc_1: 0.7033 - val_loss: 0.6483 - val_acc: 0.7083 - val_auc_1: 0.6679\n",
      "Epoch 28/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.6637 - acc: 0.6413 - auc_1: 0.7052 - val_loss: 0.6469 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 29/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6626 - acc: 0.6413 - auc_1: 0.7076 - val_loss: 0.6455 - val_acc: 0.6667 - val_auc_1: 0.6714\n",
      "Epoch 30/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.6614 - acc: 0.6413 - auc_1: 0.7107 - val_loss: 0.6442 - val_acc: 0.6667 - val_auc_1: 0.6714\n",
      "Epoch 31/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6602 - acc: 0.6413 - auc_1: 0.7093 - val_loss: 0.6428 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 32/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6589 - acc: 0.6630 - auc_1: 0.7093 - val_loss: 0.6415 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 33/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.6577 - acc: 0.6630 - auc_1: 0.7074 - val_loss: 0.6402 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 34/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6565 - acc: 0.6630 - auc_1: 0.7069 - val_loss: 0.6389 - val_acc: 0.6667 - val_auc_1: 0.6821\n",
      "Epoch 35/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.6552 - acc: 0.6630 - auc_1: 0.7107 - val_loss: 0.6376 - val_acc: 0.6667 - val_auc_1: 0.6821\n",
      "Epoch 36/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.6540 - acc: 0.6739 - auc_1: 0.7100 - val_loss: 0.6363 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 37/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6527 - acc: 0.6739 - auc_1: 0.7133 - val_loss: 0.6350 - val_acc: 0.6667 - val_auc_1: 0.6821\n",
      "Epoch 38/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6514 - acc: 0.6848 - auc_1: 0.7150 - val_loss: 0.6336 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 39/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6501 - acc: 0.6848 - auc_1: 0.7152 - val_loss: 0.6323 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 40/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6488 - acc: 0.6848 - auc_1: 0.7152 - val_loss: 0.6310 - val_acc: 0.6667 - val_auc_1: 0.6857\n",
      "Epoch 41/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6475 - acc: 0.6957 - auc_1: 0.7145 - val_loss: 0.6296 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 42/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6462 - acc: 0.6848 - auc_1: 0.7188 - val_loss: 0.6282 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 43/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6449 - acc: 0.6848 - auc_1: 0.7217 - val_loss: 0.6269 - val_acc: 0.6667 - val_auc_1: 0.6893\n",
      "Epoch 44/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6435 - acc: 0.6957 - auc_1: 0.7214 - val_loss: 0.6254 - val_acc: 0.6667 - val_auc_1: 0.6964\n",
      "Epoch 45/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6421 - acc: 0.6957 - auc_1: 0.7219 - val_loss: 0.6240 - val_acc: 0.6667 - val_auc_1: 0.6929\n",
      "Epoch 46/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6408 - acc: 0.6848 - auc_1: 0.7231 - val_loss: 0.6226 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 47/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6394 - acc: 0.6848 - auc_1: 0.7281 - val_loss: 0.6211 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 48/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6379 - acc: 0.6848 - auc_1: 0.7281 - val_loss: 0.6196 - val_acc: 0.7083 - val_auc_1: 0.7036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6365 - acc: 0.6848 - auc_1: 0.7279 - val_loss: 0.6181 - val_acc: 0.7083 - val_auc_1: 0.7071\n",
      "Epoch 50/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6351 - acc: 0.6848 - auc_1: 0.7295 - val_loss: 0.6165 - val_acc: 0.7083 - val_auc_1: 0.7071\n",
      "Epoch 51/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6336 - acc: 0.6848 - auc_1: 0.7307 - val_loss: 0.6150 - val_acc: 0.7083 - val_auc_1: 0.7107\n",
      "Epoch 52/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.6321 - acc: 0.6848 - auc_1: 0.7319 - val_loss: 0.6134 - val_acc: 0.7083 - val_auc_1: 0.7107\n",
      "Epoch 53/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6306 - acc: 0.6848 - auc_1: 0.7326 - val_loss: 0.6118 - val_acc: 0.7083 - val_auc_1: 0.7107\n",
      "Epoch 54/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6291 - acc: 0.6848 - auc_1: 0.7324 - val_loss: 0.6101 - val_acc: 0.7083 - val_auc_1: 0.7107\n",
      "Epoch 55/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6276 - acc: 0.6848 - auc_1: 0.7329 - val_loss: 0.6085 - val_acc: 0.7083 - val_auc_1: 0.7179\n",
      "Epoch 56/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6260 - acc: 0.6848 - auc_1: 0.7355 - val_loss: 0.6068 - val_acc: 0.7083 - val_auc_1: 0.7179\n",
      "Epoch 57/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.6245 - acc: 0.6848 - auc_1: 0.7367 - val_loss: 0.6050 - val_acc: 0.7083 - val_auc_1: 0.7179\n",
      "Epoch 58/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6229 - acc: 0.6848 - auc_1: 0.7376 - val_loss: 0.6033 - val_acc: 0.7083 - val_auc_1: 0.7214\n",
      "Epoch 59/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6212 - acc: 0.6957 - auc_1: 0.7386 - val_loss: 0.6015 - val_acc: 0.7083 - val_auc_1: 0.7250\n",
      "Epoch 60/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6196 - acc: 0.6957 - auc_1: 0.7414 - val_loss: 0.5997 - val_acc: 0.7083 - val_auc_1: 0.7250\n",
      "Epoch 61/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6180 - acc: 0.6957 - auc_1: 0.7426 - val_loss: 0.5979 - val_acc: 0.7083 - val_auc_1: 0.7250\n",
      "Epoch 62/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6163 - acc: 0.6957 - auc_1: 0.7455 - val_loss: 0.5960 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 63/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6146 - acc: 0.6957 - auc_1: 0.7450 - val_loss: 0.5941 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 64/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6129 - acc: 0.6957 - auc_1: 0.7471 - val_loss: 0.5922 - val_acc: 0.7083 - val_auc_1: 0.7357\n",
      "Epoch 65/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6111 - acc: 0.6848 - auc_1: 0.7495 - val_loss: 0.5903 - val_acc: 0.7083 - val_auc_1: 0.7357\n",
      "Epoch 66/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6093 - acc: 0.6957 - auc_1: 0.7500 - val_loss: 0.5883 - val_acc: 0.7083 - val_auc_1: 0.7393\n",
      "Epoch 67/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6075 - acc: 0.6957 - auc_1: 0.7524 - val_loss: 0.5863 - val_acc: 0.7083 - val_auc_1: 0.7429\n",
      "Epoch 68/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.6057 - acc: 0.6957 - auc_1: 0.7540 - val_loss: 0.5843 - val_acc: 0.7083 - val_auc_1: 0.7429\n",
      "Epoch 69/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.6039 - acc: 0.6957 - auc_1: 0.7567 - val_loss: 0.5822 - val_acc: 0.7083 - val_auc_1: 0.7429\n",
      "Epoch 70/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.6020 - acc: 0.7065 - auc_1: 0.7588 - val_loss: 0.5802 - val_acc: 0.7083 - val_auc_1: 0.7429\n",
      "Epoch 71/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.6001 - acc: 0.7065 - auc_1: 0.7586 - val_loss: 0.5781 - val_acc: 0.7083 - val_auc_1: 0.7464\n",
      "Epoch 72/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.5982 - acc: 0.7065 - auc_1: 0.7619 - val_loss: 0.5760 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 73/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.5963 - acc: 0.7065 - auc_1: 0.7655 - val_loss: 0.5739 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 74/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.5943 - acc: 0.7065 - auc_1: 0.7690 - val_loss: 0.5717 - val_acc: 0.6667 - val_auc_1: 0.7679\n",
      "Epoch 75/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.5923 - acc: 0.7174 - auc_1: 0.7712 - val_loss: 0.5696 - val_acc: 0.6667 - val_auc_1: 0.7750\n",
      "Epoch 76/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.5903 - acc: 0.7065 - auc_1: 0.7736 - val_loss: 0.5674 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 77/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.5883 - acc: 0.7065 - auc_1: 0.7738 - val_loss: 0.5653 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 78/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.5862 - acc: 0.6957 - auc_1: 0.7757 - val_loss: 0.5631 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 79/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5842 - acc: 0.7065 - auc_1: 0.7767 - val_loss: 0.5610 - val_acc: 0.7500 - val_auc_1: 0.7893\n",
      "Epoch 80/3000\n",
      "92/92 [==============================] - 0s 185us/step - loss: 0.5821 - acc: 0.7065 - auc_1: 0.7771 - val_loss: 0.5588 - val_acc: 0.7500 - val_auc_1: 0.7857\n",
      "Epoch 81/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.5800 - acc: 0.7065 - auc_1: 0.7781 - val_loss: 0.5567 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 82/3000\n",
      "92/92 [==============================] - 0s 207us/step - loss: 0.5779 - acc: 0.7065 - auc_1: 0.7788 - val_loss: 0.5546 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 83/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5757 - acc: 0.7174 - auc_1: 0.7805 - val_loss: 0.5525 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 84/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.5736 - acc: 0.7065 - auc_1: 0.7812 - val_loss: 0.5504 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 85/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.5715 - acc: 0.7065 - auc_1: 0.7824 - val_loss: 0.5484 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 86/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.5693 - acc: 0.7065 - auc_1: 0.7840 - val_loss: 0.5464 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 87/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.5671 - acc: 0.7065 - auc_1: 0.7862 - val_loss: 0.5445 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 88/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5650 - acc: 0.7065 - auc_1: 0.7893 - val_loss: 0.5426 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 89/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.5628 - acc: 0.7065 - auc_1: 0.7940 - val_loss: 0.5408 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 90/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.5607 - acc: 0.7065 - auc_1: 0.7950 - val_loss: 0.5390 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 91/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5585 - acc: 0.7065 - auc_1: 0.7969 - val_loss: 0.5373 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 92/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5563 - acc: 0.7065 - auc_1: 0.7995 - val_loss: 0.5357 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 93/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.5542 - acc: 0.7065 - auc_1: 0.7995 - val_loss: 0.5342 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 94/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5521 - acc: 0.7065 - auc_1: 0.8019 - val_loss: 0.5327 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 95/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5500 - acc: 0.7065 - auc_1: 0.8050 - val_loss: 0.5313 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 96/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5479 - acc: 0.6957 - auc_1: 0.8074 - val_loss: 0.5300 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 97/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5458 - acc: 0.7065 - auc_1: 0.8107 - val_loss: 0.5289 - val_acc: 0.7917 - val_auc_1: 0.8893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5438 - acc: 0.6957 - auc_1: 0.8112 - val_loss: 0.5278 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 99/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5417 - acc: 0.6957 - auc_1: 0.8119 - val_loss: 0.5268 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 100/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5397 - acc: 0.7174 - auc_1: 0.8140 - val_loss: 0.5259 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 101/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5378 - acc: 0.7283 - auc_1: 0.8138 - val_loss: 0.5252 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 102/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5358 - acc: 0.7283 - auc_1: 0.8140 - val_loss: 0.5245 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 103/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5339 - acc: 0.7283 - auc_1: 0.8143 - val_loss: 0.5239 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 104/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5320 - acc: 0.7283 - auc_1: 0.8148 - val_loss: 0.5235 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 105/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.5302 - acc: 0.7283 - auc_1: 0.8148 - val_loss: 0.5231 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 106/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5284 - acc: 0.7283 - auc_1: 0.8162 - val_loss: 0.5229 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 107/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5266 - acc: 0.7283 - auc_1: 0.8193 - val_loss: 0.5227 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 108/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5249 - acc: 0.7283 - auc_1: 0.8198 - val_loss: 0.5227 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 109/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5233 - acc: 0.7283 - auc_1: 0.8231 - val_loss: 0.5227 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 110/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.5216 - acc: 0.7283 - auc_1: 0.8245 - val_loss: 0.5229 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 111/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5200 - acc: 0.7174 - auc_1: 0.8257 - val_loss: 0.5231 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 112/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5185 - acc: 0.7174 - auc_1: 0.8276 - val_loss: 0.5234 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 113/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5170 - acc: 0.7174 - auc_1: 0.8283 - val_loss: 0.5237 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 114/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5155 - acc: 0.7283 - auc_1: 0.8300 - val_loss: 0.5242 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 115/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5141 - acc: 0.7283 - auc_1: 0.8295 - val_loss: 0.5247 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 116/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.5127 - acc: 0.7391 - auc_1: 0.8300 - val_loss: 0.5253 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 117/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5114 - acc: 0.7391 - auc_1: 0.8302 - val_loss: 0.5259 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 118/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5101 - acc: 0.7391 - auc_1: 0.8312 - val_loss: 0.5266 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 119/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5088 - acc: 0.7283 - auc_1: 0.8307 - val_loss: 0.5273 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 120/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.5076 - acc: 0.7283 - auc_1: 0.8310 - val_loss: 0.5281 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 121/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5064 - acc: 0.7283 - auc_1: 0.8307 - val_loss: 0.5289 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 122/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5053 - acc: 0.7283 - auc_1: 0.8317 - val_loss: 0.5297 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 123/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5041 - acc: 0.7283 - auc_1: 0.8312 - val_loss: 0.5306 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 124/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.5030 - acc: 0.7283 - auc_1: 0.8302 - val_loss: 0.5314 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 125/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5020 - acc: 0.7283 - auc_1: 0.8319 - val_loss: 0.5325 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 126/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.5010 - acc: 0.7283 - auc_1: 0.8331 - val_loss: 0.5332 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 127/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.5000 - acc: 0.7391 - auc_1: 0.8324 - val_loss: 0.5347 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 128/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4990 - acc: 0.7500 - auc_1: 0.8319 - val_loss: 0.5343 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 129/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4980 - acc: 0.7500 - auc_1: 0.8329 - val_loss: 0.5386 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 130/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4971 - acc: 0.7500 - auc_1: 0.8336 - val_loss: 0.5315 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 131/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4964 - acc: 0.7500 - auc_1: 0.8333 - val_loss: 0.5530 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 132/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4965 - acc: 0.7717 - auc_1: 0.8340 - val_loss: 0.5158 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 133/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4985 - acc: 0.7391 - auc_1: 0.8374 - val_loss: 0.5748 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 134/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4991 - acc: 0.7609 - auc_1: 0.8348 - val_loss: 0.5191 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 135/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4961 - acc: 0.7391 - auc_1: 0.8367 - val_loss: 0.5579 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 136/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4935 - acc: 0.7826 - auc_1: 0.8360 - val_loss: 0.5328 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 137/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4920 - acc: 0.7500 - auc_1: 0.8362 - val_loss: 0.5490 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 138/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4909 - acc: 0.7500 - auc_1: 0.8371 - val_loss: 0.5399 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 139/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4901 - acc: 0.7500 - auc_1: 0.8371 - val_loss: 0.5471 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 140/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4893 - acc: 0.7500 - auc_1: 0.8379 - val_loss: 0.5437 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 141/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4886 - acc: 0.7500 - auc_1: 0.8383 - val_loss: 0.5475 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 142/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4879 - acc: 0.7500 - auc_1: 0.8388 - val_loss: 0.5464 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 143/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4872 - acc: 0.7500 - auc_1: 0.8381 - val_loss: 0.5487 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 144/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4865 - acc: 0.7500 - auc_1: 0.8393 - val_loss: 0.5485 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 145/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4858 - acc: 0.7500 - auc_1: 0.8393 - val_loss: 0.5503 - val_acc: 0.7500 - val_auc_1: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4851 - acc: 0.7500 - auc_1: 0.8400 - val_loss: 0.5506 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 147/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4845 - acc: 0.7500 - auc_1: 0.8410 - val_loss: 0.5520 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 148/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4838 - acc: 0.7500 - auc_1: 0.8400 - val_loss: 0.5525 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 149/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4831 - acc: 0.7500 - auc_1: 0.8410 - val_loss: 0.5538 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 150/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4824 - acc: 0.7500 - auc_1: 0.8414 - val_loss: 0.5545 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 151/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4818 - acc: 0.7500 - auc_1: 0.8414 - val_loss: 0.5557 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 152/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4811 - acc: 0.7500 - auc_1: 0.8419 - val_loss: 0.5564 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 153/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4804 - acc: 0.7500 - auc_1: 0.8436 - val_loss: 0.5576 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 154/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4798 - acc: 0.7500 - auc_1: 0.8426 - val_loss: 0.5584 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 155/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4791 - acc: 0.7609 - auc_1: 0.8433 - val_loss: 0.5596 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 156/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4784 - acc: 0.7609 - auc_1: 0.8436 - val_loss: 0.5603 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 157/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4777 - acc: 0.7609 - auc_1: 0.8443 - val_loss: 0.5615 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 158/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4771 - acc: 0.7609 - auc_1: 0.8457 - val_loss: 0.5623 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 159/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4764 - acc: 0.7609 - auc_1: 0.8462 - val_loss: 0.5635 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 160/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4757 - acc: 0.7609 - auc_1: 0.8462 - val_loss: 0.5642 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 161/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.4750 - acc: 0.7609 - auc_1: 0.8467 - val_loss: 0.5655 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 162/3000\n",
      "92/92 [==============================] - 0s 185us/step - loss: 0.4743 - acc: 0.7609 - auc_1: 0.8486 - val_loss: 0.5662 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 163/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.4736 - acc: 0.7609 - auc_1: 0.8498 - val_loss: 0.5674 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 164/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4729 - acc: 0.7609 - auc_1: 0.8493 - val_loss: 0.5681 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 165/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4722 - acc: 0.7609 - auc_1: 0.8495 - val_loss: 0.5694 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 166/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4714 - acc: 0.7609 - auc_1: 0.8490 - val_loss: 0.5699 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 167/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4707 - acc: 0.7609 - auc_1: 0.8507 - val_loss: 0.5714 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 168/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4700 - acc: 0.7609 - auc_1: 0.8517 - val_loss: 0.5717 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 169/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4692 - acc: 0.7609 - auc_1: 0.8521 - val_loss: 0.5735 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 170/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4685 - acc: 0.7609 - auc_1: 0.8529 - val_loss: 0.5735 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 171/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4677 - acc: 0.7609 - auc_1: 0.8526 - val_loss: 0.5756 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 172/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4669 - acc: 0.7609 - auc_1: 0.8536 - val_loss: 0.5750 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 173/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4662 - acc: 0.7609 - auc_1: 0.8538 - val_loss: 0.5778 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 174/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4654 - acc: 0.7609 - auc_1: 0.8545 - val_loss: 0.5763 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 175/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4646 - acc: 0.7609 - auc_1: 0.8540 - val_loss: 0.5804 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 176/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4638 - acc: 0.7717 - auc_1: 0.8550 - val_loss: 0.5771 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 177/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4630 - acc: 0.7609 - auc_1: 0.8550 - val_loss: 0.5836 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 178/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4622 - acc: 0.7717 - auc_1: 0.8560 - val_loss: 0.5771 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 179/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4614 - acc: 0.7717 - auc_1: 0.8564 - val_loss: 0.5880 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 180/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4607 - acc: 0.7717 - auc_1: 0.8564 - val_loss: 0.5753 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 181/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4599 - acc: 0.7609 - auc_1: 0.8576 - val_loss: 0.5949 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 182/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.4593 - acc: 0.7935 - auc_1: 0.8574 - val_loss: 0.5710 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 183/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4588 - acc: 0.7717 - auc_1: 0.8598 - val_loss: 0.6051 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 184/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4586 - acc: 0.7935 - auc_1: 0.8574 - val_loss: 0.5652 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 185/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4584 - acc: 0.7609 - auc_1: 0.8619 - val_loss: 0.6148 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 186/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4582 - acc: 0.7826 - auc_1: 0.8588 - val_loss: 0.5639 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 187/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4573 - acc: 0.7609 - auc_1: 0.8636 - val_loss: 0.6146 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 188/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4562 - acc: 0.7935 - auc_1: 0.8602 - val_loss: 0.5697 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 189/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4547 - acc: 0.7717 - auc_1: 0.8648 - val_loss: 0.6079 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 190/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4533 - acc: 0.7935 - auc_1: 0.8624 - val_loss: 0.5774 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 191/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4520 - acc: 0.7717 - auc_1: 0.8652 - val_loss: 0.6023 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 192/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4509 - acc: 0.7935 - auc_1: 0.8626 - val_loss: 0.5835 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 193/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4499 - acc: 0.7609 - auc_1: 0.8669 - val_loss: 0.5994 - val_acc: 0.7500 - val_auc_1: 0.9071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4489 - acc: 0.7935 - auc_1: 0.8650 - val_loss: 0.5878 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 195/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4480 - acc: 0.7717 - auc_1: 0.8679 - val_loss: 0.5982 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 196/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4471 - acc: 0.7935 - auc_1: 0.8671 - val_loss: 0.5909 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 197/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4462 - acc: 0.7826 - auc_1: 0.8698 - val_loss: 0.5981 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 198/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4453 - acc: 0.7935 - auc_1: 0.8695 - val_loss: 0.5932 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 199/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4444 - acc: 0.7826 - auc_1: 0.8721 - val_loss: 0.5984 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 200/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4435 - acc: 0.7935 - auc_1: 0.8721 - val_loss: 0.5951 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 201/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4427 - acc: 0.7826 - auc_1: 0.8740 - val_loss: 0.5991 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 202/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4418 - acc: 0.7826 - auc_1: 0.8740 - val_loss: 0.5968 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 203/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.4409 - acc: 0.7826 - auc_1: 0.8745 - val_loss: 0.6000 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 204/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4400 - acc: 0.7826 - auc_1: 0.8752 - val_loss: 0.5982 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 205/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4391 - acc: 0.7935 - auc_1: 0.8757 - val_loss: 0.6009 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 206/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.4382 - acc: 0.7826 - auc_1: 0.8762 - val_loss: 0.5995 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 207/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.4373 - acc: 0.7935 - auc_1: 0.8767 - val_loss: 0.6019 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 208/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.4364 - acc: 0.7935 - auc_1: 0.8776 - val_loss: 0.6007 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 209/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.4354 - acc: 0.7935 - auc_1: 0.8783 - val_loss: 0.6029 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 210/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.4345 - acc: 0.7935 - auc_1: 0.8783 - val_loss: 0.6018 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 211/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4336 - acc: 0.7935 - auc_1: 0.8788 - val_loss: 0.6039 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 212/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4327 - acc: 0.7935 - auc_1: 0.8786 - val_loss: 0.6028 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 213/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4318 - acc: 0.7935 - auc_1: 0.8800 - val_loss: 0.6049 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 214/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.4309 - acc: 0.7935 - auc_1: 0.8810 - val_loss: 0.6038 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 215/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4300 - acc: 0.7935 - auc_1: 0.8807 - val_loss: 0.6059 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 216/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4290 - acc: 0.7935 - auc_1: 0.8814 - val_loss: 0.6046 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 217/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4281 - acc: 0.7935 - auc_1: 0.8829 - val_loss: 0.6069 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 218/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4272 - acc: 0.7935 - auc_1: 0.8838 - val_loss: 0.6053 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 219/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.4263 - acc: 0.7935 - auc_1: 0.8836 - val_loss: 0.6079 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 220/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4254 - acc: 0.7935 - auc_1: 0.8843 - val_loss: 0.6059 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 221/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4245 - acc: 0.7935 - auc_1: 0.8860 - val_loss: 0.6090 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 222/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.4236 - acc: 0.7935 - auc_1: 0.8857 - val_loss: 0.6063 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 223/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.4227 - acc: 0.7935 - auc_1: 0.8874 - val_loss: 0.6101 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 224/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.4217 - acc: 0.7935 - auc_1: 0.8876 - val_loss: 0.6065 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 225/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4208 - acc: 0.7935 - auc_1: 0.8886 - val_loss: 0.6114 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 226/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4199 - acc: 0.7935 - auc_1: 0.8895 - val_loss: 0.6063 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 227/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4191 - acc: 0.7935 - auc_1: 0.8907 - val_loss: 0.6130 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 228/3000\n",
      "92/92 [==============================] - 0s 185us/step - loss: 0.4182 - acc: 0.7935 - auc_1: 0.8907 - val_loss: 0.6056 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 229/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4173 - acc: 0.7935 - auc_1: 0.8919 - val_loss: 0.6152 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 230/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4164 - acc: 0.7935 - auc_1: 0.8917 - val_loss: 0.6040 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 231/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4156 - acc: 0.7717 - auc_1: 0.8936 - val_loss: 0.6184 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 232/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4148 - acc: 0.7935 - auc_1: 0.8940 - val_loss: 0.6012 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 233/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4141 - acc: 0.7717 - auc_1: 0.8955 - val_loss: 0.6232 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 234/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4134 - acc: 0.7826 - auc_1: 0.8943 - val_loss: 0.5970 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 235/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4129 - acc: 0.7826 - auc_1: 0.8969 - val_loss: 0.6298 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 236/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.4124 - acc: 0.7826 - auc_1: 0.8957 - val_loss: 0.5919 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 237/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4121 - acc: 0.8043 - auc_1: 0.8981 - val_loss: 0.6365 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 238/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4118 - acc: 0.7935 - auc_1: 0.8969 - val_loss: 0.5885 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 239/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4113 - acc: 0.8043 - auc_1: 0.9000 - val_loss: 0.6387 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 240/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4106 - acc: 0.7826 - auc_1: 0.8983 - val_loss: 0.5893 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 241/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.4095 - acc: 0.8043 - auc_1: 0.9014 - val_loss: 0.6348 - val_acc: 0.7083 - val_auc_1: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4083 - acc: 0.7826 - auc_1: 0.9005 - val_loss: 0.5933 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 243/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4070 - acc: 0.8043 - auc_1: 0.9017 - val_loss: 0.6286 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 244/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4059 - acc: 0.7826 - auc_1: 0.9024 - val_loss: 0.5978 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 245/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.4048 - acc: 0.7935 - auc_1: 0.9029 - val_loss: 0.6233 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 246/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4038 - acc: 0.7826 - auc_1: 0.9043 - val_loss: 0.6013 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 247/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4028 - acc: 0.7826 - auc_1: 0.9038 - val_loss: 0.6196 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 248/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.4019 - acc: 0.7717 - auc_1: 0.9057 - val_loss: 0.6038 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 249/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.4011 - acc: 0.7826 - auc_1: 0.9048 - val_loss: 0.6170 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 250/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.4003 - acc: 0.7717 - auc_1: 0.9060 - val_loss: 0.6053 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 251/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3995 - acc: 0.7826 - auc_1: 0.9055 - val_loss: 0.6152 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 252/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3988 - acc: 0.7826 - auc_1: 0.9062 - val_loss: 0.6062 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 253/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3980 - acc: 0.7717 - auc_1: 0.9069 - val_loss: 0.6139 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 254/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3973 - acc: 0.7717 - auc_1: 0.9067 - val_loss: 0.6066 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 255/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3966 - acc: 0.7717 - auc_1: 0.9081 - val_loss: 0.6129 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 256/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3959 - acc: 0.7717 - auc_1: 0.9083 - val_loss: 0.6067 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 257/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3952 - acc: 0.7717 - auc_1: 0.9088 - val_loss: 0.6120 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 258/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3945 - acc: 0.7717 - auc_1: 0.9098 - val_loss: 0.6066 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 259/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3938 - acc: 0.7717 - auc_1: 0.9102 - val_loss: 0.6113 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 260/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3931 - acc: 0.7717 - auc_1: 0.9105 - val_loss: 0.6063 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 261/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3924 - acc: 0.7717 - auc_1: 0.9110 - val_loss: 0.6107 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 262/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3917 - acc: 0.7826 - auc_1: 0.9112 - val_loss: 0.6058 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 263/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3911 - acc: 0.7717 - auc_1: 0.9110 - val_loss: 0.6101 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 264/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3904 - acc: 0.7826 - auc_1: 0.9119 - val_loss: 0.6051 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 265/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3897 - acc: 0.7826 - auc_1: 0.9119 - val_loss: 0.6096 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 266/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3891 - acc: 0.7826 - auc_1: 0.9126 - val_loss: 0.6043 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 267/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3885 - acc: 0.7826 - auc_1: 0.9133 - val_loss: 0.6092 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 268/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3878 - acc: 0.7826 - auc_1: 0.9129 - val_loss: 0.6033 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 269/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3872 - acc: 0.7826 - auc_1: 0.9138 - val_loss: 0.6088 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 270/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.3866 - acc: 0.7826 - auc_1: 0.9133 - val_loss: 0.6021 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 271/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3860 - acc: 0.7826 - auc_1: 0.9148 - val_loss: 0.6087 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 272/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3854 - acc: 0.7826 - auc_1: 0.9145 - val_loss: 0.6006 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 273/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3848 - acc: 0.7826 - auc_1: 0.9152 - val_loss: 0.6087 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 274/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3842 - acc: 0.7935 - auc_1: 0.9155 - val_loss: 0.5987 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 275/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3836 - acc: 0.7935 - auc_1: 0.9150 - val_loss: 0.6092 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 276/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3831 - acc: 0.7935 - auc_1: 0.9152 - val_loss: 0.5964 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 277/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3826 - acc: 0.7935 - auc_1: 0.9167 - val_loss: 0.6104 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 278/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3821 - acc: 0.7935 - auc_1: 0.9164 - val_loss: 0.5933 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 279/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3816 - acc: 0.8152 - auc_1: 0.9181 - val_loss: 0.6123 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 280/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3812 - acc: 0.7935 - auc_1: 0.9160 - val_loss: 0.5895 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 281/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3808 - acc: 0.8043 - auc_1: 0.9174 - val_loss: 0.6153 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 282/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3806 - acc: 0.7935 - auc_1: 0.9157 - val_loss: 0.5852 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 283/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3804 - acc: 0.8043 - auc_1: 0.9171 - val_loss: 0.6189 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 284/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3802 - acc: 0.7935 - auc_1: 0.9148 - val_loss: 0.5810 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 285/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3801 - acc: 0.8152 - auc_1: 0.9164 - val_loss: 0.6216 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 286/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3799 - acc: 0.8043 - auc_1: 0.9140 - val_loss: 0.5784 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 287/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3795 - acc: 0.8152 - auc_1: 0.9169 - val_loss: 0.6213 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 288/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3791 - acc: 0.8043 - auc_1: 0.9143 - val_loss: 0.5781 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 289/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3784 - acc: 0.8261 - auc_1: 0.9171 - val_loss: 0.6177 - val_acc: 0.7500 - val_auc_1: 0.8857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3776 - acc: 0.7935 - auc_1: 0.9145 - val_loss: 0.5795 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 291/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3768 - acc: 0.8152 - auc_1: 0.9169 - val_loss: 0.6125 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 292/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3760 - acc: 0.7935 - auc_1: 0.9162 - val_loss: 0.5816 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 293/3000\n",
      "92/92 [==============================] - 0s 468us/step - loss: 0.3752 - acc: 0.8152 - auc_1: 0.9174 - val_loss: 0.6075 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 294/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3745 - acc: 0.7935 - auc_1: 0.9160 - val_loss: 0.5833 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 295/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3739 - acc: 0.8152 - auc_1: 0.9179 - val_loss: 0.6034 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 296/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3732 - acc: 0.7935 - auc_1: 0.9167 - val_loss: 0.5845 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 297/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3727 - acc: 0.8152 - auc_1: 0.9179 - val_loss: 0.6001 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 298/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3722 - acc: 0.8043 - auc_1: 0.9160 - val_loss: 0.5851 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 299/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3717 - acc: 0.8152 - auc_1: 0.9186 - val_loss: 0.5975 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 300/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3712 - acc: 0.8043 - auc_1: 0.9171 - val_loss: 0.5853 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 301/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3707 - acc: 0.8152 - auc_1: 0.9188 - val_loss: 0.5954 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 302/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3703 - acc: 0.8043 - auc_1: 0.9174 - val_loss: 0.5851 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 303/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3698 - acc: 0.8152 - auc_1: 0.9202 - val_loss: 0.5936 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 304/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3694 - acc: 0.8043 - auc_1: 0.9174 - val_loss: 0.5847 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 305/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3690 - acc: 0.8152 - auc_1: 0.9198 - val_loss: 0.5921 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 306/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3686 - acc: 0.8043 - auc_1: 0.9186 - val_loss: 0.5840 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 307/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3682 - acc: 0.8152 - auc_1: 0.9190 - val_loss: 0.5909 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 308/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3678 - acc: 0.8043 - auc_1: 0.9190 - val_loss: 0.5832 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 309/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3674 - acc: 0.8152 - auc_1: 0.9188 - val_loss: 0.5897 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 310/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3670 - acc: 0.8043 - auc_1: 0.9190 - val_loss: 0.5823 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 311/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.3666 - acc: 0.8152 - auc_1: 0.9195 - val_loss: 0.5887 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 312/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3663 - acc: 0.8043 - auc_1: 0.9205 - val_loss: 0.5812 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 313/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3659 - acc: 0.8152 - auc_1: 0.9207 - val_loss: 0.5879 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 314/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.3655 - acc: 0.8043 - auc_1: 0.9207 - val_loss: 0.5800 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 315/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3652 - acc: 0.8152 - auc_1: 0.9200 - val_loss: 0.5872 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 316/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3648 - acc: 0.8043 - auc_1: 0.9200 - val_loss: 0.5787 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 317/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3645 - acc: 0.8152 - auc_1: 0.9205 - val_loss: 0.5867 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 318/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3642 - acc: 0.8043 - auc_1: 0.9193 - val_loss: 0.5772 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 319/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3639 - acc: 0.8152 - auc_1: 0.9202 - val_loss: 0.5864 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 320/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3635 - acc: 0.8043 - auc_1: 0.9200 - val_loss: 0.5755 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 321/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3632 - acc: 0.8152 - auc_1: 0.9212 - val_loss: 0.5865 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 322/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3630 - acc: 0.8043 - auc_1: 0.9205 - val_loss: 0.5735 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 323/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3627 - acc: 0.8152 - auc_1: 0.9207 - val_loss: 0.5869 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 324/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3624 - acc: 0.8152 - auc_1: 0.9210 - val_loss: 0.5712 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 325/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3622 - acc: 0.8152 - auc_1: 0.9212 - val_loss: 0.5878 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 326/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3620 - acc: 0.8152 - auc_1: 0.9207 - val_loss: 0.5686 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 327/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3618 - acc: 0.8152 - auc_1: 0.9207 - val_loss: 0.5893 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 328/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3617 - acc: 0.8152 - auc_1: 0.9210 - val_loss: 0.5657 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 329/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3616 - acc: 0.8152 - auc_1: 0.9205 - val_loss: 0.5912 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 330/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3616 - acc: 0.8152 - auc_1: 0.9202 - val_loss: 0.5627 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 331/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3616 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.5931 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 332/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3615 - acc: 0.8152 - auc_1: 0.9202 - val_loss: 0.5601 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 333/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3615 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.5942 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 334/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3614 - acc: 0.8152 - auc_1: 0.9207 - val_loss: 0.5585 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 335/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3613 - acc: 0.8152 - auc_1: 0.9217 - val_loss: 0.5937 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 336/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3610 - acc: 0.8043 - auc_1: 0.9202 - val_loss: 0.5580 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 337/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3606 - acc: 0.8152 - auc_1: 0.9217 - val_loss: 0.5915 - val_acc: 0.7500 - val_auc_1: 0.8607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3602 - acc: 0.8152 - auc_1: 0.9207 - val_loss: 0.5585 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 339/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3597 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.5882 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 340/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3592 - acc: 0.8152 - auc_1: 0.9217 - val_loss: 0.5596 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 341/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3588 - acc: 0.8152 - auc_1: 0.9224 - val_loss: 0.5848 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 342/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3583 - acc: 0.8152 - auc_1: 0.9219 - val_loss: 0.5608 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 343/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3579 - acc: 0.8152 - auc_1: 0.9221 - val_loss: 0.5817 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 344/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3574 - acc: 0.8261 - auc_1: 0.9217 - val_loss: 0.5618 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 345/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3571 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.5791 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 346/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3567 - acc: 0.8261 - auc_1: 0.9217 - val_loss: 0.5625 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 347/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3564 - acc: 0.8152 - auc_1: 0.9221 - val_loss: 0.5770 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 348/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3561 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.5630 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 349/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.3558 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.5752 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 350/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.3556 - acc: 0.8152 - auc_1: 0.9217 - val_loss: 0.5633 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 351/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.3553 - acc: 0.8261 - auc_1: 0.9212 - val_loss: 0.5739 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 352/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.3550 - acc: 0.8152 - auc_1: 0.9219 - val_loss: 0.5634 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 353/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3548 - acc: 0.8261 - auc_1: 0.9214 - val_loss: 0.5727 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 354/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3546 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.5633 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 355/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3543 - acc: 0.8261 - auc_1: 0.9214 - val_loss: 0.5718 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 356/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3541 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.5632 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 357/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3539 - acc: 0.8261 - auc_1: 0.9219 - val_loss: 0.5711 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 358/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3537 - acc: 0.8152 - auc_1: 0.9221 - val_loss: 0.5629 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 359/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3535 - acc: 0.8261 - auc_1: 0.9221 - val_loss: 0.5705 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 360/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3533 - acc: 0.8152 - auc_1: 0.9217 - val_loss: 0.5625 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 361/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.3531 - acc: 0.8261 - auc_1: 0.9221 - val_loss: 0.5701 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 362/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3529 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.5621 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 363/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3527 - acc: 0.8370 - auc_1: 0.9224 - val_loss: 0.5697 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 364/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3525 - acc: 0.8152 - auc_1: 0.9217 - val_loss: 0.5616 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 365/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3523 - acc: 0.8370 - auc_1: 0.9221 - val_loss: 0.5695 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 366/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3521 - acc: 0.8152 - auc_1: 0.9221 - val_loss: 0.5610 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 367/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3520 - acc: 0.8370 - auc_1: 0.9221 - val_loss: 0.5695 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 368/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3518 - acc: 0.8261 - auc_1: 0.9219 - val_loss: 0.5603 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 369/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3516 - acc: 0.8370 - auc_1: 0.9226 - val_loss: 0.5696 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 370/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3514 - acc: 0.8261 - auc_1: 0.9226 - val_loss: 0.5595 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 371/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3513 - acc: 0.8370 - auc_1: 0.9226 - val_loss: 0.5699 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 372/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3511 - acc: 0.8261 - auc_1: 0.9217 - val_loss: 0.5585 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 373/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.3510 - acc: 0.8478 - auc_1: 0.9221 - val_loss: 0.5704 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 374/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.3508 - acc: 0.8261 - auc_1: 0.9221 - val_loss: 0.5575 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 375/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3507 - acc: 0.8478 - auc_1: 0.9226 - val_loss: 0.5711 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 376/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3506 - acc: 0.8261 - auc_1: 0.9226 - val_loss: 0.5562 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 377/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.3505 - acc: 0.8478 - auc_1: 0.9226 - val_loss: 0.5722 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 378/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3504 - acc: 0.8261 - auc_1: 0.9219 - val_loss: 0.5548 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 379/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3503 - acc: 0.8478 - auc_1: 0.9221 - val_loss: 0.5735 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 380/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3503 - acc: 0.8261 - auc_1: 0.9226 - val_loss: 0.5532 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 381/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3502 - acc: 0.8478 - auc_1: 0.9226 - val_loss: 0.5750 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 382/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3502 - acc: 0.8261 - auc_1: 0.9219 - val_loss: 0.5517 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 383/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3502 - acc: 0.8478 - auc_1: 0.9229 - val_loss: 0.5766 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 384/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3502 - acc: 0.8261 - auc_1: 0.9226 - val_loss: 0.5502 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 385/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3502 - acc: 0.8478 - auc_1: 0.9221 - val_loss: 0.5780 - val_acc: 0.7500 - val_auc_1: 0.8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3502 - acc: 0.8370 - auc_1: 0.9224 - val_loss: 0.5492 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 387/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3501 - acc: 0.8478 - auc_1: 0.9224 - val_loss: 0.5787 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 388/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3500 - acc: 0.8370 - auc_1: 0.9219 - val_loss: 0.5486 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 389/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3499 - acc: 0.8478 - auc_1: 0.9229 - val_loss: 0.5787 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 390/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3497 - acc: 0.8370 - auc_1: 0.9229 - val_loss: 0.5486 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 391/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3496 - acc: 0.8478 - auc_1: 0.9229 - val_loss: 0.5778 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 392/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3493 - acc: 0.8370 - auc_1: 0.9224 - val_loss: 0.5492 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 393/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3490 - acc: 0.8478 - auc_1: 0.9231 - val_loss: 0.5763 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 394/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3487 - acc: 0.8261 - auc_1: 0.9226 - val_loss: 0.5501 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 395/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3484 - acc: 0.8478 - auc_1: 0.9236 - val_loss: 0.5745 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 396/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3481 - acc: 0.8261 - auc_1: 0.9229 - val_loss: 0.5513 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 397/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3478 - acc: 0.8478 - auc_1: 0.9229 - val_loss: 0.5727 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 398/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3475 - acc: 0.8261 - auc_1: 0.9226 - val_loss: 0.5524 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 399/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3472 - acc: 0.8478 - auc_1: 0.9238 - val_loss: 0.5711 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 400/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3470 - acc: 0.8261 - auc_1: 0.9231 - val_loss: 0.5535 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 401/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3467 - acc: 0.8478 - auc_1: 0.9233 - val_loss: 0.5698 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 402/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3465 - acc: 0.8370 - auc_1: 0.9231 - val_loss: 0.5544 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 403/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3463 - acc: 0.8478 - auc_1: 0.9240 - val_loss: 0.5687 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 404/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3461 - acc: 0.8370 - auc_1: 0.9226 - val_loss: 0.5552 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 405/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3459 - acc: 0.8478 - auc_1: 0.9238 - val_loss: 0.5678 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 406/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3457 - acc: 0.8370 - auc_1: 0.9226 - val_loss: 0.5559 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 407/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3455 - acc: 0.8478 - auc_1: 0.9243 - val_loss: 0.5671 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 408/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3453 - acc: 0.8370 - auc_1: 0.9233 - val_loss: 0.5564 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 409/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3451 - acc: 0.8478 - auc_1: 0.9240 - val_loss: 0.5666 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 410/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3449 - acc: 0.8370 - auc_1: 0.9233 - val_loss: 0.5568 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 411/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3448 - acc: 0.8478 - auc_1: 0.9243 - val_loss: 0.5662 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 412/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3446 - acc: 0.8370 - auc_1: 0.9236 - val_loss: 0.5571 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 413/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3444 - acc: 0.8478 - auc_1: 0.9245 - val_loss: 0.5659 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 414/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3443 - acc: 0.8370 - auc_1: 0.9236 - val_loss: 0.5573 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 415/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3441 - acc: 0.8478 - auc_1: 0.9245 - val_loss: 0.5657 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 416/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3439 - acc: 0.8370 - auc_1: 0.9238 - val_loss: 0.5575 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 417/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3438 - acc: 0.8478 - auc_1: 0.9245 - val_loss: 0.5656 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 418/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3436 - acc: 0.8478 - auc_1: 0.9240 - val_loss: 0.5576 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 419/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3434 - acc: 0.8478 - auc_1: 0.9245 - val_loss: 0.5655 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 420/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3433 - acc: 0.8478 - auc_1: 0.9243 - val_loss: 0.5576 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 421/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3431 - acc: 0.8478 - auc_1: 0.9248 - val_loss: 0.5655 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 422/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3430 - acc: 0.8478 - auc_1: 0.9250 - val_loss: 0.5575 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 423/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3428 - acc: 0.8478 - auc_1: 0.9248 - val_loss: 0.5656 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 424/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3426 - acc: 0.8478 - auc_1: 0.9250 - val_loss: 0.5574 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 425/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3425 - acc: 0.8478 - auc_1: 0.9248 - val_loss: 0.5658 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 426/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3423 - acc: 0.8478 - auc_1: 0.9252 - val_loss: 0.5571 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 427/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3422 - acc: 0.8478 - auc_1: 0.9250 - val_loss: 0.5660 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 428/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3420 - acc: 0.8370 - auc_1: 0.9252 - val_loss: 0.5568 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 429/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3418 - acc: 0.8478 - auc_1: 0.9250 - val_loss: 0.5663 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 430/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3417 - acc: 0.8370 - auc_1: 0.9250 - val_loss: 0.5565 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 431/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3415 - acc: 0.8478 - auc_1: 0.9252 - val_loss: 0.5666 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 432/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3414 - acc: 0.8370 - auc_1: 0.9252 - val_loss: 0.5560 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 433/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3412 - acc: 0.8478 - auc_1: 0.9255 - val_loss: 0.5671 - val_acc: 0.7500 - val_auc_1: 0.8679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3411 - acc: 0.8370 - auc_1: 0.9252 - val_loss: 0.5554 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 435/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3409 - acc: 0.8478 - auc_1: 0.9255 - val_loss: 0.5677 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 436/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3408 - acc: 0.8370 - auc_1: 0.9257 - val_loss: 0.5546 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 437/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3407 - acc: 0.8478 - auc_1: 0.9255 - val_loss: 0.5684 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 438/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3405 - acc: 0.8370 - auc_1: 0.9262 - val_loss: 0.5538 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 439/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3404 - acc: 0.8478 - auc_1: 0.9255 - val_loss: 0.5692 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 440/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3403 - acc: 0.8370 - auc_1: 0.9260 - val_loss: 0.5529 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 441/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3401 - acc: 0.8478 - auc_1: 0.9252 - val_loss: 0.5702 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 442/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3400 - acc: 0.8370 - auc_1: 0.9262 - val_loss: 0.5518 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 443/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3399 - acc: 0.8478 - auc_1: 0.9252 - val_loss: 0.5712 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 444/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3398 - acc: 0.8370 - auc_1: 0.9260 - val_loss: 0.5507 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 445/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3397 - acc: 0.8478 - auc_1: 0.9255 - val_loss: 0.5723 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 446/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.3396 - acc: 0.8370 - auc_1: 0.9262 - val_loss: 0.5496 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 447/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3395 - acc: 0.8478 - auc_1: 0.9257 - val_loss: 0.5733 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 448/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3394 - acc: 0.8370 - auc_1: 0.9269 - val_loss: 0.5486 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 449/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3393 - acc: 0.8478 - auc_1: 0.9257 - val_loss: 0.5740 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 450/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3392 - acc: 0.8370 - auc_1: 0.9269 - val_loss: 0.5478 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 451/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3391 - acc: 0.8478 - auc_1: 0.9262 - val_loss: 0.5745 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 452/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3389 - acc: 0.8370 - auc_1: 0.9269 - val_loss: 0.5472 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 453/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3388 - acc: 0.8478 - auc_1: 0.9264 - val_loss: 0.5745 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 454/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3385 - acc: 0.8370 - auc_1: 0.9279 - val_loss: 0.5469 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 455/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3384 - acc: 0.8478 - auc_1: 0.9264 - val_loss: 0.5740 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 456/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3381 - acc: 0.8370 - auc_1: 0.9279 - val_loss: 0.5470 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 457/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3379 - acc: 0.8478 - auc_1: 0.9262 - val_loss: 0.5730 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 458/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3376 - acc: 0.8370 - auc_1: 0.9281 - val_loss: 0.5472 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 459/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3373 - acc: 0.8478 - auc_1: 0.9262 - val_loss: 0.5718 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 460/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3370 - acc: 0.8370 - auc_1: 0.9286 - val_loss: 0.5477 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 461/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.3367 - acc: 0.8478 - auc_1: 0.9274 - val_loss: 0.5704 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 462/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.3364 - acc: 0.8370 - auc_1: 0.9286 - val_loss: 0.5482 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 463/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3361 - acc: 0.8478 - auc_1: 0.9271 - val_loss: 0.5689 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 464/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3358 - acc: 0.8370 - auc_1: 0.9281 - val_loss: 0.5488 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 465/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3355 - acc: 0.8478 - auc_1: 0.9271 - val_loss: 0.5675 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 466/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3352 - acc: 0.8370 - auc_1: 0.9283 - val_loss: 0.5493 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 467/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3349 - acc: 0.8478 - auc_1: 0.9276 - val_loss: 0.5661 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 468/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3347 - acc: 0.8370 - auc_1: 0.9283 - val_loss: 0.5497 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 469/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3344 - acc: 0.8478 - auc_1: 0.9281 - val_loss: 0.5648 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 470/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3341 - acc: 0.8370 - auc_1: 0.9286 - val_loss: 0.5500 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 471/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3338 - acc: 0.8478 - auc_1: 0.9286 - val_loss: 0.5636 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 472/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3335 - acc: 0.8478 - auc_1: 0.9286 - val_loss: 0.5501 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 473/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3333 - acc: 0.8478 - auc_1: 0.9286 - val_loss: 0.5625 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 474/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3330 - acc: 0.8478 - auc_1: 0.9286 - val_loss: 0.5502 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 475/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3327 - acc: 0.8478 - auc_1: 0.9286 - val_loss: 0.5615 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 476/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3325 - acc: 0.8478 - auc_1: 0.9288 - val_loss: 0.5501 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 477/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3322 - acc: 0.8478 - auc_1: 0.9283 - val_loss: 0.5605 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 478/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3319 - acc: 0.8478 - auc_1: 0.9290 - val_loss: 0.5500 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 479/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3316 - acc: 0.8478 - auc_1: 0.9290 - val_loss: 0.5596 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 480/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3314 - acc: 0.8478 - auc_1: 0.9293 - val_loss: 0.5497 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 481/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3311 - acc: 0.8478 - auc_1: 0.9293 - val_loss: 0.5588 - val_acc: 0.7500 - val_auc_1: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3308 - acc: 0.8478 - auc_1: 0.9295 - val_loss: 0.5494 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 483/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3305 - acc: 0.8478 - auc_1: 0.9293 - val_loss: 0.5580 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 484/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3302 - acc: 0.8478 - auc_1: 0.9298 - val_loss: 0.5490 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 485/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3299 - acc: 0.8478 - auc_1: 0.9295 - val_loss: 0.5572 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 486/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3296 - acc: 0.8478 - auc_1: 0.9298 - val_loss: 0.5485 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 487/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3293 - acc: 0.8478 - auc_1: 0.9302 - val_loss: 0.5564 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 488/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.3290 - acc: 0.8478 - auc_1: 0.9302 - val_loss: 0.5479 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 489/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3287 - acc: 0.8478 - auc_1: 0.9302 - val_loss: 0.5557 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 490/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.3284 - acc: 0.8478 - auc_1: 0.9302 - val_loss: 0.5473 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 491/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3281 - acc: 0.8478 - auc_1: 0.9300 - val_loss: 0.5550 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 492/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3278 - acc: 0.8478 - auc_1: 0.9302 - val_loss: 0.5466 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 493/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3275 - acc: 0.8478 - auc_1: 0.9302 - val_loss: 0.5543 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 494/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3271 - acc: 0.8478 - auc_1: 0.9305 - val_loss: 0.5459 - val_acc: 0.7500 - val_auc_1: 0.8821\n",
      "Epoch 495/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3268 - acc: 0.8478 - auc_1: 0.9302 - val_loss: 0.5537 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 496/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3265 - acc: 0.8478 - auc_1: 0.9312 - val_loss: 0.5451 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 497/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3261 - acc: 0.8478 - auc_1: 0.9300 - val_loss: 0.5530 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 498/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3258 - acc: 0.8478 - auc_1: 0.9312 - val_loss: 0.5442 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 499/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3254 - acc: 0.8478 - auc_1: 0.9310 - val_loss: 0.5525 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 500/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3251 - acc: 0.8478 - auc_1: 0.9317 - val_loss: 0.5433 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 501/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3247 - acc: 0.8478 - auc_1: 0.9310 - val_loss: 0.5519 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 502/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3244 - acc: 0.8478 - auc_1: 0.9317 - val_loss: 0.5424 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 503/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3240 - acc: 0.8478 - auc_1: 0.9314 - val_loss: 0.5515 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 504/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3236 - acc: 0.8478 - auc_1: 0.9321 - val_loss: 0.5414 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 505/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3233 - acc: 0.8478 - auc_1: 0.9314 - val_loss: 0.5510 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 506/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3229 - acc: 0.8478 - auc_1: 0.9324 - val_loss: 0.5403 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 507/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.3225 - acc: 0.8478 - auc_1: 0.9319 - val_loss: 0.5507 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 508/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3221 - acc: 0.8478 - auc_1: 0.9326 - val_loss: 0.5392 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 509/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3217 - acc: 0.8478 - auc_1: 0.9331 - val_loss: 0.5504 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 510/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3213 - acc: 0.8478 - auc_1: 0.9326 - val_loss: 0.5381 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 511/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3209 - acc: 0.8587 - auc_1: 0.9336 - val_loss: 0.5503 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 512/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3205 - acc: 0.8478 - auc_1: 0.9331 - val_loss: 0.5369 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 513/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3201 - acc: 0.8587 - auc_1: 0.9333 - val_loss: 0.5502 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 514/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3197 - acc: 0.8478 - auc_1: 0.9331 - val_loss: 0.5357 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 515/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3192 - acc: 0.8587 - auc_1: 0.9340 - val_loss: 0.5502 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 516/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3188 - acc: 0.8478 - auc_1: 0.9331 - val_loss: 0.5345 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 517/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3184 - acc: 0.8587 - auc_1: 0.9336 - val_loss: 0.5503 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 518/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3179 - acc: 0.8478 - auc_1: 0.9333 - val_loss: 0.5332 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 519/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3175 - acc: 0.8587 - auc_1: 0.9343 - val_loss: 0.5505 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 520/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3171 - acc: 0.8370 - auc_1: 0.9343 - val_loss: 0.5320 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 521/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3166 - acc: 0.8696 - auc_1: 0.9343 - val_loss: 0.5507 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 522/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3162 - acc: 0.8370 - auc_1: 0.9348 - val_loss: 0.5308 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 523/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3157 - acc: 0.8696 - auc_1: 0.9352 - val_loss: 0.5509 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 524/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3152 - acc: 0.8370 - auc_1: 0.9352 - val_loss: 0.5297 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 525/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3148 - acc: 0.8696 - auc_1: 0.9357 - val_loss: 0.5511 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 526/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3143 - acc: 0.8370 - auc_1: 0.9355 - val_loss: 0.5288 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 527/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3138 - acc: 0.8696 - auc_1: 0.9357 - val_loss: 0.5512 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 528/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3133 - acc: 0.8478 - auc_1: 0.9362 - val_loss: 0.5280 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 529/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3128 - acc: 0.8696 - auc_1: 0.9367 - val_loss: 0.5512 - val_acc: 0.7500 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3123 - acc: 0.8478 - auc_1: 0.9374 - val_loss: 0.5274 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 531/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3117 - acc: 0.8696 - auc_1: 0.9374 - val_loss: 0.5510 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 532/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3111 - acc: 0.8478 - auc_1: 0.9376 - val_loss: 0.5271 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 533/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3106 - acc: 0.8696 - auc_1: 0.9379 - val_loss: 0.5505 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 534/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3100 - acc: 0.8478 - auc_1: 0.9381 - val_loss: 0.5271 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 535/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3094 - acc: 0.8696 - auc_1: 0.9388 - val_loss: 0.5499 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 536/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.3087 - acc: 0.8478 - auc_1: 0.9386 - val_loss: 0.5272 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 537/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3081 - acc: 0.8696 - auc_1: 0.9390 - val_loss: 0.5492 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 538/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3074 - acc: 0.8478 - auc_1: 0.9383 - val_loss: 0.5276 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 539/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3068 - acc: 0.8696 - auc_1: 0.9400 - val_loss: 0.5484 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 540/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.3061 - acc: 0.8478 - auc_1: 0.9388 - val_loss: 0.5280 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 541/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3054 - acc: 0.8696 - auc_1: 0.9402 - val_loss: 0.5475 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 542/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3047 - acc: 0.8478 - auc_1: 0.9393 - val_loss: 0.5286 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 543/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3040 - acc: 0.8696 - auc_1: 0.9419 - val_loss: 0.5467 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 544/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3033 - acc: 0.8478 - auc_1: 0.9398 - val_loss: 0.5293 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 545/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.3026 - acc: 0.8696 - auc_1: 0.9426 - val_loss: 0.5459 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 546/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.3019 - acc: 0.8587 - auc_1: 0.9410 - val_loss: 0.5299 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 547/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.3012 - acc: 0.8696 - auc_1: 0.9433 - val_loss: 0.5452 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 548/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.3005 - acc: 0.8696 - auc_1: 0.9412 - val_loss: 0.5306 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 549/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2998 - acc: 0.8696 - auc_1: 0.9433 - val_loss: 0.5446 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 550/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2991 - acc: 0.8696 - auc_1: 0.9421 - val_loss: 0.5313 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 551/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.2983 - acc: 0.8696 - auc_1: 0.9438 - val_loss: 0.5442 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 552/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.2976 - acc: 0.8696 - auc_1: 0.9426 - val_loss: 0.5320 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 553/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.2969 - acc: 0.8696 - auc_1: 0.9450 - val_loss: 0.5438 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 554/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2961 - acc: 0.8696 - auc_1: 0.9429 - val_loss: 0.5326 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 555/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2954 - acc: 0.8696 - auc_1: 0.9452 - val_loss: 0.5435 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 556/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2946 - acc: 0.8696 - auc_1: 0.9436 - val_loss: 0.5333 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 557/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2939 - acc: 0.8696 - auc_1: 0.9460 - val_loss: 0.5434 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 558/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2931 - acc: 0.8696 - auc_1: 0.9443 - val_loss: 0.5340 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 559/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2924 - acc: 0.8696 - auc_1: 0.9464 - val_loss: 0.5433 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 560/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2916 - acc: 0.8696 - auc_1: 0.9457 - val_loss: 0.5346 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 561/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.2909 - acc: 0.8587 - auc_1: 0.9476 - val_loss: 0.5433 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 562/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.2901 - acc: 0.8696 - auc_1: 0.9476 - val_loss: 0.5353 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 563/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.2893 - acc: 0.8587 - auc_1: 0.9483 - val_loss: 0.5435 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 564/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2886 - acc: 0.8696 - auc_1: 0.9488 - val_loss: 0.5359 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 565/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2878 - acc: 0.8587 - auc_1: 0.9490 - val_loss: 0.5437 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 566/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2870 - acc: 0.8696 - auc_1: 0.9493 - val_loss: 0.5366 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 567/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2862 - acc: 0.8587 - auc_1: 0.9495 - val_loss: 0.5439 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 568/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2854 - acc: 0.8696 - auc_1: 0.9505 - val_loss: 0.5373 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 569/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2846 - acc: 0.8587 - auc_1: 0.9498 - val_loss: 0.5443 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 570/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2839 - acc: 0.8696 - auc_1: 0.9507 - val_loss: 0.5380 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 571/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2831 - acc: 0.8587 - auc_1: 0.9498 - val_loss: 0.5447 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 572/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.2823 - acc: 0.8696 - auc_1: 0.9512 - val_loss: 0.5387 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 573/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.2815 - acc: 0.8696 - auc_1: 0.9514 - val_loss: 0.5452 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 574/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2807 - acc: 0.8696 - auc_1: 0.9519 - val_loss: 0.5395 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 575/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2799 - acc: 0.8696 - auc_1: 0.9526 - val_loss: 0.5457 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 576/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2791 - acc: 0.8696 - auc_1: 0.9526 - val_loss: 0.5402 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 577/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2783 - acc: 0.8696 - auc_1: 0.9536 - val_loss: 0.5463 - val_acc: 0.8333 - val_auc_1: 0.8786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2775 - acc: 0.8696 - auc_1: 0.9536 - val_loss: 0.5410 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 579/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2766 - acc: 0.8696 - auc_1: 0.9543 - val_loss: 0.5469 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 580/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2758 - acc: 0.8696 - auc_1: 0.9545 - val_loss: 0.5418 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 581/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2750 - acc: 0.8696 - auc_1: 0.9550 - val_loss: 0.5476 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 582/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.2742 - acc: 0.8696 - auc_1: 0.9548 - val_loss: 0.5426 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 583/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.2734 - acc: 0.8696 - auc_1: 0.9552 - val_loss: 0.5484 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 584/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2726 - acc: 0.8696 - auc_1: 0.9550 - val_loss: 0.5435 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 585/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2718 - acc: 0.8696 - auc_1: 0.9560 - val_loss: 0.5492 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 586/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2710 - acc: 0.8696 - auc_1: 0.9557 - val_loss: 0.5443 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 587/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2702 - acc: 0.8696 - auc_1: 0.9567 - val_loss: 0.5500 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 588/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2694 - acc: 0.8696 - auc_1: 0.9564 - val_loss: 0.5452 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 589/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2686 - acc: 0.8696 - auc_1: 0.9569 - val_loss: 0.5509 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 590/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2678 - acc: 0.8696 - auc_1: 0.9569 - val_loss: 0.5461 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 591/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2669 - acc: 0.8696 - auc_1: 0.9574 - val_loss: 0.5519 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 592/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2661 - acc: 0.8696 - auc_1: 0.9576 - val_loss: 0.5470 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 593/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2653 - acc: 0.8696 - auc_1: 0.9574 - val_loss: 0.5529 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 594/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.2645 - acc: 0.8696 - auc_1: 0.9581 - val_loss: 0.5480 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 595/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2637 - acc: 0.8696 - auc_1: 0.9595 - val_loss: 0.5539 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 596/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2630 - acc: 0.8696 - auc_1: 0.9595 - val_loss: 0.5489 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 597/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2622 - acc: 0.8696 - auc_1: 0.9602 - val_loss: 0.5550 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 598/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2614 - acc: 0.8804 - auc_1: 0.9605 - val_loss: 0.5499 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 599/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2606 - acc: 0.8696 - auc_1: 0.9610 - val_loss: 0.5561 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 600/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2598 - acc: 0.8804 - auc_1: 0.9610 - val_loss: 0.5509 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 601/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2590 - acc: 0.8804 - auc_1: 0.9617 - val_loss: 0.5573 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 602/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2582 - acc: 0.8804 - auc_1: 0.9617 - val_loss: 0.5519 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 603/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2575 - acc: 0.8804 - auc_1: 0.9621 - val_loss: 0.5586 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 604/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2567 - acc: 0.8696 - auc_1: 0.9624 - val_loss: 0.5529 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 605/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2559 - acc: 0.8804 - auc_1: 0.9633 - val_loss: 0.5599 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 606/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2552 - acc: 0.8696 - auc_1: 0.9631 - val_loss: 0.5539 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 607/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2544 - acc: 0.8804 - auc_1: 0.9636 - val_loss: 0.5613 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 608/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2536 - acc: 0.8587 - auc_1: 0.9648 - val_loss: 0.5549 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 609/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2529 - acc: 0.8804 - auc_1: 0.9643 - val_loss: 0.5627 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 610/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2521 - acc: 0.8587 - auc_1: 0.9650 - val_loss: 0.5559 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 611/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2514 - acc: 0.8804 - auc_1: 0.9652 - val_loss: 0.5642 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 612/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2507 - acc: 0.8587 - auc_1: 0.9652 - val_loss: 0.5568 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 613/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2499 - acc: 0.8804 - auc_1: 0.9652 - val_loss: 0.5658 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 614/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2492 - acc: 0.8587 - auc_1: 0.9655 - val_loss: 0.5578 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 615/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2485 - acc: 0.8913 - auc_1: 0.9655 - val_loss: 0.5675 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 616/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2477 - acc: 0.8587 - auc_1: 0.9657 - val_loss: 0.5587 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 617/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2470 - acc: 0.8913 - auc_1: 0.9660 - val_loss: 0.5693 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 618/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2463 - acc: 0.8587 - auc_1: 0.9657 - val_loss: 0.5596 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 619/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2456 - acc: 0.8913 - auc_1: 0.9667 - val_loss: 0.5713 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 620/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.2449 - acc: 0.8587 - auc_1: 0.9662 - val_loss: 0.5604 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 621/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2442 - acc: 0.8913 - auc_1: 0.9667 - val_loss: 0.5733 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 622/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2435 - acc: 0.8587 - auc_1: 0.9662 - val_loss: 0.5612 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 623/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2429 - acc: 0.9022 - auc_1: 0.9671 - val_loss: 0.5755 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 624/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2422 - acc: 0.8587 - auc_1: 0.9671 - val_loss: 0.5619 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 625/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2415 - acc: 0.9022 - auc_1: 0.9683 - val_loss: 0.5779 - val_acc: 0.8333 - val_auc_1: 0.8679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2409 - acc: 0.8587 - auc_1: 0.9671 - val_loss: 0.5625 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 627/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2402 - acc: 0.9022 - auc_1: 0.9695 - val_loss: 0.5804 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 628/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2396 - acc: 0.8587 - auc_1: 0.9674 - val_loss: 0.5631 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 629/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2390 - acc: 0.9022 - auc_1: 0.9698 - val_loss: 0.5831 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 630/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2384 - acc: 0.8696 - auc_1: 0.9681 - val_loss: 0.5636 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 631/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2378 - acc: 0.9022 - auc_1: 0.9700 - val_loss: 0.5859 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 632/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2372 - acc: 0.8696 - auc_1: 0.9683 - val_loss: 0.5641 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 633/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2366 - acc: 0.9022 - auc_1: 0.9705 - val_loss: 0.5887 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 634/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2360 - acc: 0.8696 - auc_1: 0.9688 - val_loss: 0.5647 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 635/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.2355 - acc: 0.9022 - auc_1: 0.9705 - val_loss: 0.5915 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 636/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2349 - acc: 0.8696 - auc_1: 0.9690 - val_loss: 0.5655 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 637/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2343 - acc: 0.9022 - auc_1: 0.9705 - val_loss: 0.5941 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 638/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2337 - acc: 0.8696 - auc_1: 0.9695 - val_loss: 0.5665 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 639/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2332 - acc: 0.9022 - auc_1: 0.9705 - val_loss: 0.5965 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 640/3000\n",
      "92/92 [==============================] - 0s 185us/step - loss: 0.2326 - acc: 0.8696 - auc_1: 0.9695 - val_loss: 0.5679 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 641/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2320 - acc: 0.9022 - auc_1: 0.9707 - val_loss: 0.5985 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 642/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2313 - acc: 0.8804 - auc_1: 0.9700 - val_loss: 0.5696 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 643/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2307 - acc: 0.9022 - auc_1: 0.9712 - val_loss: 0.6001 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 644/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2300 - acc: 0.8913 - auc_1: 0.9705 - val_loss: 0.5718 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 645/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2294 - acc: 0.9022 - auc_1: 0.9714 - val_loss: 0.6014 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 646/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2287 - acc: 0.8913 - auc_1: 0.9712 - val_loss: 0.5742 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 647/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2280 - acc: 0.8913 - auc_1: 0.9717 - val_loss: 0.6024 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 648/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2273 - acc: 0.8913 - auc_1: 0.9717 - val_loss: 0.5768 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 649/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2266 - acc: 0.8913 - auc_1: 0.9726 - val_loss: 0.6033 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 650/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2259 - acc: 0.8913 - auc_1: 0.9719 - val_loss: 0.5795 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 651/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2253 - acc: 0.8913 - auc_1: 0.9736 - val_loss: 0.6041 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 652/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2246 - acc: 0.8804 - auc_1: 0.9731 - val_loss: 0.5822 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 653/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2239 - acc: 0.8913 - auc_1: 0.9738 - val_loss: 0.6050 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 654/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2232 - acc: 0.8804 - auc_1: 0.9733 - val_loss: 0.5849 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 655/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2225 - acc: 0.8913 - auc_1: 0.9748 - val_loss: 0.6059 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 656/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2219 - acc: 0.8804 - auc_1: 0.9738 - val_loss: 0.5875 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 657/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2212 - acc: 0.9022 - auc_1: 0.9748 - val_loss: 0.6070 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 658/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2205 - acc: 0.8804 - auc_1: 0.9740 - val_loss: 0.5900 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 659/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.2199 - acc: 0.9022 - auc_1: 0.9752 - val_loss: 0.6082 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 660/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2193 - acc: 0.8804 - auc_1: 0.9748 - val_loss: 0.5924 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 661/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2186 - acc: 0.9022 - auc_1: 0.9760 - val_loss: 0.6096 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 662/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2180 - acc: 0.8804 - auc_1: 0.9748 - val_loss: 0.5947 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 663/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2174 - acc: 0.9022 - auc_1: 0.9767 - val_loss: 0.6110 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 664/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2168 - acc: 0.8804 - auc_1: 0.9752 - val_loss: 0.5968 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 665/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2161 - acc: 0.9022 - auc_1: 0.9771 - val_loss: 0.6126 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 666/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2155 - acc: 0.8804 - auc_1: 0.9757 - val_loss: 0.5989 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 667/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2149 - acc: 0.9022 - auc_1: 0.9774 - val_loss: 0.6142 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 668/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2143 - acc: 0.8804 - auc_1: 0.9762 - val_loss: 0.6008 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 669/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2137 - acc: 0.9022 - auc_1: 0.9774 - val_loss: 0.6160 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 670/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2131 - acc: 0.9022 - auc_1: 0.9767 - val_loss: 0.6025 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 671/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2125 - acc: 0.9022 - auc_1: 0.9779 - val_loss: 0.6178 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 672/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2119 - acc: 0.9022 - auc_1: 0.9769 - val_loss: 0.6041 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 673/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2113 - acc: 0.9022 - auc_1: 0.9774 - val_loss: 0.6197 - val_acc: 0.8333 - val_auc_1: 0.8607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 674/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2107 - acc: 0.9022 - auc_1: 0.9767 - val_loss: 0.6055 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 675/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2101 - acc: 0.9022 - auc_1: 0.9774 - val_loss: 0.6216 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 676/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2096 - acc: 0.9022 - auc_1: 0.9771 - val_loss: 0.6068 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 677/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2090 - acc: 0.9022 - auc_1: 0.9776 - val_loss: 0.6236 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 678/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2084 - acc: 0.9022 - auc_1: 0.9781 - val_loss: 0.6078 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 679/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2079 - acc: 0.9022 - auc_1: 0.9779 - val_loss: 0.6256 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 680/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2073 - acc: 0.9022 - auc_1: 0.9786 - val_loss: 0.6087 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 681/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.2068 - acc: 0.9022 - auc_1: 0.9779 - val_loss: 0.6277 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 682/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2062 - acc: 0.9022 - auc_1: 0.9790 - val_loss: 0.6094 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 683/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.2057 - acc: 0.9022 - auc_1: 0.9781 - val_loss: 0.6298 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 684/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2052 - acc: 0.9130 - auc_1: 0.9793 - val_loss: 0.6099 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 685/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2047 - acc: 0.9022 - auc_1: 0.9793 - val_loss: 0.6320 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 686/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2042 - acc: 0.9130 - auc_1: 0.9790 - val_loss: 0.6102 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 687/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2037 - acc: 0.9022 - auc_1: 0.9798 - val_loss: 0.6340 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 688/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.2032 - acc: 0.9130 - auc_1: 0.9802 - val_loss: 0.6104 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 689/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2028 - acc: 0.9022 - auc_1: 0.9802 - val_loss: 0.6360 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 690/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2023 - acc: 0.9130 - auc_1: 0.9800 - val_loss: 0.6106 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 691/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.2018 - acc: 0.9130 - auc_1: 0.9802 - val_loss: 0.6377 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 692/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2014 - acc: 0.9130 - auc_1: 0.9800 - val_loss: 0.6109 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 693/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2009 - acc: 0.9130 - auc_1: 0.9805 - val_loss: 0.6390 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 694/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.2004 - acc: 0.9130 - auc_1: 0.9800 - val_loss: 0.6114 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 695/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1999 - acc: 0.9130 - auc_1: 0.9812 - val_loss: 0.6399 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 696/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1994 - acc: 0.9239 - auc_1: 0.9802 - val_loss: 0.6120 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 697/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1988 - acc: 0.9130 - auc_1: 0.9812 - val_loss: 0.6403 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 698/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1982 - acc: 0.9239 - auc_1: 0.9805 - val_loss: 0.6128 - val_acc: 0.8333 - val_auc_1: 0.8536\n",
      "Epoch 699/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1976 - acc: 0.9130 - auc_1: 0.9812 - val_loss: 0.6402 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 700/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1970 - acc: 0.9239 - auc_1: 0.9805 - val_loss: 0.6137 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 701/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1964 - acc: 0.9130 - auc_1: 0.9817 - val_loss: 0.6399 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 702/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1958 - acc: 0.9239 - auc_1: 0.9805 - val_loss: 0.6147 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 703/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1951 - acc: 0.9130 - auc_1: 0.9817 - val_loss: 0.6393 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 704/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1945 - acc: 0.9239 - auc_1: 0.9807 - val_loss: 0.6157 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 705/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1938 - acc: 0.9130 - auc_1: 0.9819 - val_loss: 0.6386 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 706/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1932 - acc: 0.9239 - auc_1: 0.9814 - val_loss: 0.6166 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 707/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1926 - acc: 0.9130 - auc_1: 0.9821 - val_loss: 0.6379 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 708/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1920 - acc: 0.9239 - auc_1: 0.9812 - val_loss: 0.6173 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 709/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1913 - acc: 0.9130 - auc_1: 0.9826 - val_loss: 0.6373 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 710/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1907 - acc: 0.9239 - auc_1: 0.9817 - val_loss: 0.6179 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 711/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1902 - acc: 0.9130 - auc_1: 0.9831 - val_loss: 0.6368 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 712/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1896 - acc: 0.9239 - auc_1: 0.9817 - val_loss: 0.6184 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 713/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1890 - acc: 0.9130 - auc_1: 0.9831 - val_loss: 0.6365 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 714/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1885 - acc: 0.9239 - auc_1: 0.9821 - val_loss: 0.6187 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 715/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1879 - acc: 0.9130 - auc_1: 0.9831 - val_loss: 0.6364 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 716/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1874 - acc: 0.9239 - auc_1: 0.9826 - val_loss: 0.6189 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 717/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1868 - acc: 0.9130 - auc_1: 0.9838 - val_loss: 0.6364 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 718/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1863 - acc: 0.9239 - auc_1: 0.9826 - val_loss: 0.6189 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 719/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1858 - acc: 0.9130 - auc_1: 0.9838 - val_loss: 0.6366 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 720/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1853 - acc: 0.9239 - auc_1: 0.9836 - val_loss: 0.6188 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 721/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1848 - acc: 0.9130 - auc_1: 0.9840 - val_loss: 0.6371 - val_acc: 0.7917 - val_auc_1: 0.8643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 722/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1843 - acc: 0.9239 - auc_1: 0.9838 - val_loss: 0.6185 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 723/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1838 - acc: 0.9130 - auc_1: 0.9843 - val_loss: 0.6377 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 724/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1833 - acc: 0.9348 - auc_1: 0.9838 - val_loss: 0.6182 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 725/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1829 - acc: 0.9130 - auc_1: 0.9845 - val_loss: 0.6386 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 726/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1824 - acc: 0.9348 - auc_1: 0.9850 - val_loss: 0.6177 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 727/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1820 - acc: 0.9130 - auc_1: 0.9850 - val_loss: 0.6396 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 728/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1816 - acc: 0.9348 - auc_1: 0.9852 - val_loss: 0.6172 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 729/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.1811 - acc: 0.9130 - auc_1: 0.9857 - val_loss: 0.6409 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 730/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.1807 - acc: 0.9348 - auc_1: 0.9857 - val_loss: 0.6166 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 731/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1803 - acc: 0.9130 - auc_1: 0.9860 - val_loss: 0.6423 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 732/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.1799 - acc: 0.9348 - auc_1: 0.9857 - val_loss: 0.6160 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 733/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1796 - acc: 0.9130 - auc_1: 0.9862 - val_loss: 0.6438 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 734/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1792 - acc: 0.9348 - auc_1: 0.9860 - val_loss: 0.6155 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 735/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.1788 - acc: 0.9130 - auc_1: 0.9864 - val_loss: 0.6453 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 736/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1785 - acc: 0.9348 - auc_1: 0.9862 - val_loss: 0.6152 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 737/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1781 - acc: 0.9130 - auc_1: 0.9867 - val_loss: 0.6467 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 738/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.1777 - acc: 0.9348 - auc_1: 0.9871 - val_loss: 0.6151 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 739/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1774 - acc: 0.9130 - auc_1: 0.9867 - val_loss: 0.6479 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 740/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.1770 - acc: 0.9348 - auc_1: 0.9871 - val_loss: 0.6154 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 741/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1766 - acc: 0.9130 - auc_1: 0.9864 - val_loss: 0.6487 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 742/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1762 - acc: 0.9348 - auc_1: 0.9874 - val_loss: 0.6160 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 743/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1758 - acc: 0.9130 - auc_1: 0.9864 - val_loss: 0.6492 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 744/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.1753 - acc: 0.9348 - auc_1: 0.9874 - val_loss: 0.6169 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 745/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1748 - acc: 0.9130 - auc_1: 0.9864 - val_loss: 0.6494 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 746/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1743 - acc: 0.9348 - auc_1: 0.9876 - val_loss: 0.6180 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 747/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1739 - acc: 0.9130 - auc_1: 0.9869 - val_loss: 0.6493 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 748/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1733 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 0.6192 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 749/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1728 - acc: 0.9239 - auc_1: 0.9871 - val_loss: 0.6492 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 750/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1723 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 0.6205 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 751/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1718 - acc: 0.9239 - auc_1: 0.9871 - val_loss: 0.6490 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 752/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1713 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 0.6217 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 753/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1708 - acc: 0.9239 - auc_1: 0.9879 - val_loss: 0.6489 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 754/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1703 - acc: 0.9348 - auc_1: 0.9886 - val_loss: 0.6229 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 755/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1698 - acc: 0.9239 - auc_1: 0.9879 - val_loss: 0.6489 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 756/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1693 - acc: 0.9348 - auc_1: 0.9888 - val_loss: 0.6241 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 757/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1688 - acc: 0.9239 - auc_1: 0.9881 - val_loss: 0.6490 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 758/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1683 - acc: 0.9348 - auc_1: 0.9888 - val_loss: 0.6251 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 759/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1679 - acc: 0.9239 - auc_1: 0.9883 - val_loss: 0.6492 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 760/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1674 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 0.6260 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 761/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1669 - acc: 0.9239 - auc_1: 0.9883 - val_loss: 0.6497 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 762/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1665 - acc: 0.9457 - auc_1: 0.9893 - val_loss: 0.6269 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 763/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1660 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 0.6503 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 764/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1656 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 0.6277 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 765/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1652 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 0.6510 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 766/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1648 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 0.6283 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 767/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1644 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 0.6519 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 768/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1639 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 0.6290 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 769/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1635 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 0.6529 - val_acc: 0.7917 - val_auc_1: 0.8536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1631 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 0.6295 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 771/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1628 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 0.6541 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 772/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1624 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 0.6299 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 773/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1620 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 0.6554 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 774/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1616 - acc: 0.9457 - auc_1: 0.9898 - val_loss: 0.6304 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 775/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1613 - acc: 0.9348 - auc_1: 0.9886 - val_loss: 0.6568 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 776/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1609 - acc: 0.9457 - auc_1: 0.9895 - val_loss: 0.6307 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 777/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1606 - acc: 0.9348 - auc_1: 0.9888 - val_loss: 0.6582 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 778/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1602 - acc: 0.9457 - auc_1: 0.9898 - val_loss: 0.6311 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 779/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1599 - acc: 0.9348 - auc_1: 0.9888 - val_loss: 0.6597 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 780/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1595 - acc: 0.9457 - auc_1: 0.9898 - val_loss: 0.6315 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 781/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1592 - acc: 0.9348 - auc_1: 0.9888 - val_loss: 0.6612 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 782/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1588 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.6319 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 783/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1585 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 0.6627 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 784/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1581 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.6324 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 785/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1578 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 0.6640 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 786/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1574 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.6330 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 787/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1571 - acc: 0.9348 - auc_1: 0.9895 - val_loss: 0.6652 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 788/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1566 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6337 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 789/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1563 - acc: 0.9348 - auc_1: 0.9895 - val_loss: 0.6662 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 790/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1559 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6346 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 791/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1555 - acc: 0.9348 - auc_1: 0.9895 - val_loss: 0.6670 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 792/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1551 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6356 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 793/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1547 - acc: 0.9348 - auc_1: 0.9895 - val_loss: 0.6677 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 794/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1542 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6366 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 795/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1538 - acc: 0.9348 - auc_1: 0.9895 - val_loss: 0.6683 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 796/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1534 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6378 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 797/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1530 - acc: 0.9348 - auc_1: 0.9895 - val_loss: 0.6687 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 798/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1525 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6389 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 799/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1521 - acc: 0.9457 - auc_1: 0.9898 - val_loss: 0.6691 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 800/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1516 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6401 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 801/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1512 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.6695 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 802/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1507 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6413 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 803/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1503 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.6699 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 804/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1499 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6424 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 805/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1495 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.6704 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 806/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1490 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6434 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 807/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1486 - acc: 0.9457 - auc_1: 0.9902 - val_loss: 0.6709 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 808/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1482 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6444 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 809/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1478 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6715 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 810/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1473 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6453 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 811/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1470 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6721 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 812/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1465 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6461 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 813/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1462 - acc: 0.9457 - auc_1: 0.9910 - val_loss: 0.6728 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 814/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1457 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6469 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 815/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1454 - acc: 0.9457 - auc_1: 0.9910 - val_loss: 0.6736 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 816/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1450 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 0.6475 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 817/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1446 - acc: 0.9457 - auc_1: 0.9910 - val_loss: 0.6745 - val_acc: 0.7917 - val_auc_1: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 818/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1442 - acc: 0.9457 - auc_1: 0.9910 - val_loss: 0.6481 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 819/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1438 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 0.6754 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 820/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1434 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.6487 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 821/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1431 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.6763 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 822/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1427 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 0.6491 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 823/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1424 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 0.6774 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 824/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1420 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 0.6495 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 825/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1416 - acc: 0.9565 - auc_1: 0.9917 - val_loss: 0.6784 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 826/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1413 - acc: 0.9457 - auc_1: 0.9917 - val_loss: 0.6499 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 827/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1409 - acc: 0.9565 - auc_1: 0.9917 - val_loss: 0.6794 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 828/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1405 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.6503 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 829/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1402 - acc: 0.9565 - auc_1: 0.9919 - val_loss: 0.6805 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 830/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1398 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.6506 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 831/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1395 - acc: 0.9565 - auc_1: 0.9919 - val_loss: 0.6815 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 832/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1391 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 0.6509 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 833/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1388 - acc: 0.9565 - auc_1: 0.9921 - val_loss: 0.6824 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 834/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.1384 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 0.6513 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 835/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1381 - acc: 0.9565 - auc_1: 0.9926 - val_loss: 0.6833 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 836/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1377 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 0.6517 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 837/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1374 - acc: 0.9565 - auc_1: 0.9926 - val_loss: 0.6842 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 838/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1370 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 0.6521 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 839/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1367 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 0.6849 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 840/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1362 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 0.6526 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 841/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1359 - acc: 0.9565 - auc_1: 0.9931 - val_loss: 0.6855 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 842/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1355 - acc: 0.9457 - auc_1: 0.9926 - val_loss: 0.6531 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 843/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1352 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 0.6860 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 844/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1347 - acc: 0.9457 - auc_1: 0.9926 - val_loss: 0.6536 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 845/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1344 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 0.6865 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 846/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.1340 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 0.6542 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 847/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.1336 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 0.6868 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 848/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1332 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 0.6549 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 849/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1328 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 0.6871 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 850/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1324 - acc: 0.9457 - auc_1: 0.9933 - val_loss: 0.6555 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 851/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1320 - acc: 0.9565 - auc_1: 0.9936 - val_loss: 0.6873 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 852/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1316 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.6562 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 853/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1313 - acc: 0.9565 - auc_1: 0.9936 - val_loss: 0.6875 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 854/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1308 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.6568 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 855/3000\n",
      "92/92 [==============================] - 0s 185us/step - loss: 0.1305 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 0.6877 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 856/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1301 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.6574 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 857/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1297 - acc: 0.9565 - auc_1: 0.9945 - val_loss: 0.6879 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 858/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1293 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.6580 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 859/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1289 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.6881 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 860/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1285 - acc: 0.9565 - auc_1: 0.9940 - val_loss: 0.6586 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 861/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1282 - acc: 0.9565 - auc_1: 0.9950 - val_loss: 0.6883 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 862/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1278 - acc: 0.9565 - auc_1: 0.9943 - val_loss: 0.6591 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 863/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1274 - acc: 0.9565 - auc_1: 0.9955 - val_loss: 0.6885 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 864/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1270 - acc: 0.9565 - auc_1: 0.9945 - val_loss: 0.6596 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 865/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1267 - acc: 0.9565 - auc_1: 0.9955 - val_loss: 0.6888 - val_acc: 0.7917 - val_auc_1: 0.8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 866/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1263 - acc: 0.9565 - auc_1: 0.9945 - val_loss: 0.6600 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 867/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1259 - acc: 0.9565 - auc_1: 0.9955 - val_loss: 0.6891 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 868/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1255 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.6604 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 869/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.1252 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 0.6894 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 870/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1248 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.6607 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 871/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1245 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 0.6897 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 872/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1241 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.6610 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 873/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1238 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.6901 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 874/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.1234 - acc: 0.9674 - auc_1: 0.9955 - val_loss: 0.6613 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 875/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1231 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.6905 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 876/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1227 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6615 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 877/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1224 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.6909 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 878/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1220 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6616 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 879/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1217 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.6914 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 880/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1213 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6618 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 881/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1210 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6918 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 882/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1206 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6619 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 883/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1203 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6923 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 884/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1200 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6620 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 885/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1197 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6928 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 886/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1193 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6621 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 887/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1190 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6932 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 888/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1186 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6622 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 889/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1183 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6937 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 890/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1180 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6622 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 891/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1177 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6941 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 892/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1173 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6624 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 893/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1170 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6945 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 894/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1167 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6625 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 895/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1164 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6948 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 896/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1160 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6626 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 897/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1157 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6952 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 898/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1153 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6628 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 899/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1150 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6955 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 900/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1147 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6630 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 901/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1144 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6957 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 902/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1140 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6632 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 903/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.1137 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6959 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 904/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1133 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6635 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 905/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.1130 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6961 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 906/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1127 - acc: 0.9674 - auc_1: 0.9957 - val_loss: 0.6638 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 907/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1123 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.6962 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 908/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1120 - acc: 0.9674 - auc_1: 0.9960 - val_loss: 0.6641 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 909/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.1117 - acc: 0.9674 - auc_1: 0.9969 - val_loss: 0.6964 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 910/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1113 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.6645 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 911/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1110 - acc: 0.9674 - auc_1: 0.9969 - val_loss: 0.6965 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 912/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1106 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.6648 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 913/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1103 - acc: 0.9674 - auc_1: 0.9969 - val_loss: 0.6965 - val_acc: 0.7917 - val_auc_1: 0.8857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1100 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.6652 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 915/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1097 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.6966 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 916/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1093 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 0.6656 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 917/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1090 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.6966 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 918/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1086 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 0.6660 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 919/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1083 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.6967 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 920/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1080 - acc: 0.9783 - auc_1: 0.9964 - val_loss: 0.6665 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 921/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1077 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.6968 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 922/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1073 - acc: 0.9783 - auc_1: 0.9964 - val_loss: 0.6669 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 923/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1070 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.6968 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 924/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1067 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.6673 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 925/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1064 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.6969 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 926/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1060 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.6677 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 927/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1057 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.6970 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 928/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1054 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.6681 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 929/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1051 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.6971 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 930/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1048 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.6684 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 931/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1044 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 0.6972 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 932/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1041 - acc: 0.9783 - auc_1: 0.9969 - val_loss: 0.6688 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 933/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1038 - acc: 0.9674 - auc_1: 0.9979 - val_loss: 0.6973 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 934/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1035 - acc: 0.9783 - auc_1: 0.9969 - val_loss: 0.6692 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 935/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.1032 - acc: 0.9674 - auc_1: 0.9979 - val_loss: 0.6975 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 936/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1029 - acc: 0.9783 - auc_1: 0.9969 - val_loss: 0.6695 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 937/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1026 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.6977 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 938/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1023 - acc: 0.9783 - auc_1: 0.9969 - val_loss: 0.6698 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 939/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.1020 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.6979 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 940/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1016 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 0.6701 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 941/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.1013 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.6981 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 942/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1010 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 0.6704 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 943/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.1007 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.6983 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 944/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1004 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.6707 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 945/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.1001 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.6985 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 946/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0998 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.6709 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 947/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0995 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.6988 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 948/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0992 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.6712 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 949/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0989 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.6991 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 950/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0986 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.6714 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 951/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0984 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.6993 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 952/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0981 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.6717 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 953/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0978 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.6996 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 954/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0975 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 0.6719 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 955/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0972 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.6999 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 956/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0969 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6721 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 957/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0966 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.7002 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 958/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0963 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6724 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 959/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0960 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.7005 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 960/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0957 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6726 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 961/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0955 - acc: 0.9783 - auc_1: 0.9983 - val_loss: 0.7007 - val_acc: 0.7917 - val_auc_1: 0.9071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0952 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6728 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 963/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0949 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7010 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 964/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0946 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6730 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 965/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0943 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7013 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 966/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0940 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6732 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 967/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0938 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7015 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 968/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0935 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6735 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 969/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0932 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7018 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 970/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0929 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6737 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 971/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0926 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7020 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 972/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0923 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6739 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 973/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0921 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7022 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 974/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0918 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6742 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 975/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0915 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7024 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 976/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0912 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6744 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 977/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0909 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7025 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 978/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0907 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6747 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 979/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0904 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7027 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 980/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0901 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6750 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 981/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0898 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.7028 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 982/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0896 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6753 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 983/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0893 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7029 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 984/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0890 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6755 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 985/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0887 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7029 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 986/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0884 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6758 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 987/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0882 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7030 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 988/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0879 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6761 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 989/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0876 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7030 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 990/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0873 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6764 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 991/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0871 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7030 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 992/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0868 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6767 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 993/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0865 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7030 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 994/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0863 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6770 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 995/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0860 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7030 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 996/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0857 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6773 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 997/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0854 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7030 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 998/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0852 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6776 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 999/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0849 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7029 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1000/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0846 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6779 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1001/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0844 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7028 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1002/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0841 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6782 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1003/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0838 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7028 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1004/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0836 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6785 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1005/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0833 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7027 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1006/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0830 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6788 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1007/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0828 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.7026 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1008/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0825 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6790 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1009/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0823 - acc: 0.9891 - auc_1: 0.9988 - val_loss: 0.7024 - val_acc: 0.7917 - val_auc_1: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1010/3000\n",
      "92/92 [==============================] - 0s 185us/step - loss: 0.0820 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6793 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1011/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0817 - acc: 0.9891 - auc_1: 0.9988 - val_loss: 0.7023 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1012/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0815 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6795 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1013/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0812 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7022 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1014/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0810 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6797 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1015/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0807 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7020 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1016/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0804 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6799 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1017/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0802 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7019 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1018/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0799 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6801 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1019/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0797 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7017 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1020/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0794 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6803 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1021/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0792 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7016 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1022/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0789 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6804 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1023/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0787 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7014 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1024/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0784 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6806 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1025/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0782 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7012 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1026/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0779 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6807 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1027/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0777 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7010 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1028/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0774 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6808 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1029/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0772 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7008 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1030/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0769 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.6808 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1031/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0767 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7006 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1032/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0764 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6809 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1033/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0762 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7004 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1034/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0759 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6809 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1035/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0757 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7001 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1036/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0754 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6810 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1037/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0752 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6999 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1038/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0750 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6810 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1039/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0747 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6997 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1040/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0745 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6810 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1041/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0742 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6994 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1042/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0740 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6809 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1043/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0738 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6991 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1044/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0735 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6809 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1045/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0733 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6989 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1046/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0731 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6808 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1047/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0728 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6986 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1048/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0726 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6807 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1049/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0724 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6983 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1050/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0721 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6806 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 1051/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0719 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6980 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1052/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0717 - acc: 0.9891 - auc_1: 0.9988 - val_loss: 0.6805 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1053/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0714 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6977 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1054/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0712 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6804 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1055/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0710 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6973 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1056/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0707 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6803 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1057/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0705 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6970 - val_acc: 0.7917 - val_auc_1: 0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1058/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0703 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6801 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1059/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0701 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6966 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1060/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0698 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6800 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1061/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0696 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6963 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1062/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0694 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6798 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1063/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0692 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6959 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1064/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0689 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6796 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1065/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0687 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6955 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1066/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0685 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6794 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1067/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0683 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6951 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1068/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0680 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6792 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1069/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0678 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6947 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1070/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0676 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6790 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1071/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0674 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6943 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1072/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0672 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6788 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 1073/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0669 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6938 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1074/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0667 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6786 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1075/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0665 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6934 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1076/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0663 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6784 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1077/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0661 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6929 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 1078/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0659 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6781 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1079/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0656 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6925 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 1080/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0654 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6779 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1081/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0652 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6920 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 1082/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0650 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6777 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1083/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0648 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6915 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 1084/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0646 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6774 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1085/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0644 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6910 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 1086/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0642 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6772 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 1087/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0640 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6905 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1088/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0637 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6769 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 1089/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0635 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6899 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1090/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0633 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6767 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 1091/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0631 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6894 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1092/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0629 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6764 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1093/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0627 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6889 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1094/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0625 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6762 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1095/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0623 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6883 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1096/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0621 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6759 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1097/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0619 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6878 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1098/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0617 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6756 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1099/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0615 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6872 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1100/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0613 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6754 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1101/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0611 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6866 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1102/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0609 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6751 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1103/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0607 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6860 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1104/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0605 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6749 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1105/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0603 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6855 - val_acc: 0.7917 - val_auc_1: 0.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1106/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0601 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6746 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1107/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0599 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6849 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1108/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0597 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6744 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1109/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0595 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6843 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1110/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0593 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6741 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1111/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0591 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6837 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1112/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0589 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6739 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1113/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0587 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6831 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1114/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0586 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6737 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1115/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0584 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6825 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1116/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0582 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6734 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 1117/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0580 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6819 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1118/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0578 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6732 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 1119/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0576 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6813 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1120/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0574 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6729 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 1121/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0572 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6807 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 1122/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0571 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6727 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 1123/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0569 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6801 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 1124/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0567 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6725 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 1125/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0565 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6796 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 1126/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0563 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6722 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 1127/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0561 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6790 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 1128/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0560 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6720 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 1129/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0558 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6784 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 1130/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0556 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6718 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 1131/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0554 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6778 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 1132/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0553 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6716 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 1133/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0551 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6773 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 1134/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0549 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6714 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 1135/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0547 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6767 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 1136/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0546 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6711 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 1137/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0544 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6762 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 1138/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0542 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.6709 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 1139/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0540 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6756 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1140/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0539 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 0.6707 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1141/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0537 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6751 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1142/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0535 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 0.6705 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1143/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0534 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6746 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1144/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0532 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6703 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1145/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0530 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6741 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1146/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0529 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6701 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1147/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0527 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6736 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1148/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0525 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6699 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1149/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0524 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6731 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1150/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0522 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6697 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1151/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0520 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6726 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1152/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0519 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6695 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1153/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0517 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6721 - val_acc: 0.7500 - val_auc_1: 0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1154/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0515 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6693 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1155/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0514 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6717 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1156/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0512 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6691 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1157/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0511 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6713 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1158/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0509 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6689 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1159/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0508 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6709 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1160/3000\n",
      "92/92 [==============================] - 0s 196us/step - loss: 0.0506 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6687 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 1161/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0504 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6704 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1162/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0503 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6685 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1163/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0501 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6701 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1164/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0500 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6683 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1165/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0498 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6697 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1166/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0497 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6681 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1167/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0495 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6693 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1168/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0494 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6679 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1169/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0492 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6690 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1170/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0491 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6677 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1171/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0489 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6687 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1172/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0488 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6675 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1173/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0486 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6683 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1174/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0485 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6673 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1175/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0483 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6680 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1176/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0482 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6672 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 1177/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0481 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6678 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1178/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0479 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6670 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1179/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0478 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6675 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1180/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0476 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6668 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1181/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0475 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6672 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1182/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0473 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6666 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1183/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0472 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6670 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1184/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0471 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6665 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1185/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0469 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6667 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1186/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0468 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6663 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1187/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0466 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6665 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1188/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0465 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6661 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1189/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0464 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6663 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1190/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0462 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6660 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1191/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0461 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6661 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1192/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0460 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6658 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1193/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0458 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6659 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1194/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0457 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6656 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 1195/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0456 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6657 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 1196/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0454 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6655 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 1197/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0453 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6655 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1198/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0452 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6654 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1199/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0450 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6654 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1200/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0449 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6652 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1201/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0448 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6652 - val_acc: 0.7917 - val_auc_1: 0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1202/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0447 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6651 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1203/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0445 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6651 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1204/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0444 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6649 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1205/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0443 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6649 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1206/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0441 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6648 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1207/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0440 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6648 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1208/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0439 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6647 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1209/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0438 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6647 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1210/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0436 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6646 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1211/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0435 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6645 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1212/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0434 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6644 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1213/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0433 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6644 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1214/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0432 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6643 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1215/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0430 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6643 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1216/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0429 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6642 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1217/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0428 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6642 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1218/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0427 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6641 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1219/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0426 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6641 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1220/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0424 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6640 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1221/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0423 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6640 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1222/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0422 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6639 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1223/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0421 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6639 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1224/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0420 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6638 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1225/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0419 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6638 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1226/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0417 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6637 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1227/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0416 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6637 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1228/3000\n",
      "92/92 [==============================] - 0s 185us/step - loss: 0.0415 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6636 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1229/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0414 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6636 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1230/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0413 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6635 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1231/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0412 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6635 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1232/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0411 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6634 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1233/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0410 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6634 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1234/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0408 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6633 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1235/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0407 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6633 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1236/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0406 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6632 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1237/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0405 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6632 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1238/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0404 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6631 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1239/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0403 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6631 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1240/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0402 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6631 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1241/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0401 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6630 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1242/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0400 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6630 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1243/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0399 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6629 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1244/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0398 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6629 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1245/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0397 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6628 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1246/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0395 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6628 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1247/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0394 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6627 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1248/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0393 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6627 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1249/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0392 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6626 - val_acc: 0.7917 - val_auc_1: 0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1250/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0391 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6626 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1251/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0390 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6625 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1252/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0389 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6625 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1253/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0388 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6624 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1254/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0387 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6624 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1255/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0386 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6623 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1256/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0385 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6623 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1257/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0384 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6622 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1258/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0383 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6622 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1259/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0382 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6621 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1260/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0381 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6621 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1261/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0380 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6620 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1262/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0379 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6620 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1263/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0378 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6619 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1264/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0377 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6618 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1265/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0376 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6618 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1266/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0375 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6617 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1267/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0374 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6617 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1268/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0373 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6616 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1269/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0372 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6615 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1270/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0371 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6615 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1271/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0370 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6614 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1272/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0369 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6613 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1273/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0368 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6613 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1274/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0367 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6612 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1275/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0366 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6611 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1276/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0366 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6610 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1277/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0365 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6610 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1278/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0364 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6609 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1279/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0363 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6608 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1280/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0362 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6607 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1281/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0361 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6606 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 1282/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0360 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6606 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1283/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0359 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6605 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 1284/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0358 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6604 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1285/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0357 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6603 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1286/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0356 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6602 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1287/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0355 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6601 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1288/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0354 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6600 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1289/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0353 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6599 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1290/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0352 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6598 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1291/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0352 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6597 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1292/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0351 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6596 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1293/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0350 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6595 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1294/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0349 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6594 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1295/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0348 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6593 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1296/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0347 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6592 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1297/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0346 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6591 - val_acc: 0.7917 - val_auc_1: 0.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1298/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0345 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6589 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1299/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0344 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6588 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1300/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0343 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6587 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1301/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0342 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6586 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1302/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0341 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6584 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1303/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0340 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6583 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1304/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0340 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6582 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1305/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0339 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6580 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 1306/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0338 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6579 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1307/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0337 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6577 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1308/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0336 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6576 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1309/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0335 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6575 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1310/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0334 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6573 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1311/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0333 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6572 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1312/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0332 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6570 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1313/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0331 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6568 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1314/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0330 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6567 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1315/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0329 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6565 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1316/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0328 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6564 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1317/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0328 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6562 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1318/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0327 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6560 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1319/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0326 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6558 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1320/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0325 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6557 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1321/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0324 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6555 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1322/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0323 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6553 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1323/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0322 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6551 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1324/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0321 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6550 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1325/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0320 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 0.6548 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1326/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0319 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6546 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1327/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0318 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6544 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1328/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0317 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6542 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1329/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0316 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6540 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1330/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0315 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6539 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1331/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0314 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6537 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1332/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0313 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6535 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 1333/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0312 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6533 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 1334/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0311 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6531 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 1335/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0310 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6530 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1336/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0309 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6528 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1337/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0308 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6526 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1338/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0307 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6525 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1339/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0305 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6523 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1340/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0304 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6522 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1341/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0303 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6520 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1342/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0302 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6519 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1343/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0301 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6518 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1344/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0300 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6517 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1345/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0299 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6516 - val_acc: 0.7917 - val_auc_1: 0.9393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1346/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0298 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6515 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1347/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0297 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6514 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1348/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0295 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6513 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1349/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0294 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6513 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1350/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0293 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6512 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1351/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0292 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6512 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1352/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0291 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6512 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1353/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0289 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6512 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1354/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0288 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6513 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1355/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0287 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6513 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1356/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0286 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6514 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1357/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0285 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6515 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1358/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0283 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6516 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1359/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0282 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6517 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1360/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0281 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6518 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1361/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0280 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6520 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1362/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0279 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6522 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1363/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0277 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6524 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1364/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0276 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6527 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1365/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0275 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6529 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1366/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0274 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6532 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1367/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0272 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6535 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1368/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0271 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6538 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1369/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0270 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6541 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1370/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0269 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6545 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1371/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0267 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6549 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1372/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0266 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6553 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1373/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0265 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6557 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1374/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0264 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6561 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1375/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0262 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6566 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1376/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0261 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6570 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1377/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0260 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6575 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1378/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0259 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6580 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1379/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0258 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6585 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1380/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0256 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6591 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1381/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0255 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6596 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1382/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0254 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6602 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1383/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0253 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6608 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1384/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0252 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6614 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1385/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0250 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6620 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1386/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0249 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6626 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1387/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0248 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6632 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1388/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0247 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6639 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1389/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0246 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6646 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1390/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0245 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6653 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1391/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0243 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6660 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1392/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0242 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6667 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1393/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0241 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6674 - val_acc: 0.7917 - val_auc_1: 0.9393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1394/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0240 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6681 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1395/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0239 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6689 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1396/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0238 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6696 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1397/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0237 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6704 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1398/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0236 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6712 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 1399/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0234 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6720 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 1400/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0233 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6728 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1401/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0232 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6736 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1402/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0231 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6744 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1403/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0230 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6753 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1404/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0229 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6761 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1405/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0228 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6770 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1406/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0227 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6779 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1407/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0226 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6787 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1408/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0225 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6796 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1409/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0224 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6805 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1410/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0223 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6815 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1411/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0222 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6824 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1412/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0221 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6833 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1413/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0220 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6843 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1414/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0218 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6852 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1415/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0217 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6862 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 1416/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0216 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6872 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 1417/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0215 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6881 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1418/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0214 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6891 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1419/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0213 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6901 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1420/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0213 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6911 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1421/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0212 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6922 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1422/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0211 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6932 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1423/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0210 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6942 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1424/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0209 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6953 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1425/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0208 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6963 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1426/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0207 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6974 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1427/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0206 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6984 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1428/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0205 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6995 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1429/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0204 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7006 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1430/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0203 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7017 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1431/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0202 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7028 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1432/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0201 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7039 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1433/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0200 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7050 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1434/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0199 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7061 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1435/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0198 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7072 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1436/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0198 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7084 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1437/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0197 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7095 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1438/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0196 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7107 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1439/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0195 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7118 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1440/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0194 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7130 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1441/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0193 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7141 - val_acc: 0.7917 - val_auc_1: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1442/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0192 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7153 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1443/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0191 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7165 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1444/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0191 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7177 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1445/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0190 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7189 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1446/3000\n",
      "92/92 [==============================] - 0s 218us/step - loss: 0.0189 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7200 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1447/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0188 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7212 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1448/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0187 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7224 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1449/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0186 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7236 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1450/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0186 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7249 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1451/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0185 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7261 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1452/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0184 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7273 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1453/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0183 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7285 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1454/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0182 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7297 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1455/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0182 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7310 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1456/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0181 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7322 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1457/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0180 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7334 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 1458/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0179 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7346 - val_acc: 0.7500 - val_auc_1: 0.9286\n",
      "Epoch 1459/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0179 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7359 - val_acc: 0.7500 - val_auc_1: 0.9286\n",
      "Epoch 1460/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0178 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7371 - val_acc: 0.7500 - val_auc_1: 0.9286\n",
      "Epoch 1461/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0177 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7384 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 1462/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0176 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7396 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1463/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0175 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7408 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1464/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0175 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7421 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1465/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0174 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7433 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1466/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0173 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7446 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1467/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0172 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7458 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 1468/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0172 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7470 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1469/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0171 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7483 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1470/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0170 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7495 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1471/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0170 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7508 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1472/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0169 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7520 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1473/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0168 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7532 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1474/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0167 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7545 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1475/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0167 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7557 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1476/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0166 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7570 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1477/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0165 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7582 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1478/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0165 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7594 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1479/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0164 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7606 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1480/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0163 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7619 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1481/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0163 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7631 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1482/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0162 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7643 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1483/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0161 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7655 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1484/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0161 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7667 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1485/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0160 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7679 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1486/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0159 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7692 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1487/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0159 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7704 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1488/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0158 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7716 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1489/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0157 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7727 - val_acc: 0.7083 - val_auc_1: 0.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1490/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0157 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7739 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1491/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0156 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7751 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1492/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0155 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7763 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1493/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0155 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7775 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1494/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0154 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7787 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1495/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0154 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7798 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1496/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0153 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7810 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1497/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0152 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7822 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1498/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0152 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7833 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1499/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0151 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7845 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1500/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0150 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7856 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1501/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0150 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7868 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1502/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0149 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7879 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1503/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0149 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7890 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1504/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0148 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7902 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1505/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0147 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7913 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1506/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0147 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7924 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1507/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0146 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7935 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1508/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0146 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7946 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1509/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0145 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7957 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1510/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0145 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7968 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1511/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0144 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7979 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1512/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0143 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7990 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1513/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0143 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8001 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1514/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0142 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8012 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1515/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0142 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8023 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1516/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0141 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8033 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1517/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0141 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8044 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1518/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0140 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8054 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1519/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0139 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8065 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1520/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0139 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8076 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1521/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0138 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8086 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1522/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0138 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8096 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1523/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0137 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8107 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1524/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0137 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8117 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1525/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0136 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8127 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1526/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0136 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8137 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1527/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0135 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8148 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1528/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0135 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8158 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1529/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0134 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8168 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1530/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0134 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8178 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1531/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0133 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8188 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1532/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0133 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8198 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1533/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0132 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8207 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1534/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0132 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8217 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1535/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0131 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8227 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1536/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0131 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8237 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1537/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0130 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8246 - val_acc: 0.7083 - val_auc_1: 0.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1538/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0130 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8256 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1539/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0129 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8266 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1540/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0129 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8275 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1541/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0128 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8285 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1542/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0128 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8294 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1543/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0127 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8303 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1544/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0127 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8313 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1545/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0126 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8322 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1546/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0126 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8331 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1547/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0125 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8341 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1548/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0125 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8350 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1549/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8359 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1550/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8368 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1551/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0123 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8377 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1552/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0123 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8386 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1553/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8395 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1554/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8404 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1555/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8413 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1556/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0121 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8422 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1557/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0121 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8431 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1558/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0120 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8440 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1559/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0120 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8448 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1560/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0119 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8457 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1561/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0119 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8466 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1562/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0118 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8475 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1563/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0118 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8483 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1564/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0118 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8492 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1565/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0117 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8500 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1566/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0117 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8509 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1567/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0116 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8517 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1568/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0116 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8526 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1569/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0115 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8534 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1570/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0115 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8543 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1571/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0115 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8551 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1572/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0114 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8559 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1573/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0114 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8568 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1574/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0113 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8576 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1575/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0113 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8584 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1576/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0113 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8592 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1577/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0112 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8600 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1578/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0112 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8609 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1579/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0111 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8617 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1580/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0111 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8625 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1581/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0111 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8633 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1582/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0110 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8641 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1583/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0110 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8649 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1584/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0109 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8657 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1585/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0109 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8665 - val_acc: 0.7083 - val_auc_1: 0.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1586/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0109 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8673 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1587/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0108 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8680 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1588/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0108 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8688 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1589/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8696 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1590/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8704 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1591/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8712 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1592/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0106 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8719 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1593/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0106 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8727 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1594/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0106 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8735 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1595/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0105 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8742 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1596/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0105 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8750 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1597/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0104 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8757 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1598/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0104 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8765 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1599/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0104 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8772 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1600/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0103 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8780 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1601/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0103 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8787 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1602/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0103 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8795 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1603/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0102 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8802 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1604/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0102 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8810 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1605/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8817 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1606/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8824 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1607/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8832 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1608/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0100 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8839 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1609/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0100 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8846 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1610/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0100 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8853 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1611/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8861 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1612/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8868 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1613/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8875 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1614/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0098 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8882 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1615/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0098 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8889 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1616/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0098 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8896 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1617/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8903 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1618/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8910 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1619/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8917 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1620/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8924 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1621/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8931 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1622/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8938 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1623/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8945 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1624/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8952 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1625/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8958 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1626/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0094 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8965 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1627/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0094 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8972 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1628/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0094 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8979 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1629/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0093 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8985 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1630/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0093 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8992 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1631/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0093 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8999 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1632/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0092 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9005 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1633/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0092 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9012 - val_acc: 0.7083 - val_auc_1: 0.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1634/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0092 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9019 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1635/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0092 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9025 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1636/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9032 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1637/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9038 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1638/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9045 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1639/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9051 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1640/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9058 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1641/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9064 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1642/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9070 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1643/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9077 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 1644/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9083 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1645/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0088 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9089 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1646/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0088 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9096 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1647/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0088 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9102 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1648/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0088 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9108 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1649/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9114 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1650/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9120 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1651/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9126 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1652/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9133 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1653/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9139 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1654/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9145 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1655/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9151 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1656/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9157 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1657/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9163 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1658/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9169 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1659/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9174 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1660/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9180 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1661/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9186 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1662/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9192 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1663/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9198 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1664/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9204 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1665/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9209 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1666/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9215 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1667/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9221 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1668/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9226 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1669/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9232 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1670/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9238 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1671/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9243 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1672/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9249 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1673/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9254 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1674/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9260 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1675/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9265 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1676/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9271 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1677/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9276 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1678/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9282 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1679/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9287 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1680/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9292 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1681/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9298 - val_acc: 0.7083 - val_auc_1: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1682/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9303 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1683/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9308 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1684/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9314 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1685/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9319 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1686/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9324 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1687/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9329 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1688/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9334 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1689/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9339 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1690/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9344 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1691/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9350 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1692/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9355 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1693/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9360 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1694/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9365 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1695/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9370 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1696/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9375 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1697/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9379 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1698/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9384 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1699/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9389 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1700/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9394 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1701/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9399 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1702/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9404 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1703/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9408 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1704/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9413 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1705/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9418 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1706/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9423 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1707/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9427 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1708/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9432 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1709/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9436 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1710/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9441 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1711/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9446 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1712/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9450 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1713/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9455 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1714/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9459 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1715/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9464 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1716/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9468 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1717/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9473 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1718/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9477 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1719/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9481 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1720/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9486 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1721/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9490 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1722/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9494 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1723/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9499 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1724/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9503 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1725/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9507 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1726/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9511 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1727/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9516 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1728/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9520 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1729/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9524 - val_acc: 0.7083 - val_auc_1: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1730/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9528 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1731/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9532 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1732/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9536 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1733/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9540 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1734/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9544 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1735/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9548 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1736/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9552 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1737/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9556 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1738/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9560 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1739/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9564 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1740/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9568 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1741/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9572 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1742/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9576 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1743/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9580 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1744/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9584 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1745/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9588 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1746/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9591 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1747/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9595 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1748/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9599 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1749/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9603 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1750/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9606 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1751/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9610 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1752/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9614 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1753/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9617 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1754/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9621 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1755/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9625 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1756/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9628 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1757/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9632 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1758/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9636 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1759/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9639 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1760/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9643 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1761/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9646 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1762/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9650 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1763/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9653 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1764/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9657 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1765/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9660 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1766/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9664 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1767/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9667 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1768/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9670 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1769/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9674 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1770/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9677 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1771/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9680 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1772/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9684 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1773/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9687 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1774/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9690 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1775/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9694 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1776/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9697 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1777/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9700 - val_acc: 0.7083 - val_auc_1: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1778/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9704 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1779/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9707 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1780/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9710 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1781/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9713 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1782/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9716 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1783/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9720 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1784/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9723 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1785/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9726 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1786/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9729 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1787/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9732 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1788/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9735 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1789/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9738 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1790/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9741 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1791/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9744 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1792/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9747 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1793/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9750 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1794/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9753 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1795/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9756 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1796/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9759 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1797/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9762 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1798/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9765 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1799/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9768 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1800/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9771 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1801/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9774 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1802/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9777 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1803/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9780 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1804/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9783 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1805/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9786 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1806/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9789 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1807/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9791 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1808/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9794 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1809/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9797 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1810/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9800 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1811/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9803 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1812/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9806 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1813/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9808 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1814/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9811 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1815/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9814 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1816/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9817 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1817/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9819 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1818/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9822 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1819/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9825 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1820/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9827 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1821/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9830 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1822/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9833 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1823/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9835 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1824/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9838 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1825/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9841 - val_acc: 0.7083 - val_auc_1: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1826/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9843 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1827/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9846 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1828/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9849 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1829/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9851 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1830/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9854 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1831/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9857 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1832/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9859 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1833/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9862 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1834/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9864 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1835/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9867 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1836/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9869 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1837/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9872 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1838/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9874 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1839/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9877 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1840/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9879 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1841/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9882 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1842/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9884 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1843/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9887 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1844/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9889 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1845/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9892 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1846/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9894 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1847/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9897 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1848/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9899 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1849/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9902 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1850/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9904 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1851/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9907 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1852/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9909 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1853/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9911 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1854/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9914 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1855/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9916 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1856/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9918 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1857/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9921 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1858/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9923 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1859/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9926 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1860/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9928 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1861/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9930 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1862/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9933 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1863/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9935 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1864/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9937 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1865/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9940 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1866/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9942 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1867/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9944 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1868/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9947 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1869/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9949 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1870/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9951 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1871/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9953 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1872/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9956 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1873/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9958 - val_acc: 0.7083 - val_auc_1: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1874/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9960 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1875/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9962 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1876/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9965 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1877/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9967 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1878/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9969 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1879/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9971 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1880/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9974 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1881/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9976 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1882/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9978 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1883/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9980 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1884/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9983 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1885/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9985 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1886/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9987 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1887/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9989 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1888/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9991 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1889/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9993 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1890/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9996 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1891/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9998 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1892/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0000 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1893/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0002 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1894/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0004 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1895/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0006 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1896/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0009 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1897/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0011 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1898/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0013 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1899/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0015 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1900/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0017 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1901/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0019 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1902/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0021 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1903/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0023 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1904/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0026 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1905/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0028 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1906/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0030 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1907/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0032 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1908/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0034 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1909/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0036 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1910/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0038 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1911/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0040 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1912/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0042 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1913/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0044 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1914/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0046 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1915/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0049 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1916/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0051 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1917/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0053 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1918/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0055 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1919/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0057 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1920/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0059 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1921/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0061 - val_acc: 0.7083 - val_auc_1: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1922/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0063 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1923/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0065 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1924/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0067 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1925/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0069 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1926/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0071 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1927/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0073 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1928/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0075 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1929/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0077 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1930/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0079 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1931/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0081 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1932/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0083 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1933/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0085 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1934/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0087 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1935/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0089 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1936/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0091 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1937/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0093 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1938/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0095 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1939/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0097 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1940/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0099 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1941/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0101 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1942/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0103 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1943/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0105 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1944/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0107 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1945/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0109 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1946/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0111 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1947/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0113 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1948/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0115 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1949/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0117 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1950/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0119 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1951/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0121 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1952/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0123 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1953/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0125 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1954/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0127 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1955/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0129 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1956/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0131 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1957/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0133 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1958/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0134 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1959/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0136 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1960/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0138 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1961/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0140 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1962/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0142 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1963/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0144 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1964/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0146 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1965/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0148 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1966/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0150 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1967/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0152 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1968/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0154 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1969/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0156 - val_acc: 0.7083 - val_auc_1: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1970/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0158 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1971/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0160 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1972/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0162 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1973/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0163 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1974/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0165 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1975/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0167 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1976/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0169 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1977/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0171 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1978/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0173 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1979/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0175 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1980/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0177 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1981/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0179 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1982/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0181 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1983/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0183 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1984/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0184 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1985/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0186 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1986/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0188 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1987/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0190 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1988/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0192 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1989/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0194 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1990/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0196 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1991/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0198 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1992/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0200 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1993/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0202 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1994/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0203 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1995/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0205 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1996/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0207 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1997/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0209 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1998/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0211 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 1999/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0213 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2000/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0215 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2001/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0217 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2002/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0218 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2003/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0220 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2004/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0222 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2005/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0224 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2006/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0226 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2007/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0228 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2008/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0230 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2009/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0232 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2010/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0234 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2011/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0235 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2012/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0237 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2013/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0239 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2014/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0241 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2015/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0243 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2016/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0245 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2017/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0247 - val_acc: 0.7083 - val_auc_1: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2018/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0249 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2019/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0250 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2020/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0252 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2021/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0254 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2022/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0256 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2023/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0258 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2024/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0260 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2025/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0262 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2026/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0264 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2027/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0265 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2028/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0267 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2029/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0269 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2030/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0271 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2031/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0273 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2032/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0275 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2033/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0277 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2034/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0278 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2035/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0280 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2036/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0282 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2037/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0284 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2038/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0286 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2039/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0288 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2040/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0290 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2041/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0292 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2042/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0293 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2043/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0295 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2044/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0297 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2045/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0299 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2046/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0301 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2047/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0303 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2048/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0305 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2049/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0306 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2050/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0308 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2051/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0310 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2052/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0312 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2053/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0314 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2054/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0316 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2055/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0318 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2056/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0320 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2057/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0321 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2058/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0323 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2059/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0325 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2060/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0327 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2061/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0329 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2062/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0331 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2063/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0333 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2064/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0334 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2065/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0336 - val_acc: 0.7083 - val_auc_1: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2066/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0338 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2067/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0340 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2068/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0342 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2069/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0344 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2070/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0346 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2071/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0348 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2072/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0349 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2073/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0351 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2074/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0353 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2075/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0355 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2076/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0357 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2077/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0359 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2078/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0361 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2079/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0363 - val_acc: 0.7083 - val_auc_1: 0.9250\n",
      "Epoch 2080/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0364 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2081/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0366 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2082/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0368 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2083/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0370 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2084/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0372 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2085/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0374 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2086/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0376 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2087/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0378 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2088/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0379 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2089/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0381 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2090/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0383 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2091/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0385 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2092/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0387 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2093/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0389 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2094/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0391 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2095/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0393 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2096/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0394 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2097/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0396 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2098/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0398 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2099/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0400 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2100/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0402 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2101/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0404 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2102/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0406 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2103/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0408 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2104/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0410 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2105/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0411 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2106/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0413 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2107/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0415 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2108/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0417 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2109/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0419 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2110/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0421 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2111/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0423 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2112/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0425 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2113/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0427 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2114/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0429 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2115/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0430 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2116/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0432 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2117/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0434 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2118/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0436 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2119/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0438 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2120/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0440 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2121/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0442 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2122/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0444 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2123/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0446 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2124/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0448 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2125/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0449 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2126/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0451 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2127/3000\n",
      "92/92 [==============================] - 0s 228us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0453 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2128/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0455 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2129/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0457 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2130/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0459 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2131/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0461 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2132/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0463 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2133/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0465 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2134/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0467 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2135/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0469 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2136/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0471 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2137/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0472 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2138/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0474 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2139/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0476 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2140/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0478 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2141/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0480 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2142/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0482 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2143/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0484 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2144/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0486 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2145/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0488 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2146/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0490 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2147/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0492 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2148/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0494 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2149/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0496 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2150/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0498 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2151/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0500 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2152/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0501 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2153/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0503 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2154/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0505 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2155/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0507 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2156/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0509 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2157/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0511 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2158/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0513 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2159/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0515 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2160/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0517 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2161/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0519 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2162/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0521 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2163/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0523 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2164/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0525 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2165/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0527 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2166/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0529 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2167/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0531 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2168/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0533 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2169/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0535 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2170/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0537 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2171/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0539 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2172/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0541 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2173/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0543 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2174/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0545 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2175/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0546 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2176/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0548 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2177/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0550 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2178/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0552 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2179/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0554 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2180/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0556 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2181/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0558 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2182/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0560 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2183/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0562 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2184/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0564 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2185/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0566 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2186/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0568 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2187/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0570 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2188/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0572 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2189/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0574 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2190/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0576 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2191/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0578 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2192/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0580 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2193/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0582 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2194/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0584 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2195/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0586 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2196/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0588 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2197/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0590 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2198/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0592 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2199/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0594 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2200/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0596 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2201/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0598 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2202/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0600 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2203/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0602 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2204/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0604 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2205/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0606 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2206/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0608 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2207/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0611 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2208/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0613 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2209/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0615 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2210/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0617 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2211/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0619 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2212/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0621 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2213/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0623 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2214/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0625 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2215/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0627 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2216/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0629 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2217/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0631 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2218/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0633 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2219/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0635 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2220/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0637 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2221/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0639 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2222/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0641 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2223/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0643 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2224/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0645 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2225/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0647 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2226/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0649 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2227/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0651 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2228/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0653 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2229/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0656 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2230/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0658 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2231/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0660 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2232/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0662 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2233/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0664 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2234/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0666 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2235/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0668 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2236/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0670 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2237/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0672 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2238/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0674 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2239/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0676 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2240/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0678 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2241/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0680 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2242/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0683 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2243/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0685 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2244/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0687 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2245/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0689 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2246/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0691 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2247/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0693 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2248/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0695 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2249/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0697 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2250/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0699 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2251/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0701 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2252/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0703 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2253/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0706 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2254/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0708 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2255/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0710 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2256/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0712 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2257/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0714 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2258/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0716 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2259/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0718 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2260/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0720 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2261/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0722 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2262/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0725 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2263/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0727 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2264/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0729 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2265/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0731 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2266/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0733 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2267/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0735 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2268/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0737 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2269/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0740 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2270/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0742 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2271/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0744 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2272/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0746 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2273/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0748 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2274/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0750 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2275/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0752 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2276/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0754 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2277/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0757 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2278/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0759 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2279/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0761 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2280/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0763 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2281/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0765 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2282/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0767 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2283/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0770 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2284/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0772 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2285/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0774 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2286/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0776 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2287/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0778 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2288/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0780 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2289/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0782 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2290/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0785 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2291/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0787 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2292/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0789 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2293/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0791 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2294/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0793 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2295/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0795 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2296/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0798 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2297/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0800 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2298/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0802 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2299/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0804 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2300/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0806 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2301/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0808 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2302/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0811 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2303/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0813 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2304/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0815 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2305/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0817 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2306/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0819 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2307/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0822 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2308/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0824 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2309/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0826 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2310/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0828 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2311/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0830 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2312/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0832 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2313/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0835 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2314/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0837 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2315/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0839 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2316/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0841 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2317/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0843 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2318/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0846 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2319/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0848 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2320/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0850 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2321/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0852 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2322/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0854 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2323/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0857 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2324/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0859 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2325/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0861 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2326/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0863 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2327/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0865 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2328/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0868 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2329/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0870 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2330/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0872 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2331/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0874 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2332/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0876 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2333/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0879 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2334/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0881 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2335/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0883 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2336/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0885 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2337/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0887 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2338/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0890 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2339/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0892 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2340/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0894 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2341/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0896 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2342/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0898 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2343/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0901 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2344/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0903 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2345/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0905 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2346/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0907 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2347/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0909 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2348/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0912 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2349/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0914 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2350/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0916 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2351/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0918 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2352/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0921 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2353/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0923 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2354/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0925 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2355/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0927 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2356/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0929 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2357/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0932 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2358/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0934 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2359/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0936 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2360/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0938 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2361/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0940 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2362/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0943 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2363/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0945 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2364/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0947 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2365/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0949 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2366/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0951 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2367/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0954 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2368/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0956 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2369/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0958 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2370/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0960 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2371/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0962 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2372/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0965 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2373/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0967 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2374/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0969 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2375/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0971 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2376/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0974 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2377/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0976 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2378/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0978 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2379/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0980 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2380/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0982 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2381/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0985 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2382/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0987 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2383/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0989 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2384/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0991 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2385/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0993 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2386/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0996 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2387/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0998 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2388/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1000 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2389/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1002 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2390/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1004 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2391/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1006 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2392/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1009 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2393/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1011 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2394/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1013 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2395/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1015 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2396/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1017 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2397/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1020 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2398/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1022 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2399/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1024 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2400/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1026 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2401/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1028 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2402/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1031 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2403/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1033 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2404/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1035 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2405/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1037 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2406/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1039 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2407/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1041 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2408/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1044 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2409/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1046 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2410/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1048 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2411/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1050 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2412/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1052 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2413/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1055 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2414/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1057 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2415/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1059 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2416/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1061 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2417/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1063 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2418/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1065 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2419/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1068 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2420/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1070 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2421/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1072 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2422/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1074 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2423/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1076 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2424/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1078 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2425/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1080 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2426/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1083 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2427/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1085 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2428/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1087 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2429/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1089 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2430/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1091 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2431/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1093 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2432/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1096 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2433/3000\n",
      "92/92 [==============================] - 0s 305us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1098 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2434/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1100 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2435/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1102 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2436/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1104 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2437/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1106 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2438/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1108 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2439/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1111 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2440/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1113 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2441/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1115 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2442/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1117 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2443/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1119 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2444/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1121 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2445/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1123 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2446/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1125 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2447/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1128 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2448/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1130 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2449/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1132 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2450/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1134 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2451/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1136 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2452/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1138 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2453/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1140 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2454/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1142 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2455/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1144 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2456/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1147 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2457/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1149 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2458/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1151 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2459/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1153 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2460/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1155 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2461/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1157 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2462/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1159 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2463/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1161 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2464/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1163 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2465/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1165 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2466/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1168 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2467/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1170 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2468/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1172 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2469/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1174 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2470/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1176 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2471/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1178 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2472/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1180 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2473/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1182 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2474/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1184 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2475/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1186 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2476/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1188 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2477/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1190 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2478/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1192 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2479/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1194 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2480/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1197 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2481/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1199 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2482/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1201 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2483/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1203 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2484/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1205 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2485/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1207 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2486/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1209 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2487/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1211 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2488/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1213 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2489/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1215 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2490/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1217 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2491/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1219 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2492/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1221 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2493/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1223 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2494/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1225 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2495/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1227 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2496/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1229 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2497/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1231 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2498/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1233 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2499/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1235 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2500/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1237 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2501/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1239 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2502/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1241 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2503/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1243 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2504/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1245 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2505/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1247 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2506/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1249 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2507/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1251 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2508/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1253 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2509/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1255 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2510/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1257 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2511/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1259 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2512/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1261 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2513/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1263 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2514/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1265 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2515/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1267 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2516/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1269 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2517/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1271 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2518/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1273 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2519/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1275 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2520/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1277 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2521/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1279 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2522/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1281 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2523/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1283 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2524/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1285 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2525/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1287 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2526/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1289 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2527/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1291 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2528/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1293 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2529/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1295 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2530/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1297 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2531/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1299 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2532/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1301 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2533/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1303 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2534/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1305 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2535/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1307 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2536/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1308 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2537/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1310 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2538/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1312 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2539/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1314 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2540/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1316 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2541/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1318 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2542/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1320 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2543/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1322 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2544/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1324 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2545/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1326 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2546/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1328 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2547/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1330 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2548/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1332 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2549/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1334 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2550/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1335 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2551/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1337 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2552/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1339 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2553/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1341 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2554/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1343 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2555/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1345 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2556/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1347 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2557/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1349 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2558/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1351 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2559/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1353 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2560/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1354 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2561/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1356 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2562/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1358 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2563/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1360 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2564/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1362 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2565/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1364 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2566/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1366 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2567/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1368 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2568/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1369 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2569/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1371 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2570/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1373 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2571/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1375 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2572/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1377 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2573/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1379 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2574/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1381 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2575/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1383 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2576/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1384 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2577/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1386 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2578/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1388 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2579/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1390 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2580/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1392 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2581/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1394 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2582/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1396 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2583/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1397 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2584/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1399 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2585/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1401 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2586/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1403 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2587/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1405 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2588/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1407 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2589/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1408 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2590/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1410 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2591/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1412 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2592/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1414 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2593/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1416 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2594/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1418 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2595/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1419 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2596/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1421 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2597/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1423 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2598/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1425 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2599/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1427 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2600/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1428 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2601/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1430 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2602/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1432 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2603/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1434 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2604/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1436 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2605/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1437 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2606/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1439 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2607/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1441 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2608/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1443 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2609/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1445 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2610/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1446 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2611/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1448 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2612/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1450 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2613/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1452 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2614/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1454 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2615/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1455 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2616/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1457 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2617/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1459 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2618/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1461 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2619/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1462 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2620/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1464 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2621/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1466 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2622/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1468 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2623/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1470 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2624/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1471 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2625/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1473 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2626/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1475 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2627/3000\n",
      "92/92 [==============================] - 0s 185us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1477 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2628/3000\n",
      "92/92 [==============================] - 0s 196us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1478 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2629/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1480 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2630/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1482 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2631/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1484 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2632/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1485 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2633/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1487 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2634/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1489 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2635/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1491 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2636/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1492 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2637/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1494 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2638/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1496 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2639/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1498 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2640/3000\n",
      "92/92 [==============================] - 0s 163us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1499 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2641/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1501 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2642/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1503 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2643/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1505 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2644/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1506 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2645/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1508 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2646/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1510 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2647/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1511 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2648/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1513 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2649/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1515 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2650/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1517 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2651/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1518 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2652/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1520 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2653/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1522 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2654/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1523 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2655/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1525 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2656/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1527 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2657/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1529 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2658/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1530 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2659/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1532 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2660/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1534 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2661/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1535 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2662/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1537 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2663/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1539 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2664/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1541 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2665/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1542 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2666/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1544 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2667/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1546 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2668/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1547 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2669/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1549 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2670/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1551 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2671/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1552 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2672/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1554 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2673/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1556 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2674/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1557 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2675/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1559 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2676/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1561 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2677/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1562 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2678/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1564 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2679/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1566 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2680/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1567 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2681/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1569 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2682/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1571 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2683/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1572 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2684/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1574 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2685/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1576 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2686/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1577 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2687/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1579 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2688/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1581 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2689/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1582 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2690/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1584 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2691/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1586 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2692/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1587 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2693/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1589 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2694/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1591 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2695/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1592 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2696/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1594 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2697/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1596 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2698/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1597 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2699/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1599 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2700/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1601 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2701/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1602 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2702/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1604 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2703/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1606 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2704/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1607 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2705/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1609 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2706/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1610 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2707/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1612 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2708/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1614 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2709/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1615 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2710/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1617 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2711/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1619 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2712/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1620 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2713/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1622 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2714/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1623 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2715/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1625 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2716/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1627 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2717/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.9913e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1628 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2718/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.9787e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1630 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2719/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.9662e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1632 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2720/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.9538e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1633 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2721/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 9.9413e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1635 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2722/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.9289e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1636 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2723/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.9165e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1638 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2724/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 9.9041e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1640 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2725/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.8917e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1641 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2726/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.8794e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1643 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2727/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.8671e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1644 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2728/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.8548e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1646 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2729/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.8426e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1648 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2730/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.8303e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1649 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2731/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.8181e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1651 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2732/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.8059e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1652 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2733/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.7938e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1654 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2734/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 9.7816e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1656 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2735/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.7695e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1657 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2736/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.7574e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1659 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2737/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.7454e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1660 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2738/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.7333e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1662 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2739/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.7213e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1664 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2740/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.7093e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1665 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2741/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.6973e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1667 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2742/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 9.6854e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1668 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2743/3000\n",
      "92/92 [==============================] - 0s 130us/step - loss: 9.6734e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1670 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2744/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 9.6615e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1672 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2745/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.6497e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1673 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2746/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.6378e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1675 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2747/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.6260e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1676 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2748/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.6142e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1678 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2749/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.6024e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1679 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2750/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 9.5906e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1681 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2751/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 9.5789e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1683 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2752/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.5671e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1684 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2753/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.5554e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1686 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2754/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 9.5438e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1687 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2755/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.5321e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1689 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2756/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.5205e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1690 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2757/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 9.5089e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1692 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2758/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 9.4973e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1694 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2759/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 9.4857e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1695 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2760/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.4742e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1697 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2761/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.4626e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1698 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2762/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 9.4511e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1700 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2763/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.4397e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1701 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2764/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.4282e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1703 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2765/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.4168e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1705 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2766/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 9.4054e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1706 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2767/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.3940e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1708 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2768/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.3826e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1709 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2769/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.3712e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1711 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2770/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.3599e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1712 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2771/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 9.3486e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1714 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2772/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 9.3373e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1715 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2773/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 9.3261e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1717 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2774/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.3148e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1719 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2775/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 9.3036e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1720 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2776/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 9.2924e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1722 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2777/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 9.2812e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1723 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2778/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 9.2701e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1725 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2779/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 9.2589e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1726 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2780/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.2478e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1728 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2781/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.2367e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1729 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2782/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.2256e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1731 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2783/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.2146e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1732 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2784/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.2035e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1734 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2785/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.1925e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1735 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2786/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 9.1815e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1737 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2787/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.1706e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1739 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2788/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.1596e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1740 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2789/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.1487e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1742 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2790/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.1378e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1743 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2791/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.1269e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1745 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2792/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 9.1160e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1746 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2793/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.1051e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1748 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2794/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 9.0943e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1749 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2795/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.0835e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1751 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2796/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.0727e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1752 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2797/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.0619e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1754 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2798/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.0512e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1755 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2799/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.0404e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1757 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2800/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.0297e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1758 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2801/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 9.0190e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1760 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2802/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 9.0084e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1761 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2803/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.9977e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1763 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2804/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.9871e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1764 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2805/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.9764e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1766 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2806/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.9658e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1767 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2807/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.9553e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1769 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2808/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.9447e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1770 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2809/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.9341e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1772 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2810/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.9236e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1773 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2811/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.9131e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1775 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2812/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.9026e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1776 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2813/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.8922e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1778 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2814/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 8.8817e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1779 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2815/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.8713e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1781 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2816/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.8609e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1783 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2817/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.8505e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1784 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2818/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.8401e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1786 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2819/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.8298e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1787 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2820/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.8194e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1789 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2821/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.8091e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1790 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2822/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.7988e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1792 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2823/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.7885e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1793 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2824/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.7783e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1794 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2825/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.7680e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1796 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2826/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.7578e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1797 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2827/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.7476e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1799 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2828/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.7374e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1800 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2829/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.7272e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1802 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2830/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.7171e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1803 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2831/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.7070e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1805 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2832/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.6968e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1806 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2833/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.6867e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1808 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2834/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.6767e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1809 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2835/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.6666e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1811 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2836/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.6565e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1812 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2837/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 8.6465e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1814 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2838/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.6365e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1815 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2839/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 8.6265e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1817 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2840/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.6165e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1818 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2841/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.6066e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1820 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2842/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.5966e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1821 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2843/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.5867e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1823 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2844/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.5768e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1824 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2845/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.5669e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1826 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2846/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.5570e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1827 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2847/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.5472e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1829 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2848/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.5373e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1830 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2849/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.5275e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1832 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2850/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 8.5177e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1833 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2851/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.5079e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1834 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2852/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.4982e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1836 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2853/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.4884e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1837 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2854/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.4787e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1839 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2855/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.4689e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1840 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2856/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.4592e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1842 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2857/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.4496e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1843 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2858/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.4399e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1845 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2859/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.4302e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1846 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2860/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.4206e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1848 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2861/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.4110e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1849 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2862/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 8.4014e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1851 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2863/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 8.3918e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1852 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2864/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.3822e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1853 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2865/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.3727e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1855 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2866/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.3631e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1856 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2867/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.3536e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1858 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2868/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.3441e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1859 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2869/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.3346e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1861 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2870/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.3251e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1862 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2871/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.3157e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1864 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2872/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.3062e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1865 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2873/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.2968e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1867 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2874/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.2874e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1868 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2875/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.2780e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1869 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2876/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.2686e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1871 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2877/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.2593e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1872 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2878/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.2499e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1874 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2879/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.2406e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1875 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2880/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.2313e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1877 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2881/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.2220e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1878 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2882/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.2127e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1880 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2883/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.2034e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1881 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2884/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.1942e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1882 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2885/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.1849e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1884 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2886/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.1757e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1885 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2887/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.1665e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1887 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2888/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.1573e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1888 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2889/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.1482e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1890 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2890/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.1390e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1891 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2891/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.1298e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1892 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2892/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.1207e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1894 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2893/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.1116e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1895 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2894/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.1025e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1897 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2895/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.0934e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1898 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2896/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.0844e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1900 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2897/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.0753e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1901 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2898/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 8.0663e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1902 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2899/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 8.0572e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1904 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2900/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.0482e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1905 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2901/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 8.0393e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1907 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2902/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.0303e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1908 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2903/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 8.0213e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1910 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2904/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 8.0124e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1911 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2905/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 8.0034e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1912 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2906/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.9945e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1914 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2907/3000\n",
      "92/92 [==============================] - 0s 76us/step - loss: 7.9856e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1915 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2908/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.9767e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1917 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2909/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 7.9678e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1918 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2910/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 7.9590e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1919 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2911/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.9501e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1921 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2912/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 7.9413e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1922 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2913/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.9325e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1924 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2914/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 7.9237e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1925 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2915/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.9149e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1927 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2916/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.9061e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1928 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2917/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 7.8974e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1929 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2918/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.8886e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1931 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2919/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.8799e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1932 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2920/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.8712e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1934 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2921/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.8625e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1935 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2922/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.8538e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1936 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2923/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.8451e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1938 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2924/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.8364e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1939 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2925/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.8278e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1941 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2926/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.8192e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1942 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2927/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.8105e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1943 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2928/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.8019e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1945 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2929/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 7.7933e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1946 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2930/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.7848e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1948 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2931/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.7762e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1949 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2932/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.7676e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1950 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2933/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.7591e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1952 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2934/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.7506e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1953 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2935/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.7421e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1955 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2936/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.7336e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1956 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2937/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.7251e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1957 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2938/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.7166e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1959 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2939/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.7082e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1960 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2940/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.6998e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1962 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2941/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 7.6913e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1963 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2942/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.6829e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1964 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2943/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.6745e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1966 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2944/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.6661e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1967 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2945/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.6578e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1969 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2946/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.6494e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1970 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2947/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 7.6410e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1971 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2948/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.6327e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1973 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2949/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.6244e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1974 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2950/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.6161e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1975 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2951/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.6078e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1977 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2952/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.5995e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1978 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2953/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 7.5912e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1980 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2954/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.5830e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1981 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2955/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.5747e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1982 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2956/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.5665e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1984 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2957/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.5583e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1985 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2958/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.5501e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1987 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2959/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 7.5419e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1988 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2960/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 7.5337e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1989 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2961/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 7.5256e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1991 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2962/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.5174e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1992 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2963/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.5093e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1993 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2964/3000\n",
      "92/92 [==============================] - 0s 87us/step - loss: 7.5012e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1995 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2965/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.4930e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1996 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2966/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.4850e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1998 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2967/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.4769e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1999 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2968/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.4688e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2000 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2969/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.4607e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2002 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2970/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.4527e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2003 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2971/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.4446e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2004 - val_acc: 0.7083 - val_auc_1: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2972/3000\n",
      "92/92 [==============================] - 0s 152us/step - loss: 7.4366e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2006 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2973/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.4286e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2007 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2974/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.4206e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2009 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 2975/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 7.4126e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2010 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2976/3000\n",
      "92/92 [==============================] - 0s 174us/step - loss: 7.4046e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2011 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2977/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 7.3967e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2013 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2978/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 7.3887e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2014 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2979/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.3808e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2015 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2980/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.3729e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2017 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2981/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.3650e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2018 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2982/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.3571e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2019 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2983/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.3492e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2021 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2984/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.3413e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2022 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2985/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.3334e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2024 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2986/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.3256e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2025 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2987/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.3177e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2026 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2988/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.3099e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2028 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2989/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.3021e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2029 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2990/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 7.2943e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2030 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2991/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.2865e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2032 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2992/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.2787e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2033 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2993/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.2710e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2034 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2994/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.2632e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2036 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2995/3000\n",
      "92/92 [==============================] - 0s 120us/step - loss: 7.2555e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2037 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2996/3000\n",
      "92/92 [==============================] - 0s 131us/step - loss: 7.2477e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2038 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2997/3000\n",
      "92/92 [==============================] - 0s 141us/step - loss: 7.2400e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2040 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2998/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.2323e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2041 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 2999/3000\n",
      "92/92 [==============================] - 0s 98us/step - loss: 7.2246e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2043 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 3000/3000\n",
      "92/92 [==============================] - 0s 109us/step - loss: 7.2169e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2044 - val_acc: 0.7083 - val_auc_1: 0.8607\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5, X6, X7], Y, validation_split=0.2, epochs = 3000, batch_size = 92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZwU1bn/8c8zC+uwbyLDqrhGgxH3XaKiUdGYXwJuMYvGhasxMTeYXA0xRpOb3CR6Y/Rq9CYaNyQxFxU1alCzqAGNqIAIQZBhHUa2AQZmpp/fH1XN9Mx0z8ZUd8/U9/16zWuqTlVXP0UP9fQ5p+occ3dERCS+CnIdgIiI5JYSgYhIzCkRiIjEnBKBiEjMKRGIiMScEoGISMwpEUjsmVmhmVWa2YiIjj/GzCqjOLZIe1AikA4nvGgnfxJmtiNl/aLWHs/da929xN0/akMs+5pZo4dxzOx3ZjY9PP4ydy9pwbG+amYvtzYGkT1VlOsARFor9aJqZsuBr7r7i5n2N7Mid6/JRmy5FJfzlPanGoF0OmZ2q5k9bmaPmtlW4GIzO8bMXjezTWa2xszuNLPicP8iM3MzGxWu/y7c/qyZbTWz18xs9B7EU6/WYGZfMbPl4bGXmdlkMzsE+CVwQliz2RDu2zeMpzx8zY1mZuG2r5rZq2GsHwO3hud3YMp7DTWz7WY2oK3xS+enRCCd1fnAI0Af4HGgBrgOGAgcB0wEvtbE6y8EbgL6Ax8BP2iPoMysN/Az4DR37xXG8o67vwtMBf4SNlMNDF/yK6AHMAY4FfgKcGnKIY8FFgGDgO8DM4CLG5zH8+5e0R7xS+ekRCCd1V/d/Sl3T7j7Dnef6+5vuHuNuy8D7gVOauL1M919nrtXAw8D45p6s/Cb+O4f4PNN7O7AJ8ysm7uvcfeFGY5ZHB5nmrtvDeP+OXBJym4fufvdYT/HDuC3wIXJWkO470NNxS6iRCCd1crUFTM7wMyeMbO1ZrYFuIWgdpDJ2pTl7UCTnb3u3jf1h+Cbebr9tgBTgGuAtWb2tJntl+Gwg4FCYEVK2QpgWMp6vfN0978R1H6ON7NPACOAZ5qKXUSJQDqrhnfy/A/wHrCvu/cGbgas0auywN2fdfdPA0OBpWFs0Djm9UAtMDKlbASwKvVwad7iQYLmoUuAGe6+sz3ils5LiUDiohewGdgWdqY21T8QmbDz9hwz6wHsArYRXOwB1gGlyU7ssFlqJnCbmZWEHdbXA79r5m0eAj5H0D/wYASnIZ2MEoHExTeBLwJbCb6BP56jOAqBbwFrgAqCzt6p4bYXgCXAOjNLNk1dTZAwPgReIegDaPLi7u7LgXeBXe7+93aOXzoh08Q0Ip2PmT0ILHP36bmORfKfHigT6WTMbAwwCTgk17FIx6CmIZFOxMxuB+YDt7VlyAyJJzUNiYjEnGoEIiIx1+H6CAYOHOijRo3KdRgiIh3Km2++ucHdB6Xb1uESwahRo5g3b16uwxAR6VDMbEWmbWoaEhGJOSUCEZGYUyIQEYm5DtdHICKdS3V1NWVlZVRVVeU6lE6hW7dulJaWUlxc3OLXKBGISE6VlZXRq1cvRo0aRd00CtIW7k5FRQVlZWWMHt3ySfUiaxoyswfMbL2ZvZdhu4VT7C01s3fM7FNRxSIi+auqqooBAwYoCbQDM2PAgAGtrl1F2UfwG4LpADM5Exgb/lwB3B1hLCKSx5QE2k9b/i0jaxpy91eTk4FnMAl40IMxLl4PJ+ke6u5roopJ8lN1bYIPN2zbvV5T63TvUphx1pjtu2r53qz3OPMTQxnSuxsJd5ygWgwE607wE67j4ATliZRlB3bsqqGyqibq05QMjhtYzdrN6h9oid7di+jRpf0v27nsIxhG/Wn2ysKyRonAzK4gqDUwYsSIrAQnrff+2i089o/gI02488S8MnZU16bdt3tx4e7lTPs0Z+7yjW16XSb6Upobh54zlPVblQhaoriwe6dLBOn+26UdAc/d7yWYbJzx48drlLw88/qyCibf+3qL959y5HB6dau7o+H5BWtZUbG93j6XnzCag/bunfb1O3Yl+Mnz7/Nfn/8kpf16YCQv4kaBBVXjZFlBeHW3sLzAwLBgnaCsqMDo26NYzRM5smjRIg4s7ZvrMCLx5S9/maeffprBgwfz3ntpu0vzQi4TQRkwPGW9FFido1ikFWoTztsrN3HHS0t49YPyZvefePBeXHnyPowbnv4/+3fOOrDVMVx4lGqGkv8uu+wypk6dyqWXXprrUJqUy0QwC5hqZo8BRwGb1T+QXz6q2M6JP5nTon1P3n8Q91x8ON1SmnxEWuv7Ty1g4eot7XrMg/buzffOObjJfc477zxWrlxJVVUV1113HVdccQUlJSVUVlYCMHPmTJ5++ml+85vfsG7dOq688kqWLVsGwN13382xxx6b9rgnnngiy5cvb9fziUJkicDMHgVOBgaaWRnwPSA5Kfc9wGzgLGApsB34UlSxSOt858l3eeSNpuc0OXjv3txz8eEM798jS1GJROeBBx6gf//+7NixgyOOOIILLrgg477XXnstJ510Ek8++SS1tbW7k0VHFuVdQ1Oa2e7ANVG9v7Te0vWVfPpnr6TddtDQ3sy86phIOqpEkpr75h6VO++8kyeffBKAlStXsmTJkoz7/vnPf+bBBx8EoLCwkD59+mQlxijpf7Xw3HtruPJ3b9Uru27CWK46eR819Uin9/LLL/Piiy/y2muv0aNHD04++WSqqqrq3TzQ2Ye/0KBzMbZp+y5GTXumURL4121ncf1p+ykJSCxs3ryZfv360aNHD95//31efz24A27IkCEsWrSIRCKxu7YAMGHCBO6+O3j+tba2li1b2rdPIxeUCGKocmcNo6Y9w7hbXqhX/vINJ7P8R5+hsEC3UUp8TJw4kZqaGg499FBuuukmjj76aAB+9KMfcfbZZ3PqqacydOjQ3fvfcccdzJkzh0MOOYTDDz+cBQsWZDz2lClTOOaYY1i8eDGlpaXcf//9kZ9PW3S4yevHjx/vmqGs7Soqd3L4rS/WK1v6wzMpKtR3AsmNRYsWceCBrb+FWDJL929qZm+6+/h0+6uPIEY+3LCNU3768u71F79xIvsO7pW7gEQkLygRxMSoac/UW19221kUqAlIZI9VVFQwYcKERuUvvfQSAwYMyEFEradE0Mm5Owd/7/l6Zf9SEhBpNwMGDODtt9/OdRh7RA3DnVgyCWzfFQzq9tlPDVNnsIg0ohpBJ/b7t1axfVct+wzqyZPXHEfvbi2fuk5E4kOJoJOqqq7lxj+8w7C+3Xnu6ydSrLuCRCQDJYJOqKq6lgNueg6A2z97iJKAiDRJV4hO6P/d8xoAYwb25ISxA3McjUjnUlJSkrP3njhxIn379uXss89u1+MqEXQy1zz8Fu+u2kzfHsX8+YaTNdmKSCfyrW99i4ceeqjdj6umoU5kRcU2nnk3mNLh9Rsb39cskveenQZr323fY+51CJz5o4ybv/3tbzNy5EiuvvpqAKZPn46Z8eqrr7Jx40aqq6u59dZbmTRpUrNvVVlZyaRJkxq9bvny5Zx99tm7Zyn76U9/SmVlJdOnT2fp0qVceeWVlJeXU1hYyBNPPME+++yT9vgTJkzg5Zdfbv2/QTOUCDqJnTW1nPSTl4GgX0ADxom0zOTJk/n617++OxHMmDGD5557juuvv57evXuzYcMGjj76aM4999xma9jdunXjySefbPS6plx00UVMmzaN888/n6qqKhKJRLudW0spEXQCiYSz/388t3t9ypGaxlE6qCa+uUflsMMOY/369axevZry8nL69evH0KFDuf7663n11VcpKChg1apVrFu3jr322qvJY7k73/nOdxq9LpOtW7eyatUqzj//fCBIJLmgRNAJjPnO7N3Ld0wel8NIOrBd26FqU/ptPQZCUZfsxiNZ9bnPfY6ZM2eydu1aJk+ezMMPP0x5eTlvvvkmxcXFjBo1qkVzEmR6XVFRUb1v+slj5cugn0oEHdx7qzbvXr746BFMGjcsh9F0UO7w34fD1tXpt486AS57OrsxSVZNnjyZyy+/nA0bNvDKK68wY8YMBg8eTHFxMXPmzGHFihUtOs7mzZvTvm7IkCGsX7+eiooKSkpKePrpp5k4cSK9e/emtLSUP/7xj5x33nns3LmT2tpaevTI7hSwSgQd2LLySs7+778CUNK1iFvPOyTHEXVQ5e8HSeCTU2DE0fW3vfd7WJd5vHnpHA4++GC2bt3KsGHDGDp0KBdddBHnnHMO48ePZ9y4cRxwwAEtOk6m1xUXF3PzzTdz1FFHMXr06HrHe+ihh/ja177GzTffTHFxMU888QRjxoxJe/wTTjiB999/n8rKyt3zG5xxxhl7fP6aj6ADWr+liiNve2n3+swrj2H8qP45jKgDqyyHv/wXvHE3XPYMjDq+/vZXfwp//gF89j7Y99PQQ//O7U3zEbQ/zUfQiS1as4Uv/e9c1m6pa6u8Y/I4JYE98cqPYO6voWtvKD2i8fZB4Te3P1wOx/4bnH5rduMTyQIlgjx3yf1v8JclG9Ju+9dtZ2kk0T21dS0M2Be+8gIUdW28/YDPwHXvwEPnwcaUduJ3ZsCL34drXoeumtwnbt59910uueSSemVdu3bljTfeyOtjZ6JEkEfWbq7imkfe4s0VG9NuL+3Xne+fezATDhyS5cjyxM5KuH0YTHkc9p+458d78zew6k3oPyZzk48Z9BsJfUfCyjfgqevqXgtQsRT2PmzP4lg5F97+3Z4dI9uGfhLGf7ndDufuHeop+EMOOSSyOQj29Nhtae5XIsii7btqeGvFJi6+v/WZ/W/TTmVY3+4RRNVBVJbD/5wYLD/6BZi+uen9M3GH9QuDpDL736GwGPY5pfnX7XdG8LrFz9Yv//BVqK1uWyxJc34Iy/8KPTrGbFbs3Arv/aHdEkG3bt2oqKhgwIABHSoZ5CN3p6KiotXPIygRZMHke1/j9WUft+o1mlC+gZ/u2z7HWfUW/PrUuvVzfgHjLmz+dUdfFfwkbasIYnrh5vaJ68Bz4AsdpFbwp/+Aufe32+FKS0spKyujvLy83Y4ZZ926daO0tLRVr1EiiMj7a7cw8Rd/ybj9oqNGMHpgT44aPYAR/XvQvUshXYp04W8kUQu3NGi2Oei8th+vYmnwe9KvoO9wGHFM247TcwBc8QpsW9/2WFIN3cPmpWwqKIJETbsdrri4mNGjR7fb8aT1lAgikEh42iSw+NaJdC3SGECtsj2lJnX0NbD4GShs4inf+Y/BlgwPhgF8FAzRzcHnQZeeexbb0EP37PUdVTsnAsk9JYK22P5xk/eTX/jr1+utjx7Ykzk3nBxxUJ3U3F/XLU+8DT54DjzDoFxb1sCTX2v+mIMP2vMkEGcFxcFnkEhAgWqxnYESQWv94z6YfUOw/M3F0Kv+IFQrP96+uz9g4S1nUFxYoBnC2upffw7u809lBZkTweay4PcXHg4e/sqkqRqFNK8grNUmaqBA/5adgRJBU+bcHlxQhh8R3Bky61pYntLk89pdcPoPdq+6Oyf85xwAnvv6CfToon/eeu4YBxs/hH0mBLdlAix9sf4+N28MvmUmEvDQ+XXl14a301kBeG1d+eJn62oN28LOxn6joDg3ozjGQkH4d52oAZQIOoNIr1RmNhG4AygEfu3uP2qwfSTwADAI+Bi42N3LooypRWpr4J3Hg2+jr/wITv8hVK6F+Y9A/5QJI/5+Z71EMPneuiahA/bqnc2I81/1jiAJACx7GfYeF3QENzT3Ptj0EZQMrl/eP+xMLCgMagTrFwW3c/79v2HDEhi0f3CB2m8iDBwb6anEXr1EIJ1BZInAzAqBu4DTgDJgrpnNcveFKbv9FHjQ3X9rZqcCtwOXND5ali2eDf93dd36n75bt3z+PXD/aWlf9saHQZPQ36admnZ7rP0wpQnt7J/B4ZcFtawfNJhT+dl/b/za1GcGrCB4FuCRL8Cm8EnfcRfDeXe1e8iSgRJBpxNljeBIYKm7LwMws8eASUBqIjgIuD5cngP8McJ4WmZnJcxoIhf13jtt8az5dXeqxPrBr4a2rIGfNRi5sSRMCoXFTb/2ildg4H71y9a9F/wAHHE5HHk59NOth1lVmEwEaWp00iFF2Ys5DFiZsl4WlqWaD1wQLp8P9DKzRo9XmtkVZjbPzOZF/tBJsvki1d6HwUGTYOKPofewugd/+o3avcu1j/4TgKmntNODT03ZtQ0evRCeuxEemAg1u6J/z7b4zzGNk8Dwo4KndJNGh08LX/IkTH6k7r7+qW8GzUddmhiXfchBQZOQJo3JLtUIOp0oawTpnhVvOAjGDcAvzewy4FVgFdDor8vd7wXuhWAY6vYNs4ENS4Lfn/4+zHsArvwrdGvQ3n/gOXDUlfDGPcn4dm+6/rQG32CjMOe24H76pPtOhckPB2Pi5IudlbC9onH5V/5Uf/2LT9VfP+AzLX+Pgz/b+rhkzyUTwep/Nv3MhrSPgftCtz6RvkWUiaAMGJ6yXgrU+6tx99XAZwHMrAS4wN3bOIhMO5n5peD3wefB8V/PvF/yFsSt65hXETRxHDKsT3ZGA93eYLiKde/CHYe2ffydKNyeZqa09hhCIZ/OMa6So60+NiW3ccTFvqfBxTMjfYsoE8FcYKyZjSb4pj8ZqDeoi5kNBD529wRwI8EdRPmhpJkRPpN3puzcygsLg0HH7rnk8IiDCs1/JH35qrdg2KfgzsPg42XwvU11t2lmy8P/D5b8qXH5hU/AfqdnNxaJxv6fgUtnQc3OXEfS+c25FXa0bpyytogsEbh7jZlNBZ4nuH30AXdfYGa3APPcfRZwMnC7mTlB09A1UcXTasXNdPh2KQHAl83h3lf35sjR/es6id3hrQfhqWuD9W/9C3oOzHCgVkodYnb0SXDa9+Hek4P1+06BG5YESQBg65qMnduRSCTSJ4FLZ8GYk7IXh0SrsEifZ7bM/XVw63rEIn3k1d1nu/t+7r6Pu/8wLLs5TAK4+0x3Hxvu81V3z+1XjF3bg98Tvtf8vmE7qc2+gUJqOWx437pt6xbUJQGAn+xDu9mUMjnKMVMbj4X/i5R5i2dc2n7v2xKv/TJ9uS4aIm1TWJyVu7P06GuqZBWsJfPSbq577u3TBW9xxYlnpN3Wrmp2wR2fDJbPvzd9U0tN3TSWlM2NJo5U05vpxFKbvkjbFRRm5e4sDYKTKtkJ270FiSB5LzuwX5cNDChJmebw/acb778t/XSTrbLgD+nLr/p75tdM71P3U7Vlz2NojQtnZPf9RDqbLI30qhpBqtbUCArqhpOe2uNF+PknYPNK6DmobsybVG8/Asdd27i8pXZtqz+y5oFn1y0PORj6jIDNHzV9jGe+ARf8uul9WmPJC+nLv7tOY/2ItIcsJQLVCFLtCOcK7t6v2V2rRtZNb9h1+5ogCUD6JADwwk17FtuL0+uW//3DxsMoX/9u3fLA/dMf490n9iyGhh7+XPpyJQGR9lGgPoLsWzgr+N2CuWOfqj6Cn1fdyct9vk+XnWkenAK4qQJ+0IJ5aNO1s/ccBJfNhkHhA2rv/T743Wto5hrLjauCAdmKusKtg9Pvk3yv6xdCnzT3+rdUc30DIrLn1EeQA7XhUA3NPUMA3PHSElYzMHMSOPsXwW12F6TM7Zq8KylVujIIahYPnht8G/ifk+qe0m14l1CqriXBU9BFXTPvk7RoVv31N39Tvz/h9XvgloF169U7mj8mwGd+1rL9RKR5BUXB4IxRv03k79CRbP8YRh7f7ENYVdW1lG0ML4xn3J5+p0+Ewx/0SXm4euaXg0fyyz8IxtFf+Y/g3v+GDjw3+L11DTz7bVjzdt22025p4cmELszQHPTcNKiugkVPwYI/wlPXNdj+bUik/AH+5z4w73/rftKZvhmO+Err4hORzNRZnANVm6D/mGZ3O+Cm5+pWjrkanr+xbv36BdCntG69ZFD94//swObj+MJDdU0vc++rK//8Q60fa3+/0+tu4Vzxd/jfM+u2/bD5ms9u1dvg6SaG3PjkhZm3iUjbFBSpjyDraqtb1qwSuvrk8EGxbyyC+Y8GQyanJgGon1gqlqY/0H4Tg4fQBuxTNx7Pl56FNfODb+4QjM65TyvmOfjm4rrBwZJGHgvHfR3+9ouWH6eljry8/Y8pEneFRbCrEn51bLB+4g11rQ3tSIkgVaK68cWzgc076ppLbjg9vDun995wwjebP37DO4oO+XzQlDLi6Mb7jjw2+HnjHti4HMakaUJqSoO5lHc75buZE8GYU2DZnLr1zz/U9NwMqZrquxCRtjloEnz8Yd083Q1HQm4nSgSpErXNJoIb//AOEHQjFLR0pNHP/Cy4hz/Vl/8EI45q/rXXzW/Ze7RUUZegqSjdXT+f+a+gVtIaenJYJDrDDg+aiiOmRJAqUVPvQbGGVlRsY/a7a+lSWMAHPzwz436NjDy2cVlLkkCUUi/gyaTQ0iTwndWNn2MQkQ5Ldw2lStQ0WSM46ScvA/DMtce37ri1DWYQa2pIiFw4/3+CPoh0vvlB/fVDJysJiHQySgSpmkgEGyrrBkYdO6RX6447+KC65f9YHwwJkU8+OTlzR3SvIUHt4RPhU8Tn35O9uEQkK9Q0lKqJPoLH5wZDSPz2y0e2/riFxR2/Lf1z9wc/ItLpqEaQKkONYN2WKn7y/GIAThzbThPMiIjkCSWCVGkSgbtz1G0vAfCN0/bDsj31o4hIxJQIUjVIBDW1CUbfOHv3+rUTWvlUr4hIB6BEkJRIBA9tpCSCJesrdy//86bTchGViEjklAiSPBzPI3yO4P21Wzjzjr8AcO2p+9KvZ5dcRSYiEiklgqTkCH8FRSQSzsRf/GX3pm+cnmGiFxGRTkCJICklEaz4uG6OgLnf/XSOAhIRyQ4lgqSURLBgdXDP/9P/djyDerV8NFIRkY5IiSApUddH8MHarRQYjB1SktuYRESyQIkgKaVGULZpB0N6d6NrUeYB6EREOgslgqSURLBmUxV79+2e23hERLJEiSApTAQrNlbx2rIKRg7okeOARESyQ4kgqSYYKnr+mmBS+qtOauUELSIiHZQSQVJtMMz0yi0J9h1c0vqhpkVEOqhIE4GZTTSzxWa21Mympdk+wszmmNk/zewdMzsryniaFNYI1lQmGDVAE6+ISHxElgjMrBC4CzgTOAiYYmYHNdjtP4AZ7n4YMBn4VVTxNCusEayurGV4f3UUi0h8RFkjOBJY6u7L3H0X8BgwqcE+DvQOl/sAqyOMp2k1QSLYUl3A8H7qKBaR+IgyEQwDVqasl4VlqaYDF5tZGTAb+Ld0BzKzK8xsnpnNKy8vjyLW3fMK76KY4f2VCEQkPqJMBOlmcPEG61OA37h7KXAW8JCZNYrJ3e919/HuPn7QoEERhMruGkGQCNQ0JCLxEWUiKAOGp6yX0rjp5yvADAB3fw3oBuRmLsjdNYIiPUwmIrESZSKYC4w1s9Fm1oWgM3hWg30+AiYAmNmBBIkgorafZmz/GAAr6kKvruknsBcR6YwiSwTuXgNMBZ4HFhHcHbTAzG4xs3PD3b4JXG5m84FHgcvcvWHzUXY8+y0AepX01LzEIhIrkX71dffZBJ3AqWU3pywvBI6LMobWGtZPI46KSLzoyeKQ9ykFYNBew5vZU0Skc1FjeKi2uBcv1Y5n9EA9VSwi8aIaQWjXjkq20Y19B6tpSETiRYkglNhZSU1BN44Y1T/XoYiIZJUSQaiwZgfdS3rTpUj/JCISL7rqASQSdGUnvXr1bn5fEZFORokAqNpRSQFOcTf1D4hI/CgRAJu2bAGgaw8lAhGJn2ZvHzWzrsAFwKjU/d39lujCyq6NmzezF9BdiUBEYqglzxH8H7AZeBPYGW04ubFkVTkHAj16anpKEYmfliSCUnefGHkkOVS2LhhwbkDfPjmOREQk+1rSR/B3Mzsk8khyqHrndgB6664hEYmhltQIjgcuM7MPCZqGDHB3PzTSyLJo0+bNwUKx5iEQkfhpSSI4M/Iocmzz1uCuISUCEYmjjInAzHq7+xZgaxbjybrKnTXs2rENugBFSgQiEj9N1QgeAc4muFvIqT8HsQNjIowra15cuI5xBUuDla66a0hE4idjInD3s8Pfo7MXTvZV7qzhmIKFwUrP3EyXLCKSSy2aj8DM+gFjCeYUBsDdX40qqGxas3kHp9g2/MBzsaKuuQ5HRCTrWvJk8VeB64BS4G3gaOA14NRoQ8uOd1Zu4jrbhPXv1BUfEZGMWvIcwXXAEcAKdz8FOAwojzSqLHF33l26nC7UQK+huQ5HRCQnWpIIqty9CoJxh9z9fWD/aMPKjr8u3cAgC58hKBmc22BERHKkJX0EZWbWF/gj8IKZbQRWRxtWdtw1Zyn9k3fH9hiQ22BERHKk2UTg7ueHi9PNbA7QB3gu0qiy5ONtuziyoCxY6a4pKkUknppsGjKzAjN7L7nu7q+4+yx33xV9aNH7cMM2jhscnkrfEbkNRkQkR5pMBO6eAOabWae7Sv6rvJLqWmegbww6irv3zXVIIiI50ZI+gqHAAjP7B7AtWeju50YWVRas3rQDgEN3zoP+w3McjYhI7rQkEZQQDDWRZMCPowkne37/ZtA3UJTYBYVdchyNiEjutCQRFLn7K6kFZtbhR2f708J1GAkKdm2BkcflOhwRkZxpavTRq4CrgTFm9k7Kpl7A36IOLEoP/PVDtu+q5ZSC+Zgn1D8gIrHW3OijzwK3A9NSyre6+8eRRhWxW54OBpnbv2BlUHDgOTmMRkQktzLeNeTum919ubtPcfcVKT8tTgJmNtHMFpvZUjOblmb7z83s7fDnAzPb1NYTaY1xw4MawKWf6AZdekG/Udl4WxGRvNSi0UfbwswKgbuA04AyYK6ZzXL3hcl93P36lP3/jWAco8jtrEkw4YDB7F24GXoNycZbiojkrZaMNdRWRwJL3X1Z+ADaY8CkJvafAjwaYTy7bdq+i/49u8DWdVCyVzbeUkQkb0WZCIYBK1PWy8KyRsxsJDAa+HOG7VeY2Twzm1devmcDn+7YVcuazVXBiKMf/R0Ki/foeCIiHV2UicDSlHmGfScDM929Nt1Gd7/X3ce7+/hBgwbtUVCvfz7ZSCQAAAzCSURBVFgBwLkf3R4ULJuzR8cTEenookwEZUDqI7ulZB61dDJZahYqKgjy0wEl27PxdiIieS/KRDAXGGtmo82sC8HFflbDncxsf6AfwaxnkauqTgBQmKyvDD4oG28rIpK3IksE7l4DTAWeBxYBM9x9gZndYmap4xRNAR5z90zNRu1q+64aAKpGnhIUnP3zbLytiEjeiuz2UQB3nw3MblB2c4P16VHG0NCWHdUADHzt1qCg5571OYiIdHRRNg3lpU3bq+nJjlyHISKSN2KXCCp31nBx8ct1BQP2yVksIiL5IHaJYGdNghsLH8p1GCIieSOWiWC36+bnLhARkTwRr0TwzhPc/s7xdeslGmdIRCReieAPX62/Xtzh59cREdlj8UoEqUqPzHUEIiJ5Ib6JYOQxuY5ARCQvxDcRFPfIdQQiInkhvomgqFuuIxARyQvxTQTqKBYRAeKWCPqMqFtWIhARAeKWCFLnvSlSIhARgbglgkRN3XKx+ghERCBuiaC2um5ZNQIRESBuiSCR0jSkSetFRIDYJYKUpqGCSOfkERHpMGKWCFKahlQjEBEBYpcIVCMQEWkoPokgkQBPmYtANQIRESBWiaCm/rpqBCIiQKwTgWoEIiIQ60RQmJs4RETyTHwTAZ6TMERE8k18E4ErEYiIQJwTQbc+uYlDRCTPxCcRpI4zBNBzYG7iEBHJM/FJBGGNYFbtMSw44Vc5DkZEJH/ELhG8UHs4W0dPzHEwIiL5I9JEYGYTzWyxmS01s2kZ9vm8mS00swVm9khkwYSJoIZCuhTFJ/+JiDQnssdrzawQuAs4DSgD5prZLHdfmLLPWOBG4Dh332hmg6OKp14iKFQiEBFJivKKeCSw1N2Xufsu4DFgUoN9LgfucveNAO6+PrJoausSQVfVCEREdovyijgMWJmyXhaWpdoP2M/M/mZmr5tZ2sZ7M7vCzOaZ2bzy8vK2RRPWCGopoGuRnioWEUmKMhFYmrKGT3EVAWOBk4EpwK/NrG+jF7nf6+7j3X38oEGD2hZNmAiqKVIfgYhIiiiviGXA8JT1UmB1mn3+z92r3f1DYDFBYmh/4aQ0tV6gRCAikiLKK+JcYKyZjTazLsBkYFaDff4InAJgZgMJmoqWRRJNSmdxcWG6yoqISDxFlgjcvQaYCjwPLAJmuPsCM7vFzM4Nd3seqDCzhcAc4FvuXhFJQOHE9UEiUI1ARCQp0tlZ3H02MLtB2c0pyw58I/yJVjjERK0SgYhIPfG5IiabhqyQwgI1DYmIJMUuEZhpikoRkVSxSwQUKhGIiKSKXSJwTVovIlJP7BKBKRGIiNQTn0QQ3jVUUFic40BERPJLfBJB+ByBq49ARKSeGCWCoGlINQIRkfrikwgKitheUKI+AhGRBuJzVTz6Sq5dPJ7aTTtyHYmISF6JT40AqEkkNOCciEgD8UoEtU6RhpcQEaknVomgujZBkQacExGpJ1ZXxepaNQ2JiDQUq0RQk3ANQS0i0kCsrorVtU5RQaxOWUSkWbG6KtaoaUhEpJF4JYKEq7NYRKSBWF0Vq2sTFOv2URGRemKVCGpqnSI1DYmI1BOvRJDQcwQiIg3F6qpYXetqGhIRaSBmiUA1AhGRhmJ1VdxZk6BbcaxOWUSkWbG5KtbUJqhNOF2LCnMdiohIXolNIqiqSQCoRiAi0kBsroo7q4M5i1UjEBGpLz6JQDUCEZG0YnNVrFKNQEQkrdgkAtUIRETSi/SqaGYTzWyxmS01s2lptl9mZuVm9nb489WoYlGNQEQkvaKoDmxmhcBdwGlAGTDXzGa5+8IGuz7u7lOjiiMpWSPoWqQagYhIqiivikcCS919mbvvAh4DJkX4fk3aXSMoVo1ARCRVlIlgGLAyZb0sLGvoAjN7x8xmmtnwdAcysyvMbJ6ZzSsvL29TMKoRiIikF+VVMd3obt5g/SlglLsfCrwI/Dbdgdz9Xncf7+7jBw0a1KZgkjWCbqoRiIjUE2UiKANSv+GXAqtTd3D3CnffGa7eBxweVTCqEYiIpBflVXEuMNbMRptZF2AyMCt1BzMbmrJ6LrAoqmB2qkYgIpJWZHcNuXuNmU0FngcKgQfcfYGZ3QLMc/dZwLVmdi5QA3wMXBZVPLtrBHqOQESknsgSAYC7zwZmNyi7OWX5RuDGKGNIGtG/B2d+Yi+66TkCEZF6Ik0E+eT0g/fi9IP3ynUYIiJ5R+0kIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJz5t5wQND8ZmblwIo2vnwgsKEdw8klnUt+6izn0lnOA3QuSSPdPe3wzR0uEewJM5vn7uNzHUd70Lnkp85yLp3lPEDn0hJqGhIRiTklAhGRmItbIrg31wG0I51Lfuos59JZzgN0Ls2KVR+BiIg0FrcagYiINKBEICISc7FJBGY20cwWm9lSM5uW63iaY2bLzexdM3vbzOaFZf3N7AUzWxL+7heWm5ndGZ7bO2b2qRzH/oCZrTez91LKWh27mX0x3H+JmX0xj85lupmtCj+bt83srJRtN4bnstjMzkgpz+nfn5kNN7M5ZrbIzBaY2XVheYf7XJo4l474uXQzs3+Y2fzwXL4flo82szfCf+PHw3nfMbOu4frScPuo5s6xRdy90/8QzJn8L2AM0AWYDxyU67iaiXk5MLBB2X8C08LlacCPw+WzgGcBA44G3shx7CcCnwLea2vsQH9gWfi7X7jcL0/OZTpwQ5p9Dwr/troCo8O/ucJ8+PsDhgKfCpd7AR+E8Xa4z6WJc+mIn4sBJeFyMfBG+O89A5gclt8DXBUuXw3cEy5PBh5v6hxbGkdcagRHAkvdfZm77wIeAyblOKa2mAT8Nlz+LXBeSvmDHngd6GtmQ3MRIIC7vwp83KC4tbGfAbzg7h+7+0bgBWBi9NHXl+FcMpkEPObuO939Q2Apwd9ezv/+3H2Nu78VLm8FFgHD6ICfSxPnkkk+fy7u7pXhanH448CpwMywvOHnkvy8ZgITzMzIfI4tEpdEMAxYmbJeRtN/OPnAgT+Z2ZtmdkVYNsTd10DwnwEYHJZ3hPNrbez5fk5TwyaTB5LNKXSQcwmbEw4j+PbZoT+XBucCHfBzMbNCM3sbWE+QWP8FbHL3mjRx7Y453L4ZGMAenktcEoGlKcv3+2aPc/dPAWcC15jZiU3s2xHPLylT7Pl8TncD+wDjgDXAf4XleX8uZlYC/B74urtvaWrXNGX5fi4d8nNx91p3HweUEnyLPzDdbuHvSM4lLomgDBiesl4KrM5RLC3i7qvD3+uBJwn+QNYlm3zC3+vD3TvC+bU29rw9J3dfF/7nTQD3UVcFz+tzMbNiggvnw+7+h7C4Q34u6c6lo34uSe6+CXiZoI+gr5kVpYlrd8zh9j4ETZd7dC5xSQRzgbFhT3wXgk6WWTmOKSMz62lmvZLLwOnAewQxJ+/S+CLwf+HyLODS8E6Po4HNyep+Hmlt7M8Dp5tZv7CKf3pYlnMN+l/OJ/hsIDiXyeGdHaOBscA/yIO/v7Ad+X5gkbv/LGVTh/tcMp1LB/1cBplZ33C5O/Bpgj6POcDnwt0afi7Jz+tzwJ896C3OdI4tk80e8lz+ENwF8QFB+9t3cx1PM7GOIbgDYD6wIBkvQVvgS8CS8Hd/r7vz4K7w3N4Fxuc4/kcJqubVBN9UvtKW2IEvE3R6LQW+lEfn8lAY6zvhf8ChKft/NzyXxcCZ+fL3BxxP0FTwDvB2+HNWR/xcmjiXjvi5HAr8M4z5PeDmsHwMwYV8KfAE0DUs7xauLw23j2nuHFvyoyEmRERiLi5NQyIikoESgYhIzCkRiIjEnBKBiEjMKRGIiMScEoFIA2ZWmzKC5dvtOSqlmY2ylJFMRfJBUfO7iMTODg8e+ReJBdUIRFrIgjkifhyOH/8PM9s3LB9pZi+Fg529ZGYjwvIhZvZkONb8fDM7NjxUoZndF44//6fwiVKRnFEiEGmse4OmoS+kbNvi7kcCvwR+EZb9kmDI5kOBh4E7w/I7gVfc/ZMEcxosCMvHAne5+8HAJuCCiM9HpEl6slikATOrdPeSNOXLgVPdfVk46Nladx9gZhsIhjOoDsvXuPtAMysHSt19Z8oxRhGM5z82XP82UOzut0Z/ZiLpqUYg0jqeYTnTPunsTFmuRX11kmNKBCKt84WU36+Fy38nGLkS4CLgr+HyS8BVsHvykd7ZClKkNfRNRKSx7uGMUUnPuXvyFtKuZvYGwZeoKWHZtcADZvYtoBz4Ulh+HXCvmX2F4Jv/VQQjmYrkFfURiLRQ2Ecw3t035DoWkfakpiERkZhTjUBEJOZUIxARiTklAhGRmFMiEBGJOSUCEZGYUyIQEYm5/w9DXiFzUNs1LwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.16233411,  1.6479195 , -0.2964031 , -0.0292096 , -0.25076336,\n",
      "         0.05412256,  0.67107475,  2.1589172 , -0.76383203],\n",
      "       [-0.60222405, -0.46373376, -0.8221943 , -0.11465962,  0.70416504,\n",
      "         0.41307205,  2.002445  , -2.1724787 ,  0.31145364],\n",
      "       [ 0.5783706 ,  0.22072566,  0.90406185,  0.12621816, -0.05907676,\n",
      "        -1.8873965 ,  0.26826936, -0.59576726,  0.08460434],\n",
      "       [-0.48345023,  0.9864924 , -1.3779043 ,  1.9860586 , -1.2744032 ,\n",
      "         1.4664408 , -0.62610716,  0.9992336 ,  0.48158938],\n",
      "       [-0.85741806,  0.27448028, -0.51380837,  0.35098428, -0.8307464 ,\n",
      "         0.4462562 , -1.6616946 , -1.2919801 ,  1.5262406 ],\n",
      "       [ 0.05267512,  0.54642564,  0.11927473, -0.26054683,  0.19800268,\n",
      "        -0.55944616, -1.0434368 ,  1.5081736 ,  0.6378763 ],\n",
      "       [-0.03300872,  0.11356798, -0.19540699, -0.78597355,  0.3966812 ,\n",
      "         1.9410893 , -1.2015653 , -2.342252  , -0.12446466]],\n",
      "      dtype=float32), array([ 0.46482155,  0.18538173,  0.25920093,  0.20337482,  0.12936214,\n",
      "        0.20808354, -0.03848932,  0.15471675, -0.20390527], dtype=float32), array([[ 0.7915078 ,  0.15341933,  0.6383428 ,  0.92581415, -0.44373214,\n",
      "         1.971404  ,  1.4794934 , -0.6151286 ,  1.019509  ],\n",
      "       [ 0.35707363,  0.14449425, -0.05528171,  1.1878928 , -0.48579842,\n",
      "         0.5212091 , -0.26359037,  0.93332136, -1.2217213 ],\n",
      "       [-0.40853566, -0.8454728 ,  0.4208369 ,  1.4109603 , -1.0112063 ,\n",
      "         2.2280357 ,  1.6660849 , -1.0861588 ,  0.88683856],\n",
      "       [ 0.3918294 ,  0.28717843,  1.6125733 , -2.492959  , -0.58845556,\n",
      "         1.6718937 , -1.2471614 ,  1.4020817 , -1.006624  ],\n",
      "       [ 1.8711302 ,  0.1858019 , -1.6512429 ,  2.1567888 ,  0.09774264,\n",
      "        -1.0352103 ,  0.8686788 , -1.7357115 ,  2.4428158 ],\n",
      "       [ 0.6982643 ,  0.5677892 , -0.8993598 , -2.0645912 ,  0.11859874,\n",
      "        -2.550713  ,  0.293498  ,  1.8769412 , -0.64332706],\n",
      "       [ 1.0498973 , -0.37321517, -0.27482405,  2.1548414 ,  0.11316005,\n",
      "         0.3499681 , -2.7560203 , -2.287058  ,  1.422404  ],\n",
      "       [ 0.5403162 ,  1.0115871 ,  2.4406233 ,  1.6460941 , -0.74278605,\n",
      "         0.6048872 , -0.52870196,  0.69079477, -0.691917  ],\n",
      "       [-2.36188   , -1.7732968 , -0.92296463, -1.598231  ,  0.66643625,\n",
      "         1.3314569 , -0.01295424,  1.1417217 , -0.7125175 ]],\n",
      "      dtype=float32), array([ 0.2995093 , -0.3273541 , -0.24511199, -0.44205126, -0.13059033,\n",
      "        0.61131066,  0.13832869,  0.47431976,  0.09102093], dtype=float32), array([[ 1.5497346 ,  1.7542377 ,  1.5414958 , -0.84022975,  2.1696665 ,\n",
      "         1.4150175 , -0.58577096, -0.12921509, -1.1518605 ],\n",
      "       [-0.57658976,  0.9775503 ,  0.45578435, -0.06485565,  1.5887916 ,\n",
      "        -0.61244863,  0.5198819 , -1.3367388 ,  0.39687818],\n",
      "       [ 0.78549093, -0.29906973,  0.1767632 , -2.387683  , -0.5509767 ,\n",
      "         1.7028813 , -1.1861875 , -2.5614324 , -1.2943038 ],\n",
      "       [ 1.6997274 , -0.84516937, -0.89155406,  0.10531584, -1.7409061 ,\n",
      "        -1.0149226 , -1.0621866 , -1.212393  ,  1.0129696 ],\n",
      "       [-0.8762145 , -1.2037606 , -0.86653423,  0.6245385 , -1.1886568 ,\n",
      "        -0.887509  ,  0.81270957,  1.5530066 ,  1.4159923 ],\n",
      "       [ 1.6784556 , -1.7963313 , -1.3799808 ,  1.7856213 , -2.017774  ,\n",
      "        -0.9036427 , -1.4817683 , -0.93983364,  0.7231051 ],\n",
      "       [-0.03373734,  1.7367541 ,  1.179797  , -1.846181  ,  1.6483985 ,\n",
      "         1.5410013 , -0.5312745 , -0.29768595, -1.464855  ],\n",
      "       [-1.5803056 , -1.800643  , -1.2571657 , -0.43541384, -1.9274218 ,\n",
      "        -1.2004628 ,  1.2609673 ,  0.40279377,  0.9447482 ],\n",
      "       [ 1.4770299 ,  1.9685847 ,  1.484509  , -1.3675848 ,  2.5259335 ,\n",
      "         0.8656672 , -0.7316624 ,  0.05378557, -1.2359301 ]],\n",
      "      dtype=float32), array([ 0.34561613,  0.22981629,  0.2740578 , -0.8219136 , -0.19240922,\n",
      "        0.5990297 , -0.28481266, -0.04306791, -0.6792967 ], dtype=float32), array([[-1.1525644],\n",
      "       [-2.316802 ],\n",
      "       [-2.2907841],\n",
      "       [ 2.5844703],\n",
      "       [-2.1435237],\n",
      "       [-3.0698936],\n",
      "       [ 1.290012 ],\n",
      "       [ 3.1786418],\n",
      "       [ 3.0280616]], dtype=float32), array([-1.2504233], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.08626589e-05]\n",
      " [9.99673247e-01]\n",
      " [9.99999166e-01]\n",
      " [1.25540482e-05]\n",
      " [1.47035066e-03]\n",
      " [1.00000000e+00]\n",
      " [9.99912381e-01]\n",
      " [9.99999881e-01]\n",
      " [9.99996066e-01]\n",
      " [9.99998927e-01]\n",
      " [3.52017028e-04]\n",
      " [3.84356768e-04]\n",
      " [9.99672055e-01]\n",
      " [8.27074764e-05]\n",
      " [1.39239524e-03]\n",
      " [9.99999881e-01]\n",
      " [9.12792457e-04]\n",
      " [9.99067605e-01]\n",
      " [9.99999642e-01]\n",
      " [1.00000000e+00]\n",
      " [1.64843994e-04]\n",
      " [2.06624696e-04]\n",
      " [3.29208747e-03]\n",
      " [9.99397397e-01]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [9.99391794e-01]\n",
      " [9.99158025e-01]\n",
      " [5.00348142e-05]\n",
      " [1.00000000e+00]\n",
      " [6.73762770e-05]\n",
      " [8.74009203e-08]\n",
      " [1.08653633e-03]\n",
      " [4.77900990e-08]\n",
      " [1.82456177e-04]\n",
      " [1.00000000e+00]\n",
      " [9.99470770e-01]\n",
      " [9.99317765e-01]\n",
      " [9.95284975e-01]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [1.48101139e-03]\n",
      " [4.66978003e-04]\n",
      " [1.21996243e-04]\n",
      " [9.98386383e-01]\n",
      " [9.99564111e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99545157e-01]\n",
      " [2.49799527e-03]\n",
      " [2.76191658e-05]\n",
      " [9.98035729e-01]\n",
      " [7.69372491e-06]\n",
      " [1.48959880e-05]\n",
      " [3.13110970e-04]\n",
      " [2.78541259e-03]\n",
      " [5.27591584e-03]\n",
      " [1.00000000e+00]\n",
      " [1.09907376e-06]\n",
      " [8.98752641e-03]\n",
      " [4.53803316e-03]\n",
      " [1.00000000e+00]\n",
      " [9.94841278e-01]\n",
      " [1.00000000e+00]\n",
      " [9.48040281e-07]\n",
      " [5.05044998e-04]\n",
      " [3.86892088e-06]\n",
      " [9.99636054e-01]\n",
      " [5.97260419e-09]\n",
      " [3.24363500e-04]\n",
      " [1.11344655e-03]\n",
      " [9.99999762e-01]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [9.99999762e-01]\n",
      " [2.98085768e-04]\n",
      " [9.99985218e-01]\n",
      " [2.18640067e-04]\n",
      " [9.99124348e-01]\n",
      " [3.53656056e-08]\n",
      " [3.73976841e-03]\n",
      " [1.10180354e-05]\n",
      " [9.99927998e-01]\n",
      " [9.99909520e-01]\n",
      " [9.99340355e-01]\n",
      " [9.99664903e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99927044e-01]\n",
      " [1.05566585e-04]\n",
      " [9.99947786e-01]\n",
      " [9.98140335e-01]\n",
      " [1.00000000e+00]\n",
      " [7.06395440e-06]\n",
      " [8.81870031e-01]\n",
      " [9.99753416e-01]\n",
      " [1.51740806e-03]\n",
      " [2.52187921e-04]\n",
      " [1.00000000e+00]\n",
      " [5.67939060e-06]\n",
      " [1.00000000e+00]\n",
      " [2.30209455e-02]\n",
      " [3.11876065e-04]\n",
      " [9.93930101e-01]\n",
      " [1.00000000e+00]\n",
      " [2.14951068e-01]\n",
      " [4.87146806e-03]\n",
      " [2.97658903e-06]\n",
      " [2.99252915e-05]\n",
      " [1.00000000e+00]\n",
      " [2.10639018e-06]\n",
      " [2.23208757e-04]\n",
      " [2.92181134e-01]\n",
      " [9.99999881e-01]\n",
      " [9.99995351e-01]\n",
      " [6.28592645e-09]\n",
      " [8.27254145e-04]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5, X6, X7])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
