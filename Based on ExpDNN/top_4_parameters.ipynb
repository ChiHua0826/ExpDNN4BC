{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,5:6] #Leptin\n",
    "X2 = dataset[:,6:7] #Adiponectin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,7:8] #Resistin\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 4)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            45          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 235\n",
      "Trainable params: 235\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.7011 - acc: 0.4674 - auc_1: 0.5138 - val_loss: 0.6747 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6872 - acc: 0.4891 - auc_1: 0.5829 - val_loss: 0.6664 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6853 - acc: 0.5217 - auc_1: 0.5421 - val_loss: 0.6662 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6794 - acc: 0.5109 - auc_1: 0.5998 - val_loss: 0.6647 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6735 - acc: 0.5652 - auc_1: 0.6167 - val_loss: 0.6574 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6733 - acc: 0.5109 - auc_1: 0.6107 - val_loss: 0.6597 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6699 - acc: 0.5326 - auc_1: 0.6098 - val_loss: 0.6606 - val_acc: 0.6667 - val_auc_1: 0.6500\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6672 - acc: 0.5109 - auc_1: 0.6055 - val_loss: 0.6670 - val_acc: 0.5000 - val_auc_1: 0.6679\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6646 - acc: 0.6087 - auc_1: 0.6286 - val_loss: 0.6606 - val_acc: 0.5417 - val_auc_1: 0.6679\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6652 - acc: 0.5652 - auc_1: 0.6043 - val_loss: 0.6587 - val_acc: 0.5417 - val_auc_1: 0.6679\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6586 - acc: 0.5761 - auc_1: 0.6376 - val_loss: 0.6568 - val_acc: 0.5417 - val_auc_1: 0.6750\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6540 - acc: 0.5435 - auc_1: 0.6431 - val_loss: 0.6517 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6532 - acc: 0.6196 - auc_1: 0.6483 - val_loss: 0.6548 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6483 - acc: 0.6087 - auc_1: 0.6438 - val_loss: 0.6757 - val_acc: 0.5833 - val_auc_1: 0.6964\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6470 - acc: 0.6087 - auc_1: 0.6571 - val_loss: 0.6465 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6453 - acc: 0.5652 - auc_1: 0.6519 - val_loss: 0.6574 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6425 - acc: 0.5870 - auc_1: 0.6605 - val_loss: 0.6541 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6355 - acc: 0.6413 - auc_1: 0.6783 - val_loss: 0.6540 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6336 - acc: 0.5978 - auc_1: 0.6769 - val_loss: 0.6695 - val_acc: 0.5417 - val_auc_1: 0.6929\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6315 - acc: 0.5978 - auc_1: 0.6779 - val_loss: 0.6550 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6284 - acc: 0.5978 - auc_1: 0.6812 - val_loss: 0.6527 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6242 - acc: 0.5870 - auc_1: 0.6795 - val_loss: 0.6432 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6183 - acc: 0.6196 - auc_1: 0.7031 - val_loss: 0.6392 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6178 - acc: 0.5978 - auc_1: 0.7012 - val_loss: 0.6606 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6091 - acc: 0.6413 - auc_1: 0.7152 - val_loss: 0.6549 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6016 - acc: 0.6630 - auc_1: 0.7295 - val_loss: 0.6593 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6033 - acc: 0.6304 - auc_1: 0.7160 - val_loss: 0.6461 - val_acc: 0.5833 - val_auc_1: 0.7107\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5979 - acc: 0.6630 - auc_1: 0.7207 - val_loss: 0.6649 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5934 - acc: 0.6630 - auc_1: 0.7471 - val_loss: 0.6721 - val_acc: 0.5833 - val_auc_1: 0.6179\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5936 - acc: 0.7283 - auc_1: 0.7540 - val_loss: 0.6661 - val_acc: 0.6250 - val_auc_1: 0.6321\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5828 - acc: 0.7174 - auc_1: 0.7583 - val_loss: 0.6905 - val_acc: 0.6250 - val_auc_1: 0.6071\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5756 - acc: 0.7283 - auc_1: 0.7781 - val_loss: 0.6344 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5810 - acc: 0.7174 - auc_1: 0.7660 - val_loss: 0.6512 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5743 - acc: 0.7500 - auc_1: 0.7681 - val_loss: 0.6498 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5742 - acc: 0.7283 - auc_1: 0.7707 - val_loss: 0.6528 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5747 - acc: 0.7174 - auc_1: 0.7619 - val_loss: 0.6256 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5706 - acc: 0.7174 - auc_1: 0.7662 - val_loss: 0.6709 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5628 - acc: 0.7391 - auc_1: 0.7876 - val_loss: 0.6960 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5664 - acc: 0.7500 - auc_1: 0.7736 - val_loss: 0.6714 - val_acc: 0.5417 - val_auc_1: 0.6857\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5597 - acc: 0.7391 - auc_1: 0.7819 - val_loss: 0.6871 - val_acc: 0.5833 - val_auc_1: 0.6750\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5596 - acc: 0.7717 - auc_1: 0.7812 - val_loss: 0.6917 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5549 - acc: 0.7174 - auc_1: 0.7795 - val_loss: 0.6685 - val_acc: 0.5833 - val_auc_1: 0.6893\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5532 - acc: 0.7174 - auc_1: 0.7764 - val_loss: 0.6682 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5536 - acc: 0.7065 - auc_1: 0.7850 - val_loss: 0.7293 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5529 - acc: 0.7065 - auc_1: 0.7824 - val_loss: 0.6901 - val_acc: 0.5833 - val_auc_1: 0.6750\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5453 - acc: 0.7609 - auc_1: 0.7902 - val_loss: 0.7036 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5406 - acc: 0.7826 - auc_1: 0.7943 - val_loss: 0.7040 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5412 - acc: 0.7391 - auc_1: 0.7886 - val_loss: 0.7049 - val_acc: 0.5833 - val_auc_1: 0.6964\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5364 - acc: 0.7935 - auc_1: 0.7974 - val_loss: 0.7240 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5328 - acc: 0.7935 - auc_1: 0.7950 - val_loss: 0.7252 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5421 - acc: 0.7283 - auc_1: 0.7826 - val_loss: 0.7416 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5350 - acc: 0.7391 - auc_1: 0.7886 - val_loss: 0.7429 - val_acc: 0.5833 - val_auc_1: 0.6857\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5285 - acc: 0.7609 - auc_1: 0.7981 - val_loss: 0.7498 - val_acc: 0.5833 - val_auc_1: 0.6893\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5277 - acc: 0.7391 - auc_1: 0.7950 - val_loss: 0.7505 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5240 - acc: 0.7717 - auc_1: 0.7960 - val_loss: 0.7526 - val_acc: 0.5833 - val_auc_1: 0.6929\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5253 - acc: 0.7500 - auc_1: 0.8088 - val_loss: 0.7710 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5276 - acc: 0.7826 - auc_1: 0.7945 - val_loss: 0.7667 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5176 - acc: 0.7609 - auc_1: 0.8002 - val_loss: 0.7633 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5163 - acc: 0.7826 - auc_1: 0.8086 - val_loss: 0.7651 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5157 - acc: 0.7717 - auc_1: 0.8067 - val_loss: 0.7901 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5108 - acc: 0.7826 - auc_1: 0.8060 - val_loss: 0.7815 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5095 - acc: 0.7935 - auc_1: 0.8093 - val_loss: 0.7844 - val_acc: 0.5833 - val_auc_1: 0.6857\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5085 - acc: 0.7717 - auc_1: 0.8076 - val_loss: 0.8012 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5056 - acc: 0.7609 - auc_1: 0.8069 - val_loss: 0.8037 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5040 - acc: 0.7826 - auc_1: 0.8190 - val_loss: 0.7929 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5069 - acc: 0.7717 - auc_1: 0.8083 - val_loss: 0.8161 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5042 - acc: 0.7935 - auc_1: 0.8129 - val_loss: 0.8192 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4991 - acc: 0.7826 - auc_1: 0.8219 - val_loss: 0.8151 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5030 - acc: 0.7609 - auc_1: 0.8081 - val_loss: 0.8183 - val_acc: 0.5833 - val_auc_1: 0.6214\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4921 - acc: 0.8043 - auc_1: 0.8157 - val_loss: 0.8293 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4913 - acc: 0.8043 - auc_1: 0.8183 - val_loss: 0.8295 - val_acc: 0.5833 - val_auc_1: 0.6393\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4904 - acc: 0.7826 - auc_1: 0.8233 - val_loss: 0.8219 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4979 - acc: 0.7826 - auc_1: 0.8148 - val_loss: 0.8312 - val_acc: 0.5833 - val_auc_1: 0.6464\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4905 - acc: 0.7826 - auc_1: 0.8250 - val_loss: 0.8419 - val_acc: 0.5833 - val_auc_1: 0.6214\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4798 - acc: 0.7935 - auc_1: 0.8324 - val_loss: 0.8583 - val_acc: 0.6250 - val_auc_1: 0.6143\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4919 - acc: 0.7717 - auc_1: 0.8229 - val_loss: 0.8500 - val_acc: 0.5833 - val_auc_1: 0.6357\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4835 - acc: 0.7609 - auc_1: 0.8369 - val_loss: 0.8569 - val_acc: 0.5833 - val_auc_1: 0.6179\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4859 - acc: 0.7717 - auc_1: 0.8360 - val_loss: 0.8593 - val_acc: 0.6250 - val_auc_1: 0.5821\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4776 - acc: 0.7935 - auc_1: 0.8310 - val_loss: 0.8415 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4755 - acc: 0.7826 - auc_1: 0.8369 - val_loss: 0.8780 - val_acc: 0.5833 - val_auc_1: 0.6107\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4732 - acc: 0.7500 - auc_1: 0.8443 - val_loss: 0.8529 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4787 - acc: 0.7826 - auc_1: 0.8360 - val_loss: 0.8753 - val_acc: 0.5833 - val_auc_1: 0.6250\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4832 - acc: 0.7609 - auc_1: 0.8383 - val_loss: 0.8837 - val_acc: 0.5833 - val_auc_1: 0.5964\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4635 - acc: 0.8043 - auc_1: 0.8548 - val_loss: 0.8533 - val_acc: 0.6250 - val_auc_1: 0.6464\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4739 - acc: 0.7717 - auc_1: 0.8448 - val_loss: 0.8696 - val_acc: 0.5833 - val_auc_1: 0.6357\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4628 - acc: 0.7826 - auc_1: 0.8493 - val_loss: 0.9420 - val_acc: 0.5833 - val_auc_1: 0.5929\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4662 - acc: 0.8043 - auc_1: 0.8548 - val_loss: 0.8688 - val_acc: 0.5833 - val_auc_1: 0.6250\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4658 - acc: 0.7935 - auc_1: 0.8488 - val_loss: 0.8976 - val_acc: 0.5833 - val_auc_1: 0.6250\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4602 - acc: 0.7935 - auc_1: 0.8452 - val_loss: 0.9258 - val_acc: 0.5833 - val_auc_1: 0.5929\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4655 - acc: 0.7717 - auc_1: 0.8595 - val_loss: 0.9054 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4551 - acc: 0.8043 - auc_1: 0.8588 - val_loss: 0.9177 - val_acc: 0.5833 - val_auc_1: 0.5714\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4554 - acc: 0.8043 - auc_1: 0.8581 - val_loss: 0.9047 - val_acc: 0.5833 - val_auc_1: 0.6107\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4552 - acc: 0.7935 - auc_1: 0.8657 - val_loss: 0.8961 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4576 - acc: 0.7935 - auc_1: 0.8595 - val_loss: 0.9054 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4556 - acc: 0.8043 - auc_1: 0.8495 - val_loss: 0.8933 - val_acc: 0.5833 - val_auc_1: 0.5964\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4527 - acc: 0.7826 - auc_1: 0.8636 - val_loss: 0.9339 - val_acc: 0.6250 - val_auc_1: 0.5893\n",
      "Epoch 97/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4488 - acc: 0.8043 - auc_1: 0.8707 - val_loss: 0.9032 - val_acc: 0.5833 - val_auc_1: 0.6107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4438 - acc: 0.7826 - auc_1: 0.8719 - val_loss: 0.9427 - val_acc: 0.5833 - val_auc_1: 0.5893\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4444 - acc: 0.8152 - auc_1: 0.8674 - val_loss: 0.9369 - val_acc: 0.5833 - val_auc_1: 0.5929\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4388 - acc: 0.7935 - auc_1: 0.8719 - val_loss: 0.9342 - val_acc: 0.6250 - val_auc_1: 0.5750\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4397 - acc: 0.8043 - auc_1: 0.8719 - val_loss: 0.9325 - val_acc: 0.6250 - val_auc_1: 0.5929\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4416 - acc: 0.7826 - auc_1: 0.8764 - val_loss: 0.9528 - val_acc: 0.5833 - val_auc_1: 0.5929\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4478 - acc: 0.7826 - auc_1: 0.8757 - val_loss: 0.9976 - val_acc: 0.5833 - val_auc_1: 0.5821\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4481 - acc: 0.7717 - auc_1: 0.8719 - val_loss: 0.9812 - val_acc: 0.5833 - val_auc_1: 0.5821\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4376 - acc: 0.8043 - auc_1: 0.8767 - val_loss: 0.9488 - val_acc: 0.5833 - val_auc_1: 0.5857\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4303 - acc: 0.8043 - auc_1: 0.8776 - val_loss: 0.9329 - val_acc: 0.5833 - val_auc_1: 0.5964\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4242 - acc: 0.7935 - auc_1: 0.8862 - val_loss: 0.9509 - val_acc: 0.5833 - val_auc_1: 0.5857\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4246 - acc: 0.8370 - auc_1: 0.8798 - val_loss: 0.9138 - val_acc: 0.5833 - val_auc_1: 0.5821\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4307 - acc: 0.7826 - auc_1: 0.8800 - val_loss: 0.9137 - val_acc: 0.5833 - val_auc_1: 0.5964\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4220 - acc: 0.8043 - auc_1: 0.8840 - val_loss: 0.9430 - val_acc: 0.5833 - val_auc_1: 0.6036\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4293 - acc: 0.7717 - auc_1: 0.8793 - val_loss: 0.9407 - val_acc: 0.5833 - val_auc_1: 0.5964\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4162 - acc: 0.7826 - auc_1: 0.8874 - val_loss: 0.9801 - val_acc: 0.5833 - val_auc_1: 0.5964\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4198 - acc: 0.8261 - auc_1: 0.8760 - val_loss: 0.9143 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4161 - acc: 0.8043 - auc_1: 0.8876 - val_loss: 0.9133 - val_acc: 0.5833 - val_auc_1: 0.6107\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4214 - acc: 0.8043 - auc_1: 0.8821 - val_loss: 1.0288 - val_acc: 0.5833 - val_auc_1: 0.6071\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4191 - acc: 0.8152 - auc_1: 0.8874 - val_loss: 0.9306 - val_acc: 0.5833 - val_auc_1: 0.5929\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4134 - acc: 0.8043 - auc_1: 0.8898 - val_loss: 0.9657 - val_acc: 0.5833 - val_auc_1: 0.6036\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4065 - acc: 0.8152 - auc_1: 0.8912 - val_loss: 0.9254 - val_acc: 0.5833 - val_auc_1: 0.6107\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4084 - acc: 0.8261 - auc_1: 0.8862 - val_loss: 0.9376 - val_acc: 0.5833 - val_auc_1: 0.6071\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4138 - acc: 0.8043 - auc_1: 0.8852 - val_loss: 0.9406 - val_acc: 0.5833 - val_auc_1: 0.6107\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4042 - acc: 0.7826 - auc_1: 0.8974 - val_loss: 0.9544 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3945 - acc: 0.8152 - auc_1: 0.9012 - val_loss: 0.9671 - val_acc: 0.5833 - val_auc_1: 0.6000\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3969 - acc: 0.8043 - auc_1: 0.9019 - val_loss: 0.8927 - val_acc: 0.5833 - val_auc_1: 0.6107\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3951 - acc: 0.8043 - auc_1: 0.8969 - val_loss: 0.9634 - val_acc: 0.5833 - val_auc_1: 0.5893\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3956 - acc: 0.8152 - auc_1: 0.8950 - val_loss: 0.9535 - val_acc: 0.5833 - val_auc_1: 0.5929\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3908 - acc: 0.8370 - auc_1: 0.8962 - val_loss: 0.9572 - val_acc: 0.5833 - val_auc_1: 0.5964\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3878 - acc: 0.8043 - auc_1: 0.9040 - val_loss: 0.9936 - val_acc: 0.6250 - val_auc_1: 0.6036\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3872 - acc: 0.8152 - auc_1: 0.9064 - val_loss: 0.9482 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3851 - acc: 0.8370 - auc_1: 0.9045 - val_loss: 0.8804 - val_acc: 0.5833 - val_auc_1: 0.6321\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3858 - acc: 0.7717 - auc_1: 0.9040 - val_loss: 0.9747 - val_acc: 0.5833 - val_auc_1: 0.6143\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3758 - acc: 0.8370 - auc_1: 0.9081 - val_loss: 0.8643 - val_acc: 0.6250 - val_auc_1: 0.6250\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3694 - acc: 0.8043 - auc_1: 0.9133 - val_loss: 0.9014 - val_acc: 0.6250 - val_auc_1: 0.6250\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3783 - acc: 0.8261 - auc_1: 0.9088 - val_loss: 0.8976 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3623 - acc: 0.8043 - auc_1: 0.9160 - val_loss: 0.8288 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3762 - acc: 0.8043 - auc_1: 0.9069 - val_loss: 0.8486 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3742 - acc: 0.7935 - auc_1: 0.9129 - val_loss: 0.8328 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3682 - acc: 0.8043 - auc_1: 0.9145 - val_loss: 0.8913 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3714 - acc: 0.8152 - auc_1: 0.9150 - val_loss: 0.8009 - val_acc: 0.7083 - val_auc_1: 0.6643\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3586 - acc: 0.7935 - auc_1: 0.9181 - val_loss: 0.9613 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3606 - acc: 0.8152 - auc_1: 0.9195 - val_loss: 0.9575 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3566 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.9180 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3478 - acc: 0.8370 - auc_1: 0.9240 - val_loss: 0.9218 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3557 - acc: 0.8261 - auc_1: 0.9195 - val_loss: 0.9974 - val_acc: 0.6250 - val_auc_1: 0.6464\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3454 - acc: 0.8152 - auc_1: 0.9276 - val_loss: 0.9037 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 145/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3726 - acc: 0.8043 - auc_1: 0.9105 - val_loss: 1.0000 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 146/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3430 - acc: 0.8261 - auc_1: 0.9276 - val_loss: 0.8752 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3589 - acc: 0.7935 - auc_1: 0.9157 - val_loss: 0.9231 - val_acc: 0.6667 - val_auc_1: 0.6750\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3399 - acc: 0.8478 - auc_1: 0.9310 - val_loss: 0.8999 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3471 - acc: 0.7935 - auc_1: 0.9217 - val_loss: 0.9807 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3465 - acc: 0.8043 - auc_1: 0.9262 - val_loss: 0.9904 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3421 - acc: 0.8370 - auc_1: 0.9314 - val_loss: 0.8636 - val_acc: 0.6667 - val_auc_1: 0.6607\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3406 - acc: 0.8261 - auc_1: 0.9286 - val_loss: 0.8798 - val_acc: 0.7083 - val_auc_1: 0.6643\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3430 - acc: 0.8478 - auc_1: 0.9279 - val_loss: 0.9100 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3444 - acc: 0.8043 - auc_1: 0.9233 - val_loss: 0.9261 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3453 - acc: 0.8261 - auc_1: 0.9260 - val_loss: 0.9953 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3448 - acc: 0.8478 - auc_1: 0.9260 - val_loss: 0.9540 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3280 - acc: 0.8370 - auc_1: 0.9329 - val_loss: 1.0139 - val_acc: 0.6667 - val_auc_1: 0.6464\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3353 - acc: 0.8261 - auc_1: 0.9281 - val_loss: 1.0311 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3364 - acc: 0.8261 - auc_1: 0.9314 - val_loss: 0.9796 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3311 - acc: 0.8370 - auc_1: 0.9352 - val_loss: 0.9519 - val_acc: 0.6667 - val_auc_1: 0.6357\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3519 - acc: 0.7935 - auc_1: 0.9152 - val_loss: 1.0632 - val_acc: 0.6667 - val_auc_1: 0.6393\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3338 - acc: 0.8152 - auc_1: 0.9302 - val_loss: 1.0413 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3220 - acc: 0.8370 - auc_1: 0.9348 - val_loss: 1.0050 - val_acc: 0.6250 - val_auc_1: 0.6393\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3214 - acc: 0.8478 - auc_1: 0.9379 - val_loss: 1.0220 - val_acc: 0.6667 - val_auc_1: 0.6714\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3271 - acc: 0.8370 - auc_1: 0.9350 - val_loss: 0.9687 - val_acc: 0.6667 - val_auc_1: 0.6464\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3237 - acc: 0.8370 - auc_1: 0.9360 - val_loss: 1.0131 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3230 - acc: 0.8152 - auc_1: 0.9390 - val_loss: 1.0245 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3181 - acc: 0.8370 - auc_1: 0.9369 - val_loss: 1.1494 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3108 - acc: 0.8478 - auc_1: 0.9400 - val_loss: 0.9587 - val_acc: 0.7083 - val_auc_1: 0.6643\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3108 - acc: 0.8152 - auc_1: 0.9393 - val_loss: 1.0289 - val_acc: 0.6667 - val_auc_1: 0.6714\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3140 - acc: 0.8370 - auc_1: 0.9438 - val_loss: 1.0296 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3183 - acc: 0.8261 - auc_1: 0.9376 - val_loss: 1.0170 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3031 - acc: 0.8478 - auc_1: 0.9495 - val_loss: 0.9547 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3073 - acc: 0.8152 - auc_1: 0.9448 - val_loss: 1.0626 - val_acc: 0.6667 - val_auc_1: 0.6250\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3030 - acc: 0.8261 - auc_1: 0.9445 - val_loss: 1.0531 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3272 - acc: 0.8043 - auc_1: 0.9333 - val_loss: 1.1875 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3149 - acc: 0.8370 - auc_1: 0.9400 - val_loss: 1.0718 - val_acc: 0.6250 - val_auc_1: 0.6286\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3142 - acc: 0.8478 - auc_1: 0.9414 - val_loss: 1.1041 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3045 - acc: 0.8261 - auc_1: 0.9412 - val_loss: 1.1576 - val_acc: 0.6250 - val_auc_1: 0.6393\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3141 - acc: 0.8261 - auc_1: 0.9424 - val_loss: 1.1252 - val_acc: 0.6667 - val_auc_1: 0.6464\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3104 - acc: 0.8261 - auc_1: 0.9440 - val_loss: 1.1480 - val_acc: 0.6250 - val_auc_1: 0.6250\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3080 - acc: 0.8370 - auc_1: 0.9433 - val_loss: 1.1041 - val_acc: 0.6667 - val_auc_1: 0.6571\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2964 - acc: 0.8370 - auc_1: 0.9514 - val_loss: 0.9910 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2969 - acc: 0.8587 - auc_1: 0.9469 - val_loss: 0.9791 - val_acc: 0.6667 - val_auc_1: 0.6821\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3007 - acc: 0.8478 - auc_1: 0.9457 - val_loss: 1.0306 - val_acc: 0.7083 - val_auc_1: 0.6643\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3076 - acc: 0.8370 - auc_1: 0.9400 - val_loss: 1.1037 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3033 - acc: 0.8370 - auc_1: 0.9431 - val_loss: 1.0861 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2888 - acc: 0.8587 - auc_1: 0.9507 - val_loss: 1.0253 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2867 - acc: 0.8478 - auc_1: 0.9517 - val_loss: 1.0667 - val_acc: 0.6667 - val_auc_1: 0.6821\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2945 - acc: 0.8370 - auc_1: 0.9467 - val_loss: 1.0283 - val_acc: 0.6667 - val_auc_1: 0.6679\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.2728 - acc: 0.8519 - auc_1: 0.959 - 0s 4ms/step - loss: 0.2922 - acc: 0.8370 - auc_1: 0.9502 - val_loss: 1.1172 - val_acc: 0.6667 - val_auc_1: 0.6536\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2800 - acc: 0.8478 - auc_1: 0.9545 - val_loss: 1.1715 - val_acc: 0.6250 - val_auc_1: 0.6393\n",
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3048 - acc: 0.8261 - auc_1: 0.9407 - val_loss: 1.1067 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 194/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2801 - acc: 0.8478 - auc_1: 0.9543 - val_loss: 1.0299 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2826 - acc: 0.8478 - auc_1: 0.9507 - val_loss: 0.9718 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2782 - acc: 0.8696 - auc_1: 0.9571 - val_loss: 1.1466 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2804 - acc: 0.8478 - auc_1: 0.9545 - val_loss: 1.0286 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2701 - acc: 0.8478 - auc_1: 0.9624 - val_loss: 1.2105 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2862 - acc: 0.8478 - auc_1: 0.9488 - val_loss: 1.1447 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2542 - acc: 0.8913 - auc_1: 0.9674 - val_loss: 1.0687 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3014 - acc: 0.8587 - auc_1: 0.9421 - val_loss: 1.0991 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2721 - acc: 0.8913 - auc_1: 0.9600 - val_loss: 1.2891 - val_acc: 0.5833 - val_auc_1: 0.6357\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2825 - acc: 0.8587 - auc_1: 0.9526 - val_loss: 1.2757 - val_acc: 0.5833 - val_auc_1: 0.6393\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2806 - acc: 0.8587 - auc_1: 0.9540 - val_loss: 1.2152 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2912 - acc: 0.8587 - auc_1: 0.9476 - val_loss: 1.2239 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2566 - acc: 0.8913 - auc_1: 0.9700 - val_loss: 1.1359 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2642 - acc: 0.8696 - auc_1: 0.9638 - val_loss: 1.2580 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2595 - acc: 0.8804 - auc_1: 0.9640 - val_loss: 1.1961 - val_acc: 0.5833 - val_auc_1: 0.6893\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2587 - acc: 0.8913 - auc_1: 0.9652 - val_loss: 1.1946 - val_acc: 0.5833 - val_auc_1: 0.6464\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2540 - acc: 0.9022 - auc_1: 0.9674 - val_loss: 1.1342 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2466 - acc: 0.9022 - auc_1: 0.9702 - val_loss: 1.1704 - val_acc: 0.5833 - val_auc_1: 0.6750\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2338 - acc: 0.9130 - auc_1: 0.9762 - val_loss: 0.9838 - val_acc: 0.5833 - val_auc_1: 0.7071\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2608 - acc: 0.8696 - auc_1: 0.9638 - val_loss: 1.1397 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2539 - acc: 0.8913 - auc_1: 0.9652 - val_loss: 1.3057 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2469 - acc: 0.9022 - auc_1: 0.9671 - val_loss: 1.2200 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2471 - acc: 0.8804 - auc_1: 0.9688 - val_loss: 1.2680 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2286 - acc: 0.9022 - auc_1: 0.9743 - val_loss: 1.2092 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2610 - acc: 0.8804 - auc_1: 0.9586 - val_loss: 1.1558 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2394 - acc: 0.9130 - auc_1: 0.9760 - val_loss: 1.2510 - val_acc: 0.5417 - val_auc_1: 0.6393\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2484 - acc: 0.8696 - auc_1: 0.9669 - val_loss: 1.3739 - val_acc: 0.5833 - val_auc_1: 0.6429\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2327 - acc: 0.9022 - auc_1: 0.9757 - val_loss: 1.2225 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2362 - acc: 0.9130 - auc_1: 0.9700 - val_loss: 1.2624 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2465 - acc: 0.8696 - auc_1: 0.9662 - val_loss: 1.2823 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2164 - acc: 0.9130 - auc_1: 0.9805 - val_loss: 1.3260 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2310 - acc: 0.8913 - auc_1: 0.9752 - val_loss: 1.2673 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2273 - acc: 0.8804 - auc_1: 0.9755 - val_loss: 1.1772 - val_acc: 0.5833 - val_auc_1: 0.6857\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2075 - acc: 0.9022 - auc_1: 0.9802 - val_loss: 1.2206 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2456 - acc: 0.8804 - auc_1: 0.9657 - val_loss: 1.3094 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2654 - acc: 0.8804 - auc_1: 0.9612 - val_loss: 1.3031 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2234 - acc: 0.8804 - auc_1: 0.9757 - val_loss: 1.2612 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2084 - acc: 0.8913 - auc_1: 0.9795 - val_loss: 1.3948 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2143 - acc: 0.9130 - auc_1: 0.9793 - val_loss: 1.3848 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2282 - acc: 0.8913 - auc_1: 0.9748 - val_loss: 1.3041 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1974 - acc: 0.9130 - auc_1: 0.9817 - val_loss: 1.1724 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.1971 - acc: 0.9195 - auc_1: 0.986 - 0s 4ms/step - loss: 0.2098 - acc: 0.9130 - auc_1: 0.9821 - val_loss: 1.3897 - val_acc: 0.5833 - val_auc_1: 0.6464\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1978 - acc: 0.9130 - auc_1: 0.9838 - val_loss: 1.3444 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1934 - acc: 0.9457 - auc_1: 0.9874 - val_loss: 1.2608 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2007 - acc: 0.9022 - auc_1: 0.9814 - val_loss: 1.3604 - val_acc: 0.5833 - val_auc_1: 0.6393\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2053 - acc: 0.9022 - auc_1: 0.9802 - val_loss: 1.2793 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1845 - acc: 0.9130 - auc_1: 0.9888 - val_loss: 1.2548 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 241/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2265 - acc: 0.9022 - auc_1: 0.9743 - val_loss: 1.3600 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1900 - acc: 0.9130 - auc_1: 0.9845 - val_loss: 1.1826 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2019 - acc: 0.9130 - auc_1: 0.9833 - val_loss: 1.3670 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1970 - acc: 0.9348 - auc_1: 0.9852 - val_loss: 1.2992 - val_acc: 0.5833 - val_auc_1: 0.6750\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1991 - acc: 0.8804 - auc_1: 0.9812 - val_loss: 1.2000 - val_acc: 0.5833 - val_auc_1: 0.6857\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1979 - acc: 0.9239 - auc_1: 0.9836 - val_loss: 1.2040 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1831 - acc: 0.9348 - auc_1: 0.9879 - val_loss: 1.2389 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1785 - acc: 0.9348 - auc_1: 0.9902 - val_loss: 1.2844 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1785 - acc: 0.9239 - auc_1: 0.9893 - val_loss: 1.4404 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2201 - acc: 0.8913 - auc_1: 0.9710 - val_loss: 1.2745 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2018 - acc: 0.9239 - auc_1: 0.9774 - val_loss: 1.2509 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1684 - acc: 0.9565 - auc_1: 0.9921 - val_loss: 1.3915 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1777 - acc: 0.9239 - auc_1: 0.9871 - val_loss: 1.2537 - val_acc: 0.5417 - val_auc_1: 0.6571\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1650 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 1.3552 - val_acc: 0.5833 - val_auc_1: 0.6464\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2055 - acc: 0.9022 - auc_1: 0.9781 - val_loss: 1.2809 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1998 - acc: 0.9022 - auc_1: 0.9821 - val_loss: 1.3065 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1988 - acc: 0.9348 - auc_1: 0.9836 - val_loss: 1.3549 - val_acc: 0.5833 - val_auc_1: 0.6821\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1784 - acc: 0.9022 - auc_1: 0.9871 - val_loss: 1.3106 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1594 - acc: 0.9348 - auc_1: 0.9924 - val_loss: 1.2209 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1780 - acc: 0.9348 - auc_1: 0.9879 - val_loss: 1.2241 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1692 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 1.3065 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.1477 - acc: 0.9529 - auc_1: 0.993 - 0s 4ms/step - loss: 0.1543 - acc: 0.9565 - auc_1: 0.9936 - val_loss: 1.2886 - val_acc: 0.5833 - val_auc_1: 0.6857\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1705 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 1.2701 - val_acc: 0.5833 - val_auc_1: 0.6821\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1763 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 1.4449 - val_acc: 0.5833 - val_auc_1: 0.6750\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1664 - acc: 0.9239 - auc_1: 0.9898 - val_loss: 1.4084 - val_acc: 0.5417 - val_auc_1: 0.6500\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1624 - acc: 0.9457 - auc_1: 0.9921 - val_loss: 1.3964 - val_acc: 0.5417 - val_auc_1: 0.6464\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1551 - acc: 0.9348 - auc_1: 0.9919 - val_loss: 1.3663 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1561 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 1.4306 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1577 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 1.3902 - val_acc: 0.5833 - val_auc_1: 0.6536\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1606 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.4372 - val_acc: 0.5833 - val_auc_1: 0.6464\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1541 - acc: 0.9565 - auc_1: 0.9940 - val_loss: 1.4155 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1472 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 1.4624 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1620 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 1.4428 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2020 - acc: 0.8696 - auc_1: 0.9764 - val_loss: 1.4925 - val_acc: 0.5417 - val_auc_1: 0.6429\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1545 - acc: 0.9348 - auc_1: 0.9938 - val_loss: 1.4429 - val_acc: 0.5833 - val_auc_1: 0.6500\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1522 - acc: 0.9457 - auc_1: 0.9933 - val_loss: 1.4383 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1467 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 1.3277 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1416 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 1.5105 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1335 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 1.4510 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1948 - acc: 0.9348 - auc_1: 0.9771 - val_loss: 1.3969 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1311 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.4199 - val_acc: 0.5417 - val_auc_1: 0.6571\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1679 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 1.4288 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1422 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 1.3114 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1389 - acc: 0.9674 - auc_1: 0.9969 - val_loss: 1.5111 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1388 - acc: 0.9457 - auc_1: 0.9933 - val_loss: 1.3537 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1407 - acc: 0.9239 - auc_1: 0.9919 - val_loss: 1.4945 - val_acc: 0.6250 - val_auc_1: 0.6607\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1328 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 1.5211 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1340 - acc: 0.9457 - auc_1: 0.9931 - val_loss: 1.4187 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 289/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1297 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.4881 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 290/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1395 - acc: 0.9565 - auc_1: 0.9905 - val_loss: 1.4150 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1135 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.4089 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1254 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.4837 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1332 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 1.4587 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1575 - acc: 0.9457 - auc_1: 0.9883 - val_loss: 1.4225 - val_acc: 0.5833 - val_auc_1: 0.6643\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1195 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.4925 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1178 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 1.3880 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1244 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 1.3642 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1158 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.3811 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1141 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.4652 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1315 - acc: 0.9565 - auc_1: 0.9943 - val_loss: 1.4501 - val_acc: 0.6250 - val_auc_1: 0.6393\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1333 - acc: 0.9457 - auc_1: 0.9957 - val_loss: 1.5015 - val_acc: 0.6250 - val_auc_1: 0.6464\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1237 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.4773 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1210 - acc: 0.9348 - auc_1: 0.9979 - val_loss: 1.5898 - val_acc: 0.5833 - val_auc_1: 0.6464\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1296 - acc: 0.9565 - auc_1: 0.9969 - val_loss: 1.5134 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1093 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4711 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1149 - acc: 0.9457 - auc_1: 0.9969 - val_loss: 1.4846 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1181 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 1.5221 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1788 - acc: 0.9239 - auc_1: 0.9812 - val_loss: 1.5672 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1096 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4931 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1072 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.5137 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1016 - acc: 0.9674 - auc_1: 1.0000 - val_loss: 1.5533 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1626 - acc: 0.9239 - auc_1: 0.9840 - val_loss: 1.5299 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1144 - acc: 0.9565 - auc_1: 0.9969 - val_loss: 1.5772 - val_acc: 0.6250 - val_auc_1: 0.6464\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1404 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 1.4956 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1132 - acc: 0.9457 - auc_1: 0.9960 - val_loss: 1.4819 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1064 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.5418 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0992 - acc: 0.9674 - auc_1: 0.9988 - val_loss: 1.5476 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1015 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.4445 - val_acc: 0.5833 - val_auc_1: 0.6821\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0952 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 1.4845 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0940 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.5625 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1062 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.5163 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1033 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 1.6101 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1223 - acc: 0.9783 - auc_1: 0.9938 - val_loss: 1.5388 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0985 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 1.6387 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0950 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6171 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0920 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5844 - val_acc: 0.5833 - val_auc_1: 0.6607\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0845 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.4793 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0994 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.5616 - val_acc: 0.5833 - val_auc_1: 0.6679\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0960 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5206 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0862 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.5625 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0897 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 1.5959 - val_acc: 0.5833 - val_auc_1: 0.6464\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0802 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3921 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1028 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.5234 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0895 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.4555 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1119 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 1.5916 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0873 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6059 - val_acc: 0.6250 - val_auc_1: 0.6464\n",
      "Epoch 337/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1010 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.5743 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 338/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0864 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.5639 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1050 - acc: 0.9674 - auc_1: 0.9960 - val_loss: 1.5279 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0853 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5297 - val_acc: 0.5833 - val_auc_1: 0.6714\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0777 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.5775 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0814 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6499 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0867 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 1.6267 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0808 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.4668 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1423 - acc: 0.9239 - auc_1: 0.9886 - val_loss: 1.7143 - val_acc: 0.5833 - val_auc_1: 0.6571\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0871 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7266 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0851 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5762 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0692 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6612 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0909 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.6401 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1067 - acc: 0.9565 - auc_1: 0.9964 - val_loss: 1.6524 - val_acc: 0.6250 - val_auc_1: 0.6000\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0822 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4765 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0871 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 1.5974 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0708 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.5342 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0710 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5451 - val_acc: 0.5833 - val_auc_1: 0.6786\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0741 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5521 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0880 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.6399 - val_acc: 0.6250 - val_auc_1: 0.6536\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0758 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.6022 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0660 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6097 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0749 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6303 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0701 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.5950 - val_acc: 0.6250 - val_auc_1: 0.6679\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0679 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.5362 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0674 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.5316 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1379 - acc: 0.9674 - auc_1: 0.9886 - val_loss: 1.4917 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0901 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 1.6091 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0665 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 1.6127 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0656 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.5617 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0623 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3955 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0712 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5880 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0658 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.6525 - val_acc: 0.6250 - val_auc_1: 0.6429\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1206 - acc: 0.9565 - auc_1: 0.9907 - val_loss: 1.5811 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1191 - acc: 0.9565 - auc_1: 0.9933 - val_loss: 1.5205 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0637 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 1.5542 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0588 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.5443 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0593 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.5798 - val_acc: 0.6250 - val_auc_1: 0.6750\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0539 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.5433 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0609 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6143 - val_acc: 0.6250 - val_auc_1: 0.6571\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0607 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.6351 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0532 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.5414 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0592 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6610 - val_acc: 0.6250 - val_auc_1: 0.6500\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0631 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6727 - val_acc: 0.6250 - val_auc_1: 0.6464\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0677 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.4487 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0766 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 1.6605 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0570 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6046 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0547 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6060 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 385/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0506 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6260 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 386/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0597 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.6775 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0756 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.6792 - val_acc: 0.6250 - val_auc_1: 0.6357\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0573 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6551 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0575 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6487 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0526 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6509 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0534 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.6203 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0518 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6002 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0608 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6219 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0607 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.6777 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0512 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6424 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0436 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6824 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0463 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6311 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0638 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.7355 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0820 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.6535 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0965 - acc: 0.9674 - auc_1: 0.9933 - val_loss: 1.6034 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0556 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.7129 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0809 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.7971 - val_acc: 0.6667 - val_auc_1: 0.6857\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1881 - acc: 0.9565 - auc_1: 0.9755 - val_loss: 1.6998 - val_acc: 0.5833 - val_auc_1: 0.6857\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0508 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6259 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0469 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6488 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0441 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6461 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0430 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6676 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0412 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6565 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0406 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6850 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0414 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.7201 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0504 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6881 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0441 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6885 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0462 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7318 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0613 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.8145 - val_acc: 0.6250 - val_auc_1: 0.6857\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0604 - acc: 0.9891 - auc_1: 0.9971 - val_loss: 1.7892 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0408 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6761 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0479 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7774 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0452 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7642 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0409 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.8067 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0392 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7360 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0535 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 1.6958 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1192 - acc: 0.9565 - auc_1: 0.9890 - val_loss: 1.8799 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0390 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.8155 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0395 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8310 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1257 - acc: 0.9783 - auc_1: 0.9840 - val_loss: 1.8531 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0384 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8413 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0367 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.8010 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0459 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8028 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0395 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8675 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0355 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8573 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0379 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8499 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0342 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7993 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 433/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 0.9565 - auc_1: 0.9943 - val_loss: 1.7265 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 434/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1383 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 1.5503 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1322 - acc: 0.9348 - auc_1: 0.9924 - val_loss: 1.8050 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0353 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.8174 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0319 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8244 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0312 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8234 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0325 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8144 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0313 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8521 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0349 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8406 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0333 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8306 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0345 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8574 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0345 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8750 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0293 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8653 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0666 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.8396 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0345 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.8572 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0285 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8716 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0294 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8795 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0308 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9108 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0373 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9092 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0331 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.8988 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0280 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8750 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0299 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9182 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0311 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.8883 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0272 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9108 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0570 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.9281 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0353 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8524 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0306 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9208 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0338 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9517 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0265 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9321 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0257 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9614 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0313 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9268 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0398 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.9780 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1098 - acc: 0.9783 - auc_1: 0.9893 - val_loss: 1.4778 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0319 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6236 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0304 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7240 - val_acc: 0.6667 - val_auc_1: 0.7107\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0247 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6738 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0307 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7377 - val_acc: 0.6667 - val_auc_1: 0.7107\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0317 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6739 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1609 - acc: 0.9565 - auc_1: 0.9762 - val_loss: 1.6312 - val_acc: 0.7083 - val_auc_1: 0.7321\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5636 - acc: 0.8478 - auc_1: 0.9036 - val_loss: 1.6447 - val_acc: 0.6667 - val_auc_1: 0.7107\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1246 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 1.9134 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0282 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9325 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0244 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9581 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0225 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9605 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0215 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9606 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0211 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9703 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0208 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9804 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0212 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9797 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 481/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0199 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9759 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 482/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0197 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9263 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0199 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0008 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0204 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9633 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0215 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0211 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0201 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0004 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0215 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9714 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0238 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0021 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0207 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0865 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0265 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1485 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0213 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0499 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1208 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 1.8013 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1126 - acc: 0.9565 - auc_1: 0.9921 - val_loss: 2.0446 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0356 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1407 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0221 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1293 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0185 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1077 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0196 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1155 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0198 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1049 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0198 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1398 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0205 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1228 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0185 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1091 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0186 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9913 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0704 - acc: 0.9891 - auc_1: 0.9933 - val_loss: 2.0956 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0168 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1114 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0196 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1150 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0242 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1992 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0259 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1396 - val_acc: 0.6667 - val_auc_1: 0.7036\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0241 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0622 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0304 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.1568 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0206 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1001 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0160 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0933 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0176 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1066 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0183 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1636 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0186 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1110 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0287 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.9950 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1062 - acc: 0.9783 - auc_1: 0.9895 - val_loss: 2.0892 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1737 - acc: 0.9457 - auc_1: 0.9845 - val_loss: 2.2701 - val_acc: 0.6250 - val_auc_1: 0.6714\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0934 - acc: 0.9674 - auc_1: 0.9964 - val_loss: 2.0947 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0166 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1415 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0157 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1323 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0151 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1227 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0145 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0963 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0137 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1088 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0136 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0890 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0140 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1345 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0129 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1232 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0146 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1035 - val_acc: 0.6667 - val_auc_1: 0.7214\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0131 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1050 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 529/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0129 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1273 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 530/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0134 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1481 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0131 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1343 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0145 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1242 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1458 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1703 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0120 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1388 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1710 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0119 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1837 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0114 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2011 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0129 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1305 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1076 - acc: 0.9674 - auc_1: 0.9857 - val_loss: 2.0435 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0690 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.9350 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0436 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 2.0980 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0924 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 2.0820 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0371 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.2060 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0153 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1636 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0184 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1956 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0218 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2414 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0607 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 2.0889 - val_acc: 0.6250 - val_auc_1: 0.7464\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0311 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.1717 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0981 - acc: 0.9674 - auc_1: 0.9907 - val_loss: 2.0400 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0314 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 2.1495 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0508 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 2.1410 - val_acc: 0.6250 - val_auc_1: 0.7464\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0116 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1339 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0109 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1408 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1249 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0103 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1213 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1231 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0102 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1250 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1434 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1150 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0099 - acc: 1.0000 - auc_1: 1.000 - 0s 4ms/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1217 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1306 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1435 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0100 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1392 - val_acc: 0.6667 - val_auc_1: 0.72500\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0092 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1529 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0094 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1521 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0094 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1279 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0102 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1558 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0103 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2114 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1640 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1507 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0100 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1708 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0127 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2057 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0104 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3001 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2047 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2844 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 577/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0197 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.8429 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 578/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2083 - acc: 0.9565 - auc_1: 0.9717 - val_loss: 2.1426 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1334 - acc: 0.9239 - auc_1: 0.9910 - val_loss: 1.9717 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1725 - acc: 0.9457 - auc_1: 0.9793 - val_loss: 2.2178 - val_acc: 0.6250 - val_auc_1: 0.6929\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0431 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.2483 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0396 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 2.1627 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0092 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1898 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1703 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1738 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1580 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1744 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1559 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1657 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1592 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1713 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1870 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1746 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2183 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2082 - val_acc: 0.6250 - val_auc_1: 0.7071\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2109 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2139 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2116 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2165 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2375 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1955 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2341 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2281 - val_acc: 0.6250 - val_auc_1: 0.7107\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2944 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2718 - val_acc: 0.6250 - val_auc_1: 0.71070  \n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0794 - acc: 0.9457 - auc_1: 0.9967 - val_loss: 2.4556 - val_acc: 0.6250 - val_auc_1: 0.6893\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6163 - acc: 0.8261 - auc_1: 0.9081 - val_loss: 2.0402 - val_acc: 0.7083 - val_auc_1: 0.6679\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3119 - acc: 0.9348 - auc_1: 0.9564 - val_loss: 1.7342 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0334 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.7943 - val_acc: 0.6667 - val_auc_1: 0.7107\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0302 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.8373 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0093 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8565 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8621 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8665 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8865 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8992 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9020 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9239 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9336 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9522 - val_acc: 0.6667 - val_auc_1: 0.73570  \n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9603 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9655 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9796 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9879 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0100 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 625/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0137 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 626/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0291 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0446 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0326 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0295 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0655 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0750 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0634 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9883 - val_acc: 0.6667 - val_auc_1: 0.7429\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0150 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2296 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0926 - acc: 0.9891 - auc_1: 0.9840 - val_loss: 2.1193 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0624 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 2.4467 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1914 - acc: 0.9348 - auc_1: 0.9883 - val_loss: 2.2464 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0790 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 2.3356 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0541 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 2.1742 - val_acc: 0.6250 - val_auc_1: 0.7036\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0112 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0229 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0408 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0782 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0847 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0950 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0977 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1088 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0965 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1144 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1110 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1136 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1215 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1310 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1523 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1477 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1680 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1628 - val_acc: 0.6250 - val_auc_1: 0.7250\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1609 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1747 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1547 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1940 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1794 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1825 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2223 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1575 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2055 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2190 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2236 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2393 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2550 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0157 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 2.2153 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0482 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 2.0960 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1894 - acc: 0.9457 - auc_1: 0.9857 - val_loss: 2.0080 - val_acc: 0.6667 - val_auc_1: 0.7357\n",
      "Epoch 673/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1384 - acc: 0.9783 - auc_1: 0.9793 - val_loss: 2.2699 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 674/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2678 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2697 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2649 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2505 - val_acc: 0.6250 - val_auc_1: 0.7464\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2578 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2679 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2553 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2513 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2440 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2332 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2235 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2151 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2138 - val_acc: 0.6250 - val_auc_1: 0.7286\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2340 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2296 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2413 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2577 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2471 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000    - 0s 4ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2023 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2387 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2864 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3058 - val_acc: 0.6667 - val_auc_1: 0.7214\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2532 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2736 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3457 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1307 - acc: 0.9783 - auc_1: 0.9821 - val_loss: 1.9488 - val_acc: 0.7500 - val_auc_1: 0.7536\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1927 - acc: 0.9674 - auc_1: 0.9824 - val_loss: 2.2603 - val_acc: 0.6250 - val_auc_1: 0.6893\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 8.56361352e-03,  2.50269794e+00, -1.02937505e-01,\n",
      "        -8.17059457e-01, -3.82311314e-01, -1.49907589e-01,\n",
      "        -6.61107719e-01,  4.96194541e-01, -8.62986147e-01],\n",
      "       [ 5.19470684e-02, -4.85296100e-01, -4.98523384e-01,\n",
      "        -1.33650668e-03,  7.75950551e-01, -1.14557631e-01,\n",
      "         1.04506540e+00, -1.94045126e+00, -6.10617746e-04],\n",
      "       [ 6.53825581e-01, -1.60306662e-01,  1.02219176e+00,\n",
      "         1.69568285e-01, -9.36928540e-02, -1.74324894e+00,\n",
      "         1.43235338e+00, -1.94515064e-01, -5.06691575e-01],\n",
      "       [ 2.33795857e+00,  1.69501531e+00, -2.54022169e+00,\n",
      "         2.84878659e+00, -2.69246483e+00,  1.11735284e+00,\n",
      "        -1.08466074e-01, -9.18680668e-01,  2.03782368e+00]], dtype=float32), array([-0.47854945, -0.14318715, -0.19443575, -0.20789707,  0.13270487,\n",
      "        0.26561818, -0.73137397,  0.3139458 , -0.04280604], dtype=float32), array([[-2.144071  , -0.79500335,  0.10311586, -1.87705   ,  0.7356237 ,\n",
      "         2.864803  ,  0.7072448 , -3.770244  , -0.74963236],\n",
      "       [-0.2516694 ,  0.48965442, -0.50571686,  0.1383733 , -0.94134945,\n",
      "         0.1442642 ,  0.37146673, -0.42562595, -2.0469778 ],\n",
      "       [-2.4437168 ,  0.81060845,  2.6584291 ,  2.8324087 , -1.0202082 ,\n",
      "         0.68157166, -0.7466236 , -0.02513492,  1.4532284 ],\n",
      "       [-0.9725029 , -1.490342  , -0.18777981, -4.000716  ,  1.7124888 ,\n",
      "         2.7421758 , -0.5289278 , -1.6219324 , -0.93322855],\n",
      "       [ 1.3149936 ,  0.27831584,  0.1147048 ,  2.5865154 , -0.39780328,\n",
      "        -1.3358699 ,  0.45775986,  0.8403119 ,  2.2149794 ],\n",
      "       [ 0.68754876, -0.91546214, -0.90188026, -1.0659695 ,  0.6355012 ,\n",
      "        -1.0777706 ,  1.032557  ,  2.9561195 , -0.6214408 ],\n",
      "       [-1.521353  , -0.62445253,  1.4090561 ,  1.0859752 ,  0.43319014,\n",
      "        -0.01136421, -0.4577143 , -2.8404486 ,  0.9277038 ],\n",
      "       [-0.89910764,  1.4474006 ,  0.5733106 ,  0.67240906, -0.56778437,\n",
      "         1.3310695 , -1.0403637 ,  3.1496303 , -0.8262568 ],\n",
      "       [-0.21895003, -1.312478  , -0.9938239 , -0.767071  ,  1.0196497 ,\n",
      "         0.5777784 ,  0.20892704,  0.30561984,  0.06492332]],\n",
      "      dtype=float32), array([ 1.5357774 ,  0.5897824 ,  0.0215236 , -0.7223426 , -0.42402294,\n",
      "        0.07965124, -0.1790027 , -0.07567622,  0.03245764], dtype=float32), array([[ 0.17841369,  0.4876819 ,  1.6586882 , -0.4445995 ,  1.6188506 ,\n",
      "         0.1904222 ,  0.7286147 ,  2.3030875 , -2.6448877 ],\n",
      "       [ 0.18408804,  2.383981  ,  1.4047185 , -2.268394  ,  1.084268  ,\n",
      "        -1.5910915 ,  0.29136842, -0.5433847 ,  0.73780644],\n",
      "       [ 1.2707086 , -1.4608071 , -1.8163064 , -0.28727007,  0.148042  ,\n",
      "         0.24332659, -2.476628  , -0.22767754,  1.7766949 ],\n",
      "       [ 2.3376713 ,  0.9261891 , -0.09118171, -1.7900592 , -0.18439063,\n",
      "         0.7078273 , -2.1178517 , -0.92689896,  3.4208071 ],\n",
      "       [-0.98292285, -1.8850073 , -1.3039566 ,  2.6070042 , -0.03958664,\n",
      "         0.11112072,  0.8829784 ,  1.192234  ,  0.23594742],\n",
      "       [-0.6069832 , -0.29465148,  0.15314011,  2.0824041 , -0.8106731 ,\n",
      "        -0.60825354,  0.8861961 , -1.601508  ,  0.23285446],\n",
      "       [ 0.42437115,  0.19743633, -0.4270263 ,  0.24205494,  1.5619656 ,\n",
      "         3.56714   , -1.4210389 ,  0.7004305 , -0.90151167],\n",
      "       [ 0.12274902,  0.24756692, -0.03213005,  0.37761298, -1.27642   ,\n",
      "         3.9955444 ,  0.51244134, -2.5481462 , -0.5507607 ],\n",
      "       [ 6.11385   ,  0.87654704,  1.5422031 , -1.3973404 ,  0.7865075 ,\n",
      "         0.23304644, -7.0267706 ,  1.011735  ,  0.27668887]],\n",
      "      dtype=float32), array([-0.04419497,  1.4650673 ,  0.9772572 , -0.58399695, -0.6746431 ,\n",
      "       -0.50677997,  0.03757767,  0.04523075,  0.0030918 ], dtype=float32), array([[-2.110623 ],\n",
      "       [-1.9772809],\n",
      "       [-2.085233 ],\n",
      "       [ 1.6855386],\n",
      "       [ 2.8698158],\n",
      "       [-4.0191917],\n",
      "       [ 3.5076897],\n",
      "       [ 4.5210032],\n",
      "       [ 5.9190435]], dtype=float32), array([-0.09707052], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.47294456e-04]\n",
      " [9.83229578e-01]\n",
      " [9.86993968e-01]\n",
      " [2.55261839e-04]\n",
      " [6.89222245e-04]\n",
      " [9.99745786e-01]\n",
      " [9.99908090e-01]\n",
      " [9.96663034e-01]\n",
      " [9.94369209e-01]\n",
      " [9.99933839e-01]\n",
      " [3.59912496e-03]\n",
      " [5.05043368e-04]\n",
      " [9.99711812e-01]\n",
      " [5.58215361e-05]\n",
      " [2.08777580e-02]\n",
      " [9.99992967e-01]\n",
      " [1.07701095e-02]\n",
      " [9.93926108e-01]\n",
      " [2.65658587e-01]\n",
      " [9.99902725e-01]\n",
      " [7.57044228e-03]\n",
      " [5.38612599e-04]\n",
      " [3.66064273e-02]\n",
      " [9.99942899e-01]\n",
      " [9.53382015e-01]\n",
      " [9.99996662e-01]\n",
      " [9.93994892e-01]\n",
      " [9.99914765e-01]\n",
      " [6.29870861e-04]\n",
      " [9.99999404e-01]\n",
      " [1.66601731e-05]\n",
      " [3.31358276e-02]\n",
      " [1.63057745e-02]\n",
      " [1.43246362e-02]\n",
      " [2.32672857e-04]\n",
      " [9.99983311e-01]\n",
      " [9.95685935e-01]\n",
      " [9.99414921e-01]\n",
      " [9.99921203e-01]\n",
      " [9.99987006e-01]\n",
      " [9.99995232e-01]\n",
      " [9.99254882e-01]\n",
      " [1.75095405e-02]\n",
      " [2.23471988e-02]\n",
      " [1.06417542e-06]\n",
      " [9.65946317e-01]\n",
      " [9.99978423e-01]\n",
      " [9.94571149e-01]\n",
      " [9.99990702e-01]\n",
      " [2.00344613e-04]\n",
      " [1.99440823e-04]\n",
      " [9.93969321e-01]\n",
      " [2.90583848e-04]\n",
      " [2.51460675e-04]\n",
      " [1.93110594e-04]\n",
      " [2.24409974e-03]\n",
      " [1.24671727e-01]\n",
      " [9.99997497e-01]\n",
      " [2.15443695e-04]\n",
      " [3.51408944e-02]\n",
      " [4.46380302e-03]\n",
      " [9.99996543e-01]\n",
      " [9.99649286e-01]\n",
      " [9.88592744e-01]\n",
      " [3.39634111e-03]\n",
      " [1.44494534e-01]\n",
      " [6.87973748e-04]\n",
      " [9.99358833e-01]\n",
      " [1.44507363e-03]\n",
      " [1.44081807e-03]\n",
      " [2.66973721e-03]\n",
      " [9.99918699e-01]\n",
      " [9.83793795e-01]\n",
      " [9.97680128e-01]\n",
      " [9.99995708e-01]\n",
      " [1.01273727e-05]\n",
      " [9.99948859e-01]\n",
      " [3.95311639e-02]\n",
      " [3.47991288e-01]\n",
      " [7.58639544e-06]\n",
      " [5.89785818e-03]\n",
      " [1.93621294e-04]\n",
      " [9.94810462e-01]\n",
      " [9.99999523e-01]\n",
      " [9.97133970e-01]\n",
      " [9.99994636e-01]\n",
      " [9.70901549e-01]\n",
      " [9.99989748e-01]\n",
      " [7.94164464e-03]\n",
      " [9.92824912e-01]\n",
      " [9.97135162e-01]\n",
      " [9.99997973e-01]\n",
      " [1.79793074e-06]\n",
      " [9.99944925e-01]\n",
      " [9.99129951e-01]\n",
      " [2.75581470e-03]\n",
      " [9.92781997e-01]\n",
      " [9.50106263e-01]\n",
      " [9.99994159e-01]\n",
      " [6.24850945e-05]\n",
      " [9.94925380e-01]\n",
      " [8.01677913e-07]\n",
      " [1.06021643e-01]\n",
      " [9.99975324e-01]\n",
      " [2.53991131e-03]\n",
      " [9.99952912e-01]\n",
      " [1.07220031e-01]\n",
      " [7.82416646e-06]\n",
      " [9.99927640e-01]\n",
      " [5.67595882e-04]\n",
      " [9.97632742e-01]\n",
      " [9.97107923e-01]\n",
      " [9.98029053e-01]\n",
      " [3.59050959e-01]\n",
      " [3.09807860e-04]\n",
      " [9.15212214e-01]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
