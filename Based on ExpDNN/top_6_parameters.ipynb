{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,5:6] #Leptin\n",
    "X2 = dataset[:,6:7] #Adiponectin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,7:8] #Resistin\n",
    "X5 = dataset[:,2:3] #Glucose\n",
    "X6 = dataset[:,4:5] #HOMA\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "X6 = normalization(X6)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X6 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 6)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "                                                                 input_layer_X6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            63          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 253\n",
      "Trainable params: 253\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "input_layer_X6 = keras.layers.Input(shape=(1, ), name='input_layer_X6')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.6936 - acc: 0.5543 - auc_1: 0.5636 - val_loss: 0.6461 - val_acc: 0.7500 - val_auc_1: 0.7250\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6631 - acc: 0.6739 - auc_1: 0.6838 - val_loss: 0.6156 - val_acc: 0.7500 - val_auc_1: 0.7429\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6441 - acc: 0.6304 - auc_1: 0.7067 - val_loss: 0.5913 - val_acc: 0.7500 - val_auc_1: 0.7643\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6209 - acc: 0.6522 - auc_1: 0.7288 - val_loss: 0.5694 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6003 - acc: 0.6739 - auc_1: 0.7440 - val_loss: 0.5401 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5888 - acc: 0.6522 - auc_1: 0.7567 - val_loss: 0.5498 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5758 - acc: 0.6630 - auc_1: 0.7564 - val_loss: 0.5230 - val_acc: 0.8333 - val_auc_1: 0.8679\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5659 - acc: 0.6630 - auc_1: 0.7721 - val_loss: 0.5610 - val_acc: 0.5833 - val_auc_1: 0.8714\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5570 - acc: 0.6630 - auc_1: 0.7779 - val_loss: 0.5191 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5550 - acc: 0.6848 - auc_1: 0.7793 - val_loss: 0.5504 - val_acc: 0.6667 - val_auc_1: 0.8929\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5472 - acc: 0.6957 - auc_1: 0.7905 - val_loss: 0.5234 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5384 - acc: 0.7065 - auc_1: 0.7976 - val_loss: 0.5203 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5366 - acc: 0.7065 - auc_1: 0.7957 - val_loss: 0.5456 - val_acc: 0.6667 - val_auc_1: 0.8964\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5294 - acc: 0.7065 - auc_1: 0.7990 - val_loss: 0.6225 - val_acc: 0.5833 - val_auc_1: 0.9000\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5287 - acc: 0.7283 - auc_1: 0.8076 - val_loss: 0.4934 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5308 - acc: 0.6848 - auc_1: 0.7981 - val_loss: 0.5451 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5262 - acc: 0.7391 - auc_1: 0.8024 - val_loss: 0.5260 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5199 - acc: 0.7283 - auc_1: 0.8140 - val_loss: 0.5180 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5161 - acc: 0.7174 - auc_1: 0.8238 - val_loss: 0.6122 - val_acc: 0.6667 - val_auc_1: 0.9214\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5182 - acc: 0.7065 - auc_1: 0.8095 - val_loss: 0.5847 - val_acc: 0.6667 - val_auc_1: 0.9143\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5184 - acc: 0.7174 - auc_1: 0.8086 - val_loss: 0.5966 - val_acc: 0.6667 - val_auc_1: 0.9107\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5152 - acc: 0.7174 - auc_1: 0.8102 - val_loss: 0.5746 - val_acc: 0.6667 - val_auc_1: 0.9071\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5080 - acc: 0.7391 - auc_1: 0.8236 - val_loss: 0.5129 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5115 - acc: 0.7826 - auc_1: 0.8176 - val_loss: 0.5728 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5024 - acc: 0.7391 - auc_1: 0.8257 - val_loss: 0.5513 - val_acc: 0.7083 - val_auc_1: 0.92144  \n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5000 - acc: 0.7500 - auc_1: 0.8260 - val_loss: 0.5464 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5028 - acc: 0.7500 - auc_1: 0.8198 - val_loss: 0.5576 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4981 - acc: 0.6957 - auc_1: 0.8255 - val_loss: 0.5644 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4864 - acc: 0.7174 - auc_1: 0.8314 - val_loss: 0.6265 - val_acc: 0.6667 - val_auc_1: 0.9214\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4953 - acc: 0.7283 - auc_1: 0.8290 - val_loss: 0.5923 - val_acc: 0.6667 - val_auc_1: 0.9214\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4814 - acc: 0.7717 - auc_1: 0.8431 - val_loss: 0.6017 - val_acc: 0.6667 - val_auc_1: 0.9179\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4808 - acc: 0.7391 - auc_1: 0.8426 - val_loss: 0.5238 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4801 - acc: 0.7500 - auc_1: 0.8405 - val_loss: 0.5569 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4789 - acc: 0.7391 - auc_1: 0.8407 - val_loss: 0.5484 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4775 - acc: 0.7283 - auc_1: 0.8440 - val_loss: 0.5594 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4833 - acc: 0.7609 - auc_1: 0.8455 - val_loss: 0.5046 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4731 - acc: 0.7717 - auc_1: 0.8500 - val_loss: 0.5478 - val_acc: 0.7083 - val_auc_1: 0.9214\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4626 - acc: 0.7500 - auc_1: 0.8624 - val_loss: 0.5981 - val_acc: 0.6667 - val_auc_1: 0.9214\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4638 - acc: 0.7935 - auc_1: 0.8536 - val_loss: 0.5276 - val_acc: 0.7083 - val_auc_1: 0.9179\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4620 - acc: 0.7717 - auc_1: 0.8486 - val_loss: 0.5450 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4494 - acc: 0.7717 - auc_1: 0.8690 - val_loss: 0.6220 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4436 - acc: 0.7717 - auc_1: 0.8700 - val_loss: 0.5035 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4485 - acc: 0.7283 - auc_1: 0.8626 - val_loss: 0.5235 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4414 - acc: 0.8043 - auc_1: 0.8740 - val_loss: 0.6886 - val_acc: 0.6250 - val_auc_1: 0.8964\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4537 - acc: 0.7935 - auc_1: 0.8690 - val_loss: 0.5708 - val_acc: 0.6667 - val_auc_1: 0.90712   \n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4424 - acc: 0.7717 - auc_1: 0.8671 - val_loss: 0.5267 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4301 - acc: 0.7935 - auc_1: 0.8776 - val_loss: 0.5228 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4336 - acc: 0.7935 - auc_1: 0.8800 - val_loss: 0.5231 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4287 - acc: 0.8152 - auc_1: 0.8833 - val_loss: 0.6108 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4192 - acc: 0.8152 - auc_1: 0.8914 - val_loss: 0.5054 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4374 - acc: 0.8043 - auc_1: 0.8721 - val_loss: 0.5409 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4315 - acc: 0.7935 - auc_1: 0.8745 - val_loss: 0.5560 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4240 - acc: 0.8152 - auc_1: 0.8848 - val_loss: 0.5524 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4243 - acc: 0.7935 - auc_1: 0.8845 - val_loss: 0.5349 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4186 - acc: 0.8043 - auc_1: 0.8857 - val_loss: 0.5400 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4114 - acc: 0.8370 - auc_1: 0.8874 - val_loss: 0.6034 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4249 - acc: 0.8261 - auc_1: 0.8793 - val_loss: 0.5539 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4166 - acc: 0.8152 - auc_1: 0.8843 - val_loss: 0.5455 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4053 - acc: 0.7935 - auc_1: 0.8931 - val_loss: 0.5222 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4161 - acc: 0.7826 - auc_1: 0.8919 - val_loss: 0.5772 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4075 - acc: 0.8152 - auc_1: 0.8952 - val_loss: 0.5435 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4051 - acc: 0.8043 - auc_1: 0.8943 - val_loss: 0.5254 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3989 - acc: 0.8152 - auc_1: 0.9033 - val_loss: 0.6217 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4044 - acc: 0.7826 - auc_1: 0.8981 - val_loss: 0.5825 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4141 - acc: 0.7935 - auc_1: 0.8905 - val_loss: 0.5711 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4014 - acc: 0.7935 - auc_1: 0.8998 - val_loss: 0.6453 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4019 - acc: 0.7935 - auc_1: 0.8931 - val_loss: 0.6321 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3908 - acc: 0.7935 - auc_1: 0.9081 - val_loss: 0.5759 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4066 - acc: 0.8152 - auc_1: 0.8883 - val_loss: 0.6007 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3915 - acc: 0.8261 - auc_1: 0.8981 - val_loss: 0.6046 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3958 - acc: 0.8261 - auc_1: 0.9026 - val_loss: 0.6167 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3892 - acc: 0.8261 - auc_1: 0.9043 - val_loss: 0.5928 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3996 - acc: 0.8043 - auc_1: 0.8957 - val_loss: 0.5970 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3903 - acc: 0.8152 - auc_1: 0.9000 - val_loss: 0.6261 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3800 - acc: 0.8261 - auc_1: 0.9055 - val_loss: 0.6179 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3915 - acc: 0.8152 - auc_1: 0.9052 - val_loss: 0.6337 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3894 - acc: 0.8261 - auc_1: 0.9067 - val_loss: 0.6306 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3849 - acc: 0.8152 - auc_1: 0.9021 - val_loss: 0.6701 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3796 - acc: 0.8478 - auc_1: 0.9083 - val_loss: 0.6120 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3759 - acc: 0.8152 - auc_1: 0.9079 - val_loss: 0.7035 - val_acc: 0.5833 - val_auc_1: 0.8429\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3851 - acc: 0.8261 - auc_1: 0.9024 - val_loss: 0.6578 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3892 - acc: 0.8043 - auc_1: 0.8986 - val_loss: 0.6961 - val_acc: 0.6250 - val_auc_1: 0.8250\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3847 - acc: 0.8152 - auc_1: 0.9024 - val_loss: 0.6465 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3733 - acc: 0.8370 - auc_1: 0.9140 - val_loss: 0.6104 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3803 - acc: 0.7826 - auc_1: 0.9031 - val_loss: 0.6193 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3807 - acc: 0.8261 - auc_1: 0.9048 - val_loss: 0.7328 - val_acc: 0.5833 - val_auc_1: 0.8250\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3592 - acc: 0.8587 - auc_1: 0.9240 - val_loss: 0.6176 - val_acc: 0.6667 - val_auc_1: 0.8179\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3840 - acc: 0.8261 - auc_1: 0.9048 - val_loss: 0.6840 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3710 - acc: 0.8152 - auc_1: 0.9131 - val_loss: 0.6886 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3724 - acc: 0.8152 - auc_1: 0.9090 - val_loss: 0.7232 - val_acc: 0.6250 - val_auc_1: 0.8321\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3621 - acc: 0.8370 - auc_1: 0.9171 - val_loss: 0.7110 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3704 - acc: 0.8478 - auc_1: 0.9076 - val_loss: 0.7466 - val_acc: 0.5833 - val_auc_1: 0.8107\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3655 - acc: 0.8152 - auc_1: 0.9160 - val_loss: 0.6835 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3782 - acc: 0.8152 - auc_1: 0.9029 - val_loss: 0.7149 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3621 - acc: 0.8370 - auc_1: 0.9174 - val_loss: 0.6929 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3738 - acc: 0.8261 - auc_1: 0.9110 - val_loss: 0.7187 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 97/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3572 - acc: 0.8370 - auc_1: 0.9129 - val_loss: 0.6844 - val_acc: 0.6250 - val_auc_1: 0.8179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3687 - acc: 0.8152 - auc_1: 0.9062 - val_loss: 0.7165 - val_acc: 0.5833 - val_auc_1: 0.8000\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3741 - acc: 0.8261 - auc_1: 0.9079 - val_loss: 0.7258 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3633 - acc: 0.8370 - auc_1: 0.9145 - val_loss: 0.7173 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3728 - acc: 0.8043 - auc_1: 0.9060 - val_loss: 0.7290 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3631 - acc: 0.8478 - auc_1: 0.9105 - val_loss: 0.7650 - val_acc: 0.5833 - val_auc_1: 0.8036\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3524 - acc: 0.8478 - auc_1: 0.9210 - val_loss: 0.7846 - val_acc: 0.5833 - val_auc_1: 0.8071\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3700 - acc: 0.8370 - auc_1: 0.9069 - val_loss: 0.7507 - val_acc: 0.5833 - val_auc_1: 0.8071\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3441 - acc: 0.8370 - auc_1: 0.9281 - val_loss: 0.6855 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3643 - acc: 0.7935 - auc_1: 0.9129 - val_loss: 0.7259 - val_acc: 0.6250 - val_auc_1: 0.8000\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3460 - acc: 0.8370 - auc_1: 0.9219 - val_loss: 0.8577 - val_acc: 0.5833 - val_auc_1: 0.8286\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3485 - acc: 0.8370 - auc_1: 0.9240 - val_loss: 0.7076 - val_acc: 0.5833 - val_auc_1: 0.7857\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3605 - acc: 0.8478 - auc_1: 0.9133 - val_loss: 0.7200 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3570 - acc: 0.8370 - auc_1: 0.9167 - val_loss: 0.8186 - val_acc: 0.5833 - val_auc_1: 0.8286\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3580 - acc: 0.8152 - auc_1: 0.9164 - val_loss: 0.7054 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3460 - acc: 0.8370 - auc_1: 0.9214 - val_loss: 0.7785 - val_acc: 0.5833 - val_auc_1: 0.8000\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3416 - acc: 0.8370 - auc_1: 0.9281 - val_loss: 0.7004 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3453 - acc: 0.8152 - auc_1: 0.9200 - val_loss: 0.7190 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3445 - acc: 0.8370 - auc_1: 0.9238 - val_loss: 0.8233 - val_acc: 0.5833 - val_auc_1: 0.8143\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3376 - acc: 0.8587 - auc_1: 0.9274 - val_loss: 0.6903 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3415 - acc: 0.8370 - auc_1: 0.9279 - val_loss: 0.7437 - val_acc: 0.6250 - val_auc_1: 0.8071\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3373 - acc: 0.8261 - auc_1: 0.9255 - val_loss: 0.7661 - val_acc: 0.5833 - val_auc_1: 0.8107\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3318 - acc: 0.8478 - auc_1: 0.9293 - val_loss: 0.7206 - val_acc: 0.6250 - val_auc_1: 0.7929\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3371 - acc: 0.8478 - auc_1: 0.9264 - val_loss: 0.7042 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3413 - acc: 0.8261 - auc_1: 0.9217 - val_loss: 0.7040 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3288 - acc: 0.8261 - auc_1: 0.9286 - val_loss: 0.7498 - val_acc: 0.5833 - val_auc_1: 0.8036\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3333 - acc: 0.8261 - auc_1: 0.9298 - val_loss: 0.7174 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3328 - acc: 0.8478 - auc_1: 0.9288 - val_loss: 0.6995 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3311 - acc: 0.8370 - auc_1: 0.9262 - val_loss: 0.7741 - val_acc: 0.5833 - val_auc_1: 0.8000\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3330 - acc: 0.8261 - auc_1: 0.9252 - val_loss: 0.7382 - val_acc: 0.6250 - val_auc_1: 0.7857\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3211 - acc: 0.8478 - auc_1: 0.9321 - val_loss: 0.7674 - val_acc: 0.5833 - val_auc_1: 0.7786\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3282 - acc: 0.8478 - auc_1: 0.9276 - val_loss: 0.7300 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3239 - acc: 0.8370 - auc_1: 0.9283 - val_loss: 0.7523 - val_acc: 0.6250 - val_auc_1: 0.7786\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3188 - acc: 0.8152 - auc_1: 0.9376 - val_loss: 0.8317 - val_acc: 0.5833 - val_auc_1: 0.7964\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3245 - acc: 0.8370 - auc_1: 0.9300 - val_loss: 0.7170 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3184 - acc: 0.8696 - auc_1: 0.9343 - val_loss: 0.7340 - val_acc: 0.6250 - val_auc_1: 0.7893\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3199 - acc: 0.8478 - auc_1: 0.9343 - val_loss: 0.7377 - val_acc: 0.6250 - val_auc_1: 0.7750\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3085 - acc: 0.8587 - auc_1: 0.9388 - val_loss: 0.7004 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3130 - acc: 0.8587 - auc_1: 0.9350 - val_loss: 0.6932 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3112 - acc: 0.8696 - auc_1: 0.9364 - val_loss: 0.7492 - val_acc: 0.6250 - val_auc_1: 0.7750\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3118 - acc: 0.8804 - auc_1: 0.9338 - val_loss: 0.7796 - val_acc: 0.5833 - val_auc_1: 0.7750\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3080 - acc: 0.8587 - auc_1: 0.9393 - val_loss: 0.7093 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3079 - acc: 0.8587 - auc_1: 0.9388 - val_loss: 0.7562 - val_acc: 0.6250 - val_auc_1: 0.7786\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3051 - acc: 0.8696 - auc_1: 0.9421 - val_loss: 0.6881 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3120 - acc: 0.8587 - auc_1: 0.9393 - val_loss: 0.6977 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3027 - acc: 0.8587 - auc_1: 0.9440 - val_loss: 0.7782 - val_acc: 0.6250 - val_auc_1: 0.7679\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2976 - acc: 0.8696 - auc_1: 0.9407 - val_loss: 0.7777 - val_acc: 0.6250 - val_auc_1: 0.8036\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2960 - acc: 0.8587 - auc_1: 0.9436 - val_loss: 0.7502 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 145/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2998 - acc: 0.8587 - auc_1: 0.9421 - val_loss: 0.8177 - val_acc: 0.6250 - val_auc_1: 0.7929\n",
      "Epoch 146/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2963 - acc: 0.8696 - auc_1: 0.9433 - val_loss: 0.7050 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2942 - acc: 0.8587 - auc_1: 0.9412 - val_loss: 0.7004 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2873 - acc: 0.8696 - auc_1: 0.9486 - val_loss: 0.7383 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2866 - acc: 0.8804 - auc_1: 0.9502 - val_loss: 0.7553 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3041 - acc: 0.8478 - auc_1: 0.9436 - val_loss: 0.7095 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2853 - acc: 0.8696 - auc_1: 0.9505 - val_loss: 0.7150 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2897 - acc: 0.8587 - auc_1: 0.9414 - val_loss: 0.6749 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2856 - acc: 0.8587 - auc_1: 0.9498 - val_loss: 0.7277 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2857 - acc: 0.8587 - auc_1: 0.9490 - val_loss: 0.7185 - val_acc: 0.6667 - val_auc_1: 0.7607\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2905 - acc: 0.8696 - auc_1: 0.9490 - val_loss: 0.7483 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2826 - acc: 0.8696 - auc_1: 0.9512 - val_loss: 0.7105 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2906 - acc: 0.8696 - auc_1: 0.9417 - val_loss: 0.8220 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2622 - acc: 0.8804 - auc_1: 0.9595 - val_loss: 0.6772 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2861 - acc: 0.8804 - auc_1: 0.9452 - val_loss: 0.7309 - val_acc: 0.6667 - val_auc_1: 0.7679\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2789 - acc: 0.8804 - auc_1: 0.9493 - val_loss: 0.7329 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2696 - acc: 0.8804 - auc_1: 0.9576 - val_loss: 0.7693 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2685 - acc: 0.8696 - auc_1: 0.9512 - val_loss: 0.7391 - val_acc: 0.7083 - val_auc_1: 0.7714\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2659 - acc: 0.8804 - auc_1: 0.9586 - val_loss: 0.7489 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2687 - acc: 0.8587 - auc_1: 0.9569 - val_loss: 0.7240 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2768 - acc: 0.8587 - auc_1: 0.9552 - val_loss: 0.7555 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2508 - acc: 0.9130 - auc_1: 0.9621 - val_loss: 0.7959 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2693 - acc: 0.8587 - auc_1: 0.9495 - val_loss: 0.7240 - val_acc: 0.7917 - val_auc_1: 0.8143\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2536 - acc: 0.8587 - auc_1: 0.9638 - val_loss: 0.8120 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2602 - acc: 0.8804 - auc_1: 0.9583 - val_loss: 0.7185 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2560 - acc: 0.8804 - auc_1: 0.9605 - val_loss: 0.7380 - val_acc: 0.6667 - val_auc_1: 0.7750\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2413 - acc: 0.8696 - auc_1: 0.9669 - val_loss: 0.6796 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2576 - acc: 0.8696 - auc_1: 0.9652 - val_loss: 0.6735 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2471 - acc: 0.8913 - auc_1: 0.9645 - val_loss: 0.6731 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2496 - acc: 0.8913 - auc_1: 0.9671 - val_loss: 0.6750 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2423 - acc: 0.8804 - auc_1: 0.9617 - val_loss: 0.7513 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2519 - acc: 0.8804 - auc_1: 0.9645 - val_loss: 0.7176 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2345 - acc: 0.9022 - auc_1: 0.9648 - val_loss: 0.7331 - val_acc: 0.6667 - val_auc_1: 0.7571\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2378 - acc: 0.8913 - auc_1: 0.9648 - val_loss: 0.7414 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2304 - acc: 0.8804 - auc_1: 0.9695 - val_loss: 0.7366 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2368 - acc: 0.8696 - auc_1: 0.9657 - val_loss: 0.7013 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2360 - acc: 0.8696 - auc_1: 0.9633 - val_loss: 0.7031 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2334 - acc: 0.8804 - auc_1: 0.9686 - val_loss: 0.8356 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2436 - acc: 0.9022 - auc_1: 0.9633 - val_loss: 0.7096 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2393 - acc: 0.8804 - auc_1: 0.9638 - val_loss: 0.7210 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2229 - acc: 0.8587 - auc_1: 0.9671 - val_loss: 0.6854 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2438 - acc: 0.9022 - auc_1: 0.9610 - val_loss: 0.7012 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2471 - acc: 0.8696 - auc_1: 0.9595 - val_loss: 0.6889 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2211 - acc: 0.8587 - auc_1: 0.9671 - val_loss: 0.7663 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2181 - acc: 0.8804 - auc_1: 0.9660 - val_loss: 0.7165 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2234 - acc: 0.8804 - auc_1: 0.9650 - val_loss: 0.6879 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2209 - acc: 0.8913 - auc_1: 0.9688 - val_loss: 0.7496 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2172 - acc: 0.9022 - auc_1: 0.9714 - val_loss: 0.6920 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 193/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2286 - acc: 0.9022 - auc_1: 0.9671 - val_loss: 0.7121 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 194/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2132 - acc: 0.8804 - auc_1: 0.9733 - val_loss: 0.7405 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2205 - acc: 0.8913 - auc_1: 0.9707 - val_loss: 0.7757 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2417 - acc: 0.8804 - auc_1: 0.9638 - val_loss: 0.7961 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2123 - acc: 0.9022 - auc_1: 0.9743 - val_loss: 0.7555 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2072 - acc: 0.9239 - auc_1: 0.9729 - val_loss: 0.7866 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2168 - acc: 0.8913 - auc_1: 0.9717 - val_loss: 0.7619 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1982 - acc: 0.8913 - auc_1: 0.9783 - val_loss: 0.8793 - val_acc: 0.5833 - val_auc_1: 0.7357\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2475 - acc: 0.8587 - auc_1: 0.9562 - val_loss: 0.7970 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2095 - acc: 0.8696 - auc_1: 0.9707 - val_loss: 0.7146 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2109 - acc: 0.8696 - auc_1: 0.9721 - val_loss: 0.8810 - val_acc: 0.6250 - val_auc_1: 0.7536\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2021 - acc: 0.8804 - auc_1: 0.9738 - val_loss: 0.7395 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2107 - acc: 0.8913 - auc_1: 0.9700 - val_loss: 0.8033 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2143 - acc: 0.8696 - auc_1: 0.9719 - val_loss: 0.7786 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2071 - acc: 0.9022 - auc_1: 0.9724 - val_loss: 0.7845 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2079 - acc: 0.8696 - auc_1: 0.9726 - val_loss: 0.8023 - val_acc: 0.6250 - val_auc_1: 0.7714\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2367 - acc: 0.8587 - auc_1: 0.9621 - val_loss: 0.9519 - val_acc: 0.6250 - val_auc_1: 0.7500\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2147 - acc: 0.8804 - auc_1: 0.9695 - val_loss: 0.8480 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.1875 - acc: 0.9529 - auc_1: 0.980 - 0s 4ms/step - loss: 0.1974 - acc: 0.9457 - auc_1: 0.9781 - val_loss: 0.7526 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2170 - acc: 0.8696 - auc_1: 0.9676 - val_loss: 0.8373 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1899 - acc: 0.9348 - auc_1: 0.9795 - val_loss: 0.7511 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2004 - acc: 0.9022 - auc_1: 0.9757 - val_loss: 0.8735 - val_acc: 0.6250 - val_auc_1: 0.7786\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2245 - acc: 0.9022 - auc_1: 0.9660 - val_loss: 0.8621 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2154 - acc: 0.9130 - auc_1: 0.9690 - val_loss: 0.8471 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2116 - acc: 0.8696 - auc_1: 0.9681 - val_loss: 0.8393 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2000 - acc: 0.9022 - auc_1: 0.9774 - val_loss: 0.7874 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2099 - acc: 0.8804 - auc_1: 0.9707 - val_loss: 0.7621 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1934 - acc: 0.9130 - auc_1: 0.9757 - val_loss: 0.8300 - val_acc: 0.6250 - val_auc_1: 0.7714\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2051 - acc: 0.8804 - auc_1: 0.9743 - val_loss: 0.8748 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1861 - acc: 0.9130 - auc_1: 0.9800 - val_loss: 0.9095 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1989 - acc: 0.9130 - auc_1: 0.9748 - val_loss: 0.8671 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2002 - acc: 0.8913 - auc_1: 0.9750 - val_loss: 0.9118 - val_acc: 0.7083 - val_auc_1: 0.7714\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2029 - acc: 0.8913 - auc_1: 0.9733 - val_loss: 0.8332 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1910 - acc: 0.8913 - auc_1: 0.9745 - val_loss: 0.8244 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1965 - acc: 0.9022 - auc_1: 0.9740 - val_loss: 0.9761 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2228 - acc: 0.8587 - auc_1: 0.9652 - val_loss: 0.8865 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1864 - acc: 0.8913 - auc_1: 0.9790 - val_loss: 0.8339 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1924 - acc: 0.8913 - auc_1: 0.9783 - val_loss: 0.8830 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2030 - acc: 0.8913 - auc_1: 0.9726 - val_loss: 0.8866 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2006 - acc: 0.9022 - auc_1: 0.9740 - val_loss: 0.8746 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1954 - acc: 0.9022 - auc_1: 0.9767 - val_loss: 0.8847 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1861 - acc: 0.9130 - auc_1: 0.9786 - val_loss: 0.7900 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2049 - acc: 0.8804 - auc_1: 0.9714 - val_loss: 0.8503 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1999 - acc: 0.8913 - auc_1: 0.9745 - val_loss: 0.8804 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1866 - acc: 0.9348 - auc_1: 0.9788 - val_loss: 0.9201 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2007 - acc: 0.9130 - auc_1: 0.9707 - val_loss: 0.9529 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1955 - acc: 0.9022 - auc_1: 0.9764 - val_loss: 0.8801 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.1809 - acc: 0.9130 - auc_1: 0.9795 - val_loss: 0.8850 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 241/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1811 - acc: 0.9022 - auc_1: 0.9779 - val_loss: 0.9138 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1810 - acc: 0.9130 - auc_1: 0.9814 - val_loss: 0.9430 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1750 - acc: 0.9239 - auc_1: 0.9810 - val_loss: 0.9571 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1748 - acc: 0.9348 - auc_1: 0.9805 - val_loss: 0.8714 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1799 - acc: 0.9022 - auc_1: 0.9800 - val_loss: 0.9126 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1919 - acc: 0.8804 - auc_1: 0.9748 - val_loss: 0.9889 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1859 - acc: 0.8913 - auc_1: 0.9783 - val_loss: 0.9411 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.1914 - acc: 0.9000 - auc_1: 0.977 - 0s 4ms/step - loss: 0.1873 - acc: 0.9022 - auc_1: 0.9788 - val_loss: 0.9397 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1739 - acc: 0.9239 - auc_1: 0.9807 - val_loss: 0.9621 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1724 - acc: 0.9022 - auc_1: 0.9817 - val_loss: 0.9395 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1661 - acc: 0.9022 - auc_1: 0.9848 - val_loss: 0.8603 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1921 - acc: 0.8913 - auc_1: 0.9776 - val_loss: 1.0199 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1785 - acc: 0.9130 - auc_1: 0.9812 - val_loss: 0.9503 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1789 - acc: 0.9022 - auc_1: 0.9819 - val_loss: 0.8746 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1649 - acc: 0.9022 - auc_1: 0.9829 - val_loss: 0.9653 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1578 - acc: 0.9348 - auc_1: 0.9900 - val_loss: 0.8552 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1908 - acc: 0.8913 - auc_1: 0.9781 - val_loss: 0.9832 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1797 - acc: 0.9022 - auc_1: 0.9798 - val_loss: 0.8803 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1621 - acc: 0.9239 - auc_1: 0.9852 - val_loss: 0.9211 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1749 - acc: 0.9022 - auc_1: 0.9810 - val_loss: 1.0035 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1747 - acc: 0.9348 - auc_1: 0.9819 - val_loss: 1.0220 - val_acc: 0.6250 - val_auc_1: 0.7786\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1834 - acc: 0.9348 - auc_1: 0.9757 - val_loss: 1.0319 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1557 - acc: 0.9239 - auc_1: 0.9857 - val_loss: 0.8494 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1717 - acc: 0.9239 - auc_1: 0.9845 - val_loss: 1.1183 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1806 - acc: 0.9239 - auc_1: 0.9805 - val_loss: 0.9452 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1830 - acc: 0.9022 - auc_1: 0.9779 - val_loss: 0.9189 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1595 - acc: 0.9130 - auc_1: 0.9850 - val_loss: 0.9808 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1602 - acc: 0.9130 - auc_1: 0.9883 - val_loss: 0.8693 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1911 - acc: 0.8913 - auc_1: 0.9764 - val_loss: 0.9590 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1553 - acc: 0.9348 - auc_1: 0.9862 - val_loss: 0.9927 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1575 - acc: 0.9239 - auc_1: 0.9869 - val_loss: 0.9370 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1619 - acc: 0.9239 - auc_1: 0.9848 - val_loss: 0.9208 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1582 - acc: 0.9348 - auc_1: 0.9862 - val_loss: 0.9846 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1632 - acc: 0.9239 - auc_1: 0.9845 - val_loss: 0.9689 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1559 - acc: 0.9457 - auc_1: 0.9867 - val_loss: 0.9683 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1628 - acc: 0.9130 - auc_1: 0.9848 - val_loss: 0.9871 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1523 - acc: 0.9239 - auc_1: 0.9840 - val_loss: 0.9160 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1706 - acc: 0.8913 - auc_1: 0.9795 - val_loss: 1.0546 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1533 - acc: 0.9239 - auc_1: 0.9871 - val_loss: 1.0513 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1487 - acc: 0.9565 - auc_1: 0.9898 - val_loss: 0.9317 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1629 - acc: 0.9348 - auc_1: 0.9848 - val_loss: 1.0521 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1548 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 1.1045 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1559 - acc: 0.9348 - auc_1: 0.9874 - val_loss: 1.0413 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1555 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 1.0378 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1521 - acc: 0.9239 - auc_1: 0.9864 - val_loss: 1.0146 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1508 - acc: 0.9457 - auc_1: 0.9879 - val_loss: 1.0281 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1470 - acc: 0.9348 - auc_1: 0.9874 - val_loss: 1.0619 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1372 - acc: 0.9565 - auc_1: 0.9902 - val_loss: 0.9106 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 289/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1538 - acc: 0.9239 - auc_1: 0.9860 - val_loss: 0.9914 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 290/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1358 - acc: 0.9239 - auc_1: 0.9900 - val_loss: 1.1515 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1490 - acc: 0.9348 - auc_1: 0.9871 - val_loss: 1.0065 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1552 - acc: 0.9239 - auc_1: 0.9862 - val_loss: 1.0352 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1532 - acc: 0.9348 - auc_1: 0.9888 - val_loss: 0.9785 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1525 - acc: 0.9239 - auc_1: 0.9881 - val_loss: 1.0711 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1436 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 0.9784 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1610 - acc: 0.9130 - auc_1: 0.9843 - val_loss: 0.9687 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1695 - acc: 0.9130 - auc_1: 0.9833 - val_loss: 1.1990 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1637 - acc: 0.9239 - auc_1: 0.9833 - val_loss: 0.9395 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1468 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 1.1205 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1395 - acc: 0.9348 - auc_1: 0.9879 - val_loss: 1.0603 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1383 - acc: 0.9457 - auc_1: 0.9912 - val_loss: 1.0735 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1361 - acc: 0.9674 - auc_1: 0.9905 - val_loss: 1.0782 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1411 - acc: 0.9348 - auc_1: 0.9900 - val_loss: 1.1759 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1559 - acc: 0.9348 - auc_1: 0.9864 - val_loss: 0.9909 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1513 - acc: 0.9239 - auc_1: 0.9876 - val_loss: 1.0410 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1368 - acc: 0.9565 - auc_1: 0.9898 - val_loss: 0.9855 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1244 - acc: 0.9565 - auc_1: 0.9921 - val_loss: 1.0853 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1283 - acc: 0.9565 - auc_1: 0.9912 - val_loss: 0.9895 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1448 - acc: 0.9130 - auc_1: 0.9869 - val_loss: 0.9530 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1646 - acc: 0.9239 - auc_1: 0.9836 - val_loss: 0.9187 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1406 - acc: 0.9348 - auc_1: 0.9890 - val_loss: 0.9525 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1358 - acc: 0.9348 - auc_1: 0.9900 - val_loss: 0.9887 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1334 - acc: 0.9348 - auc_1: 0.9905 - val_loss: 1.0722 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1325 - acc: 0.9457 - auc_1: 0.9898 - val_loss: 1.0080 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1414 - acc: 0.9457 - auc_1: 0.9886 - val_loss: 1.0476 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1388 - acc: 0.9348 - auc_1: 0.9902 - val_loss: 1.0266 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1295 - acc: 0.9457 - auc_1: 0.9905 - val_loss: 1.0653 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1299 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 1.0517 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1244 - acc: 0.9565 - auc_1: 0.9910 - val_loss: 1.0637 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1285 - acc: 0.9348 - auc_1: 0.9907 - val_loss: 0.9403 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.1433 - acc: 0.9540 - auc_1: 0.9915   - 0s 4ms/step - loss: 0.1384 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 1.1145 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1302 - acc: 0.9457 - auc_1: 0.9893 - val_loss: 1.0130 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1188 - acc: 0.9348 - auc_1: 0.9933 - val_loss: 1.1196 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1143 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 0.9400 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1409 - acc: 0.9457 - auc_1: 0.9874 - val_loss: 0.9728 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1249 - acc: 0.9565 - auc_1: 0.9900 - val_loss: 0.9474 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1268 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.9837 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1250 - acc: 0.9457 - auc_1: 0.9933 - val_loss: 1.0712 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1157 - acc: 0.9239 - auc_1: 0.9921 - val_loss: 1.0937 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1275 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 1.1022 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.1271 - acc: 0.9333 - auc_1: 0.9905   - 0s 4ms/step - loss: 0.1246 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 1.1651 - val_acc: 0.6667 - val_auc_1: 0.8179\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1261 - acc: 0.9565 - auc_1: 0.9910 - val_loss: 1.0514 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1390 - acc: 0.9130 - auc_1: 0.9860 - val_loss: 0.9569 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1187 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 1.0544 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1193 - acc: 0.9348 - auc_1: 0.9929 - val_loss: 1.0518 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1172 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 0.9785 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 337/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1144 - acc: 0.9674 - auc_1: 0.9912 - val_loss: 0.9935 - val_acc: 0.7500 - val_auc_1: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1147 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 0.8503 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1242 - acc: 0.9457 - auc_1: 0.9926 - val_loss: 0.9405 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1001 - acc: 0.9674 - auc_1: 0.9955 - val_loss: 1.1349 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1161 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 1.0720 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1024 - acc: 0.9674 - auc_1: 0.9945 - val_loss: 1.2020 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1032 - acc: 0.9457 - auc_1: 0.9962 - val_loss: 1.0051 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1166 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 0.9991 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1029 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 1.1321 - val_acc: 0.6250 - val_auc_1: 0.7857\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1064 - acc: 0.9565 - auc_1: 0.9950 - val_loss: 1.0282 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1128 - acc: 0.9674 - auc_1: 0.9936 - val_loss: 0.9836 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1085 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 1.0426 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1154 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 1.1370 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1194 - acc: 0.9674 - auc_1: 0.9931 - val_loss: 1.0935 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1105 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.9793 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1148 - acc: 0.9457 - auc_1: 0.9926 - val_loss: 0.9739 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1751 - acc: 0.9022 - auc_1: 0.9821 - val_loss: 0.8850 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1341 - acc: 0.9130 - auc_1: 0.9881 - val_loss: 1.0409 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1073 - acc: 0.9565 - auc_1: 0.9919 - val_loss: 0.9772 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1128 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 1.1107 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0954 - acc: 0.9457 - auc_1: 0.9962 - val_loss: 0.9643 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0980 - acc: 0.9565 - auc_1: 0.9945 - val_loss: 0.9863 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1001 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.9844 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1128 - acc: 0.9348 - auc_1: 0.9943 - val_loss: 1.1141 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0935 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.9804 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0981 - acc: 0.9783 - auc_1: 0.9948 - val_loss: 0.9010 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1013 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 1.1585 - val_acc: 0.6667 - val_auc_1: 0.7714\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1074 - acc: 0.9457 - auc_1: 0.9945 - val_loss: 1.0890 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0919 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 1.0498 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0984 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 1.0545 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1145 - acc: 0.9674 - auc_1: 0.9933 - val_loss: 1.1280 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1012 - acc: 0.9457 - auc_1: 0.9955 - val_loss: 1.0584 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0906 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 1.1063 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0912 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.9486 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1049 - acc: 0.9239 - auc_1: 0.9933 - val_loss: 1.0451 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0904 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.1444 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1049 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 1.0324 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1210 - acc: 0.9565 - auc_1: 0.9919 - val_loss: 1.1212 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1037 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 1.1042 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0932 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 1.0370 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0809 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 1.0848 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1041 - acc: 0.9457 - auc_1: 0.9952 - val_loss: 0.8671 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0942 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 1.1574 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0996 - acc: 0.9783 - auc_1: 0.9933 - val_loss: 1.0866 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0925 - acc: 0.9783 - auc_1: 0.9952 - val_loss: 1.1465 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0878 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.0217 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0840 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.9791 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0810 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.1204 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 385/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0836 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 1.0613 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 386/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0831 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 1.2209 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1034 - acc: 0.9348 - auc_1: 0.9948 - val_loss: 1.1143 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0867 - acc: 0.9565 - auc_1: 0.9955 - val_loss: 1.0458 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0815 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.9128 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0904 - acc: 0.9674 - auc_1: 0.9948 - val_loss: 0.9009 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1025 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 0.9587 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0905 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 1.0521 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0882 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 1.0989 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0770 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.0239 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0815 - acc: 0.9674 - auc_1: 0.9960 - val_loss: 1.0453 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0781 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 1.1510 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0827 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 1.0162 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0744 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.2755 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0853 - acc: 0.9457 - auc_1: 0.9967 - val_loss: 1.2668 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0755 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.1136 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0915 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 1.0701 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0848 - acc: 0.9565 - auc_1: 0.9960 - val_loss: 1.0750 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0759 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.0685 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0822 - acc: 0.9674 - auc_1: 0.9979 - val_loss: 1.0734 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0832 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 1.0811 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0904 - acc: 0.9565 - auc_1: 0.9964 - val_loss: 1.0878 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0755 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.0928 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0662 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.3051 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0720 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.0190 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0872 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 1.1066 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0685 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.9570 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0768 - acc: 0.9783 - auc_1: 0.9969 - val_loss: 1.1587 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0700 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.1210 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0760 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.9987 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0764 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.0889 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0781 - acc: 0.9783 - auc_1: 0.9955 - val_loss: 1.1046 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0573 - acc: 0.9885 - auc_1: 1.000 - 0s 4ms/step - loss: 0.0574 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.4872 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1222 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 1.2910 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0647 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.0829 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0677 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.3193 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0765 - acc: 0.9674 - auc_1: 0.9969 - val_loss: 1.2555 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0659 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.3349 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0677 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.2892 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0679 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 1.3475 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0631 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.2609 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0663 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1173 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0619 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3442 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0715 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.2301 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0657 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.3691 - val_acc: 0.6667 - val_auc_1: 0.7714\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0483 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3123 - val_acc: 0.7500 - val_auc_1: 0.7679\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0731 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.4669 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0636 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.3233 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 433/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0506 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3126 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 434/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0577 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.4032 - val_acc: 0.6250 - val_auc_1: 0.7714\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0634 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.2077 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0507 - acc: 0.9880 - auc_1: 0.9997    - 0s 4ms/step - loss: 0.0533 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 1.3536 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0827 - acc: 0.9457 - auc_1: 0.9962 - val_loss: 1.2069 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0550 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3223 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0571 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.0664 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0595 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3629 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0577 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.3344 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0498 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3536 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0556 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.2374 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0608 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.4112 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0506 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.2963 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0531 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3020 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0495 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.2145 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0441 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3921 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0646 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3660 - val_acc: 0.7083 - val_auc_1: 0.7643\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0810 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 1.3423 - val_acc: 0.7083 - val_auc_1: 0.7500\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0589 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3365 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0426 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 1.4926 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0458 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3477 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0452 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.4873 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1966 - acc: 0.9348 - auc_1: 0.9774 - val_loss: 1.5919 - val_acc: 0.6250 - val_auc_1: 0.7357\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1439 - acc: 0.9457 - auc_1: 0.9881 - val_loss: 1.5713 - val_acc: 0.6667 - val_auc_1: 0.7714\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0548 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.2318 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0423 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3451 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0386 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3979 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0384 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3509 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0378 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3770 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0394 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3981 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0379 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.4347 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0397 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3997 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0352 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4813 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0397 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4815 - val_acc: 0.6250 - val_auc_1: 0.8000\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0376 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3977 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0343 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4473 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0384 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5903 - val_acc: 0.6667 - val_auc_1: 0.7393\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0369 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5419 - val_acc: 0.6667 - val_auc_1: 0.7714\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0441 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 1.2702 - val_acc: 0.6667 - val_auc_1: 0.8179\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0401 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3416 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0322 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5241 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0323 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6142 - val_acc: 0.6250 - val_auc_1: 0.7821\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0416 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.5941 - val_acc: 0.6250 - val_auc_1: 0.7893\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0396 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.5784 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0396 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4215 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0304 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5486 - val_acc: 0.6667 - val_auc_1: 0.7679\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0330 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2756 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0302 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4296 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 481/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0606 - acc: 0.9891 - auc_1: 0.9993 - val_loss: 1.3288 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 482/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1425 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 1.6981 - val_acc: 0.7083 - val_auc_1: 0.7000\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1260 - acc: 0.9348 - auc_1: 0.9914 - val_loss: 1.6633 - val_acc: 0.6250 - val_auc_1: 0.7393\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0633 - acc: 0.9891 - auc_1: 0.9976 - val_loss: 1.4234 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0310 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4292 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0286 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4671 - val_acc: 0.6250 - val_auc_1: 0.8071\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0260 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5336 - val_acc: 0.6250 - val_auc_1: 0.7964\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0273 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5311 - val_acc: 0.6250 - val_auc_1: 0.8000\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0264 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4912 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0249 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7170 - val_acc: 0.6250 - val_auc_1: 0.7429\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0292 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3998 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0253 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5609 - val_acc: 0.6250 - val_auc_1: 0.7893\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0254 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4638 - val_acc: 0.6250 - val_auc_1: 0.7929\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0333 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4402 - val_acc: 0.6250 - val_auc_1: 0.7929\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0286 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7213 - val_acc: 0.6250 - val_auc_1: 0.7750\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0310 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6109 - val_acc: 0.6250 - val_auc_1: 0.8071\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0263 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4789 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0270 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6007 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0236 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6919 - val_acc: 0.6667 - val_auc_1: 0.7536\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0236 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5632 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0357 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7446 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0273 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4240 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0263 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7917 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0265 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4645 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0251 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6217 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0340 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.6642 - val_acc: 0.6250 - val_auc_1: 0.8000\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0236 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6826 - val_acc: 0.6250 - val_auc_1: 0.7821\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0227 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7002 - val_acc: 0.6667 - val_auc_1: 0.7607\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0201 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5872 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0207 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5041 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0250 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5571 - val_acc: 0.6250 - val_auc_1: 0.8036\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0233 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6117 - val_acc: 0.6250 - val_auc_1: 0.7857\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0229 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5969 - val_acc: 0.6250 - val_auc_1: 0.7786\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0199 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5959 - val_acc: 0.6667 - val_auc_1: 0.7714\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0254 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.5397 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0414 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.5371 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0387 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7621 - val_acc: 0.6250 - val_auc_1: 0.7500\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0483 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 1.5987 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0271 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7436 - val_acc: 0.6667 - val_auc_1: 0.7250\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1516 - acc: 0.9457 - auc_1: 0.9831 - val_loss: 1.3977 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1566 - acc: 0.9130 - auc_1: 0.9869 - val_loss: 1.3288 - val_acc: 0.7917 - val_auc_1: 0.8143\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2022 - acc: 0.9239 - auc_1: 0.9783 - val_loss: 1.3505 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0451 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.1858 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0214 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2459 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0192 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2071 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0193 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2659 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0191 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1920 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0181 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3301 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 529/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0175 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3279 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 530/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0177 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3005 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0183 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2853 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0168 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3031 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0169 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3203 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0163 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4268 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0149 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2943 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0160 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3652 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0165 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3980 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0169 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3160 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0156 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3956 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0196 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3350 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0203 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5995 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0161 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5772 - val_acc: 0.6250 - val_auc_1: 0.7929\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0159 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7120 - val_acc: 0.6250 - val_auc_1: 0.8036\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0136 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4687 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0168 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5976 - val_acc: 0.6250 - val_auc_1: 0.8036\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0157 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7413 - val_acc: 0.6250 - val_auc_1: 0.7857\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0224 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4808 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0184 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8181 - val_acc: 0.6667 - val_auc_1: 0.7607\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0149 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4493 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0165 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6963 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0128 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8113 - val_acc: 0.6250 - val_auc_1: 0.7964\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0129 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6376 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0127 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8385 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0158 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8890 - val_acc: 0.6250 - val_auc_1: 0.7786\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0254 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7783 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0217 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.5771 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0143 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9765 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0145 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9896 - val_acc: 0.6250 - val_auc_1: 0.7607\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0136 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8541 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0159 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9447 - val_acc: 0.6250 - val_auc_1: 0.7536\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9510 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0139 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0295 - val_acc: 0.6250 - val_auc_1: 0.6786\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0120 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7341 - val_acc: 0.6250 - val_auc_1: 0.8036\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0152 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0257 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3157 - acc: 0.8587 - auc_1: 0.9636 - val_loss: 2.2465 - val_acc: 0.6667 - val_auc_1: 0.7000\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1195 - acc: 0.9565 - auc_1: 0.9921 - val_loss: 1.6765 - val_acc: 0.6250 - val_auc_1: 0.7679\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0153 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7272 - val_acc: 0.6250 - val_auc_1: 0.7679\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0118 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7505 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0117 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8287 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7663 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0106 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8302 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8154 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8021 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0109 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8995 - val_acc: 0.6667 - val_auc_1: 0.7536\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0100 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8173 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8458 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 577/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8779 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 578/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8606 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0097 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8709 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0094 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9843 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8828 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0098 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0141 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0094 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9803 - val_acc: 0.6250 - val_auc_1: 0.7179\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0539 - val_acc: 0.6250 - val_auc_1: 0.7000\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8382 - val_acc: 0.6250 - val_auc_1: 0.7571\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0119 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9082 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9538 - val_acc: 0.6667 - val_auc_1: 0.7500\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0144 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0157 - val_acc: 0.6667 - val_auc_1: 0.7393\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0227 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1133 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1854 - acc: 0.9022 - auc_1: 0.9814 - val_loss: 1.7155 - val_acc: 0.6667 - val_auc_1: 0.7536\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1655 - acc: 0.9348 - auc_1: 0.9855 - val_loss: 1.7081 - val_acc: 0.6250 - val_auc_1: 0.7643\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0281 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4024 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0191 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7243 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6306 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0112 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6483 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6311 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6495 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7221 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7240 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7124 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0092 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8008 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0088 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8242 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7433 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9148 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8025 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7648 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8020 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8469 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9475 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0083 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8955 - val_acc: 0.6250 - val_auc_1: 0.7214\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0352 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0078 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0106 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0528 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0142 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8079 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0220 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7590 - val_acc: 0.6667 - val_auc_1: 0.7214\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0098 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1307 - val_acc: 0.6667 - val_auc_1: 0.6964\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0296 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2441 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2571 - acc: 0.9130 - auc_1: 0.9757 - val_loss: 1.6779 - val_acc: 0.7083 - val_auc_1: 0.7607\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0713 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 1.6777 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0126 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6386 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6787 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0081 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.6817 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7737 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7767 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 625/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8203 - val_acc: 0.6667 - val_auc_1: 0.7893\n",
      "Epoch 626/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7961 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8667 - val_acc: 0.6667 - val_auc_1: 0.7571\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8619 - val_acc: 0.6667 - val_auc_1: 0.7571\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.7660 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8682 - val_acc: 0.6667 - val_auc_1: 0.7571\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8866 - val_acc: 0.6667 - val_auc_1: 0.7607\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8468 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9496 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8665 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8382 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9643 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0656 - val_acc: 0.6667 - val_auc_1: 0.6964\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0133 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9855 - val_acc: 0.6667 - val_auc_1: 0.7571\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9534 - val_acc: 0.6667 - val_auc_1: 0.7214\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0507 - val_acc: 0.6667 - val_auc_1: 0.6964\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8771 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9409 - val_acc: 0.6667 - val_auc_1: 0.7321\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0093 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0923 - val_acc: 0.6667 - val_auc_1: 0.6964\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0278 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0060 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0152 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9158 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9840 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0087 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9556 - val_acc: 0.6667 - val_auc_1: 0.6964\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1672 - val_acc: 0.6667 - val_auc_1: 0.6964\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2230 - val_acc: 0.6667 - val_auc_1: 0.6964\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0075 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1799 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1252 - acc: 0.9565 - auc_1: 0.9912 - val_loss: 1.5535 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1237 - acc: 0.9565 - auc_1: 0.9921 - val_loss: 2.3504 - val_acc: 0.6667 - val_auc_1: 0.7179\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0718 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 1.8802 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0510 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.9610 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0103 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9015 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0497 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9676 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9658 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9329 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9903 - val_acc: 0.6667 - val_auc_1: 0.7536\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9542 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9737 - val_acc: 0.6667 - val_auc_1: 0.7500\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0163 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0302 - val_acc: 0.6667 - val_auc_1: 0.7500\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9884 - val_acc: 0.6667 - val_auc_1: 0.7571\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1313 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0319 - val_acc: 0.6667 - val_auc_1: 0.7607\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0967 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0992 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0835 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0907 - val_acc: 0.6667 - val_auc_1: 0.7500\n",
      "Epoch 673/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0775 - val_acc: 0.6667 - val_auc_1: 0.7500\n",
      "Epoch 674/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1346 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1159 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1416 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1369 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2200 - val_acc: 0.6667 - val_auc_1: 0.6964\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1875 - val_acc: 0.6250 - val_auc_1: 0.6964\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0952 - val_acc: 0.6667 - val_auc_1: 0.7536\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1483 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1694 - val_acc: 0.6667 - val_auc_1: 0.7464\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1668 - val_acc: 0.6667 - val_auc_1: 0.7143\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2914 - val_acc: 0.6667 - val_auc_1: 0.6786\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9799 - val_acc: 0.6250 - val_auc_1: 0.7321\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.2365 - val_acc: 0.6667 - val_auc_1: 0.6643\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.4085 - val_acc: 0.6667 - val_auc_1: 0.6464\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0042 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0512 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.1177 - val_acc: 0.6667 - val_auc_1: 0.6964\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.0425 - val_acc: 0.6250 - val_auc_1: 0.6821\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 2.3026 - val_acc: 0.6250 - val_auc_1: 0.6643\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0128 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.9910 - val_acc: 0.6667 - val_auc_1: 0.7607\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2630 - acc: 0.9239 - auc_1: 0.9664 - val_loss: 2.1325 - val_acc: 0.7083 - val_auc_1: 0.7143\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3125 - acc: 0.9348 - auc_1: 0.9602 - val_loss: 1.7375 - val_acc: 0.7500 - val_auc_1: 0.7357\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1259 - acc: 0.9565 - auc_1: 0.9931 - val_loss: 1.8192 - val_acc: 0.6250 - val_auc_1: 0.7143\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0341 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.5407 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0159 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.7252 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0077 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8797 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8676 - val_acc: 0.6667 - val_auc_1: 0.7536\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.8803 - val_acc: 0.6667 - val_auc_1: 0.7536\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5, X6], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.20001207,  1.6925611 , -0.15049225, -1.00276   ,  0.49379894,\n",
      "         0.5659879 , -0.9452517 ,  0.41645607, -0.7003178 ],\n",
      "       [ 0.24866281, -0.5865644 , -0.28371242, -0.29564315,  1.3700826 ,\n",
      "        -0.89147776,  1.50932   , -1.5822473 ,  0.17233276],\n",
      "       [ 0.42909464,  0.14610744,  0.9976085 , -0.16340862, -0.48028478,\n",
      "        -0.4502949 ,  0.399451  , -0.48915547, -0.60466385],\n",
      "       [-0.18526642,  1.0139803 , -1.9563044 ,  1.5749204 , -2.531902  ,\n",
      "        -1.2655843 , -0.07466841, -0.36462465,  2.1976423 ],\n",
      "       [-2.0679069 ,  0.45129672, -1.33099   , -1.4463401 , -0.78299254,\n",
      "         0.37547508,  0.26796746, -0.41988364,  1.2379127 ],\n",
      "       [-0.39809752,  1.2926345 , -1.0001874 ,  1.6768341 ,  0.22526179,\n",
      "        -2.174745  , -1.6693774 , -0.3113824 ,  1.7304641 ]],\n",
      "      dtype=float32), array([ 0.17044552, -0.467353  ,  0.14787015,  0.29456505,  0.2455819 ,\n",
      "        0.4994211 , -0.4107682 ,  0.6937089 , -0.2363747 ], dtype=float32), array([[-1.1704173 , -0.08678424,  2.3465297 , -0.43419003,  2.2574825 ,\n",
      "        -0.93199617,  1.2330285 ,  1.2745916 ,  0.7757577 ],\n",
      "       [ 0.30250823, -1.0433656 , -1.8668157 ,  0.06507646, -0.5285021 ,\n",
      "         0.2619263 ,  1.0455865 ,  0.49454612, -1.6472442 ],\n",
      "       [-0.25343156,  0.35009354,  1.7671052 , -1.1229376 , -0.8378979 ,\n",
      "        -2.435261  ,  1.715408  ,  0.87470645,  1.9556935 ],\n",
      "       [-1.3578622 , -0.51857966,  1.8854421 , -0.07733306,  1.6665801 ,\n",
      "         0.32235432, -1.1000543 ,  1.2163484 , -0.35002804],\n",
      "       [ 0.8829215 ,  1.3340269 ,  1.6028428 ,  1.8438576 , -1.120437  ,\n",
      "         0.79092556,  2.7853866 , -0.26142555,  1.8391813 ],\n",
      "       [ 1.0543956 ,  2.606397  ,  0.76707625, -0.42954352, -0.9788296 ,\n",
      "        -0.39414874,  0.14645566,  0.20708701, -0.51177937],\n",
      "       [-0.99902093, -0.7259862 ,  0.22723265,  1.2342681 ,  0.5193721 ,\n",
      "        -0.37724534, -0.14848678, -1.7978102 ,  1.7767768 ],\n",
      "       [ 0.6481868 ,  1.6181526 ,  1.1368846 , -0.6454794 , -0.5825429 ,\n",
      "        -0.42274082, -0.5732026 ,  1.7009909 , -1.0275962 ],\n",
      "       [-1.9129854 , -2.8195548 , -1.844123  ,  1.2015475 ,  1.5352745 ,\n",
      "         3.8483732 , -4.6613674 , -2.234679  , -2.0218594 ]],\n",
      "      dtype=float32), array([ 1.047204  ,  0.43980962, -0.00623184, -0.2508313 , -0.37609723,\n",
      "       -0.2638662 , -0.35375336,  0.20486759,  0.2125343 ], dtype=float32), array([[ 5.1770210e-01,  2.2950420e+00,  2.1942759e+00, -2.3046868e+00,\n",
      "        -1.5991454e+00,  5.9102350e-01, -2.5687763e-01,  1.7236683e-01,\n",
      "        -1.6584904e-01],\n",
      "       [-1.8452636e+00,  2.6858268e+00,  2.5994134e+00, -2.4495485e+00,\n",
      "        -3.0324364e+00, -1.2413882e+00,  2.3756053e-01,  3.9318666e-02,\n",
      "         7.4190038e-01],\n",
      "       [-1.7238679e+00, -1.0547829e+00, -1.8917131e-01,  2.8663358e-01,\n",
      "        -1.0316269e+00,  8.3152586e-01, -2.5471554e+00, -2.0370195e+00,\n",
      "        -1.0756166e+00],\n",
      "       [-3.4041589e-01, -1.2008886e+00, -1.3007494e+00,  8.8089722e-01,\n",
      "        -1.2205726e+00, -5.8882731e-01, -7.9394054e-01,  8.1968510e-01,\n",
      "         1.2968689e+00],\n",
      "       [ 1.1756295e-02, -3.5061893e+00, -3.3534672e+00,  3.1810162e+00,\n",
      "         2.6258146e-03, -4.4194615e-01,  9.4021767e-01,  4.7990727e-01,\n",
      "         7.0498943e-01],\n",
      "       [ 1.8262055e+00, -1.6304182e+00, -8.6970156e-01,  1.4680563e+00,\n",
      "        -5.2393961e-01,  1.8678032e+00,  7.6884985e-01, -2.2639914e+00,\n",
      "        -1.5704116e+00],\n",
      "       [-4.0605116e+00,  1.0375924e+00,  1.1285377e+00, -1.1381617e+00,\n",
      "         2.1882863e+00,  2.2862327e+00, -3.1550095e+00, -1.2684271e-02,\n",
      "        -7.8229016e-01],\n",
      "       [ 6.4232028e-01,  1.0429540e+00,  1.3892500e+00, -1.7799071e+00,\n",
      "        -6.0627520e-01,  1.5228436e+00,  2.0759184e+00, -8.3124208e-01,\n",
      "        -9.8789626e-01],\n",
      "       [ 2.7122381e-01,  5.3658551e-01,  9.9841076e-01, -8.6983103e-01,\n",
      "         1.5684062e+00,  4.0196472e-01, -6.9471612e+00, -5.6877100e-01,\n",
      "        -7.9489732e-01]], dtype=float32), array([ 0.5294284 ,  0.8101071 ,  0.4718541 , -0.8123491 , -0.96192497,\n",
      "       -0.03426482, -0.23074557,  0.24293208,  0.25827932], dtype=float32), array([[-4.3501086],\n",
      "       [-1.6367133],\n",
      "       [-2.253272 ],\n",
      "       [ 1.697753 ],\n",
      "       [-2.8443055],\n",
      "       [-4.0902977],\n",
      "       [ 4.369898 ],\n",
      "       [ 3.0340948],\n",
      "       [ 3.6785445]], dtype=float32), array([0.543568], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.86363228e-06]\n",
      " [9.99998212e-01]\n",
      " [9.59940135e-01]\n",
      " [2.42937574e-07]\n",
      " [3.50969681e-03]\n",
      " [1.00000000e+00]\n",
      " [9.99818385e-01]\n",
      " [1.00000000e+00]\n",
      " [9.80416715e-01]\n",
      " [9.99123514e-01]\n",
      " [7.56106510e-06]\n",
      " [6.96560275e-03]\n",
      " [1.00000000e+00]\n",
      " [1.18598284e-03]\n",
      " [2.49470379e-02]\n",
      " [9.99999642e-01]\n",
      " [6.13968559e-02]\n",
      " [9.92136478e-01]\n",
      " [9.97395992e-01]\n",
      " [9.98551905e-01]\n",
      " [3.58762627e-04]\n",
      " [4.02027727e-05]\n",
      " [1.43993655e-02]\n",
      " [9.99639273e-01]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [9.99592721e-01]\n",
      " [9.98984873e-01]\n",
      " [7.58150563e-05]\n",
      " [1.00000000e+00]\n",
      " [2.29938407e-04]\n",
      " [6.87985175e-06]\n",
      " [3.52651909e-06]\n",
      " [7.77698879e-05]\n",
      " [3.44746809e-08]\n",
      " [1.00000000e+00]\n",
      " [9.98774350e-01]\n",
      " [9.70478773e-01]\n",
      " [9.97382581e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99998927e-01]\n",
      " [9.99696970e-01]\n",
      " [3.56695149e-03]\n",
      " [9.76932279e-05]\n",
      " [1.18638718e-05]\n",
      " [9.66073453e-01]\n",
      " [9.95582283e-01]\n",
      " [9.95769143e-01]\n",
      " [9.91400242e-01]\n",
      " [1.09930628e-03]\n",
      " [2.08725942e-06]\n",
      " [9.95201945e-01]\n",
      " [1.89653542e-06]\n",
      " [1.33186160e-03]\n",
      " [1.34739025e-06]\n",
      " [4.63133583e-05]\n",
      " [2.44974010e-02]\n",
      " [1.00000000e+00]\n",
      " [2.36756409e-06]\n",
      " [5.57638332e-03]\n",
      " [2.44257152e-02]\n",
      " [9.99971390e-01]\n",
      " [9.48300362e-01]\n",
      " [9.99540687e-01]\n",
      " [3.47518449e-06]\n",
      " [2.34739797e-04]\n",
      " [2.91240821e-03]\n",
      " [1.00000000e+00]\n",
      " [2.37559516e-06]\n",
      " [2.80546676e-02]\n",
      " [1.15601601e-07]\n",
      " [1.00000000e+00]\n",
      " [9.99977112e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99995828e-01]\n",
      " [7.30569300e-05]\n",
      " [9.94593203e-01]\n",
      " [6.07385737e-05]\n",
      " [9.97531295e-01]\n",
      " [6.27576141e-04]\n",
      " [7.37783546e-03]\n",
      " [1.80963383e-07]\n",
      " [9.99887347e-01]\n",
      " [9.98657227e-01]\n",
      " [9.81216133e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99609649e-01]\n",
      " [9.99999762e-01]\n",
      " [1.25052119e-02]\n",
      " [9.99924302e-01]\n",
      " [9.98154223e-01]\n",
      " [1.00000000e+00]\n",
      " [9.65601265e-01]\n",
      " [9.99996901e-01]\n",
      " [9.99999642e-01]\n",
      " [2.36419309e-02]\n",
      " [9.95854378e-01]\n",
      " [9.99996305e-01]\n",
      " [3.52645770e-07]\n",
      " [9.99265492e-01]\n",
      " [1.32785033e-04]\n",
      " [4.75428169e-06]\n",
      " [9.59635556e-01]\n",
      " [1.00000000e+00]\n",
      " [3.75757396e-01]\n",
      " [1.00000000e+00]\n",
      " [2.22791664e-06]\n",
      " [1.30884022e-01]\n",
      " [9.99998689e-01]\n",
      " [2.48188348e-06]\n",
      " [9.99659061e-01]\n",
      " [9.32318997e-03]\n",
      " [9.99649167e-01]\n",
      " [9.99388695e-01]\n",
      " [1.96223550e-06]\n",
      " [9.93659317e-01]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5, X6])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
