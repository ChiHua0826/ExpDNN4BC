{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,5:6] #Leptin\n",
    "X2 = dataset[:,6:7] #Adiponectin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,7:8] #Resistin\n",
    "X5 = dataset[:,2:3] #Glucose\n",
    "X6 = dataset[:,4:5] #HOMA\n",
    "X7 = dataset[:,8:9] #MCP.1\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "X6 = normalization(X6)\n",
    "X7 = normalization(X7)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X6 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X7 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 7)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "                                                                 input_layer_X6[0][0]             \n",
      "                                                                 input_layer_X7[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            72          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 262\n",
      "Trainable params: 262\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "input_layer_X6 = keras.layers.Input(shape=(1, ), name='input_layer_X6')\n",
    "input_layer_X7 = keras.layers.Input(shape=(1, ), name='input_layer_X7')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5, input_layer_X6, input_layer_X7], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.6953 - acc: 0.5652 - auc_1: 0.5693 - val_loss: 0.6519 - val_acc: 0.7083 - val_auc_1: 0.6893\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6663 - acc: 0.6848 - auc_1: 0.6714 - val_loss: 0.6259 - val_acc: 0.7083 - val_auc_1: 0.7107\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6492 - acc: 0.6196 - auc_1: 0.6969 - val_loss: 0.6046 - val_acc: 0.7500 - val_auc_1: 0.7393\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6281 - acc: 0.6739 - auc_1: 0.7162 - val_loss: 0.5827 - val_acc: 0.7083 - val_auc_1: 0.7500\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6072 - acc: 0.6522 - auc_1: 0.7374 - val_loss: 0.5536 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5935 - acc: 0.6630 - auc_1: 0.7552 - val_loss: 0.5576 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5785 - acc: 0.6630 - auc_1: 0.7602 - val_loss: 0.5282 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5685 - acc: 0.6957 - auc_1: 0.7707 - val_loss: 0.5632 - val_acc: 0.5833 - val_auc_1: 0.8714\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5594 - acc: 0.6522 - auc_1: 0.7757 - val_loss: 0.5209 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5550 - acc: 0.6957 - auc_1: 0.7802 - val_loss: 0.5475 - val_acc: 0.6667 - val_auc_1: 0.8929\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5467 - acc: 0.6739 - auc_1: 0.7879 - val_loss: 0.5226 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5361 - acc: 0.6848 - auc_1: 0.7952 - val_loss: 0.5144 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5337 - acc: 0.7174 - auc_1: 0.7995 - val_loss: 0.5407 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5249 - acc: 0.7065 - auc_1: 0.8029 - val_loss: 0.6209 - val_acc: 0.5833 - val_auc_1: 0.9071\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5240 - acc: 0.7500 - auc_1: 0.8026 - val_loss: 0.4928 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5264 - acc: 0.6957 - auc_1: 0.8069 - val_loss: 0.5391 - val_acc: 0.7083 - val_auc_1: 0.9143\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5201 - acc: 0.7609 - auc_1: 0.8145 - val_loss: 0.5247 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5112 - acc: 0.7391 - auc_1: 0.8205 - val_loss: 0.5133 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5069 - acc: 0.7391 - auc_1: 0.8288 - val_loss: 0.6058 - val_acc: 0.6667 - val_auc_1: 0.9214\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5059 - acc: 0.7500 - auc_1: 0.8271 - val_loss: 0.5737 - val_acc: 0.7083 - val_auc_1: 0.9143\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5070 - acc: 0.7174 - auc_1: 0.8238 - val_loss: 0.5788 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5019 - acc: 0.7500 - auc_1: 0.8238 - val_loss: 0.5630 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4940 - acc: 0.7500 - auc_1: 0.8407 - val_loss: 0.5005 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4969 - acc: 0.7935 - auc_1: 0.8340 - val_loss: 0.5700 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4881 - acc: 0.7500 - auc_1: 0.8324 - val_loss: 0.5462 - val_acc: 0.7083 - val_auc_1: 0.9036\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4839 - acc: 0.7500 - auc_1: 0.8383 - val_loss: 0.5516 - val_acc: 0.7083 - val_auc_1: 0.9036\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4879 - acc: 0.7500 - auc_1: 0.8336 - val_loss: 0.5524 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4817 - acc: 0.7174 - auc_1: 0.8360 - val_loss: 0.5686 - val_acc: 0.7083 - val_auc_1: 0.8964\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4717 - acc: 0.7391 - auc_1: 0.8486 - val_loss: 0.6291 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4784 - acc: 0.7609 - auc_1: 0.8438 - val_loss: 0.5973 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4655 - acc: 0.7826 - auc_1: 0.8581 - val_loss: 0.6036 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4637 - acc: 0.7609 - auc_1: 0.8598 - val_loss: 0.5221 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4650 - acc: 0.7500 - auc_1: 0.8564 - val_loss: 0.5521 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4650 - acc: 0.7500 - auc_1: 0.8581 - val_loss: 0.5538 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4619 - acc: 0.7283 - auc_1: 0.8567 - val_loss: 0.5526 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4653 - acc: 0.7609 - auc_1: 0.8664 - val_loss: 0.5078 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4638 - acc: 0.7609 - auc_1: 0.8617 - val_loss: 0.5379 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4495 - acc: 0.7717 - auc_1: 0.8748 - val_loss: 0.5990 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4523 - acc: 0.7935 - auc_1: 0.8695 - val_loss: 0.5320 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4497 - acc: 0.7717 - auc_1: 0.8652 - val_loss: 0.5456 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4385 - acc: 0.7717 - auc_1: 0.8786 - val_loss: 0.6318 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4295 - acc: 0.7500 - auc_1: 0.8810 - val_loss: 0.5068 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4412 - acc: 0.7500 - auc_1: 0.8693 - val_loss: 0.5246 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4314 - acc: 0.8152 - auc_1: 0.8833 - val_loss: 0.7229 - val_acc: 0.5833 - val_auc_1: 0.8429\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4457 - acc: 0.7717 - auc_1: 0.8717 - val_loss: 0.5780 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4366 - acc: 0.7283 - auc_1: 0.8726 - val_loss: 0.5408 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4228 - acc: 0.7826 - auc_1: 0.8871 - val_loss: 0.5388 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4288 - acc: 0.7717 - auc_1: 0.8821 - val_loss: 0.5393 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4196 - acc: 0.8152 - auc_1: 0.8905 - val_loss: 0.6710 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4149 - acc: 0.7935 - auc_1: 0.8907 - val_loss: 0.5152 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4351 - acc: 0.7826 - auc_1: 0.8795 - val_loss: 0.5876 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4297 - acc: 0.7935 - auc_1: 0.8793 - val_loss: 0.5912 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4208 - acc: 0.7717 - auc_1: 0.8848 - val_loss: 0.5816 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4206 - acc: 0.7500 - auc_1: 0.8781 - val_loss: 0.5506 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4161 - acc: 0.7935 - auc_1: 0.8883 - val_loss: 0.5664 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4059 - acc: 0.8152 - auc_1: 0.8924 - val_loss: 0.6621 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4256 - acc: 0.7826 - auc_1: 0.8843 - val_loss: 0.5807 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4146 - acc: 0.7500 - auc_1: 0.8864 - val_loss: 0.5656 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4069 - acc: 0.7826 - auc_1: 0.8905 - val_loss: 0.5438 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.4103 - acc: 0.8222 - auc_1: 0.896 - 0s 4ms/step - loss: 0.4153 - acc: 0.8152 - auc_1: 0.8921 - val_loss: 0.5964 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4070 - acc: 0.7826 - auc_1: 0.8871 - val_loss: 0.5385 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4072 - acc: 0.7826 - auc_1: 0.8919 - val_loss: 0.5264 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3920 - acc: 0.8043 - auc_1: 0.9026 - val_loss: 0.6602 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4045 - acc: 0.7717 - auc_1: 0.8886 - val_loss: 0.6146 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4119 - acc: 0.7717 - auc_1: 0.8881 - val_loss: 0.5571 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3960 - acc: 0.8043 - auc_1: 0.8979 - val_loss: 0.6474 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4009 - acc: 0.7609 - auc_1: 0.8902 - val_loss: 0.6456 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3883 - acc: 0.8152 - auc_1: 0.9045 - val_loss: 0.5477 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4053 - acc: 0.7717 - auc_1: 0.8933 - val_loss: 0.6096 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3902 - acc: 0.7826 - auc_1: 0.8955 - val_loss: 0.5842 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3941 - acc: 0.8152 - auc_1: 0.9024 - val_loss: 0.6094 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3833 - acc: 0.7935 - auc_1: 0.9029 - val_loss: 0.5977 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3968 - acc: 0.7935 - auc_1: 0.8952 - val_loss: 0.5784 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3845 - acc: 0.8261 - auc_1: 0.9031 - val_loss: 0.6341 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3803 - acc: 0.7935 - auc_1: 0.9060 - val_loss: 0.6226 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3844 - acc: 0.8152 - auc_1: 0.9026 - val_loss: 0.5687 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3858 - acc: 0.8043 - auc_1: 0.9026 - val_loss: 0.5969 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3745 - acc: 0.8043 - auc_1: 0.9095 - val_loss: 0.6379 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3758 - acc: 0.8152 - auc_1: 0.9107 - val_loss: 0.5443 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3688 - acc: 0.8043 - auc_1: 0.9129 - val_loss: 0.6878 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3777 - acc: 0.7935 - auc_1: 0.9086 - val_loss: 0.6107 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3799 - acc: 0.7826 - auc_1: 0.9060 - val_loss: 0.6317 - val_acc: 0.6250 - val_auc_1: 0.8250\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3781 - acc: 0.8152 - auc_1: 0.9067 - val_loss: 0.5853 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3566 - acc: 0.7826 - auc_1: 0.9183 - val_loss: 0.4873 - val_acc: 0.8333 - val_auc_1: 0.8500\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3741 - acc: 0.7826 - auc_1: 0.9074 - val_loss: 0.5241 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3525 - acc: 0.8152 - auc_1: 0.9240 - val_loss: 0.7463 - val_acc: 0.5833 - val_auc_1: 0.8286\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3539 - acc: 0.7935 - auc_1: 0.9238 - val_loss: 0.5013 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3675 - acc: 0.8370 - auc_1: 0.9095 - val_loss: 0.5924 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3571 - acc: 0.8370 - auc_1: 0.9167 - val_loss: 0.5694 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3530 - acc: 0.8261 - auc_1: 0.9210 - val_loss: 0.6609 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3438 - acc: 0.8370 - auc_1: 0.9286 - val_loss: 0.6314 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3512 - acc: 0.8152 - auc_1: 0.9214 - val_loss: 0.6070 - val_acc: 0.6250 - val_auc_1: 0.8571\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3485 - acc: 0.7935 - auc_1: 0.9233 - val_loss: 0.5608 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3566 - acc: 0.8261 - auc_1: 0.9202 - val_loss: 0.5961 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3438 - acc: 0.8370 - auc_1: 0.9240 - val_loss: 0.5661 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3459 - acc: 0.8043 - auc_1: 0.9269 - val_loss: 0.5952 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 97/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3363 - acc: 0.8152 - auc_1: 0.9324 - val_loss: 0.5319 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3431 - acc: 0.8152 - auc_1: 0.9212 - val_loss: 0.5287 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3382 - acc: 0.8370 - auc_1: 0.9257 - val_loss: 0.6176 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3346 - acc: 0.8370 - auc_1: 0.9300 - val_loss: 0.6032 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3377 - acc: 0.8370 - auc_1: 0.9279 - val_loss: 0.5975 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3369 - acc: 0.8696 - auc_1: 0.9271 - val_loss: 0.6163 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3087 - acc: 0.8587 - auc_1: 0.9479 - val_loss: 0.6741 - val_acc: 0.6250 - val_auc_1: 0.8607\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3347 - acc: 0.8152 - auc_1: 0.9271 - val_loss: 0.6461 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3067 - acc: 0.8478 - auc_1: 0.9457 - val_loss: 0.4857 - val_acc: 0.8333 - val_auc_1: 0.8571\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3318 - acc: 0.8478 - auc_1: 0.9324 - val_loss: 0.5361 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3088 - acc: 0.8804 - auc_1: 0.9426 - val_loss: 0.6490 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3098 - acc: 0.8478 - auc_1: 0.9438 - val_loss: 0.4860 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3216 - acc: 0.8261 - auc_1: 0.9393 - val_loss: 0.5079 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3159 - acc: 0.8370 - auc_1: 0.9379 - val_loss: 0.5879 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3208 - acc: 0.8370 - auc_1: 0.9355 - val_loss: 0.4969 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3085 - acc: 0.8587 - auc_1: 0.9402 - val_loss: 0.5725 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3055 - acc: 0.8587 - auc_1: 0.9431 - val_loss: 0.5683 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3072 - acc: 0.8478 - auc_1: 0.9440 - val_loss: 0.5761 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3129 - acc: 0.8478 - auc_1: 0.9400 - val_loss: 0.6103 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.2989 - acc: 0.8478 - auc_1: 0.9455 - val_loss: 0.4811 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3034 - acc: 0.8696 - auc_1: 0.9433 - val_loss: 0.5334 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.2881 - acc: 0.8889 - auc_1: 0.945 - 0s 5ms/step - loss: 0.2954 - acc: 0.8804 - auc_1: 0.9407 - val_loss: 0.5367 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2881 - acc: 0.8478 - auc_1: 0.9538 - val_loss: 0.4362 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.3070 - acc: 0.8478 - auc_1: 0.9400 - val_loss: 0.5265 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3017 - acc: 0.8478 - auc_1: 0.9448 - val_loss: 0.4633 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2940 - acc: 0.8804 - auc_1: 0.9464 - val_loss: 0.4942 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2851 - acc: 0.8587 - auc_1: 0.9531 - val_loss: 0.4210 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3035 - acc: 0.8261 - auc_1: 0.9393 - val_loss: 0.5501 - val_acc: 0.6667 - val_auc_1: 0.8929\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2826 - acc: 0.8696 - auc_1: 0.9500 - val_loss: 0.5874 - val_acc: 0.7083 - val_auc_1: 0.9036\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2908 - acc: 0.8370 - auc_1: 0.9479 - val_loss: 0.4439 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2796 - acc: 0.8587 - auc_1: 0.9540 - val_loss: 0.5748 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2816 - acc: 0.8696 - auc_1: 0.9550 - val_loss: 0.4860 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2780 - acc: 0.8478 - auc_1: 0.9560 - val_loss: 0.4672 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2844 - acc: 0.8587 - auc_1: 0.9517 - val_loss: 0.4986 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2813 - acc: 0.8587 - auc_1: 0.9512 - val_loss: 0.4697 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2746 - acc: 0.8804 - auc_1: 0.9526 - val_loss: 0.4843 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2669 - acc: 0.8587 - auc_1: 0.9571 - val_loss: 0.5026 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2605 - acc: 0.8804 - auc_1: 0.9624 - val_loss: 0.4544 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2680 - acc: 0.8696 - auc_1: 0.9562 - val_loss: 0.5174 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2698 - acc: 0.8478 - auc_1: 0.9567 - val_loss: 0.4663 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2609 - acc: 0.8587 - auc_1: 0.9602 - val_loss: 0.4920 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2701 - acc: 0.8696 - auc_1: 0.9545 - val_loss: 0.4806 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2562 - acc: 0.8804 - auc_1: 0.9621 - val_loss: 0.4775 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2683 - acc: 0.8587 - auc_1: 0.9598 - val_loss: 0.4600 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2692 - acc: 0.8804 - auc_1: 0.9545 - val_loss: 0.4901 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2464 - acc: 0.9130 - auc_1: 0.9686 - val_loss: 0.5952 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2549 - acc: 0.8587 - auc_1: 0.9602 - val_loss: 0.5105 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2561 - acc: 0.8478 - auc_1: 0.9586 - val_loss: 0.4563 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 145/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2452 - acc: 0.8587 - auc_1: 0.9655 - val_loss: 0.5779 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 146/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2406 - acc: 0.8913 - auc_1: 0.9681 - val_loss: 0.4490 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2427 - acc: 0.9239 - auc_1: 0.9645 - val_loss: 0.4545 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2444 - acc: 0.8696 - auc_1: 0.9667 - val_loss: 0.4399 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2195 - acc: 0.9022 - auc_1: 0.9738 - val_loss: 0.3905 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2508 - acc: 0.9130 - auc_1: 0.9631 - val_loss: 0.4885 - val_acc: 0.7083 - val_auc_1: 0.9143\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2298 - acc: 0.8804 - auc_1: 0.9698 - val_loss: 0.5178 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2389 - acc: 0.8804 - auc_1: 0.9652 - val_loss: 0.4482 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2341 - acc: 0.8913 - auc_1: 0.9695 - val_loss: 0.4890 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2435 - acc: 0.8804 - auc_1: 0.9633 - val_loss: 0.4186 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2275 - acc: 0.9239 - auc_1: 0.9705 - val_loss: 0.4704 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2564 - acc: 0.8696 - auc_1: 0.9600 - val_loss: 0.4408 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2282 - acc: 0.8913 - auc_1: 0.9693 - val_loss: 0.4377 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2251 - acc: 0.8696 - auc_1: 0.9700 - val_loss: 0.4101 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2252 - acc: 0.8913 - auc_1: 0.9686 - val_loss: 0.5175 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2345 - acc: 0.8370 - auc_1: 0.9610 - val_loss: 0.4285 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2049 - acc: 0.9130 - auc_1: 0.9771 - val_loss: 0.5060 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2285 - acc: 0.8804 - auc_1: 0.9705 - val_loss: 0.5018 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2121 - acc: 0.9130 - auc_1: 0.9736 - val_loss: 0.4428 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2245 - acc: 0.8804 - auc_1: 0.9707 - val_loss: 0.4172 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2104 - acc: 0.9022 - auc_1: 0.9733 - val_loss: 0.4447 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1994 - acc: 0.9130 - auc_1: 0.9783 - val_loss: 0.5112 - val_acc: 0.7083 - val_auc_1: 0.9000\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1963 - acc: 0.8913 - auc_1: 0.9810 - val_loss: 0.4104 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2007 - acc: 0.9239 - auc_1: 0.9755 - val_loss: 0.5616 - val_acc: 0.7083 - val_auc_1: 0.9036\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2079 - acc: 0.9022 - auc_1: 0.9738 - val_loss: 0.5135 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2085 - acc: 0.9022 - auc_1: 0.9740 - val_loss: 0.3972 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2096 - acc: 0.8913 - auc_1: 0.9736 - val_loss: 0.4642 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1954 - acc: 0.9130 - auc_1: 0.9800 - val_loss: 0.4877 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1933 - acc: 0.8913 - auc_1: 0.9793 - val_loss: 0.4099 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1942 - acc: 0.8913 - auc_1: 0.9798 - val_loss: 0.4313 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1936 - acc: 0.9130 - auc_1: 0.9790 - val_loss: 0.3910 - val_acc: 0.8333 - val_auc_1: 0.9071\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2011 - acc: 0.9130 - auc_1: 0.9788 - val_loss: 0.5253 - val_acc: 0.7083 - val_auc_1: 0.9036\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1843 - acc: 0.9130 - auc_1: 0.9807 - val_loss: 0.3912 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1986 - acc: 0.9022 - auc_1: 0.9762 - val_loss: 0.4294 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1885 - acc: 0.8913 - auc_1: 0.9790 - val_loss: 0.4802 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1874 - acc: 0.9022 - auc_1: 0.9786 - val_loss: 0.4193 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1841 - acc: 0.9022 - auc_1: 0.9790 - val_loss: 0.5613 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1987 - acc: 0.9130 - auc_1: 0.9798 - val_loss: 0.4768 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1940 - acc: 0.8913 - auc_1: 0.9762 - val_loss: 0.3644 - val_acc: 0.8750 - val_auc_1: 0.9214\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1843 - acc: 0.9130 - auc_1: 0.9812 - val_loss: 0.3704 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1785 - acc: 0.8913 - auc_1: 0.9829 - val_loss: 0.3712 - val_acc: 0.8333 - val_auc_1: 0.9036\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2039 - acc: 0.8478 - auc_1: 0.9717 - val_loss: 0.4139 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1748 - acc: 0.9239 - auc_1: 0.9826 - val_loss: 0.4075 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1831 - acc: 0.9239 - auc_1: 0.9805 - val_loss: 0.3698 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1747 - acc: 0.9022 - auc_1: 0.9826 - val_loss: 0.4096 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.1850 - acc: 0.9239 - auc_1: 0.9788 - val_loss: 0.3745 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.1770 - acc: 0.8913 - auc_1: 0.9819 - val_loss: 0.4303 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1760 - acc: 0.9130 - auc_1: 0.9831 - val_loss: 0.3840 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 193/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1702 - acc: 0.9022 - auc_1: 0.9824 - val_loss: 0.4103 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 194/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1854 - acc: 0.9239 - auc_1: 0.9790 - val_loss: 0.4734 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1724 - acc: 0.9130 - auc_1: 0.9836 - val_loss: 0.4199 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1730 - acc: 0.9130 - auc_1: 0.9817 - val_loss: 0.3971 - val_acc: 0.8750 - val_auc_1: 0.9214\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1780 - acc: 0.9022 - auc_1: 0.9814 - val_loss: 0.4042 - val_acc: 0.8333 - val_auc_1: 0.9250\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1632 - acc: 0.9130 - auc_1: 0.9845 - val_loss: 0.3812 - val_acc: 0.9167 - val_auc_1: 0.9500\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1698 - acc: 0.9457 - auc_1: 0.9860 - val_loss: 0.4690 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1778 - acc: 0.9022 - auc_1: 0.9810 - val_loss: 0.3805 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1712 - acc: 0.9022 - auc_1: 0.9833 - val_loss: 0.3683 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1648 - acc: 0.9022 - auc_1: 0.9838 - val_loss: 0.3883 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1839 - acc: 0.9130 - auc_1: 0.9795 - val_loss: 0.4502 - val_acc: 0.7500 - val_auc_1: 0.9357\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1655 - acc: 0.9348 - auc_1: 0.9852 - val_loss: 0.4213 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1470 - acc: 0.9348 - auc_1: 0.9893 - val_loss: 0.3684 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.1960 - acc: 0.9130 - auc_1: 0.9779 - val_loss: 0.4045 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1668 - acc: 0.9130 - auc_1: 0.9790 - val_loss: 0.4163 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1691 - acc: 0.9022 - auc_1: 0.9819 - val_loss: 0.3719 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1602 - acc: 0.9457 - auc_1: 0.9848 - val_loss: 0.4265 - val_acc: 0.8750 - val_auc_1: 0.9357\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1496 - acc: 0.9457 - auc_1: 0.9867 - val_loss: 0.3630 - val_acc: 0.8750 - val_auc_1: 0.9143\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1646 - acc: 0.9130 - auc_1: 0.9869 - val_loss: 0.3956 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1409 - acc: 0.9348 - auc_1: 0.9900 - val_loss: 0.3862 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1490 - acc: 0.9239 - auc_1: 0.9893 - val_loss: 0.3771 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1524 - acc: 0.9022 - auc_1: 0.9860 - val_loss: 0.3697 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1391 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 0.4641 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1836 - acc: 0.9130 - auc_1: 0.9776 - val_loss: 0.3641 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1560 - acc: 0.9022 - auc_1: 0.9852 - val_loss: 0.3947 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1486 - acc: 0.9348 - auc_1: 0.9876 - val_loss: 0.3899 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1278 - acc: 0.9565 - auc_1: 0.9943 - val_loss: 0.3692 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1375 - acc: 0.9130 - auc_1: 0.9900 - val_loss: 0.3496 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1445 - acc: 0.9565 - auc_1: 0.9890 - val_loss: 0.4087 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1558 - acc: 0.9130 - auc_1: 0.9883 - val_loss: 0.4466 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1332 - acc: 0.9457 - auc_1: 0.9910 - val_loss: 0.3621 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1432 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.4737 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1528 - acc: 0.9239 - auc_1: 0.9867 - val_loss: 0.3972 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1485 - acc: 0.9239 - auc_1: 0.9869 - val_loss: 0.4085 - val_acc: 0.8750 - val_auc_1: 0.9357\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1406 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.5457 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1543 - acc: 0.8804 - auc_1: 0.9824 - val_loss: 0.4345 - val_acc: 0.8333 - val_auc_1: 0.9393\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1494 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 0.4263 - val_acc: 0.8750 - val_auc_1: 0.9393\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1454 - acc: 0.9130 - auc_1: 0.9890 - val_loss: 0.4375 - val_acc: 0.8333 - val_auc_1: 0.9321\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1403 - acc: 0.9130 - auc_1: 0.9881 - val_loss: 0.4037 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1232 - acc: 0.9457 - auc_1: 0.9907 - val_loss: 0.5258 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1434 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 0.3793 - val_acc: 0.8333 - val_auc_1: 0.9250\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1311 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 0.3710 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1356 - acc: 0.9130 - auc_1: 0.9905 - val_loss: 0.3694 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1351 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 0.4578 - val_acc: 0.8750 - val_auc_1: 0.9393\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1377 - acc: 0.9457 - auc_1: 0.9898 - val_loss: 0.3888 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1401 - acc: 0.9239 - auc_1: 0.9895 - val_loss: 0.4479 - val_acc: 0.8333 - val_auc_1: 0.9321\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1250 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 0.3640 - val_acc: 0.9167 - val_auc_1: 0.9464\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1387 - acc: 0.9348 - auc_1: 0.9895 - val_loss: 0.3744 - val_acc: 0.8333 - val_auc_1: 0.9393\n",
      "Epoch 241/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1277 - acc: 0.9457 - auc_1: 0.9910 - val_loss: 0.4393 - val_acc: 0.8333 - val_auc_1: 0.9500\n",
      "Epoch 242/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1421 - acc: 0.9130 - auc_1: 0.9890 - val_loss: 0.3812 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1551 - acc: 0.9022 - auc_1: 0.9852 - val_loss: 0.4149 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1444 - acc: 0.9239 - auc_1: 0.9876 - val_loss: 0.3570 - val_acc: 0.8750 - val_auc_1: 0.9500\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1426 - acc: 0.9239 - auc_1: 0.9869 - val_loss: 0.3735 - val_acc: 0.8750 - val_auc_1: 0.9571\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1277 - acc: 0.9565 - auc_1: 0.9905 - val_loss: 0.4627 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1253 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 0.3800 - val_acc: 0.8750 - val_auc_1: 0.9393\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1116 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.3817 - val_acc: 0.8750 - val_auc_1: 0.9250\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1138 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 0.3742 - val_acc: 0.8333 - val_auc_1: 0.9500\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1202 - acc: 0.9457 - auc_1: 0.9936 - val_loss: 0.4039 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1436 - acc: 0.9239 - auc_1: 0.9862 - val_loss: 0.3707 - val_acc: 0.9167 - val_auc_1: 0.9643\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1308 - acc: 0.9239 - auc_1: 0.9912 - val_loss: 0.3972 - val_acc: 0.9167 - val_auc_1: 0.9500\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1113 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.3697 - val_acc: 0.8750 - val_auc_1: 0.9500\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1160 - acc: 0.9348 - auc_1: 0.9936 - val_loss: 0.3607 - val_acc: 0.8333 - val_auc_1: 0.9571\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1191 - acc: 0.9457 - auc_1: 0.9914 - val_loss: 0.3418 - val_acc: 0.8333 - val_auc_1: 0.9500\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1342 - acc: 0.9348 - auc_1: 0.9886 - val_loss: 0.3637 - val_acc: 0.8333 - val_auc_1: 0.9643\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1232 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 0.4350 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1066 - acc: 0.9565 - auc_1: 0.9940 - val_loss: 0.3767 - val_acc: 0.8750 - val_auc_1: 0.9571\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1146 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 0.3963 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1130 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 0.3680 - val_acc: 0.8750 - val_auc_1: 0.9571\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0979 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 0.3774 - val_acc: 0.8750 - val_auc_1: 0.9500\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1101 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 0.3938 - val_acc: 0.8750 - val_auc_1: 0.9286\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1234 - acc: 0.9348 - auc_1: 0.9902 - val_loss: 0.3726 - val_acc: 0.9167 - val_auc_1: 0.9500\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1088 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 0.5641 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1334 - acc: 0.9239 - auc_1: 0.9886 - val_loss: 0.4239 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1087 - acc: 0.9565 - auc_1: 0.9945 - val_loss: 0.3786 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1005 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 0.4338 - val_acc: 0.8750 - val_auc_1: 0.9357\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0998 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.3426 - val_acc: 0.8750 - val_auc_1: 0.9571\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1144 - acc: 0.9348 - auc_1: 0.9933 - val_loss: 0.3796 - val_acc: 0.9167 - val_auc_1: 0.9500\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1120 - acc: 0.9457 - auc_1: 0.9929 - val_loss: 0.4848 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1224 - acc: 0.9565 - auc_1: 0.9919 - val_loss: 0.3257 - val_acc: 0.8750 - val_auc_1: 0.9571\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1176 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 0.3697 - val_acc: 0.7917 - val_auc_1: 0.9429\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0925 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.3891 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1018 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.4952 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1052 - acc: 0.9565 - auc_1: 0.9940 - val_loss: 0.3699 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0941 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.3602 - val_acc: 0.9167 - val_auc_1: 0.9429\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1076 - acc: 0.9457 - auc_1: 0.9933 - val_loss: 0.3783 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0871 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.4039 - val_acc: 0.8333 - val_auc_1: 0.9500\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1022 - acc: 0.9565 - auc_1: 0.9950 - val_loss: 0.4112 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0867 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.3482 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1002 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.4126 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0940 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.3636 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0916 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 0.4532 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0925 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.4680 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1092 - acc: 0.9457 - auc_1: 0.9924 - val_loss: 0.4945 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0823 - acc: 0.9674 - auc_1: 0.9983 - val_loss: 0.4042 - val_acc: 0.7917 - val_auc_1: 0.9393\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0904 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.3808 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0978 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.4072 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 289/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1048 - acc: 0.9565 - auc_1: 0.9945 - val_loss: 0.3608 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 290/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0920 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.4636 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1224 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.3886 - val_acc: 0.7917 - val_auc_1: 0.9429\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0906 - acc: 0.9674 - auc_1: 0.9964 - val_loss: 0.3763 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0950 - acc: 0.9565 - auc_1: 0.9952 - val_loss: 0.4613 - val_acc: 0.8333 - val_auc_1: 0.9536\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1050 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 0.3874 - val_acc: 0.8333 - val_auc_1: 0.9536\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0684 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.3689 - val_acc: 0.7917 - val_auc_1: 0.9429\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0879 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.3607 - val_acc: 0.8333 - val_auc_1: 0.9571\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0933 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.3443 - val_acc: 0.8750 - val_auc_1: 0.9571\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0903 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 0.3760 - val_acc: 0.8750 - val_auc_1: 0.9464\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0984 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.3685 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0969 - acc: 0.9565 - auc_1: 0.9945 - val_loss: 0.3564 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0793 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.4302 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0927 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 0.3755 - val_acc: 0.8333 - val_auc_1: 0.9571\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0813 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.4152 - val_acc: 0.8333 - val_auc_1: 0.9321\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0926 - acc: 0.9457 - auc_1: 0.9957 - val_loss: 0.3549 - val_acc: 0.8750 - val_auc_1: 0.9500\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0771 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.3776 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0690 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.3751 - val_acc: 0.8333 - val_auc_1: 0.9571\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0808 - acc: 0.9674 - auc_1: 0.9964 - val_loss: 0.3689 - val_acc: 0.8750 - val_auc_1: 0.9500\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0830 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.3912 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0562 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.4594 - val_acc: 0.7500 - val_auc_1: 0.9357\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0833 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 0.3648 - val_acc: 0.8333 - val_auc_1: 0.9464\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0755 - acc: 0.9783 - auc_1: 0.9967 - val_loss: 0.4049 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0708 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.4641 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0730 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 0.3595 - val_acc: 0.8750 - val_auc_1: 0.9536\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0927 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.4131 - val_acc: 0.8333 - val_auc_1: 0.9464\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0754 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.3568 - val_acc: 0.8333 - val_auc_1: 0.9500\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0737 - acc: 0.9783 - auc_1: 0.9993 - val_loss: 0.5011 - val_acc: 0.8333 - val_auc_1: 0.9321\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0719 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.3873 - val_acc: 0.8333 - val_auc_1: 0.9500\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1312 - acc: 0.9457 - auc_1: 0.9900 - val_loss: 0.4505 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0714 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 0.4746 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0622 - acc: 0.9674 - auc_1: 0.9988 - val_loss: 0.4249 - val_acc: 0.8333 - val_auc_1: 0.9500\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0704 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.3755 - val_acc: 0.8333 - val_auc_1: 0.9500\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0621 - acc: 0.9674 - auc_1: 0.9988 - val_loss: 0.3578 - val_acc: 0.7917 - val_auc_1: 0.9429\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0592 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.5142 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0576 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 0.3420 - val_acc: 0.8333 - val_auc_1: 0.9464\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1199 - acc: 0.9674 - auc_1: 0.9907 - val_loss: 0.4458 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0643 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.3450 - val_acc: 0.8333 - val_auc_1: 0.9571\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0619 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.4725 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0740 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.3325 - val_acc: 0.8750 - val_auc_1: 0.9500\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0865 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.3718 - val_acc: 0.8333 - val_auc_1: 0.9571\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0760 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.3822 - val_acc: 0.8333 - val_auc_1: 0.9571\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0780 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 0.3879 - val_acc: 0.7917 - val_auc_1: 0.9429\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0633 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.4524 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0604 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.4747 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0635 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.4246 - val_acc: 0.8333 - val_auc_1: 0.9500\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0589 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.5604 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0593 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.3420 - val_acc: 0.8750 - val_auc_1: 0.9571\n",
      "Epoch 337/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0610 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.4338 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 338/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1048 - acc: 0.9565 - auc_1: 0.9936 - val_loss: 0.4745 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0513 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.4878 - val_acc: 0.8333 - val_auc_1: 0.9250\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0533 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.4070 - val_acc: 0.8750 - val_auc_1: 0.9429\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0543 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.4346 - val_acc: 0.8333 - val_auc_1: 0.9393\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0810 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.5866 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0627 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.4815 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0911 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 0.3945 - val_acc: 0.8333 - val_auc_1: 0.9500\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0617 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.3974 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0787 - acc: 0.9457 - auc_1: 0.9971 - val_loss: 0.3724 - val_acc: 0.8333 - val_auc_1: 0.9429\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0572 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.3924 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0452 - acc: 0.9674 - auc_1: 1.0000 - val_loss: 0.6709 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0835 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.4182 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0642 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.4796 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0546 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.4818 - val_acc: 0.7500 - val_auc_1: 0.9286\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0437 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6184 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0635 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.5217 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0442 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.5246 - val_acc: 0.8333 - val_auc_1: 0.9250\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0578 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.4452 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0554 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.5574 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0424 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.4657 - val_acc: 0.8333 - val_auc_1: 0.9250\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0436 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.5966 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0941 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.4003 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0490 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.5758 - val_acc: 0.8333 - val_auc_1: 0.9107\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0513 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 0.4992 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0454 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.5352 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0586 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.4149 - val_acc: 0.8333 - val_auc_1: 0.9250\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0771 - acc: 0.9674 - auc_1: 0.9969 - val_loss: 0.5180 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0452 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.5868 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0471 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.4850 - val_acc: 0.8333 - val_auc_1: 0.9357\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0427 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.5288 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0406 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.5183 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0424 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.4759 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0439 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.4780 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0488 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.4600 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0401 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.4821 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0508 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.7733 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1037 - acc: 0.9674 - auc_1: 0.9921 - val_loss: 0.5068 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0418 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5326 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0392 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.4234 - val_acc: 0.8750 - val_auc_1: 0.9179\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0889 - acc: 0.9783 - auc_1: 0.9938 - val_loss: 0.6156 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0500 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.4397 - val_acc: 0.8333 - val_auc_1: 0.9286\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0568 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.4881 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0361 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.4417 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0261 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5427 - val_acc: 0.7500 - val_auc_1: 0.9286\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0373 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6378 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0284 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.5096 - val_acc: 0.7500 - val_auc_1: 0.9286\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0507 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.4851 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 385/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0426 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.4971 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 386/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0439 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.5428 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0562 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.5070 - val_acc: 0.7500 - val_auc_1: 0.9321\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0599 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.4644 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0680 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.4374 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0278 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5682 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0344 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.5343 - val_acc: 0.7500 - val_auc_1: 0.9357\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0338 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.4736 - val_acc: 0.7917 - val_auc_1: 0.9321\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0423 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.6053 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0288 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5297 - val_acc: 0.7500 - val_auc_1: 0.9250\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0346 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.5608 - val_acc: 0.7500 - val_auc_1: 0.9357\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0357 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6854 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0568 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.5086 - val_acc: 0.7500 - val_auc_1: 0.9321\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0247 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5498 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0726 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 0.4585 - val_acc: 0.7917 - val_auc_1: 0.9357\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0575 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.5303 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0241 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5911 - val_acc: 0.7500 - val_auc_1: 0.9179\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0570 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.4486 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0389 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.4381 - val_acc: 0.7500 - val_auc_1: 0.9286\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0495 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.5530 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0388 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.4572 - val_acc: 0.7917 - val_auc_1: 0.9429\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0300 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.4770 - val_acc: 0.7500 - val_auc_1: 0.9286\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0252 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6173 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0285 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5216 - val_acc: 0.7917 - val_auc_1: 0.9286\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0219 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.4630 - val_acc: 0.7500 - val_auc_1: 0.9357\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0513 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.5151 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0233 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6502 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0220 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6117 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0434 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.6776 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0211 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5129 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0366 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6826 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0261 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6067 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0193 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6213 - val_acc: 0.7917 - val_auc_1: 0.9250\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0233 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6877 - val_acc: 0.7500 - val_auc_1: 0.9107\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0321 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6721 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0491 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.6990 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6101 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0211 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7585 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0321 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.7790 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0509 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.6935 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0917 - acc: 0.9674 - auc_1: 0.9936 - val_loss: 0.6295 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0448 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.5021 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0430 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.5815 - val_acc: 0.7917 - val_auc_1: 0.9179\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0534 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.5268 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0199 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5587 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0171 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5598 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0333 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 0.6014 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0190 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6393 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 433/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0378 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.5911 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 434/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0174 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6316 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0195 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6200 - val_acc: 0.7917 - val_auc_1: 0.9214\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0145 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6114 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0192 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6774 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6835 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0138 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5910 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0143 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7362 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0155 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6972 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0823 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.7707 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0253 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6673 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0155 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6838 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0133 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5973 - val_acc: 0.7500 - val_auc_1: 0.9143\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0459 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.7354 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0240 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.8470 - val_acc: 0.7083 - val_auc_1: 0.9107\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0880 - acc: 0.9565 - auc_1: 0.9976 - val_loss: 0.5737 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0885 - acc: 0.9674 - auc_1: 0.9964 - val_loss: 0.5187 - val_acc: 0.8750 - val_auc_1: 0.9107\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1754 - acc: 0.9130 - auc_1: 0.9845 - val_loss: 0.8039 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0316 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6702 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0115 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6726 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0106 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7043 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0102 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6914 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7077 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7149 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0098 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7111 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7080 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6907 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7122 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7285 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0100 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7373 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0121 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7311 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0264 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 0.7618 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0551 - acc: 0.9891 - auc_1: 0.9971 - val_loss: 0.7209 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0221 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.7128 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0148 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6960 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7035 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7192 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0089 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7117 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0090 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7804 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0189 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6561 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0284 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.6499 - val_acc: 0.7500 - val_auc_1: 0.9214\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0459 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.7923 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0408 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.6979 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0115 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6777 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0148 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8266 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0095 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6793 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0103 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6915 - val_acc: 0.7917 - val_auc_1: 0.9107\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7890 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 481/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0079 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6558 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 482/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0085 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7970 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7900 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7723 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0110 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7509 - val_acc: 0.7500 - val_auc_1: 0.9071\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7689 - val_acc: 0.7917 - val_auc_1: 0.9071\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7868 - val_acc: 0.7917 - val_auc_1: 0.9036\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8130 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7637 - val_acc: 0.7500 - val_auc_1: 0.9036\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0102 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8993 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0142 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8422 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8857 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0068 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6806 - val_acc: 0.7917 - val_auc_1: 0.9143\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0757 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.0236 - val_acc: 0.7917 - val_auc_1: 0.8750\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1278 - acc: 0.9565 - auc_1: 0.9843 - val_loss: 1.1791 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0876 - acc: 0.9674 - auc_1: 0.9995 - val_loss: 0.6956 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0588 - acc: 0.9783 - auc_1: 0.9979 - val_loss: 0.8709 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8472 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8541 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8502 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0061 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8426 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8554 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0054 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8482 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8531 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8585 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8490 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0049 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8513 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8562 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8644 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8446 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8511 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8687 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8559 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8641 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8764 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8788 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8768 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8859 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8386 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9212 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8870 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8809 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8722 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8761 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8863 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9173 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8803 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9173 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 529/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9232 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 530/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9139 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9244 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8691 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9970 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9046 - val_acc: 0.7917 - val_auc_1: 0.8786\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0044 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0401 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8094 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1485 - acc: 0.9565 - auc_1: 0.9895 - val_loss: 0.9760 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1546 - acc: 0.9565 - auc_1: 0.9826 - val_loss: 0.8508 - val_acc: 0.8333 - val_auc_1: 0.8500\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0386 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.9489 - val_acc: 0.7917 - val_auc_1: 0.8214\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0312 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 0.9173 - val_acc: 0.8333 - val_auc_1: 0.8250\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9137 - val_acc: 0.8333 - val_auc_1: 0.8179\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9150 - val_acc: 0.8333 - val_auc_1: 0.8179\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9156 - val_acc: 0.8333 - val_auc_1: 0.8179\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9164 - val_acc: 0.8333 - val_auc_1: 0.8179\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9215 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9147 - val_acc: 0.8333 - val_auc_1: 0.8179\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9210 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9239 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9258 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9209 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9185 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9252 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9288 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9293 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9216 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9225 - val_acc: 0.7917 - val_auc_1: 0.8250\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9249 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9216 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9366 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9233 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9409 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9321 - val_acc: 0.7917 - val_auc_1: 0.8321\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9292 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9355 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9348 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9510 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9361 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0026 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9215 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9217 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9411 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9356 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9523 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9489 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9650 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9402 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9942 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 577/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9738 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 578/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9726 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9404 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1160 - acc: 0.9783 - auc_1: 0.9840 - val_loss: 0.8524 - val_acc: 0.8333 - val_auc_1: 0.8321\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0154 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8601 - val_acc: 0.7917 - val_auc_1: 0.8571\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0886 - acc: 0.9674 - auc_1: 0.9962 - val_loss: 1.4666 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1619 - acc: 0.9457 - auc_1: 0.9888 - val_loss: 0.6717 - val_acc: 0.8333 - val_auc_1: 0.9000\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0220 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.5933 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6242 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6482 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6615 - val_acc: 0.8333 - val_auc_1: 0.9143\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6759 - val_acc: 0.8333 - val_auc_1: 0.9179\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6876 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.6996 - val_acc: 0.8333 - val_auc_1: 0.9214\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0024 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7056 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0022 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7195 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7255 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0021 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7375 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7396 - val_acc: 0.8333 - val_auc_1: 0.8714\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7474 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7576 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7727 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7775 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7799 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7867 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.7890 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8028 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8025 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8037 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8101 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8188 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8138 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8175 - val_acc: 0.7917 - val_auc_1: 0.8679.0000\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8226 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8327 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8426 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8479 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8709 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8590 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8583 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8699 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8664 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8768 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8872 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8886 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8782 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8987 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9198 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 625/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9281 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 626/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9282 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.8997 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9286 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9475 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9544 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9654 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9527 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 9.8023e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9624 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 9.8501e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9419 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 8.6755e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0168 - val_acc: 0.7917 - val_auc_1: 0.8464\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0166 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9641 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.4493e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9968 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 9.0001e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9990 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0927 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1853 - acc: 0.9565 - auc_1: 0.9810 - val_loss: 1.2037 - val_acc: 0.7917 - val_auc_1: 0.8357\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2014 - acc: 0.9239 - auc_1: 0.9921 - val_loss: 1.2622 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1111 - acc: 0.9674 - auc_1: 0.9910 - val_loss: 1.2026 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0561 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.8859 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9198 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9300 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9335 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9311 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9283 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000    - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9317 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9374 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9343 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9310 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9358 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9377 - val_acc: 0.7917 - val_auc_1: 0.86430\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9349 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9390 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9314 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9385 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9412 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9377 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9407 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9440 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9427 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9426 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9439 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9485 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9491 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9468 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9503 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9564 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9536 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 673/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9586 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 674/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9578 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9641 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 9.9453e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9651 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 9.6764e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9605 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 9.4875e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9684 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 9.4232e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9712 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.2559e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9729 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 9.0388e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9734 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.7570e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9755 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 8.9614e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9828 - val_acc: 0.8333 - val_auc_1: 0.8393\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.5850e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9755 - val_acc: 0.8333 - val_auc_1: 0.8607\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.3219e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9797 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.2988e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9895 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 8.0981e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9863 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 8.0008e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9837 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.7025e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9973 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.6464e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0062 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.5371e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9953 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 7.4386e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0044 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 7.4071e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0092 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 7.1204e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0060 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 7.0448e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9999 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 6.9866e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0172 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.7819e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0095 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.6014e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0393 - val_acc: 0.8333 - val_auc_1: 0.8429\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 6.6947e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9888 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 6.9551e-04 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0320 - val_acc: 0.8333 - val_auc_1: 0.8429\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5, X6, X7], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2dd5xU5fX/32d7Z4GlL7AoiFRFEbEXLFixJUIMamL0a+wtxjSDxkSTnzHGaFSMxhIbdsUuihVRUIqABSmy1KXssmzfnef3x3Pvzp3ZmdnZMruzzHm/XvOae+/ce+fM7Oz93HOe85wjxhgURVGUxCWpsw1QFEVROhcVAkVRlARHhUBRFCXBUSFQFEVJcFQIFEVREhwVAkVRlARHhUBJeEQkWUR2icigGJ1/DxHZFYtzK0p7oEKgdDmci7b78IlIlWf9nJaezxjTYIzJMcb80ApbhopIk8k4IvI/EZnhnH+VMSYninP9QkTmttQGRWkrKZ1tgKK0FO9FVUTWAL8wxrwTbn8RSTHG1HeEbZ1JonxOpf1Rj0DZ7RCRW0TkaRF5UkTKgZ+KyEEi8qmIlIrIRhG5S0RSnf1TRMSISJGz/j/n9ddFpFxE5onIkDbYE+A1iMgFIrLGOfcqEZkqImOAu4HDHM9mq7NvvmNPiXPMb0REnNd+ISIfOLZuB25xPt8Iz3v1E5FKEenZWvuV3R8VAmV35XTgCaAb8DRQD1wJFACHAJOB/4tw/E+APwA9gB+AP7WHUSKSB9wBHGuMyXVsWWKMWQpcBnzohKkKnEP+DWQBewBHAxcA53pOeTCwAugF3ATMAn4a9DneNMZsaw/7ld0TFQJld+UjY8wrxhifMabKGPO5MWa+MabeGLMKmAkcEeH4Z40xC4wxdcDjwL6R3sy5E298AD+OsLsBRotIhjFmozFmeZhzpjrnucEYU+7Y/Q9gume3H4wx9zrjHFXAI8BPXK/B2fexSLYrigqBsruyzrsiInuLyKsisklEdgI3Y72DcGzyLFcCEQd7jTH53gf2zjzUfjuBacClwCYRmS0ie4U5bW8gGVjr2bYWGOBZD/icxpiPsd7PoSIyGhgEvBrJdkVRIVB2V4Izee4HvgKGGmPygBsBaXJUB2CMed0YcwzQD1jp2AZNbd4CNACDPdsGAeu9pwvxFo9iw0PTgVnGmJr2sFvZfVEhUBKFXKAMqHAGUyOND8QMZ/D2FBHJAmqBCuzFHmAzUOgOYjthqWeBv4hIjjNgfTXwv2be5jHgLOz4wKMx+BjKboYKgZIoXAucB5Rj78Cf7iQ7koFfARuBbdjB3suc194GvgM2i4gbmroEKxirgfexYwARL+7GmDXAUqDWGPNJO9uv7IaINqZRlN0PEXkUWGWMmdHZtijxj04oU5TdDBHZA5gCjOlsW5SugYaGFGU3QkRuBRYDf2lNyQwlMdHQkKIoSoKjHoGiKEqC0+XGCAoKCkxRUVFnm6EoitKlWLhw4VZjTK9Qr3U5ISgqKmLBggWdbYaiKEqXQkTWhntNQ0OKoigJjgqBoihKgqNCoCiKkuB0uTECRVF2L+rq6iguLqa6urqzTdktyMjIoLCwkNTU1KiPUSFQFKVTKS4uJjc3l6KiIvxtFJTWYIxh27ZtFBcXM2RI9E31YhYaEpGHRGSLiHwV5nVxWuytFJElIrJfrGxRFCV+qa6upmfPnioC7YCI0LNnzxZ7V7EcI3gY2w4wHCcAw5zHRcC9MbRFUZQ4RkWg/WjNdxmz0JAx5gO3GXgYpgCPGlvj4lOnSXc/Y8zGWNmkJC7VdQ0U76hkaO/cgG1JIqzeWkFyEhTvqGK/wd3Jy7Cx1fe+3kK3rFRG9c8jPSUZsK53g8+wobSajLQkeudmsKOiljeWbWJsYTdeX7qJEf3yqKyt57RxA/hmUznZ6Sms3rqL9JRkNpZV4zOGtOQkDhjSg2cW2AZjYwZ046jhvXnui2K+3lROSpKAwMh+eVTUNJCflco3m8oxxlBeU092WgpJSQLGkJeZSlVtAwcPLWDFxp1U1tazq7qeBmNI9lwUKmsbyExLJj0liRPG9GP24o2IQEqykJqUZJ+Tk9heUUt9g88eJEJeRgo7q+rCfrfpqclMGtGbj77bGnG/cBxSUMemsmoQyM9MRYDSqjraWv1GBDJSk6mqawjdvqedSEqCgux0dlTWUtcQ25I9eZkpZKW1/2W7M8cIBhDYZq/Y2dZECETkIqzXwKBBgzrEOCX+MMbw1fqdjB6QF3DX0+AzVNTWc/e7K5n5wSpmTt+fob1z+PVzS/jpxMFM2XcA973/PXe+8x0vXXoIRQXZzP1mC1c+tSjk++xT2I0ftleyo9Je1LplpnLzlFHcO/d7tpTXsL2itnHfkf3yWL5xZ8jz/OrZJe346Zvn729/G3K7WL0I4P73V1FeUx/xfMHHhbvRNAb+35vfNLtfOMae0o8t5TaUsWVnNSJCV6uB1uAzlJTHvhFcanJmTIQgpkXnHI9gtjFmdIjXXgVuNcZ85KzPAa43xiyMdM7x48cbnVm8+1Nb7yM1WQIu+K8s3sDlT37JVccM49iRfbjo0YXcP31/rnjqS9ZsrcAXxU85NyOF8urIF0CAAfmZrC+tCthWkJNGt8xUvi+piHhsRmoS1XW+gG2XHLkn+w7M57FP1/Lhd1sbt1933F5MGtGHBz5YxfNf2g6UfztrLCP75XHD80v4ar0VmVH987j1jDHUNRj+/Opyxhbm89OJgxnUI4u3l28mLzOF6Q9+BsD1k4dz0WF7sLm8hgH5mQD89oWlPDH/B2acMpIZrywHIDstmUV/PI76BkOdz0d9g+G211cwa0Exc687kqKCbDaVVbNw7Q6OHdmHtJTQkeTj/vE+327eBcCKmyeTmZbc7PfrZcWKFYwYMYKS8ho2ltnvfEhBNrkZ0We9BLN6awXl1VbIM1OTGdYnt5kjWkd1XQPfbi4nLTmJOp9hVL8866k5/PznP2f27Nn07t2br74KOVwaE9zv1IuILDTGjA+1f2d6BMXAQM96IbChk2xRYsSG0iqWFJfy/BfruX/6/mHjlzsqaklNSSInPYXaeh/H/eN9MlKTOWO/AeyorGNkvzyud+6w73znO+585zsArnjqS1Y1c2H2EiwChwztyccrtzF94mDmrNjMhjJ7Z3r95OE8Mf8H5q/eztDeORw1vBfXHjecjNRkim6wveBfu+Iw7przHceN6sPzX6znqL17c8GhNlPj0XlreHPZJu6fPp7PVm/j6L37ANAzJy1ACC47ehgAd5y9L1cdsxdfrtvBlH1tb/pn/u9gfv/iV1w5aRiDemY1HvP8JYcEfIaTxvajwaOClxw5FKBRBAD+eMpIpk8czIh+eeRmpHLtM4upqG0gNTmJ1GTIxF68bzltDOcfPISigmwA+nbL4KSx/SJ+p90y7QX7tyfu3WIR8JKW7P9tJCe1bcygo0Yckpzfc22Dj/SU5AARADj//PO57LLLOPfcczvIotbRmULwMnCZiDwFHAiU6fjA7sXLizdwxZNfNq5/umo7RQVZ9OtmL1Bbyqv5fksF2ypquOwJu9+ym47nreWbWLOtEoC/vPZ1xPcIFoF7z9mPg/bsyb43vw3AQXv0ZN6qbQA8c/FB9MhOY9aCdaQnJ3HlMXsFXHD+dNpoDrp1DhvLqumfn4nP8ZZnnDKKQ4cVNO7380OGUFVXz8j+edw3fX8AztivMMCOcw8q4tyDigAaRQCgsLv/gv7ryXsHHDOoZ1bABT8zLZm//3ifiJ/fJTlJOH5UH4aHufNNT0lmRL88wF7cw5GWksTI/nlRvaeLK+55bbiDB0hJTuKBD1exuqSCrLTkNg0gV9c1NIrj0N653Dl134j7n3baaaxbt47q6mquvPJKLrroInJycti1y3o6zz77LLNnz+bhhx9m8+bNXHzxxaxatQoDXHfT39h3/IGEGog4/PDDWbNmTas/R0cRMyEQkSeBI4ECESkG/gi4TbnvA14DTgRWApXAz2Jli9IxLFpXyobSKk4c04+nP/+BXz+3NOD1aQ98CsDgnllM2ac/d727ssk5zn3oMwTYo1d2k4v8P6fuywffbuW5L4oBePWKQ7nt9a+Zv2o7i/54LJmp/ovHc788iMzUFIYUZHPLq8u58phh9M61F8DfnBDoMnsZ2D2LjWXV9M5N5/Bhvfh8zQ4Ku2cG7HPjKSNb9sV46JOXwU2njmLSiN4BotAe3D89pNffhO5Zae36vq6W5mW2TQhSPR5BiwcaImCiGCl+6KGH6NGjB1VVVRxwwAGceeaZYfe94oorOOKII3jhhReor69n/rc2pBeL2H1HEcusoWnNvG6AS2P1/krH4fMZkpKE0+75GICvbjqe374QPh66dltlgAhMKOrBqq272LqrloVrdwBw+dFD+Zezz0lj+vHq0o0ctEdPjhnRh5cWrafeZxjWO5dHfz6B8pr6Jv+E+w/u0bj859Oj79j4r5+M442vNjGoRxaXHjWU08YNYGCP9r1gn3dwUbuer6X0zGlvIbAX7ez0tl1OUpKTuPCwPQAYPaBb43lbw5qtFex0xgj65IX3gFzuuusuXnjhBQDWrVvHd999F3bfd999l0cffdTanJJCbl43AAYE3TB0JbquhClxwZwVm7nw0QW8fNmhjdtufmVZQMwa4O8/2ofBPbO4ZtZifthuwz7TJgziiL0KmDzaxqDnr9rG2TOt13DimH68/tUmVm7ZxV3TxnHDCXvT2/mHXnbz8ZRW1jUOXrY1JOGlT15G44VahHYXgXggP6v9vi+gTRfscOdpr3MO6pHVOIYRjrlz5/LOO+8wb948srKyOPLII6murg4ITUUzQau9bO4MVAiUqNi8s5q/vvE13bPS6JWbzlfry3jv6y1U1DYAcPK/Pmrcd9aCYqZNGMg5Bw5u3H786L7kpKfw9jWHM/z3bwBw48kjAwYXxw3qzhnjBvDzQ4cwol8ez158EDsq60hOkoALcnpKMn3yWj8omei4cyLOObB9UrEnjejNRyu3MjCO7oiz0pLZWV1HekpSs2MNZWVldO/enaysLL7++ms+/dTejPTp04cVK1YwfPhwXnjhBXJz7fjLpEmTuPfee7nqqqtoaGhgV/lOcnJbNq4Sb6gQKADsrK7j9y98xa9P2Juq2gaqahv4akMZfbtlMKGoB0ffPrfxoh8NZ+xXyOgB3RrXc5ywQXpKMmeMG8ArSzY0yTBJS0nijrP9g3r5WWnkt3M8W7GsvvXEdpvNe/7BRZw8tj+9ctPbfK6CnHSqWvA7C0ev3HRyM1LIjCJuP3nyZO677z7Gjh3L8OHDmThxIgC33XYbJ598MgMHDmT06NGNA8f//Oc/ueiii3jwwQdJTk7m2pv+xj77Twh57mnTpjF37ly2bt1KYWEhN910ExdccEGbP197o0KgAPDwx2t4efEGeuak8d+P10R93Bn7DWBQj6zGdE6X/Qd1D3vMHWfvG3U2jBIb2rOkg4i0iwgA9M9vH69CRKISAYD09HRef/31kK+dddZZTbb16dOHl156qXF9e0VN2LDQk08+GZUNnY0KQYLz4/vnkZue0pj/vLS4DIg88WrahIGctX8hn63ewcVH7IGI8LODh/DeN1u46ulFXHH00IB86h7ZTe/qtbaMsrvQI7t9RLAzUSFIIN5Zvpl9BuYH3L19tno7AOnOwOsCJ2vn8V8cSF2Dj5tfWc7fztqHCx75nOIddtbnrWeMBQIzc7plpXLauAEctXfvgMG5z393DOmp2v9I2X3Ztm0bkyZNarJ9zpw59OzZsxMsajkqBAnCzuo6fvHoAvYdmM+Llx7S5PWaeh+HDSvgw++2kpuRwh69cshJT+ElJxvow+uPYshvXmv2fYIzNNorZKAo8UrPnj1ZtCh03aquggpBgrDOSdlctK6U0+75mEXrSpk8qm/APrecNppBPbIap8t7EREG9sjkxDGRyw0oitL1UCHYjamsrWfkjW/y4/GFzFpQ3Lh90bpSAN5Ytgmw5Qn+c954Bve09WWCRcDlw+uPjrHFiqJ0Bhq83Y3ZtsuWS/aKQCh+d+IIjhreuyNMahk+HzTU2zrHDc1XDFUUpXWoEOxmVNc1sHlnNcYYNu+Mrl1d8CzguGHWdPhTT/j4TvtcXdbZFinKbokKwW7Gxf9byIF/mcM9763krPvmNW4/YXRffnX8cCYU9eC8gwYHHOPWZIk7vp5tn+fPtM/VoRvAKEpHkpOT02nvPXnyZPLz8zn55JPb9bw6RrCbMfebEgBufyuwW9U+A/O5+Ig9ufSooRhjeGTeWgpy0khJSuLMoBLKcUd1aWdboChxwa9+9SsqKyu5//772/W8KgS7CTsqaqnz+cK+fuhQfz19EeGNqw6jf35muxZsaxd2lcCzP4MzZvq31dmMJ+4cDQdfAcf9yYaJnp4OSSkw5kewb8Rit3ac4emfQnoeHHgRvPUHGH0mlP4Ax/wx/HHPXwSV26GiBH70MKxfCN+/B6fd0+aPqoTg9Rtg09Lm92sJfcfACbeFffnXv/41gwcP5pJLLgFgxowZiAgffPABO3bsoK6ujltuuYUpU6Y0+1a7du1iypQpTY5bs2YNJ598cmOXsttvv51du3YxY8YMVq5cycUXX0xJSQnJyck888wz7LnnniHPP2nSJObOndvy76AZVAi6KN9tLmdwz2zSUpJYuWUXx9zxPmnJoSN9y28+vkmZ5r37xmmRrM//A2s+tM+h+OQuKwTfvgWr37fbvp8TWQiMgfVf+ENNW5bDxkWwbaUVmWP+CPU1UFcFmfmBxy552r+84Qt4zqkTo0Kw2zB16lSuuuqqRiGYNWsWb7zxBldffTV5eXls3bqViRMncuqppzY7Iz4jI4MXXnihyXGROOecc7jhhhs4/fTTqa6uxhfhhi5WqBB0QbbsrObYf3zAnr2y+b6kgiOH9wJsuzyAly49hDeWbWJpcZktvJXahSp1ljvdSnMjzFeorWx6wY7Eqrnw2Gn+9RpnrKG2wi5X7YBZ58LqD2CGZ0A6uJ93lSdE1VAHyXHmTe0ORLhzjxXjxo1jy5YtbNiwgZKSErp3706/fv24+uqr+eCDD0hKSmL9+vVs3ryZvn37RjyXMYbf/va3TY4LR3l5OevXr+f0008HrJB0BioEXZAdlXZw122iPvebElKShHqfYUB+JiP757HPwBZcKNvC+i9sDH/Pdphj8NXzsMY2t6GmPPx+b98IexzRdPt3b0N2L+gf1JZwx+rA9QqnZ7ArCDvWWBEAeO1XUDgBtiyD8T8PPK7E0zazqhSyC2DBgzDqDMjqgdJ1Oeuss3j22WfZtGkTU6dO5fHHH6ekpISFCxeSmppKUVFRVD0Jwh2XkpIScKfvnssE32x0EioEccxTn/3AkcN7N+kxWx4iy2dU/zx+c+IIBuRnkhomRBQTHjjKPs9oY2qnz2fHBlzm3BR+388fCN3K8PGzQtuyqyRwvSYo+2jHGv/yZzPtAyAlqBLmZ55xi+pS+3j1WlgxG859Mby9StwzdepULrzwQrZu3cr777/PrFmz6N27N6mpqbz33nusXbs2qvOUlZWFPK5Pnz5s2bKFbdu2kZOTw+zZs5k8eTJ5eXkUFhby4osvctppp1FTU0NDQwNZWR3bEEnTR+OU7RW13PD8UibeOifgwr+zuo6HP1nTZP8rJg1j4h49u25HrceblvsFYPAhcN7spturdkR/7ootkV9/5vzQ2+f+JfwxVaXgcya5bQ7fllPpGowaNYry8nIGDBhAv379OOecc1iwYAHjx4/n8ccfZ++9947qPOGOS01N5cYbb+TAAw/k5JNPDjjfY489xl133cXYsWM5+OCD2bRpU9jzH3bYYfzoRz9izpw5FBYW8uabb7btgzuoRxCn1NT7m3OMmfEWD5w7nr55GZxy90ch9580ok9HmRY9ldvB1wBp2VC5FVIyoHwT9BgC6bmB+34/J/Q56qtDx+LrqgLXvXf9NeX2/KU/WMH47u22fY5QlKyAvAF2uaLEjifEsrR2bQVUboP89ukqpjRl6VJ/tlJBQQHz5s0LuZ/boCYUkY674ooruOKKK5psHzZsGO+++25UNn744YdR7ddSVAjilMqgLk3XPbOYrLQuNOgL8Lch9nnI4f4YPEDvkXBJ6H+WJtSFEYLgWca3D/Uvf3A7HP17uDNE0/qCvWDrt023N0dyOjTU+Ndfvjzw9R8+hcEHtfy80fL4j2HtR20PwSlKCFQI4pTKmkAhKKuqo6wqTmcAN4dXBMCmb758ORx9o43PL/xv+GPrqyA5RLvKym3hj9mx2g5iezn3Jeg1ArZ+A4+cErXpjfQdA+sXhH+9fGPLz9kS1jqeYH0tpGj7zs5m6dKlTJ8+PWBbeno68+fPj+tzh0OFIE6pqA1dZO2aY/fi8L16UVlTT73PMHvJBg4oioOMFZ/PhkaiDY988SgMPBCWvQgrI4Ru6qohKYRH4Gb+hGL76sAMH4D++0FGnn9yWkvpv29kIeio2c/VpZAThwUC24gxpkt1rRszZkzMehC09dytyURSIYhTwjXwvvCwPQKavh++V6+OMikyN3eH/MFwxSI7A3jvKGqh7Fjb/J10/sDQoaFwA8CZ3WHTEnglKBab4Uyga8n8Ay/99o38elWQELz9R/jyMbh+FXx4B7z3Z7gxghfj8s4M+PpVG/oacjgsfcZ6My7/2h+GnwhntG+Jgc4kIyODbdu20bNnzy4lBvGIMYZt27a1eD6CCkGcsXLLLsqqapt4BLMvP5Sl68sCRCDuKF0LuzbDzvXwWRQXqh1r7ECrS1KKPxPH5ezHbXgoGvqOhVP/BTM9cwyOmWG9AZf0oBnV13xtq5wWfx7+vEfcACOnwIqX4bu3Qu8T7BF8fKd/2U2Fra+BFE/HtpJvIKMb5Pa1IZ8NX8JH//C/vvQZ+/z5g/5tNTthyVO7lRAUFhZSXFxMSUlJ8zsrzZKRkUFhYcvqh6kQxBk3vbKMVSUVjC/q3rhtv0H5jB7QjdEDunWiZSEI5YIGT96KxNZvrXC4ZPdq6iHk9LKZRqHY9xxY9Lh//ZArrRh4OfTqwPUkj5COnQp5/eDgy+3M4nAMO856FIdfH1oIMvKbegQu3u+oqhRynewunw/umQB5hXDNMisW8+4OfY7kNJBkMKG9xK5OamoqQ4YM6WwzEhqdRxAHlFbWcsNzSyitrGXh2h2sL63ipUUbGl9//pKmPYbjgvoQMy23rIj++I1BcdCsgtD7hRosBjjw/+B3HiFJz4OkFvykT7vXPmc7Mfd++8A1Iez3OYP0KWH6L+f0hi8egXsPge/fDcwo+uwB/7LXa9jspCruLIYHjoZvXg9vZ+na3VYElPhAPYI44IEPV/HU5+uoqG1okjYa1wTn8gNs+74N56sIvT0pzM80uzekemKh6VHWiT/uFsjr7xeNbEeAasptjaMDfwl7HAnv32bXB+xvXw8nBGnO+27+Ch47PfC113/lX/Z6Dds9ntP6hZHtjRS28vlaJn6KEgIVgk5k9dYKHvlkDZvK7J31K4v9XkBeRgo3nDCCUf3jtEooNM3lT06DsnX+9bxCe8cLcOaDNqXz0whVO7sXwfZV/vWMfP95XfY7z959g/8C7hI8SS0cBwfNAcjqaZ8L9rJZT27hs+GTA/cLJwTRFp/zegStzV4CfxbVshfhmfPgyiXQfXDkYxQlAnor4bLsxab57jHmtaUbefiTNY1N5L1MGNKDnxw4qOOKx4WitgK+fs3ODv7iUX+d+C0rYOMSWBeU15yRHygE3gtzTh87cHv49eHf74wH4OeeKfOXfGqfvRfaE/5mS0789LmmF+C0II/gii8jfTo/WT3g/NcCeyCEIsXxPtJyYYpH0MKFroKpKrUTz8qK7XfbWtz3e+/P9tkVzw1f2vOvmmvXd22xoamKKLKVwrF2Huzc0Px+8UrpOlj3mZ3l/tkD4cebEhwVArBlCJ45r3UTjdpAeXX4huxn7T+wAy0Jw+vXw1PTYPFTNu791E/s9n9PhPsPaxqyyMy3FzkXrxD0GWUnQo0IkVa65yTrDWQXwKCJUDAcCg+wA7ngH+A97DobChpyGAw9pul53IygvU6wIZ0ee0T/WYsOsRk8kfBe8Ed6ylpLlP9G1aXw0PF2TCCURxDqM4WirtIOQpc6ouuG6GYeac//6BRbJvvTe+G162DR/6I7bzA+H/x3Mjw0ufl945V7D4EHj/V/FwsiTF5MYDQ0BPZuwcWtUxNjPvl+K/e974+nT5swiNED8th/cHf6dcukW2Yc1LrfvNw+uyUZSn+A5//P//qaj2y9nZ3r7XpGfmD5Bvd7nPRHf5nm1Oym7zP9+cD1yz5ruk80pRXcMYKfPNX8vq3B9UBS0iE1yuJ+uf39PRZed7yhXZttKW0vF38MfUfb5RkeQepeZNNsT/h/trPaR3fCO3+0F//kNJtaG2oyW1mxHWSGyLOwI+FmdJVGV3kzLqlxfjcrXrbPbQnJ7caoR2CMdalddnTMj/6ZBcUB6/sO7MY5Bw5m7755sROBiq0tq9qJk/q49hP/piWei2zJ11A43r8ePFnLvTB7UzbdOHtmDGZDh4vhtxdpOXDkb+H8V+0A7aQ/wkVzm+53yJX+EFj3wXD0H6I4dwiBBDjyN3DAL/wd2Nz9qkv9mUShfrOblvi3u4PUNeX2pqe2ws7Ybo5NS+xzN8c79flC94kIHiuKR9yZ5g21nWtHnKJC8PWr/vaD0LqCZC3AGMNzC4vZuqsmYPsevaLMeGktDfXw//aEu8ZFf0y9809THOIO3aW7k/+dlNK09MHAA+1zz2H+ba44uI1scvtHb09zNsQaETjy19DbKSF82DXQf1zTshpH/gaKDrXLSSlw+HXNnzucEOT2g5P+7veuXE9k5pFQ61TBfP82qAmqiPnKVdaDA0c0DNxaaAsB/qU/PHxSZHtWvQ9P/NhvA8A7N9pzeMc31nwMtw2KTYXX9iA4Jbm+JvR+CY6GhjYvC1xf8xGMPiNmbzdv1TaufWZxk+2DY9VHYMsKOxDez5lo1R51/PuO8Q8cdy+Cq5ba6pySZOPcvUfaGcK9R9qYv5t+CbYExC8/sfH7o38H6e0wSe6i9wLDex1N8OqSDJ4AACAASURBVMS61Ez/DOmkKGeCe0NNVy+Df4yyy8FejisYu4LaH3qb63QbBGU/+NerSpvO+Vi/ADYssuXBQ41NuP2g3fdc/SF88i+7Xlvht2ONUxZ53Wcw7NiwH6/TyB9oZ2NPexJevlI9gjCoEHj/gfqO9WdcxIibX1kecnuv3BiFNf49sek2X0PzFyhfg40tDxjftNjafufZgTewQuCtkT8qKI/eKwIufZyLXEsGcyOR2d0+OpvsXrZcBPhrEx1yVeA+San+CWpevELQrdCmtFZua5qRFM5z2LbSv3zGTDvI61JdGnrOh1uKI9T4i/fOOTkVnpzqX/d55rq43kFqUDe3eKG2EoafYMUuJU09gjCoEHiFYNRpMOdmePcW+P49OOVOe/fbDhhj+OC7rXy9qWmM9b/nH9D6YlsNdTbbaeQUWPQETH8RsntGPqauMvKAeG0F/Gs8GB8MnNBUCHI8TXA0f90fGjruz7DP2XY5u2foC2xqln8A00u4SWHBHkHwIPW46ba4Xck3dv3Ym60X5q3btHExvPnb8PbP6GYzrnL72TLd6d0CS10Hl9W4+wAreOe+6BeYcALV2dRW+BMUktPVIwhDTMcIRGSyiHwjIitF5IYQrw8WkTkiskRE5opIyyoltQc71sDAiTYOu9/5dtsH/89e/D4JU/slSsqq6pjx8jKqaht4cdF6znvIxtovOXJPkgT2HZjPu9cewVF7t6GscPEC+GEevHGDHdyLFM93qQ2TOVG53Xb6WvOxP9Ol59Cm+7l3vdA+Mf6ujhsaSo5wX/Xzt+BHj/jXx023cyF++Ym/1EUoksOEhlzS82xvZfeGJiXDClM3519pf6cP9PKXI3+Gmp1WBMAKVUWEAnC15bDtO1sMr2q7/33jkTpPGCslTYUgDDHzCEQkGbgHOBYoBj4XkZeNMd7YyO3Ao8aYR0TkaOBWYHrTs8WIump7wdv/fJuZAXYQ83unbZybx95CFq7dweOfrqVXXjoPf7KGR+atCQgjTx7dl0uOGkp2WnLby+4GX/ij+Yes3QWEaG1517imqYgFw5ru5x0UTo3TC0BnEGli2SBn4Pxlpzz2sGP9sXk3VObF/cEEN6EJFgJfvQ1JuRP53L9/ihOq2fMo6wEueTq6z9ASPrrDY6+v/c/fHtRWQprjRSVraCgcsfQIJgArjTGrjDG1wFPAlKB9RgJus9r3QrweO3w+mO3Eb7sX+beXewbhWjkAef5/P+P5L9dTstP+6LwiMPWAgezdN4+c9JTWi4Ax1lvZuaHpTMkPbrd39MteCH/8sz+Hly6D5y70H79+YVMROOUuWxM/mOYmXiUa7t8xqhnGzo8hVLOdUPsFnzM4NGQabIVWN0PIjdW7Ap2e6y/VEYrLPGG/sx5qxiYPBcMD1xvisHteQ71tL+rOONfQUFhiKQQDAE+9AYqdbV4WA2c6y6cDuSLSJMAtIheJyAIRWdBuNctLvobFT9rlXp4f9Yl/sxe/nkMjd8GKQF2DvTt6/sv1Adv3KezGbWeOJS2ljV/7tu/hrd/ZC/quoMyetR/BwyfCM+fbQT33H/b4W/37bFxk48pLZ9k0Q7CzXYPpMzr0+wfX9Fcs4YrjhSLashTNDRb76m3xvUaPwAkluR5BUkrkZjwFw2D0WVb0B3uq3AaX827OroY4vNN2M6UavxP1CMIRSyEIdbsbXMD+OuAIEfkSOAJYDzSpu2CMmWmMGW+MGd+rVzt15PLWxPH+6IsOhfNesTHWcOmTzVDX0PJWcS17AydTo6Y8cix3wyJ7R7jn0XDQJf46Pt64fnBa4QTPzOG0MCmt0aZEJhot8fAijSeAPxMr+LsOFoLMHtYjcEMzrgC4GVlJqc2XwDjrQdj/vMBaTRd/GPmYYOLxTtudcCfOd5icHp+CFQfEMmuoGPAWzCkEAqpXGWM2AGcAiEgOcKYxpmOmKbpTzk+/P3TGRkY32Bl9Q3Kfz1DvM6SlJNHgCy0E5x5U1ApDQ+Cm7G3+yuaMh+OTu+yg915OKqF7Qcjp5R8M3rLCTqpz8ZaCjlRGYfqLgdlDSnSYKENDP3nGenfBYbjgQntH/Np6dy7u3e8Jf7UZX4Mm+n/rzdGWzJ/6OBQCN83VFdOUtPgMYcUBsfQIPgeGicgQEUkDpgIBv0gRKRBpvF35DdCCIGUb+dIpxDX27NCvp+eGnk7voaq2gfe/LaGmvoE/vbqcvX7/Oj/9z/wm+1142BDW3HYSZ+7fTklR3rr23olDwSx/0T67IQv3wj1uuu3uBbBrk7+YHNgCcC7uHaLXY3JnBO95FPQZ2XLbFUtzpatz+8DoMyPvc/j1ThE+zziOezFPz7F3+SKBIZ9I3kFbEhfi0iNwRLfRI9DQUDhi5hEYY+pF5DLgTSAZeMgYs0xEbgYWGGNeBo4EbhURA3wAXBorewJw714Ouiz8jz89r1khuPX1FTw6by13/Hgf/vvxGgA+Wtl0XOF3J7XzBdM7qHvmg4ElMkLh5pN3Hww3/GDvMhvqA9s8XjLfXnwyu8OzTsqhGxr6xRzrZhtf9LFtJQyuR9CGf73fbrAXXndWtrfERn4ID3HEyTZkVF8Fl38BW7+DJ37U+vcPRVwKgRsacgfzdbA4HDGdUGaMeQ14LWjbjZ7lZ4FnY2lDSNwaLd0i3KGn5dj9wnSA+r5kF4/Os0W9NpaFL+D1/q+ObIulofF6BM0N6kHgj98NNQTHqN36OV4aUxH14h8R984zVA/ncLRFUNOyAU8Yx/v3yQ4zhvaz12D+fVYoIvUXOOLX/tpQR/8B3v2TXU7vFjgR7oyZcO9Bdjk5TvPzQ4WGqnZoV7cQJOa34ZaijRQDT88FDNzcvWnJYOB3LyxtXJ75waqA104c05e3rj6cd645nME9YzDj0lsvKDM/dBaPNwTgC9/3ICRuZdC2znFIFHruaZ8jZecEE21Xs5YS7m82YD978U5KjjzYf9RvYazjLRx+nT88+NPnAvfrM9LviWTkw2cz7QzlO0LMiegsggeLU7Ps//5T0zrPpjglMYXAnVkbaXDM2//2438GvHT104v4dJV/jkFZlX8A6rrj9uLf5+zPXn1yGdo7Rn0NvBlPGflwyTy4IKj6448ehn2c2H9DGCG44ks49V9waVCDmV9+Aj97o93M3e05/laY9lToukrhaEtoKBSXfg7/F2WmT0ve2ztr+lxniM+9ybjgLdvZzVsGY2dx/AzIBnsEEy+xz25JaqWRxKw15IaGIgpB6Fz5x+ev5YWg+QEuD543nkkjOiCTxlsfKSXNhriCw1y9RtjPt/iJ8G57jz1CF37L69fqWdUJSWqGLWzWEtrbI+i1V/T7RttRDfxpqclp/tLah11rn3N620dwmKusGHp0UGnwSAR7BN0G2JIbK17pPJvilMQUgmhCQ8H9b2edh0lKIWPxJuCXgDCkIJveuenMX229g/ysGMbS62tseYK9T7K1hZojf5C/M1WoapdK5xBt+mgsaZE34pnhnJQcupBesBDsWNMyIajcDv87w06MO/t/7Tcm1Zg15BG+9Fz/jaDSSGIKQTShocIDAteXv4gAZybD7+ouoJp08jJSuPsn+3HPeyuZvWQje/WJYXOZ79623cHcDmEHXQb5QZU/T7wdyjfa7IjUDH/WT7jQkNIJhCkd0ZG0JjQU6Zhg76aqhaVZ5t3t7xJY/Jnf82grwaEhsJ5+fbUNX8VqnKYLkqBCEEVoKLsnjJ0a2JrRIYNaqkkHEXrlpjPj1FHMODXGg2TlnsltRYfB8X9uus+ECwPX3YuNegTxR3Mzi2NJS2aGe0ND4QgONYXqfRCJcNVw20pjaMjrETg3azXl/j7aSoIOFkcTGgI7kNqnaT+CDGzM3bQkXbC11NfAl48HCkGwJxAON/wQL4N3ih/pxDIdLfIIXCGIcPfsZiq5E9taKgTe2eztSUiPwEngePN3sGRWbN63C5KYQuD2dw0eBwgmJQ0mXgwItUl+0UgXe2H905QwRdnak0/ugpcugc/+498W7Z1MnlNT6Ijr298upXUcc5N97sz6/S0ZLG4MZUUKozhCUHSYfW6LR9CeN1fBg8Xg/59f/AQ8f2HToo0JSmKGhtyZudGUUx73Uxj3U6578kvqlr7AvWn/JINaZv3fQewzsAV5463Fnd3sncwTrRCkZYUe3FM6jwMvso/OpFXpo5FCQ44QuJl2LfYIWrh/tLjejNcjcIssFk6w4xH3H95UlCf+0j6/fr1t1Tr9eSsYd4/37HMJTL6VkLx6HfQdbfucdBESUwiqSiEtN+o47cK1O3h58QaOdkItz5/dl+zB3aBsvU1JiyWhWkpmamxTaQMtqh4bRZaT62GkpFvBqAsR86+tgF2eXh/dBtnqvlk9/b0UwH8X31LK1lsPuKHOdlvLLrAziL32AYw41bb1PPRq+PD2poUl1823M7C3O5NE1y+AhY80bdf56b/h6N/7xxkb6m1L0LoK+PwBu613lKVlcvvZsYukFPv/XlVqv6vMHnaSYsVW+z3VlDffhraVJKYQVJe2aBbo6q02hlmNvSvKfvF8eL/Ipsld+01g68b2JtRAWlZsfgxKgtASj2CvyfDtG9GFhpJTbWOcUHf4/z3R9sFwyegG1WVNS0O3JsNt01dw3yFw0h2w6j07T2BGWZjQUBYc80e7fOzNTc/16b227auXt/8Q+n3vPgCucRouLnjQehBeHjw2Ovsz8u01qfsQuHIRPHaaP4sqPc8KW1qubREaIw8/MYWgqjRy1yYPu2rq2VVtxwRqjOefwZ3Utep9f8Py9mbBQ7BledPtmu2gtIWWCMGPHrY9LyKVG3HvuJNSbQJGfZAQ+BoCRQCsCEDT/gAL/wvDjonePoBVc+3zus/8k8Xqaz2DxS0YExl/AfQeAYgtwJiaBaVr7Gtr51kvwmWnZ2Kp28TqnOesZ2QaoivtsmGRv57TjtV2rpArAmBFAKwIgBXKGGScJaYQROkRbK+oZb8/+Us3/HXqBAjuAFmyop2NcygrhtlXh35NPQKlLbRksDg1M3RF04DzNeMRlEYolR7M17NtL/GW9MLe/n3TbXUVoT2C5khJgz2ODNxWMNQ+J6cFCoGXhhr7ektFrHACLH3Wfx354pHI+9dVQHL7t4pNTCGoKvUXCovAm8sC+wEP7VfQdKdNS+F2px1kXSWc8QAMn9xym/53lr2zyesPVy2xQuBSsBds/da/rmMESlto7zpH3tBQiiMECx+Bt/5gB2zdu9nzX/VPFpsR4WJWUQL5A8O/HowbPvWWXvnfWTa+D+3XUS9cluHaT5rUI4uajDy49FO7HOk7camtjEnP8MRMH62van4OAdYjcLn86KFN71LScuD792xzl12brBv3xq9bZ9PKt+3Er9K1dpDL+6MedpwVGJfM7q17D0WB9m816noESY5H8O2bsPQZG8LwzhHoXuRfPumO8OdraYtYd4JopacXiCsC0H5zNsL16v4wwmdpb0INxLcDiSkEDfVRTfHfWVVHekoSa247iWuPG940zSy3X+uzHCJRVxlYYXTvk2Dsj/3rnTkrVen6xMwjSLFd8Hx1sOZD6D8ucEA211PI0O10F4qKps2dIuJeHKtK/bYEmNdOl7n0MB5BLK4B4YhRnaQEFYLaqOqMlFXV0S3Ts1+weLgumrd374410f2Qq3bYPgehZv3OvRXevcW/HiqFVFFaS3vPam70CFJsz4OBE+16/mBbE+vq5XD96kBPJDUz/Pnm39ey93dDQ9WloS/6sQwNrf/CPyjdEcSoHIcKQRi+3rSTpz5fx5ZyT1ZDRj6MOMW/7mYN9B5pswVcoqkO+s5NNq647MWmr827O3Dd/QGeeDscek3z51aUSMSqO5cx9q550o3QdwzsfaIViW4Dmma6RZpZXfJNy97XDT/56kPfnbeXR5CW3TSk/Mgp/olrHUGMynEkphD4mg8Nvf9NSdONSUm2TK6Le+d/zAybLXD5F3Y9GtV2ewQEp8+Fwo1NTrjQnwOtKPFC44XWmXxWdAhc/BEMjZBBE0kIWtpgvraZi2N7eQQi8OPHArc11HasEDT3WVtJYgpBFB5BdnoUcVS3qqc7CObeLSx9Bn6YH/lY1532NfhnQIYjXGxSUeIB97fckjpB3q5mwbRYCJrJpIllgb+GWhse6ig0NNROGGP/eGGmzC/bUMamsurG9pMzp4doP9i9yDbR2O88u+7OSXCnm698Gx46zk57D4f74zQNzXsFkf5pFKW17NNOvXtdj6AlQhBpglrwhLTmqKsMWSXY/17teJnrNdy/PHKKfW6pvW0hRqGhxEs/cQd2woSGTrrrIwCOGdGbrLRkjhsVonzE5c7MP5HANLjg/gb/HAtXLm7aRhL87qqvoeV3QIrSVm7c3n4XyODQUEv5wzb4k2eSpK8+8gza4oW2cmhDHXQfbGvwDDoQehTBl/+DYcfbZIziz+z+7Zkumz/QfnfG2PN+cDu8d0vzx0WDJNsbw2tW2LlCDbX2s2V0swPhxgdZIeYytQOJ5xG4sflmQkPvrNgSmDHkJSnJPkQCf6zBPzhfPbwdJqYvUQrBJB0TUGJAUnLku/KWcMo/Ydx0GHJE645PToGT/m77bA87zm5zq4SG4tEpdjZx2Q+wZYWdpDbseBjh3KFv/z5w9n17h4aSkq3NIrDP1PY77y/ehoMvt2m2qRl2slm3ATY03K3QzvBOa37+U2tIPI8gghD4fIF3NLuq26HFY7icbVc06irDh4Zy+sBhmiWkxDndCmHK3c3vF4kDfmEf82faSp/1NeHHxry59HseBWc6vTrcPiPe+QoQuywpaNkM6OYYsL99dAKJ5xG4haBChIZ21QZe+E8c06/JPi1myVOw/OXwry9/sWmJW5eLP2r7+ytKvHLJpzYM4sUdDwsVdy/5FlbOIWwIKj0HLnwXfhRUryfW3eAuW9D8PnFO4glBBI/A6wGcf3ARfzqtDR3IDrrMvzxrOmwOqiLqur4bF8Or1/q3H+4pZZvTu/XvryjxTu8R/i56Lu5Es1Dh0nsOgP+dEbjNTdhwGbC/rdk//mf+be1dUiOYgmGxPX8HkMChoUCP4OGPV/PvubaK4d0/GcfJY/sHH9kyjv9z4MSwVXPt3f+GL6F8k7+8rJdpT9uCdR/8rW3vrShdFdcjaK5r2Y3bI1/g9zrev9yeWUO7KQkoBM5df1D66J9eXUGDM0aQm9F8+Ymw/PhR/7mP+zO89Tu7/N1btmlGJKq1raSS4KQ4HkHVdvtcWwHbVgampkpyy+7yYx0aAps92Hds7N8nRiSeVIYJDQ3I99c+yYlmMlk4Rk6xU+sB9v2Jf3s4ERhyuH85Rm3oFKXL4Fb4fcQp5fLCxbav8ExPRlJLB1RjHRoCOOACGHhA7N8nRiSgR9A0NOTzGTaV2Zj92MJuDO3VTjN5Q812POu/8Kw3fun8CcZN90/Jv+brGFSIVJQuQENt4PqW5TDoYDj4MutpS5JtDN8SNDTULIl3tWnMGvJ7BJvLq6lt8HHLaaP56cTB7fde3juR7kNgwH4w+gzYucGGjCZeAj2H2nZ13kGvvHbIVlKUrki/ff3L9TW2u9neJ9lHS3EnaHWER9DFSTwhCBEaWrfdDkwN7BGbyRqAbUrtcvBl9uFywAWxe19F6UpkF8CUe+ClS+Hvw+3/q7ehTUtISoaGBvUIoiCBhcAfGlq33RZyGhQLIZj6BOSEKFOhKEpohp8IEy+1KdYp6TDi1Nadxx0kViFolsQTgqod9tnTGGPdjkpEoH9+CxpmR0trXFpFSWSyesDkv7T9PKPPgEWP63hbFCSeVK75CFKzofeoxk0/bK+kb14G6SkaS1SU3YZT/gnXrdTqvVGQeEKwfRX03htS/KGh4u1VDOwew/EBRVE6nuRUyOnV2VZ0CRJPCEJ0J/theyWFPSL0UFUURdmNiakQiMhkEflGRFaKyA0hXh8kIu+JyJciskREToylPYAt++yJGZaU17BpZzV799UG8YqiJCYxEwIRSQbuAU4ARgLTRGRk0G6/B2YZY8YBU4F/x8qeRnz1AXnF0x+0LSX3G9Q95m+tKIoSjzQ7nC4i6cCZQJF3f2PMzc0cOgFYaYxZ5ZznKWAK4C3DaQCnMzvdgA3RGt5qfPWNHkFlbT1fbyonPyuVcSoEiqIkKNHkVb0ElAELgZb0VBwArPOsFwMHBu0zA3hLRC4HsoFjQp1IRC4CLgIYNGhQC0wIgUcIvlhbCsCdZ+9LclI7dWtSFEXpYkQjBIXGmMmtOHeoK2twR4lpwMPGmL+LyEHAYyIy2hjjCzjImJnATIDx48e3sjGqg2eMYP7qbSQnCeOLerTplIqiKF2ZaMYIPhGRMa04dzHg7eNWSNPQzwXALABjzDwgA4hNd2YXzxjB0vVl7NUnt23VRhVFUbo40QjBocBCJ/tniYgsFZElURz3OTBMRIaISBp2MDi4Z+MPwCQAERmBFYKS6M1vBZ7QUPGOKgbHsr6QoihKFyCaW+ETWnNiY0y9iFwGvAkkAw8ZY5aJyM3AAmPMy8C1wAMicjU2bHS+MaZtoZ/mcITAGEPxjkqOGq4TThRFSWzCCoGI5BljdgLlrT25MeY14LWgbTd6lpcDh7T2/K3CGSPYuquW6jofhTqjWFGUBCeSR/AEcDI2W8gQOPhrgD1iaFfscMYIinfYiqOF3XVGsaIoiU1YITDGnOw8D+k4czoAJzS0bkcH9CBQFEXpAkSVLiMi3YFh2MFcAIwxH8TKqJjiCIHrEXh7FSuKoiQi0cws/gVwJTb9cxEwEZgHHB1b02KEM0awcvMueuemk62po4qiJDjRpI9eCRwArDXGHAWMI9YpnrHEGSNYsr6MMQNCNJdXFEVJMKIRgmpjTDXYukPGmK+B4bE1K4b46qk1SXxfsovRKgSKoihRjREUi0g+8CLwtojsoCOKw8UKXz1bKxowBvUIFEVRiEIIjDGnO4szROQ9bJXQN2JqVazw+cD4KKlsAGBk/7xmDlAURdn9iSgEIpIELDHGjAYwxrzfIVbFCmMFoLzWkCTQJy8GzeoVRVG6GBHHCJwqoItFpI21n+MEXz0A5bXQIztNS08riqIQ3RhBP2CZiHwGVLgbjTGnxsyqWNEoBIaCnPRONkZRFCU+iEYIcrClJlwE+GtszIkxjhDsrDEUdFchUBRFgeiEICV4bEBEuuZ0XJ8dI9hW5aNvkY4PKIqiQOTqo78ELgH2COo/kAt8HGvDYoLjEZTVGEb004whRVEUaL766OvArcANnu3lxpjtMbUqVjhCUE8SI/rmdrIxiqIo8UGk6qNl2Kb10zrOnBjjCEGDSaZHTlonG6MoihIfRFNiYvfBGSOoJ4nsNC02pyiKAokmBNVlAFSQqVVHFUVRHBJLCCq2ArDVdCMrLbmTjVEURYkPEkwItgBQKt1IT0msj64oihKOxLoa7rJCUJXWHREtL6EoigJRtqrcbagooSYpk+TUnM62RFEUJW5ILI+gppwqySJLB4oVRVEaSSwhqK+mRrRPsaIoipfEEwKTSrZmDCmKojSSWEJQV001aeoRKIqieEgsIaivpsqkqEegKIriIcGEoIYqk6qDxYqiKB4STAiqqPSlkqNCoCiK0khCCYGpr6HSl6rlJRRFUTwklhDUVlGDegSKoiheEksI6qupNmlkaQlqRVGURhJKCKh300c1NKQoiuKSUEIg9TXUkKoegaIoiofEEQKfjyRfLdUmjcxU9QgURVFcEkcI6ioBqCaVTM0aUhRFaSThhKCSDE0fVRRF8RBTIRCRySLyjYisFJEbQrz+DxFZ5Dy+FZHSmBlTWwFApUlXIVAURfEQs1FTEUkG7gGOBYqBz0XkZWPMcncfY8zVnv0vB8bFyp5GISBDQ0OKoigeYukRTABWGmNWGWNqgaeAKRH2nwY8GTNrGkND6Zo1pCiK4iGWQjAAWOdZL3a2NUFEBgNDgHfDvH6RiCwQkQUlJSWts8YTGtKsIUVRFD+xFIJQ3eFNmH2nAs8aYxpCvWiMmWmMGW+MGd+rV6/WWeMIQX1yJslJ2rheURTFJZZCUAwM9KwXAhvC7DuVWIaFoDE05EvNjunbKIqidDViKQSfA8NEZIiIpGEv9i8H7yQiw4HuwLwY2tLoEZCaFdO3URRF6WrETAiMMfXAZcCbwApgljFmmYjcLCKnenadBjxljAkXNmofXCFIUyFQFEXxEtP0GWPMa8BrQdtuDFqfEUsbGuk9gvdzTkTScjrk7RRFUboKiZNHOXQS9+ZlkR5bv0NRFKXLkTglJoCq2gadVawoihJEQglBpQqBoihKExJOCDJ0MpmiKEoACSUEVXXqESiKogSTWEJQ26B1hhRFUYJIGCHw+QxVdQ1aZ0hRFCWIhBGCOp8PgLSUhPnIiqIoUZEwV0V33rIWnFMURQkkYYSgwWeVQHVAURQlkIQRAp9xhUCVQFEUxUsCCYF9ViFQFEUJJHGEQENDiqIoIUkcIXBCQzpYrCiKEkjCCEGDIwSioSFFUZQAEkYIjI4RKIqihCRhhMAfGupkQxRFUeKMhLksuvMINDSkKIoSSMIIgYaGFEVRQpMwQuB6BBoaUhRFCSRhLos6s1hRFCU0CSQE9lmFQFEUJZAEEgL1CBRFUUKRgELQyYYoiqLEGQkjBI1lqFUJFEVRAkgYIdD0UUVRlNAkjBBoaEhRFCU0CSMEGhpSFEUJTcIIgaaPKoqihCZhhMC4RedUCBRFUQJIGCHQ5vWKoiihSRghcENDWn1UURQlkAQSAm1VqSiKEoqEEwLVAUVRlEASSAjss4aGFEVRAkkcIfBpaEhRFCUUiSMEGhpSFEUJSUyFQEQmi8g3IrJSRG4Is8+PRWS5iCwTkSdiZYs/fVSVQFEUxUtKrE4sIsnAPcCxQDHwuYi8bIxZ7tlnGPAb4BBjzA4R6R0re3RmsaIoSmhi6RFMAFYaY1YZY2qBp4ApQftcCNxju1rqLAAAB/VJREFUjNkBYIzZEitj3JnFSQkTDFMURYmOWF4WBwDrPOvFzjYvewF7icjHIvKpiEwOdSIRuUhEFojIgpKSklYZ06AlJhRFUUISSyEIdcU1QespwDDgSGAa8B8RyW9ykDEzjTHjjTHje/Xq1SpjNH1UURQlNLEUgmJgoGe9ENgQYp+XjDF1xpjVwDdYYWh3fFprSFEUJSSxFILPgWEiMkRE0oCpwMtB+7wIHAUgIgXYUNGqWBijJSYURVFCEzMhMMbUA5cBbwIrgFnGmGUicrOInOrs9iawTUSWA+8BvzLGbIuFPZo1pCiKEpqYpY8CGGNeA14L2najZ9kA1ziPmOLTDmWKoighSZhkSp1ZrCiKEpqEEYIGozOLFUVRQpEwQqBjBIqiKKFJGCEwGhpSFEUJScIIgRadUxRFCU3CCEFjaEhdAkVRlAASRwh0ZrGiKEpIEkcIdGaxoihKSBJGCIYUZHPSmH4qBIqiKEHEdGZxPHHcqL4cN6pvZ5uhKIoSdySMR6AoiqKERoVAURQlwVEhUBRFSXBUCBRFURIcFQJFUZQER4VAURQlwVEhUBRFSXBUCBRFURIcccszdxVEpARY28rDC4Ct7WhOrOlK9nYlW6Fr2duVbAW1N5a0xdbBxpheoV7ockLQFkRkgTFmfGfbES1dyd6uZCt0LXu7kq2g9saSWNmqoSFFUZQER4VAURQlwUk0IZjZ2Qa0kK5kb1eyFbqWvV3JVlB7Y0lMbE2oMQJFURSlKYnmESiKoihBqBAoiqIkOAkjBCIyWUS+EZGVInJDZ9sDICIPicgWEfnKs62HiLwtIt85z92d7SIidzn2LxGR/TrY1oEi8p6IrBCRZSJyZbzaKyIZIvKZiCx2bL3J2T5EROY7tj4tImnO9nRnfaXzelFH2Rpkd7KIfCkis+PZXhFZIyJLRWSRiCxwtsXd78Bjb76IPCsiXzu/34Pi0V4RGe58p+5jp4hc1SG2GmN2+weQDHwP7AGkAYuBkXFg1+HAfsBXnm1/A25wlm8A/uosnwi8DggwEZjfwbb2A/ZzlnOBb4GR8Wiv8545znIqMN+xYRYw1dl+H/BLZ/kS4D5neSrwdCf9Hq4BngBmO+txaS+wBigI2hZ3vwOPbY8Av3CW04D8eLbXsSMZ2AQM7ghbO/wDdtKXehDwpmf9N8BvOtsux5aiICH4BujnLPcDvnGW7wemhdqvk+x+CTg23u0FsoAvgAOxMzJTgn8TwJvAQc5yirOfdLCdhcAc4GhgtvPPHZf2hhGCuPwdAHnA6uDvJ17t9bzvccDHHWVrooSGBgDrPOvFzrZ4pI8xZiOA89zb2R43n8EJRYzD3mnHpb1OmGURsAV4G+sRlhpj6kPY02ir83oZ0LOjbHW4E7ge8DnrPYlfew3wlogsFJGLnG1x+TvARgFKgP86Ybf/iEh2HNvrMhV40lmOua2JIgQSYltXy5uNi88gIjnAc8BVxpidkXYNsa3D7DXGNBhj9sXeaU8ARkSwp1NtFZGTgS3GmIXezSF2jQt7gUOMMfsBJwCXisjhEfbtbFtTsOHXe40x44AKbHglHJ1tL85Y0KnAM83tGmJbq2xNFCEoBgZ61guBDZ1kS3NsFpF+AM7zFmd7p38GEUnFisDjxpjnnc1xay+AMaYUmIuNoeaLSEoIexptdV7vBmzvQDMPAU4VkTXAU9jw0J3xaq8xZoPzvAV4ASu08fo7KAaKjTHznfVnscIQr/aCFdgvjDGbnfWY25ooQvA5MMzJwkjDul0vd7JN4XgZOM9ZPg8bi3e3n+tkCkwEylx3sSMQEQEeBFYYY+6IZ3tFpJeI5DvLmcAxwArgPeCsMLa6n+Es4F3jBF07AmPMb4wxhcaYIuxv811jzDnxaK+IZItIrruMjWV/RRz+DgCMMZuAdSIy3Nk0CVger/Y6TMMfFnJtiq2tHT0I0lkP7Aj7t9hY8e862x7HpieBjUAdVt0vwMZ65wDfOc89nH0FuMexfykwvoNtPRTrdi4BFjmPE+PRXmAs8KVj61fAjc72PYDPgJVYtzvd2Z7hrK90Xt+jE38TR+LPGoo7ex2bFjuPZe7/Ujz+Djw27wsscH4PLwLd49VebHLDNqCbZ1vMbdUSE4qiKAlOooSGFEVRlDCoECiKoiQ4KgSKoigJjgqBoihKgqNCoCiKkuCoEChKECLSEFQFst2q1YpIkXiqzSpKPJDS/C6KknBUGVueQlESAvUIFCVKnDr8fxXb6+AzERnqbB8sInOcmvBzRGSQs72PiLwgti/CYhE52DlVsog8ILZXwlvO7GdF6TRUCBSlKZlBoaGzPa/tNMZMAO7G1gPCWX7UGDMWeBy4y9l+F/C+MWYfbH2bZc72YcA9xphRQClwZow/j6JERGcWK0oQIrLLGJMTYvsa4GhjzCqnAN8mY0xPEdmKrQNf52zfaIwpEJESoNAYU+M5RxHwtjFmmLP+ayDVGHNL7D+ZooRGPQJFaRkmzHK4fUJR41luQMfqlE5GhUBRWsbZnud5zvIn2KqhAOcAHznLc4BfQmOjnLyOMlJRWoLeiShKUzKd7mYubxhj3BTSdBGZj72JmuZsuwJ4SER+he2G9TNn+5XATBG5AHvn/0tstVlFiSt0jEBRosQZIxhvjNna2bYoSnuioSFFUZQERz0CRVGUBEc9AkVRlARHhUBRFCXBUSFQFEVJcFQIFEVREhwVAkVRlATn/wPD1mcvLIF3gQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.48630065,  1.5294012 , -0.04040305, -1.1363782 , -0.10686349,\n",
      "        -0.18075305, -0.9371585 ,  1.3481778 , -0.5598808 ],\n",
      "       [ 0.01180527, -0.3243049 , -0.38173077, -1.1760089 ,  0.8601171 ,\n",
      "        -0.2021206 ,  0.7577524 , -1.662932  ,  0.05695267],\n",
      "       [ 0.40160123, -0.16567522,  1.0133964 ,  1.0030876 , -0.5924297 ,\n",
      "        -1.4307861 ,  1.2612592 ,  0.3781774 , -0.35437852],\n",
      "       [-0.56808084,  2.5667427 , -2.148373  ,  0.42424297, -2.8079393 ,\n",
      "         0.29319757, -1.1081934 ,  0.16034454,  1.6920391 ],\n",
      "       [-1.6947368 ,  0.3391665 , -1.2425306 , -1.1083585 , -0.723455  ,\n",
      "        -0.30786443,  0.5615693 ,  0.01285276,  1.5844867 ],\n",
      "       [ 0.97621197, -2.1168306 ,  0.5549257 ,  3.0624964 ,  0.24003088,\n",
      "        -1.9447823 , -1.626367  , -1.1427323 ,  1.34224   ],\n",
      "       [ 0.31022733, -0.07142082, -0.39479095, -0.47536677,  0.7905558 ,\n",
      "        -0.0880537 , -0.57536876, -1.1794604 ,  0.38904393]],\n",
      "      dtype=float32), array([ 0.08789897, -0.2865126 ,  0.14446504, -0.5172943 ,  0.26404223,\n",
      "        0.6099323 , -0.19309363,  0.3103653 , -0.42013666], dtype=float32), array([[ 0.1033967 , -1.516501  ,  2.5490696 , -0.38221234,  0.5036733 ,\n",
      "        -0.27170706,  0.8415298 , -0.10179336,  1.2794507 ],\n",
      "       [ 1.5294355 ,  1.208158  ,  0.07123343, -0.08384107, -1.0678679 ,\n",
      "         1.067586  , -0.5661828 ,  0.767343  , -2.626582  ],\n",
      "       [-2.805945  ,  1.0380701 ,  2.8394222 ,  0.60680765, -1.5710732 ,\n",
      "        -2.266748  ,  0.5881025 ,  0.08566235,  2.2749643 ],\n",
      "       [-0.9021464 , -0.12507942,  2.0679464 , -0.19655877,  1.2033294 ,\n",
      "         0.71420234, -0.28618863,  0.7007341 , -0.12635408],\n",
      "       [ 0.5183547 , -1.5920779 , -1.090769  ,  0.90827584, -0.5224495 ,\n",
      "        -0.03285592,  0.87332165, -0.26690406,  2.712931  ],\n",
      "       [ 2.2950833 , -1.9759346 , -0.79692906,  0.35977826,  0.49805692,\n",
      "        -1.3294281 ,  2.707689  ,  0.7194416 , -0.94398695],\n",
      "       [-1.1810386 ,  0.7433246 ,  0.90702957,  0.84986895, -1.2457745 ,\n",
      "        -0.9523246 , -0.70948464, -2.5428956 ,  0.6845793 ],\n",
      "       [ 0.03612482,  1.8608103 ,  0.8409114 ,  1.020363  , -0.5452032 ,\n",
      "        -0.7053776 ,  0.28651428,  1.963484  , -0.69168   ],\n",
      "       [-1.8464735 , -1.6721532 , -1.5722654 , -1.7235423 ,  3.0298014 ,\n",
      "         4.2433014 , -2.227777  , -0.593281  , -2.0097482 ]],\n",
      "      dtype=float32), array([ 0.36344102,  0.4707517 , -0.31144032, -0.3197361 , -0.60616   ,\n",
      "       -0.94037074,  0.17439401, -0.11641598,  0.18209866], dtype=float32), array([[ 2.343257  ,  2.2869425 ,  2.225827  , -3.5806916 , -0.48553392,\n",
      "         0.6737801 , -0.7553236 ,  0.18976893, -0.35051414],\n",
      "       [-1.775573  ,  1.55958   ,  0.8586582 , -0.812591  , -0.56030935,\n",
      "        -1.2782018 ,  0.49176526, -0.6392041 ,  0.31335375],\n",
      "       [ 0.6238192 , -0.21381778,  1.1853546 ,  0.27900282,  0.55747813,\n",
      "         0.6711033 , -1.8190459 , -2.6749516 , -1.002235  ],\n",
      "       [ 0.01359358, -0.57532936, -1.099158  ,  0.05596583, -2.239164  ,\n",
      "         0.17576854, -1.1536483 ,  0.3968621 ,  0.7715753 ],\n",
      "       [-0.8227344 , -3.5682845 , -1.2128737 ,  2.5660186 ,  0.31542242,\n",
      "        -0.18357356,  0.64204776,  1.0016754 ,  0.87638676],\n",
      "       [ 1.2018085 , -3.9274268 , -0.9256358 ,  2.6538875 ,  1.4296622 ,\n",
      "        -0.1311593 ,  0.26902223, -1.3990833 , -0.91266704],\n",
      "       [ 0.87068087,  1.5650909 ,  0.29631242, -1.5222517 , -0.5756555 ,\n",
      "         4.923912  , -1.7269539 ,  0.8615406 ,  0.02708819],\n",
      "       [ 0.51036555,  0.32579926,  1.1092415 , -1.6580174 ,  0.21812497,\n",
      "         1.3603309 ,  0.2937418 , -1.4366457 , -0.7195675 ],\n",
      "       [ 1.2755718 ,  1.1817851 ,  0.71118647, -1.5807716 ,  1.1905267 ,\n",
      "         1.2150222 , -2.0448189 , -0.45701146, -1.3309425 ]],\n",
      "      dtype=float32), array([-0.10002297,  1.3576351 ,  0.2948509 , -0.8814588 ,  0.67145306,\n",
      "        0.09947983,  0.12836316,  0.34576434, -0.403992  ], dtype=float32), array([[-2.671086 ],\n",
      "       [-2.3442655],\n",
      "       [-2.7095916],\n",
      "       [ 2.61105  ],\n",
      "       [-3.443055 ],\n",
      "       [-3.6088152],\n",
      "       [ 3.1595626],\n",
      "       [ 3.6479902],\n",
      "       [ 4.522068 ]], dtype=float32), array([-0.11702361], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6910801e-05]\n",
      " [9.9967122e-01]\n",
      " [9.9792308e-01]\n",
      " [1.3123153e-05]\n",
      " [3.7768688e-05]\n",
      " [1.0000000e+00]\n",
      " [1.0000000e+00]\n",
      " [1.0000000e+00]\n",
      " [9.9998987e-01]\n",
      " [9.9989140e-01]\n",
      " [7.8346948e-06]\n",
      " [7.4069190e-04]\n",
      " [1.0000000e+00]\n",
      " [8.3276493e-05]\n",
      " [2.4457753e-03]\n",
      " [9.9988878e-01]\n",
      " [4.5703613e-04]\n",
      " [9.9945182e-01]\n",
      " [9.9937868e-01]\n",
      " [9.9924111e-01]\n",
      " [5.7136080e-05]\n",
      " [6.8859568e-10]\n",
      " [1.9553339e-03]\n",
      " [9.9999499e-01]\n",
      " [9.9996853e-01]\n",
      " [9.9991977e-01]\n",
      " [9.9962592e-01]\n",
      " [9.9779201e-01]\n",
      " [3.1420271e-04]\n",
      " [1.0000000e+00]\n",
      " [1.0535259e-04]\n",
      " [5.2878598e-04]\n",
      " [2.5932341e-06]\n",
      " [9.5567986e-05]\n",
      " [3.3156516e-07]\n",
      " [1.0000000e+00]\n",
      " [9.9999654e-01]\n",
      " [9.9970078e-01]\n",
      " [9.9817443e-01]\n",
      " [9.9999952e-01]\n",
      " [9.9978691e-01]\n",
      " [9.9999845e-01]\n",
      " [7.7734498e-04]\n",
      " [3.0966364e-03]\n",
      " [4.1690779e-05]\n",
      " [9.9820817e-01]\n",
      " [9.9677366e-01]\n",
      " [9.9999321e-01]\n",
      " [9.9864286e-01]\n",
      " [7.0504670e-05]\n",
      " [6.9421018e-04]\n",
      " [9.9856442e-01]\n",
      " [2.4818347e-04]\n",
      " [2.5588834e-05]\n",
      " [1.5919069e-06]\n",
      " [2.7809246e-04]\n",
      " [3.7319313e-03]\n",
      " [1.0000000e+00]\n",
      " [1.4890790e-04]\n",
      " [3.4420269e-03]\n",
      " [3.1866068e-03]\n",
      " [9.9987125e-01]\n",
      " [9.9726236e-01]\n",
      " [9.9999976e-01]\n",
      " [2.6546357e-05]\n",
      " [2.5458663e-04]\n",
      " [8.1686521e-06]\n",
      " [9.9920940e-01]\n",
      " [9.3387291e-07]\n",
      " [1.4501606e-04]\n",
      " [9.5955993e-04]\n",
      " [9.9999988e-01]\n",
      " [9.9999583e-01]\n",
      " [1.0000000e+00]\n",
      " [9.9999332e-01]\n",
      " [4.2183092e-06]\n",
      " [9.9962842e-01]\n",
      " [2.8344577e-05]\n",
      " [9.9999964e-01]\n",
      " [1.6309701e-05]\n",
      " [3.2493116e-03]\n",
      " [1.2791473e-04]\n",
      " [9.9884284e-01]\n",
      " [9.9999833e-01]\n",
      " [9.9999619e-01]\n",
      " [9.9997735e-01]\n",
      " [9.9998784e-01]\n",
      " [9.9999988e-01]\n",
      " [1.1393327e-03]\n",
      " [1.0000000e+00]\n",
      " [9.9830484e-01]\n",
      " [9.9999976e-01]\n",
      " [9.4799912e-01]\n",
      " [9.9981350e-01]\n",
      " [9.9745136e-01]\n",
      " [1.1334972e-03]\n",
      " [1.4248676e-02]\n",
      " [1.0000000e+00]\n",
      " [5.1362446e-04]\n",
      " [9.9999583e-01]\n",
      " [9.6323055e-01]\n",
      " [5.9354029e-06]\n",
      " [9.9999535e-01]\n",
      " [9.9999988e-01]\n",
      " [3.3676652e-03]\n",
      " [9.9999988e-01]\n",
      " [4.5642526e-05]\n",
      " [7.0643722e-04]\n",
      " [1.0000000e+00]\n",
      " [5.9431279e-04]\n",
      " [5.3520375e-01]\n",
      " [9.9999785e-01]\n",
      " [9.9999976e-01]\n",
      " [9.9940383e-01]\n",
      " [6.0895391e-06]\n",
      " [6.4589962e-02]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5, X6, X7])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
