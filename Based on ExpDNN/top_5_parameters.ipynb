{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "#loading data\n",
    "Path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv\"\n",
    "dataset = numpy.loadtxt(Path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "#shuffling data\n",
    "numpy.random.seed(random_seed)\n",
    "numpy.random.shuffle(dataset)\n",
    "\n",
    "#loading inputs and outputs\n",
    "X1 = dataset[:,5:6] #Leptin\n",
    "X2 = dataset[:,6:7] #Adiponectin\n",
    "X3 = dataset[:,0:1] #Age\n",
    "X4 = dataset[:,7:8] #Resistin\n",
    "X5 = dataset[:,2:3] #Glucose\n",
    "Y = dataset[:,9:10] #Classification\n",
    "\n",
    "#normalization_function\n",
    "def normalization(x):\n",
    "    return (x - min(x)) / (max(x) - min(x))\n",
    "\n",
    "#normalization\n",
    "X1 = normalization(X1)\n",
    "X2 = normalization(X2)\n",
    "X3 = normalization(X3)\n",
    "X4 = normalization(X4)\n",
    "X5 = normalization(X5)\n",
    "\n",
    "#load training data (Y)\n",
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_X1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X2 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X3 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X4 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_X5 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 5)            0           input_layer_X1[0][0]             \n",
      "                                                                 input_layer_X2[0][0]             \n",
      "                                                                 input_layer_X3[0][0]             \n",
      "                                                                 input_layer_X4[0][0]             \n",
      "                                                                 input_layer_X5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_1 (Dense)          (None, 9)            54          merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_2 (Dense)          (None, 9)            90          hidden_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer_3 (Dense)          (None, 9)            90          hidden_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            10          hidden_layer_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 244\n",
      "Trainable params: 244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#setting a random seed\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "#constructing input layers\n",
    "input_layer_X1 = keras.layers.Input(shape=(1, ), name='input_layer_X1')\n",
    "input_layer_X2 = keras.layers.Input(shape=(1, ), name='input_layer_X2')\n",
    "input_layer_X3 = keras.layers.Input(shape=(1, ), name='input_layer_X3')\n",
    "input_layer_X4 = keras.layers.Input(shape=(1, ), name='input_layer_X4')\n",
    "input_layer_X5 = keras.layers.Input(shape=(1, ), name='input_layer_X5')\n",
    "\n",
    "#constructing hidden layers\n",
    "merge_layer = keras.layers.concatenate([input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5], name='merge_layer')\n",
    "hidden_layer_1 = keras.layers.Dense(9, activation = 'linear', name='hidden_layer_1')(merge_layer)\n",
    "hidden_layer_2 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_2')(hidden_layer_1)\n",
    "hidden_layer_3 = keras.layers.Dense(9, activation = 'tanh', name='hidden_layer_3')(hidden_layer_2)\n",
    "\n",
    "#constructing output layer\n",
    "output_layer = keras.layers.Dense(1, activation = 'sigmoid', name='output_layer')(hidden_layer_3)\n",
    "\n",
    "#constructing the model of neural network\n",
    "model = keras.models.Model(inputs=[input_layer_X1, input_layer_X2, input_layer_X3, input_layer_X4, input_layer_X5], outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "#setting loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = ['acc', keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/700\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6866 - acc: 0.5652 - auc_1: 0.5826 - val_loss: 0.6405 - val_acc: 0.7083 - val_auc_1: 0.7571\n",
      "Epoch 2/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.6653 - acc: 0.6522 - auc_1: 0.6845 - val_loss: 0.6137 - val_acc: 0.8333 - val_auc_1: 0.7536\n",
      "Epoch 3/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6517 - acc: 0.6304 - auc_1: 0.6924 - val_loss: 0.5946 - val_acc: 0.7917 - val_auc_1: 0.7429\n",
      "Epoch 4/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6327 - acc: 0.6304 - auc_1: 0.7169 - val_loss: 0.5774 - val_acc: 0.7083 - val_auc_1: 0.7536\n",
      "Epoch 5/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6139 - acc: 0.6630 - auc_1: 0.7310 - val_loss: 0.5528 - val_acc: 0.7917 - val_auc_1: 0.7964\n",
      "Epoch 6/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6072 - acc: 0.6413 - auc_1: 0.7410 - val_loss: 0.5626 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 7/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5937 - acc: 0.6630 - auc_1: 0.7395 - val_loss: 0.5397 - val_acc: 0.8333 - val_auc_1: 0.8250\n",
      "Epoch 8/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5821 - acc: 0.6413 - auc_1: 0.7614 - val_loss: 0.5785 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 9/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5748 - acc: 0.6522 - auc_1: 0.7731 - val_loss: 0.5325 - val_acc: 0.8333 - val_auc_1: 0.8643\n",
      "Epoch 10/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5711 - acc: 0.6522 - auc_1: 0.7593 - val_loss: 0.5462 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 11/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5641 - acc: 0.6957 - auc_1: 0.7776 - val_loss: 0.5372 - val_acc: 0.8333 - val_auc_1: 0.8750\n",
      "Epoch 12/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5515 - acc: 0.6848 - auc_1: 0.7788 - val_loss: 0.5276 - val_acc: 0.8333 - val_auc_1: 0.8786\n",
      "Epoch 13/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5481 - acc: 0.6848 - auc_1: 0.7921 - val_loss: 0.5340 - val_acc: 0.7917 - val_auc_1: 0.8714\n",
      "Epoch 14/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5397 - acc: 0.6522 - auc_1: 0.7879 - val_loss: 0.5998 - val_acc: 0.6250 - val_auc_1: 0.8821\n",
      "Epoch 15/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5404 - acc: 0.6522 - auc_1: 0.7936 - val_loss: 0.5010 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 16/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5383 - acc: 0.7174 - auc_1: 0.7964 - val_loss: 0.5484 - val_acc: 0.7917 - val_auc_1: 0.8821\n",
      "Epoch 17/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5325 - acc: 0.6957 - auc_1: 0.8040 - val_loss: 0.5184 - val_acc: 0.8333 - val_auc_1: 0.8857\n",
      "Epoch 18/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5256 - acc: 0.7283 - auc_1: 0.8071 - val_loss: 0.5122 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 19/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5189 - acc: 0.7391 - auc_1: 0.8160 - val_loss: 0.5897 - val_acc: 0.6667 - val_auc_1: 0.9036\n",
      "Epoch 20/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5222 - acc: 0.7283 - auc_1: 0.8119 - val_loss: 0.5363 - val_acc: 0.7917 - val_auc_1: 0.9000\n",
      "Epoch 21/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5183 - acc: 0.6848 - auc_1: 0.8136 - val_loss: 0.5444 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 22/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5140 - acc: 0.7283 - auc_1: 0.8133 - val_loss: 0.5291 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 23/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5044 - acc: 0.6848 - auc_1: 0.8260 - val_loss: 0.4959 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 24/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.5079 - acc: 0.7826 - auc_1: 0.8288 - val_loss: 0.5459 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 25/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4953 - acc: 0.7174 - auc_1: 0.8367 - val_loss: 0.5246 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 26/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4906 - acc: 0.7826 - auc_1: 0.8388 - val_loss: 0.5264 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 27/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4928 - acc: 0.7391 - auc_1: 0.8329 - val_loss: 0.5182 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 28/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4866 - acc: 0.7174 - auc_1: 0.8369 - val_loss: 0.5238 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 29/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4763 - acc: 0.7500 - auc_1: 0.8540 - val_loss: 0.5665 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 30/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4851 - acc: 0.7500 - auc_1: 0.8402 - val_loss: 0.5444 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 31/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4681 - acc: 0.7717 - auc_1: 0.8545 - val_loss: 0.5356 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 32/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4663 - acc: 0.7609 - auc_1: 0.8552 - val_loss: 0.4773 - val_acc: 0.8333 - val_auc_1: 0.8893\n",
      "Epoch 33/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4669 - acc: 0.7174 - auc_1: 0.8521 - val_loss: 0.4904 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 34/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4693 - acc: 0.7391 - auc_1: 0.8488 - val_loss: 0.4935 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 35/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4640 - acc: 0.7609 - auc_1: 0.8545 - val_loss: 0.4775 - val_acc: 0.8333 - val_auc_1: 0.8964\n",
      "Epoch 36/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4654 - acc: 0.7935 - auc_1: 0.8586 - val_loss: 0.4540 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 37/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4625 - acc: 0.7826 - auc_1: 0.8548 - val_loss: 0.4910 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 38/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4532 - acc: 0.7500 - auc_1: 0.8669 - val_loss: 0.5094 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 39/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4522 - acc: 0.7935 - auc_1: 0.8650 - val_loss: 0.4743 - val_acc: 0.8333 - val_auc_1: 0.8821\n",
      "Epoch 40/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4507 - acc: 0.7826 - auc_1: 0.8624 - val_loss: 0.4833 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 41/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4390 - acc: 0.7826 - auc_1: 0.8745 - val_loss: 0.5449 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 42/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4252 - acc: 0.7826 - auc_1: 0.8843 - val_loss: 0.4448 - val_acc: 0.8333 - val_auc_1: 0.8929\n",
      "Epoch 43/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4420 - acc: 0.7609 - auc_1: 0.8686 - val_loss: 0.4470 - val_acc: 0.7917 - val_auc_1: 0.8964\n",
      "Epoch 44/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4280 - acc: 0.8043 - auc_1: 0.8883 - val_loss: 0.6139 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 45/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4500 - acc: 0.7935 - auc_1: 0.8674 - val_loss: 0.4807 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 46/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4348 - acc: 0.8043 - auc_1: 0.8698 - val_loss: 0.4459 - val_acc: 0.7500 - val_auc_1: 0.8893\n",
      "Epoch 47/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4255 - acc: 0.8152 - auc_1: 0.8821 - val_loss: 0.4519 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 48/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4315 - acc: 0.8152 - auc_1: 0.8781 - val_loss: 0.4513 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - ETA: 0s - loss: 0.4813 - acc: 0.7763 - auc_1: 0.8481 - 0s 3ms/step - loss: 0.4281 - acc: 0.8152 - auc_1: 0.8843 - val_loss: 0.5268 - val_acc: 0.6667 - val_auc_1: 0.8893\n",
      "Epoch 50/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4088 - acc: 0.7935 - auc_1: 0.8971 - val_loss: 0.4397 - val_acc: 0.8750 - val_auc_1: 0.8929\n",
      "Epoch 51/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4395 - acc: 0.7826 - auc_1: 0.8736 - val_loss: 0.4884 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 52/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4326 - acc: 0.7826 - auc_1: 0.8752 - val_loss: 0.4855 - val_acc: 0.6667 - val_auc_1: 0.8929\n",
      "Epoch 53/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4260 - acc: 0.8043 - auc_1: 0.8807 - val_loss: 0.4740 - val_acc: 0.7083 - val_auc_1: 0.9071\n",
      "Epoch 54/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4289 - acc: 0.8043 - auc_1: 0.8790 - val_loss: 0.4512 - val_acc: 0.7500 - val_auc_1: 0.8929\n",
      "Epoch 55/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4232 - acc: 0.7935 - auc_1: 0.8843 - val_loss: 0.4750 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 56/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4164 - acc: 0.8587 - auc_1: 0.8888 - val_loss: 0.5275 - val_acc: 0.7083 - val_auc_1: 0.8929\n",
      "Epoch 57/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4342 - acc: 0.8043 - auc_1: 0.8731 - val_loss: 0.4585 - val_acc: 0.7500 - val_auc_1: 0.9000\n",
      "Epoch 58/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4201 - acc: 0.8043 - auc_1: 0.8774 - val_loss: 0.4784 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 59/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4105 - acc: 0.7935 - auc_1: 0.8862 - val_loss: 0.4456 - val_acc: 0.7917 - val_auc_1: 0.8929\n",
      "Epoch 60/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4253 - acc: 0.8043 - auc_1: 0.8840 - val_loss: 0.5052 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 61/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4208 - acc: 0.7935 - auc_1: 0.8840 - val_loss: 0.4620 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 62/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4175 - acc: 0.7717 - auc_1: 0.8814 - val_loss: 0.4547 - val_acc: 0.7500 - val_auc_1: 0.8964\n",
      "Epoch 63/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4049 - acc: 0.8261 - auc_1: 0.8933 - val_loss: 0.5458 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 64/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4167 - acc: 0.7609 - auc_1: 0.8871 - val_loss: 0.5185 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 65/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4316 - acc: 0.7826 - auc_1: 0.8790 - val_loss: 0.4840 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 66/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4148 - acc: 0.8043 - auc_1: 0.8931 - val_loss: 0.5248 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 67/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4145 - acc: 0.8152 - auc_1: 0.8852 - val_loss: 0.5390 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 68/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4051 - acc: 0.8261 - auc_1: 0.8962 - val_loss: 0.5003 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 69/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4225 - acc: 0.8152 - auc_1: 0.8798 - val_loss: 0.5199 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 70/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4094 - acc: 0.8043 - auc_1: 0.8888 - val_loss: 0.5079 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 71/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4149 - acc: 0.8261 - auc_1: 0.8912 - val_loss: 0.5305 - val_acc: 0.7083 - val_auc_1: 0.8857\n",
      "Epoch 72/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4060 - acc: 0.8261 - auc_1: 0.8890 - val_loss: 0.5033 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 73/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4220 - acc: 0.7935 - auc_1: 0.8833 - val_loss: 0.5123 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 74/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4008 - acc: 0.8043 - auc_1: 0.8893 - val_loss: 0.5602 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 75/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3911 - acc: 0.8043 - auc_1: 0.8998 - val_loss: 0.5279 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 76/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4092 - acc: 0.8370 - auc_1: 0.8867 - val_loss: 0.5247 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 77/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4114 - acc: 0.8152 - auc_1: 0.8890 - val_loss: 0.5369 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 78/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4052 - acc: 0.8043 - auc_1: 0.8905 - val_loss: 0.5657 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 79/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3996 - acc: 0.8152 - auc_1: 0.8955 - val_loss: 0.5174 - val_acc: 0.7917 - val_auc_1: 0.8679\n",
      "Epoch 80/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3967 - acc: 0.8043 - auc_1: 0.8969 - val_loss: 0.5972 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 81/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4090 - acc: 0.8152 - auc_1: 0.8874 - val_loss: 0.5741 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 82/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4052 - acc: 0.8152 - auc_1: 0.8905 - val_loss: 0.5849 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 83/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4074 - acc: 0.8043 - auc_1: 0.8910 - val_loss: 0.5572 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 84/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.3995 - acc: 0.8052 - auc_1: 0.8946 - 0s 3ms/step - loss: 0.3921 - acc: 0.8152 - auc_1: 0.9010 - val_loss: 0.5319 - val_acc: 0.7917 - val_auc_1: 0.8536\n",
      "Epoch 85/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4002 - acc: 0.8043 - auc_1: 0.8950 - val_loss: 0.5432 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 86/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3928 - acc: 0.7935 - auc_1: 0.9036 - val_loss: 0.6569 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 87/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3938 - acc: 0.8261 - auc_1: 0.9038 - val_loss: 0.5401 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 88/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3970 - acc: 0.8261 - auc_1: 0.9026 - val_loss: 0.6033 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 89/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3981 - acc: 0.7935 - auc_1: 0.8938 - val_loss: 0.5888 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 90/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3960 - acc: 0.8152 - auc_1: 0.8960 - val_loss: 0.6217 - val_acc: 0.6667 - val_auc_1: 0.8821\n",
      "Epoch 91/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3843 - acc: 0.8043 - auc_1: 0.9057 - val_loss: 0.6194 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 92/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3980 - acc: 0.8370 - auc_1: 0.8940 - val_loss: 0.6146 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 93/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3898 - acc: 0.8152 - auc_1: 0.9007 - val_loss: 0.5724 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 94/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4049 - acc: 0.7935 - auc_1: 0.8926 - val_loss: 0.6178 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 95/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3888 - acc: 0.8261 - auc_1: 0.8976 - val_loss: 0.6196 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 96/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3899 - acc: 0.8152 - auc_1: 0.9079 - val_loss: 0.6080 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 97/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3862 - acc: 0.8261 - auc_1: 0.8988 - val_loss: 0.5878 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 98/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3936 - acc: 0.7935 - auc_1: 0.8940 - val_loss: 0.6006 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 99/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3964 - acc: 0.8370 - auc_1: 0.8933 - val_loss: 0.6376 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 100/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3874 - acc: 0.8152 - auc_1: 0.9017 - val_loss: 0.6306 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 101/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3973 - acc: 0.8043 - auc_1: 0.8945 - val_loss: 0.6483 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 102/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3943 - acc: 0.8261 - auc_1: 0.8940 - val_loss: 0.6853 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 103/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3783 - acc: 0.8370 - auc_1: 0.9060 - val_loss: 0.6940 - val_acc: 0.6250 - val_auc_1: 0.8500\n",
      "Epoch 104/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4023 - acc: 0.7935 - auc_1: 0.8898 - val_loss: 0.6634 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 105/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3745 - acc: 0.8152 - auc_1: 0.9071 - val_loss: 0.6033 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 106/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3870 - acc: 0.8043 - auc_1: 0.9031 - val_loss: 0.6416 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 107/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3716 - acc: 0.8370 - auc_1: 0.9143 - val_loss: 0.7773 - val_acc: 0.5833 - val_auc_1: 0.8643\n",
      "Epoch 108/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3820 - acc: 0.8370 - auc_1: 0.9050 - val_loss: 0.6409 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 109/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3846 - acc: 0.8370 - auc_1: 0.9043 - val_loss: 0.6346 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 110/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3776 - acc: 0.8043 - auc_1: 0.9095 - val_loss: 0.7532 - val_acc: 0.6250 - val_auc_1: 0.8607\n",
      "Epoch 111/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3995 - acc: 0.7935 - auc_1: 0.8964 - val_loss: 0.6367 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 112/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3795 - acc: 0.7826 - auc_1: 0.9074 - val_loss: 0.6958 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 113/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3730 - acc: 0.8152 - auc_1: 0.9129 - val_loss: 0.6377 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 114/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3878 - acc: 0.8152 - auc_1: 0.8990 - val_loss: 0.6622 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 115/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3838 - acc: 0.8043 - auc_1: 0.9079 - val_loss: 0.7632 - val_acc: 0.5833 - val_auc_1: 0.8643\n",
      "Epoch 116/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3787 - acc: 0.8261 - auc_1: 0.9064 - val_loss: 0.6358 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 117/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3772 - acc: 0.8043 - auc_1: 0.9138 - val_loss: 0.6895 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 118/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3741 - acc: 0.7935 - auc_1: 0.9098 - val_loss: 0.7085 - val_acc: 0.6250 - val_auc_1: 0.8536\n",
      "Epoch 119/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3708 - acc: 0.8261 - auc_1: 0.9152 - val_loss: 0.6741 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 120/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3805 - acc: 0.8478 - auc_1: 0.9105 - val_loss: 0.6451 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 121/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3891 - acc: 0.7717 - auc_1: 0.9031 - val_loss: 0.6477 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 122/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3693 - acc: 0.8261 - auc_1: 0.9148 - val_loss: 0.7102 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 123/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3660 - acc: 0.8043 - auc_1: 0.9145 - val_loss: 0.6213 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 124/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3827 - acc: 0.7935 - auc_1: 0.9081 - val_loss: 0.6720 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 125/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3769 - acc: 0.8152 - auc_1: 0.9086 - val_loss: 0.7518 - val_acc: 0.6250 - val_auc_1: 0.8429\n",
      "Epoch 126/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3767 - acc: 0.8043 - auc_1: 0.9090 - val_loss: 0.6951 - val_acc: 0.6250 - val_auc_1: 0.8214\n",
      "Epoch 127/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3610 - acc: 0.8261 - auc_1: 0.9181 - val_loss: 0.7894 - val_acc: 0.6250 - val_auc_1: 0.8607\n",
      "Epoch 128/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3764 - acc: 0.8261 - auc_1: 0.9093 - val_loss: 0.6967 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 129/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3680 - acc: 0.8152 - auc_1: 0.9129 - val_loss: 0.7178 - val_acc: 0.6250 - val_auc_1: 0.8357\n",
      "Epoch 130/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3517 - acc: 0.8261 - auc_1: 0.9190 - val_loss: 0.7953 - val_acc: 0.5833 - val_auc_1: 0.8286\n",
      "Epoch 131/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3803 - acc: 0.7826 - auc_1: 0.9024 - val_loss: 0.6545 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 132/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3664 - acc: 0.8261 - auc_1: 0.9145 - val_loss: 0.6885 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 133/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3704 - acc: 0.8152 - auc_1: 0.9076 - val_loss: 0.6855 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 134/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3634 - acc: 0.8152 - auc_1: 0.9143 - val_loss: 0.6468 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 135/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3639 - acc: 0.8478 - auc_1: 0.9183 - val_loss: 0.6825 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 136/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3644 - acc: 0.8043 - auc_1: 0.9129 - val_loss: 0.7116 - val_acc: 0.6250 - val_auc_1: 0.8286\n",
      "Epoch 137/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3593 - acc: 0.8478 - auc_1: 0.9131 - val_loss: 0.7925 - val_acc: 0.5833 - val_auc_1: 0.8429\n",
      "Epoch 138/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3645 - acc: 0.8152 - auc_1: 0.9155 - val_loss: 0.7065 - val_acc: 0.6250 - val_auc_1: 0.8429\n",
      "Epoch 139/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3678 - acc: 0.8261 - auc_1: 0.9107 - val_loss: 0.7438 - val_acc: 0.6250 - val_auc_1: 0.8500\n",
      "Epoch 140/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3671 - acc: 0.8478 - auc_1: 0.9164 - val_loss: 0.7015 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 141/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3648 - acc: 0.8261 - auc_1: 0.9126 - val_loss: 0.6888 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 142/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3522 - acc: 0.8478 - auc_1: 0.9198 - val_loss: 0.7924 - val_acc: 0.5833 - val_auc_1: 0.8464\n",
      "Epoch 143/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3490 - acc: 0.8261 - auc_1: 0.9205 - val_loss: 0.8087 - val_acc: 0.5833 - val_auc_1: 0.8179\n",
      "Epoch 144/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3561 - acc: 0.8478 - auc_1: 0.9200 - val_loss: 0.7636 - val_acc: 0.5833 - val_auc_1: 0.8429\n",
      "Epoch 145/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3604 - acc: 0.8261 - auc_1: 0.9126 - val_loss: 0.7904 - val_acc: 0.5833 - val_auc_1: 0.8500\n",
      "Epoch 146/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3552 - acc: 0.8261 - auc_1: 0.9193 - val_loss: 0.6963 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 147/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3449 - acc: 0.8478 - auc_1: 0.9250 - val_loss: 0.7459 - val_acc: 0.6250 - val_auc_1: 0.8643\n",
      "Epoch 148/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3565 - acc: 0.8370 - auc_1: 0.9179 - val_loss: 0.7399 - val_acc: 0.6250 - val_auc_1: 0.8571\n",
      "Epoch 149/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3515 - acc: 0.8043 - auc_1: 0.9212 - val_loss: 0.7161 - val_acc: 0.6250 - val_auc_1: 0.8464\n",
      "Epoch 150/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3501 - acc: 0.8261 - auc_1: 0.9171 - val_loss: 0.7110 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 151/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3479 - acc: 0.8370 - auc_1: 0.9252 - val_loss: 0.6841 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 152/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3487 - acc: 0.8043 - auc_1: 0.9188 - val_loss: 0.6885 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 153/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3493 - acc: 0.8152 - auc_1: 0.9240 - val_loss: 0.7422 - val_acc: 0.6250 - val_auc_1: 0.8571\n",
      "Epoch 154/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3476 - acc: 0.8370 - auc_1: 0.9224 - val_loss: 0.7189 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 155/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3328 - acc: 0.8478 - auc_1: 0.9338 - val_loss: 0.8150 - val_acc: 0.5833 - val_auc_1: 0.8929\n",
      "Epoch 156/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3603 - acc: 0.8261 - auc_1: 0.9131 - val_loss: 0.7029 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 157/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3381 - acc: 0.8478 - auc_1: 0.9317 - val_loss: 0.7550 - val_acc: 0.6250 - val_auc_1: 0.8750\n",
      "Epoch 158/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3392 - acc: 0.8370 - auc_1: 0.9255 - val_loss: 0.7262 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 159/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3429 - acc: 0.8370 - auc_1: 0.9262 - val_loss: 0.7521 - val_acc: 0.6250 - val_auc_1: 0.8393\n",
      "Epoch 160/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3482 - acc: 0.7935 - auc_1: 0.9214 - val_loss: 0.7342 - val_acc: 0.6250 - val_auc_1: 0.8393\n",
      "Epoch 161/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3334 - acc: 0.8370 - auc_1: 0.9267 - val_loss: 0.7651 - val_acc: 0.6250 - val_auc_1: 0.8464\n",
      "Epoch 162/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3333 - acc: 0.8370 - auc_1: 0.9333 - val_loss: 0.7397 - val_acc: 0.6250 - val_auc_1: 0.8464\n",
      "Epoch 163/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3304 - acc: 0.8261 - auc_1: 0.9293 - val_loss: 0.8040 - val_acc: 0.5833 - val_auc_1: 0.8679\n",
      "Epoch 164/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3326 - acc: 0.8587 - auc_1: 0.9310 - val_loss: 0.7295 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 165/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3496 - acc: 0.8261 - auc_1: 0.9236 - val_loss: 0.7041 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 166/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3311 - acc: 0.8261 - auc_1: 0.9298 - val_loss: 0.7443 - val_acc: 0.6250 - val_auc_1: 0.8393\n",
      "Epoch 167/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3274 - acc: 0.8587 - auc_1: 0.9279 - val_loss: 0.7641 - val_acc: 0.6250 - val_auc_1: 0.8536\n",
      "Epoch 168/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3235 - acc: 0.8478 - auc_1: 0.9340 - val_loss: 0.8098 - val_acc: 0.5833 - val_auc_1: 0.8714\n",
      "Epoch 169/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3262 - acc: 0.8261 - auc_1: 0.9336 - val_loss: 0.7249 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 170/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3321 - acc: 0.8478 - auc_1: 0.9236 - val_loss: 0.7535 - val_acc: 0.5833 - val_auc_1: 0.8429\n",
      "Epoch 171/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3219 - acc: 0.8696 - auc_1: 0.9333 - val_loss: 0.7228 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 172/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3166 - acc: 0.8478 - auc_1: 0.9355 - val_loss: 0.7454 - val_acc: 0.5833 - val_auc_1: 0.8464\n",
      "Epoch 173/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3148 - acc: 0.8587 - auc_1: 0.9376 - val_loss: 0.6996 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 174/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3310 - acc: 0.8370 - auc_1: 0.9302 - val_loss: 0.7350 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 175/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3030 - acc: 0.8370 - auc_1: 0.9419 - val_loss: 0.7888 - val_acc: 0.6250 - val_auc_1: 0.8250\n",
      "Epoch 176/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3368 - acc: 0.8152 - auc_1: 0.9290 - val_loss: 0.7710 - val_acc: 0.5833 - val_auc_1: 0.8607\n",
      "Epoch 177/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3207 - acc: 0.8587 - auc_1: 0.9350 - val_loss: 0.7197 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 178/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3096 - acc: 0.8478 - auc_1: 0.9390 - val_loss: 0.7560 - val_acc: 0.5833 - val_auc_1: 0.8643\n",
      "Epoch 179/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3134 - acc: 0.8478 - auc_1: 0.9400 - val_loss: 0.7643 - val_acc: 0.5833 - val_auc_1: 0.8643\n",
      "Epoch 180/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3160 - acc: 0.8370 - auc_1: 0.9376 - val_loss: 0.7637 - val_acc: 0.5833 - val_auc_1: 0.8750\n",
      "Epoch 181/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3056 - acc: 0.8478 - auc_1: 0.9379 - val_loss: 0.7317 - val_acc: 0.7083 - val_auc_1: 0.8750\n",
      "Epoch 182/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3053 - acc: 0.8478 - auc_1: 0.9426 - val_loss: 0.7207 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 183/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3123 - acc: 0.8478 - auc_1: 0.9410 - val_loss: 0.7157 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 184/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3135 - acc: 0.8478 - auc_1: 0.9381 - val_loss: 0.6806 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 185/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3020 - acc: 0.8478 - auc_1: 0.9407 - val_loss: 0.7133 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 186/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3113 - acc: 0.8261 - auc_1: 0.9376 - val_loss: 0.7349 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 187/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3054 - acc: 0.8478 - auc_1: 0.9443 - val_loss: 0.7165 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 188/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3000 - acc: 0.8478 - auc_1: 0.9450 - val_loss: 0.7458 - val_acc: 0.5833 - val_auc_1: 0.8714\n",
      "Epoch 189/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2940 - acc: 0.8804 - auc_1: 0.9467 - val_loss: 0.7424 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 190/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2897 - acc: 0.8478 - auc_1: 0.9498 - val_loss: 0.6653 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 191/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3033 - acc: 0.8587 - auc_1: 0.9405 - val_loss: 0.7314 - val_acc: 0.6250 - val_auc_1: 0.8714\n",
      "Epoch 192/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2932 - acc: 0.8478 - auc_1: 0.9457 - val_loss: 0.6929 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 193/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2963 - acc: 0.8478 - auc_1: 0.9421 - val_loss: 0.7287 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 194/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2953 - acc: 0.8587 - auc_1: 0.9436 - val_loss: 0.7576 - val_acc: 0.6250 - val_auc_1: 0.8643\n",
      "Epoch 195/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3046 - acc: 0.8261 - auc_1: 0.9407 - val_loss: 0.7179 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 196/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2892 - acc: 0.8478 - auc_1: 0.9476 - val_loss: 0.7443 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 197/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3125 - acc: 0.8587 - auc_1: 0.9381 - val_loss: 0.6841 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 198/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2873 - acc: 0.8587 - auc_1: 0.9460 - val_loss: 0.7536 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 199/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2814 - acc: 0.8587 - auc_1: 0.9526 - val_loss: 0.7502 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 200/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2828 - acc: 0.8696 - auc_1: 0.9481 - val_loss: 0.7493 - val_acc: 0.6250 - val_auc_1: 0.8714\n",
      "Epoch 201/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3086 - acc: 0.8587 - auc_1: 0.9407 - val_loss: 0.7658 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 202/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2801 - acc: 0.8804 - auc_1: 0.9505 - val_loss: 0.7745 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 203/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2964 - acc: 0.8587 - auc_1: 0.9438 - val_loss: 0.7756 - val_acc: 0.6250 - val_auc_1: 0.8750\n",
      "Epoch 204/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2829 - acc: 0.8587 - auc_1: 0.9507 - val_loss: 0.7582 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 205/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2694 - acc: 0.8696 - auc_1: 0.9552 - val_loss: 0.6852 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 206/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2867 - acc: 0.8587 - auc_1: 0.9486 - val_loss: 0.7294 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 207/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2787 - acc: 0.8587 - auc_1: 0.9548 - val_loss: 0.7276 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 208/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2773 - acc: 0.8804 - auc_1: 0.9543 - val_loss: 0.7386 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 209/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2811 - acc: 0.8478 - auc_1: 0.9507 - val_loss: 0.7973 - val_acc: 0.6250 - val_auc_1: 0.8607\n",
      "Epoch 210/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2731 - acc: 0.8696 - auc_1: 0.9536 - val_loss: 0.7684 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 211/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2721 - acc: 0.8587 - auc_1: 0.9531 - val_loss: 0.7399 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 212/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2810 - acc: 0.8587 - auc_1: 0.9526 - val_loss: 0.7330 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 213/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2776 - acc: 0.8587 - auc_1: 0.9533 - val_loss: 0.7406 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 214/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2712 - acc: 0.8587 - auc_1: 0.9564 - val_loss: 0.7805 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 215/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2754 - acc: 0.8696 - auc_1: 0.9529 - val_loss: 0.7649 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 216/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2692 - acc: 0.8804 - auc_1: 0.9555 - val_loss: 0.7939 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 217/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2671 - acc: 0.8804 - auc_1: 0.9562 - val_loss: 0.8085 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 218/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2803 - acc: 0.8804 - auc_1: 0.9505 - val_loss: 0.7246 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 219/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2817 - acc: 0.8478 - auc_1: 0.9486 - val_loss: 0.7600 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 220/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2574 - acc: 0.8587 - auc_1: 0.9576 - val_loss: 0.7599 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 221/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2623 - acc: 0.8587 - auc_1: 0.9567 - val_loss: 0.7432 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 222/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2446 - acc: 0.8913 - auc_1: 0.9679 - val_loss: 0.8586 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 223/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2730 - acc: 0.9022 - auc_1: 0.9550 - val_loss: 0.8008 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 224/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2555 - acc: 0.8804 - auc_1: 0.9614 - val_loss: 0.8012 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 225/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2532 - acc: 0.8696 - auc_1: 0.9619 - val_loss: 0.8079 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 226/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2624 - acc: 0.8370 - auc_1: 0.9610 - val_loss: 0.7094 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 227/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2477 - acc: 0.8696 - auc_1: 0.9610 - val_loss: 0.8201 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 228/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2646 - acc: 0.8261 - auc_1: 0.9569 - val_loss: 0.7747 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 229/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2602 - acc: 0.8587 - auc_1: 0.9581 - val_loss: 0.7667 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 230/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2485 - acc: 0.8587 - auc_1: 0.9624 - val_loss: 0.8056 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 231/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2507 - acc: 0.8587 - auc_1: 0.9621 - val_loss: 0.7705 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 232/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2458 - acc: 0.8696 - auc_1: 0.9640 - val_loss: 0.7622 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 233/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2540 - acc: 0.8804 - auc_1: 0.9590 - val_loss: 0.7845 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 234/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2488 - acc: 0.8696 - auc_1: 0.9633 - val_loss: 0.7025 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 235/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2604 - acc: 0.8913 - auc_1: 0.9598 - val_loss: 0.7636 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 236/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2442 - acc: 0.8696 - auc_1: 0.9648 - val_loss: 0.8324 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 237/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2404 - acc: 0.8696 - auc_1: 0.9640 - val_loss: 0.7792 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 238/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2408 - acc: 0.8913 - auc_1: 0.9645 - val_loss: 0.8117 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 239/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2341 - acc: 0.8804 - auc_1: 0.9688 - val_loss: 0.7590 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 240/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2466 - acc: 0.8696 - auc_1: 0.9650 - val_loss: 0.7588 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 241/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2317 - acc: 0.8804 - auc_1: 0.9700 - val_loss: 0.7769 - val_acc: 0.6667 - val_auc_1: 0.8714\n",
      "Epoch 242/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2358 - acc: 0.8587 - auc_1: 0.9657 - val_loss: 0.8267 - val_acc: 0.6250 - val_auc_1: 0.8214\n",
      "Epoch 243/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2251 - acc: 0.8804 - auc_1: 0.9710 - val_loss: 0.7797 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 244/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2271 - acc: 0.9022 - auc_1: 0.9714 - val_loss: 0.8289 - val_acc: 0.5833 - val_auc_1: 0.8036\n",
      "Epoch 245/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2130 - acc: 0.8913 - auc_1: 0.9750 - val_loss: 0.8088 - val_acc: 0.5417 - val_auc_1: 0.7714\n",
      "Epoch 246/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2277 - acc: 0.8913 - auc_1: 0.9679 - val_loss: 0.8248 - val_acc: 0.5833 - val_auc_1: 0.8107\n",
      "Epoch 247/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2252 - acc: 0.8804 - auc_1: 0.9710 - val_loss: 0.8802 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 248/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2272 - acc: 0.8913 - auc_1: 0.9710 - val_loss: 0.7405 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 249/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2219 - acc: 0.8913 - auc_1: 0.9726 - val_loss: 0.7436 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 250/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2185 - acc: 0.8804 - auc_1: 0.9736 - val_loss: 0.7794 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 251/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2194 - acc: 0.8913 - auc_1: 0.9736 - val_loss: 0.7948 - val_acc: 0.6250 - val_auc_1: 0.7857\n",
      "Epoch 252/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2120 - acc: 0.9022 - auc_1: 0.9774 - val_loss: 0.8248 - val_acc: 0.6250 - val_auc_1: 0.8071\n",
      "Epoch 253/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2033 - acc: 0.9022 - auc_1: 0.9802 - val_loss: 0.7862 - val_acc: 0.6250 - val_auc_1: 0.7893\n",
      "Epoch 254/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2169 - acc: 0.8913 - auc_1: 0.9743 - val_loss: 0.7659 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 255/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2209 - acc: 0.8696 - auc_1: 0.9700 - val_loss: 0.7767 - val_acc: 0.6250 - val_auc_1: 0.8393\n",
      "Epoch 256/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2141 - acc: 0.8913 - auc_1: 0.9748 - val_loss: 0.7943 - val_acc: 0.5833 - val_auc_1: 0.7893\n",
      "Epoch 257/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2048 - acc: 0.8913 - auc_1: 0.9755 - val_loss: 0.8084 - val_acc: 0.5417 - val_auc_1: 0.7857\n",
      "Epoch 258/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1999 - acc: 0.9022 - auc_1: 0.9760 - val_loss: 0.8427 - val_acc: 0.5417 - val_auc_1: 0.7857\n",
      "Epoch 259/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1931 - acc: 0.9239 - auc_1: 0.9814 - val_loss: 0.7723 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 260/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2056 - acc: 0.9130 - auc_1: 0.9779 - val_loss: 0.7776 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 261/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2035 - acc: 0.8804 - auc_1: 0.9776 - val_loss: 0.8130 - val_acc: 0.6250 - val_auc_1: 0.8036\n",
      "Epoch 262/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2078 - acc: 0.8804 - auc_1: 0.9760 - val_loss: 0.8248 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 263/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1941 - acc: 0.9022 - auc_1: 0.9793 - val_loss: 0.7716 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 264/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1840 - acc: 0.9130 - auc_1: 0.9862 - val_loss: 0.9233 - val_acc: 0.6250 - val_auc_1: 0.8071\n",
      "Epoch 265/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1877 - acc: 0.9022 - auc_1: 0.9840 - val_loss: 0.8038 - val_acc: 0.5417 - val_auc_1: 0.7857\n",
      "Epoch 266/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2013 - acc: 0.9022 - auc_1: 0.9774 - val_loss: 0.7650 - val_acc: 0.6250 - val_auc_1: 0.8143\n",
      "Epoch 267/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1916 - acc: 0.9022 - auc_1: 0.9829 - val_loss: 0.7751 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 268/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1809 - acc: 0.9348 - auc_1: 0.9840 - val_loss: 0.7555 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 269/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1836 - acc: 0.8913 - auc_1: 0.9833 - val_loss: 0.7577 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 270/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1751 - acc: 0.9130 - auc_1: 0.9862 - val_loss: 0.9073 - val_acc: 0.5417 - val_auc_1: 0.7857\n",
      "Epoch 271/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1923 - acc: 0.8913 - auc_1: 0.9798 - val_loss: 0.8099 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 272/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1740 - acc: 0.9022 - auc_1: 0.9871 - val_loss: 0.7797 - val_acc: 0.5833 - val_auc_1: 0.7929\n",
      "Epoch 273/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1911 - acc: 0.8804 - auc_1: 0.9764 - val_loss: 0.8179 - val_acc: 0.5833 - val_auc_1: 0.7893\n",
      "Epoch 274/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1831 - acc: 0.9022 - auc_1: 0.9802 - val_loss: 0.7815 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 275/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1698 - acc: 0.9457 - auc_1: 0.9864 - val_loss: 0.8024 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 276/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1669 - acc: 0.9130 - auc_1: 0.9862 - val_loss: 0.8326 - val_acc: 0.6250 - val_auc_1: 0.7786\n",
      "Epoch 277/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1718 - acc: 0.9457 - auc_1: 0.9869 - val_loss: 0.8614 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 278/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1617 - acc: 0.9239 - auc_1: 0.9895 - val_loss: 0.8053 - val_acc: 0.5833 - val_auc_1: 0.7857\n",
      "Epoch 279/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1582 - acc: 0.9348 - auc_1: 0.9900 - val_loss: 0.8602 - val_acc: 0.6250 - val_auc_1: 0.8321\n",
      "Epoch 280/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1622 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 0.7187 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 281/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1672 - acc: 0.9239 - auc_1: 0.9874 - val_loss: 0.7687 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 282/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1631 - acc: 0.9239 - auc_1: 0.9881 - val_loss: 0.7435 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 283/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1433 - acc: 0.9565 - auc_1: 0.9938 - val_loss: 1.0099 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 284/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1840 - acc: 0.9239 - auc_1: 0.9824 - val_loss: 0.8436 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 285/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1666 - acc: 0.9022 - auc_1: 0.9862 - val_loss: 0.7669 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 286/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1434 - acc: 0.9565 - auc_1: 0.9924 - val_loss: 0.8738 - val_acc: 0.6250 - val_auc_1: 0.8214\n",
      "Epoch 287/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1466 - acc: 0.9130 - auc_1: 0.9919 - val_loss: 0.7872 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 288/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1446 - acc: 0.9348 - auc_1: 0.9905 - val_loss: 0.9508 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 289/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1674 - acc: 0.9348 - auc_1: 0.9881 - val_loss: 0.8358 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 290/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1389 - acc: 0.9348 - auc_1: 0.9926 - val_loss: 1.0175 - val_acc: 0.6250 - val_auc_1: 0.8107\n",
      "Epoch 291/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1675 - acc: 0.9348 - auc_1: 0.9931 - val_loss: 0.7461 - val_acc: 0.7917 - val_auc_1: 0.8429\n",
      "Epoch 292/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1434 - acc: 0.9457 - auc_1: 0.9919 - val_loss: 0.7883 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 293/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1375 - acc: 0.9674 - auc_1: 0.9952 - val_loss: 0.8552 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 294/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1350 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.7913 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 295/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1286 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.7258 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 296/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1387 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 0.8253 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 297/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1372 - acc: 0.9457 - auc_1: 0.9933 - val_loss: 0.7810 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 298/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1282 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.7986 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 299/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1373 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 0.8353 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 300/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1395 - acc: 0.9565 - auc_1: 0.9914 - val_loss: 0.7846 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 301/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1433 - acc: 0.9348 - auc_1: 0.9910 - val_loss: 0.8200 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 302/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1442 - acc: 0.9457 - auc_1: 0.9938 - val_loss: 0.8293 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 303/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1209 - acc: 0.9565 - auc_1: 0.9948 - val_loss: 0.7832 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 304/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1248 - acc: 0.9674 - auc_1: 0.9938 - val_loss: 0.7702 - val_acc: 0.7917 - val_auc_1: 0.8393\n",
      "Epoch 305/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1206 - acc: 0.9565 - auc_1: 0.9969 - val_loss: 0.8054 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 306/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1238 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.8197 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 307/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1196 - acc: 0.9565 - auc_1: 0.9950 - val_loss: 0.7931 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 308/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1151 - acc: 0.9565 - auc_1: 0.9962 - val_loss: 0.8525 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 309/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1144 - acc: 0.9891 - auc_1: 0.9967 - val_loss: 0.9301 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 310/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1106 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.7285 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 311/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1176 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.7628 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 312/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1137 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 0.7045 - val_acc: 0.7917 - val_auc_1: 0.8607\n",
      "Epoch 313/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1134 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 0.7384 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 314/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1085 - acc: 0.9891 - auc_1: 0.9967 - val_loss: 0.8632 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 315/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1117 - acc: 0.9565 - auc_1: 0.9971 - val_loss: 0.8548 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 316/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1003 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.9388 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 317/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1197 - acc: 0.9674 - auc_1: 0.9964 - val_loss: 0.7933 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 318/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1028 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 0.8965 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 319/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1089 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.8566 - val_acc: 0.7500 - val_auc_1: 0.8250\n",
      "Epoch 320/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1018 - acc: 0.9891 - auc_1: 0.9979 - val_loss: 0.8878 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 321/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1164 - acc: 0.9457 - auc_1: 0.9943 - val_loss: 0.7986 - val_acc: 0.7500 - val_auc_1: 0.8000\n",
      "Epoch 322/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1025 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.8610 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 323/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1038 - acc: 0.9565 - auc_1: 0.9957 - val_loss: 0.9523 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 324/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0873 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.7258 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 325/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0982 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 0.8279 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 326/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1004 - acc: 0.9783 - auc_1: 0.9957 - val_loss: 0.9330 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 327/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1364 - acc: 0.9674 - auc_1: 0.9890 - val_loss: 0.9779 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 328/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0905 - acc: 0.9565 - auc_1: 0.9981 - val_loss: 0.8984 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 329/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0878 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.9350 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 330/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0929 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8913 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 331/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0876 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 0.9109 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 332/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0926 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.8756 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 333/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0816 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.9267 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 334/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0817 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 1.0289 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 335/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0821 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.9107 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 336/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0820 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8011 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 337/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0938 - acc: 0.9674 - auc_1: 0.9967 - val_loss: 1.0664 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 338/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0819 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.1523 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 339/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0860 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8465 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 340/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0867 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.8547 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 341/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0772 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.0181 - val_acc: 0.6667 - val_auc_1: 0.7750\n",
      "Epoch 342/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1139 - acc: 0.9565 - auc_1: 0.9929 - val_loss: 0.8500 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 343/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0964 - acc: 0.9674 - auc_1: 0.9971 - val_loss: 0.9506 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 344/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0747 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.9403 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 345/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0719 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8758 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 346/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0704 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8617 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 347/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0818 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.1055 - val_acc: 0.7083 - val_auc_1: 0.7679\n",
      "Epoch 348/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0745 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.1091 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 349/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0727 - acc: 0.9891 - auc_1: 0.9974 - val_loss: 1.0442 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 350/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0902 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8207 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 351/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0853 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 0.7643 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 352/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0701 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.1260 - val_acc: 0.6667 - val_auc_1: 0.7750\n",
      "Epoch 353/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0692 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8327 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 354/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0701 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.0958 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 355/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0678 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1301 - val_acc: 0.6667 - val_auc_1: 0.7607\n",
      "Epoch 356/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0781 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.8567 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 357/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0680 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1841 - val_acc: 0.6667 - val_auc_1: 0.7750\n",
      "Epoch 358/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0717 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.1558 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 359/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0736 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8688 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 360/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0657 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.1521 - val_acc: 0.6667 - val_auc_1: 0.7679\n",
      "Epoch 361/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0689 - acc: 0.9783 - auc_1: 0.9974 - val_loss: 0.9329 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 362/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1314 - acc: 0.9565 - auc_1: 0.9869 - val_loss: 1.0020 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 363/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3323 - acc: 0.9130 - auc_1: 0.9300 - val_loss: 0.9310 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 364/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1092 - acc: 0.9457 - auc_1: 0.9950 - val_loss: 0.9702 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 365/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0782 - acc: 0.9783 - auc_1: 0.9971 - val_loss: 0.9537 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 366/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0814 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 0.9106 - val_acc: 0.7500 - val_auc_1: 0.8036\n",
      "Epoch 367/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0746 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 0.9776 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 368/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0667 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.8761 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 369/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0650 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.9423 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 370/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0627 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.9330 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 371/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0651 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.8484 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 372/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0639 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 1.0197 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 373/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0629 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.0201 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 374/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0637 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 0.9911 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 375/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0626 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 0.8747 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 376/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0621 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.1719 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 377/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0549 - acc: 0.9783 - auc_1: 0.9988 - val_loss: 0.9823 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 378/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0642 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 0.9599 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 379/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0585 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 0.9565 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 380/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0667 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.2198 - val_acc: 0.7083 - val_auc_1: 0.7464\n",
      "Epoch 381/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0642 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.2258 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 382/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0565 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.3861 - val_acc: 0.6667 - val_auc_1: 0.7607\n",
      "Epoch 383/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0564 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 0.9593 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 384/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0520 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.0133 - val_acc: 0.7083 - val_auc_1: 0.7893\n",
      "Epoch 385/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0541 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.0814 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 386/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0559 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.2177 - val_acc: 0.7083 - val_auc_1: 0.7607\n",
      "Epoch 387/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0551 - acc: 0.9891 - auc_1: 0.9998 - val_loss: 0.9623 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 388/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0515 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.3862 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 389/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0635 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.1069 - val_acc: 0.6250 - val_auc_1: 0.7857\n",
      "Epoch 390/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0562 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.2432 - val_acc: 0.6250 - val_auc_1: 0.7643\n",
      "Epoch 391/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0949 - acc: 0.9565 - auc_1: 0.9950 - val_loss: 1.1727 - val_acc: 0.7083 - val_auc_1: 0.7821\n",
      "Epoch 392/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1718 - acc: 0.9457 - auc_1: 0.9831 - val_loss: 1.3259 - val_acc: 0.6667 - val_auc_1: 0.7393\n",
      "Epoch 393/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0980 - acc: 0.9674 - auc_1: 0.9943 - val_loss: 0.9285 - val_acc: 0.7500 - val_auc_1: 0.8857\n",
      "Epoch 394/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0667 - acc: 0.9891 - auc_1: 0.9976 - val_loss: 1.0681 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 395/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0542 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.0064 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 396/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0565 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.3141 - val_acc: 0.6667 - val_auc_1: 0.7607\n",
      "Epoch 397/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0524 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.1350 - val_acc: 0.7083 - val_auc_1: 0.7750\n",
      "Epoch 398/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0526 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.2501 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 399/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0616 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.2866 - val_acc: 0.7083 - val_auc_1: 0.7929\n",
      "Epoch 400/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0527 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1927 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 401/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0451 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.1062 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 402/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0514 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.0099 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 403/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0523 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.1118 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 404/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0503 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.0863 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 405/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0486 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.0429 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 406/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0511 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 0.9878 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 407/700\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0510 - acc: 0.9875 - auc_1: 0.9994     - 0s 3ms/step - loss: 0.0485 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.4379 - val_acc: 0.7083 - val_auc_1: 0.7464\n",
      "Epoch 408/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0504 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.2737 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 409/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0503 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.1277 - val_acc: 0.7083 - val_auc_1: 0.8071\n",
      "Epoch 410/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0540 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1245 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 411/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0523 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.0891 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 412/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0496 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.2284 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 413/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0497 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.1345 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 414/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0492 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1464 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 415/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0490 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.2451 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 416/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0465 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.2778 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 417/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0475 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.3275 - val_acc: 0.7083 - val_auc_1: 0.7786\n",
      "Epoch 418/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0578 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1254 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 419/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0584 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.1123 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 420/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0571 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.3457 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 421/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0685 - acc: 0.9674 - auc_1: 0.9976 - val_loss: 1.1867 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 422/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0447 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.3814 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 423/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0460 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.0769 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 424/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0444 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.3909 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 425/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0454 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0079 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 426/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0553 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 1.0336 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 427/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0410 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.1504 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 428/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0495 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.0627 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 429/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0628 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.4293 - val_acc: 0.6667 - val_auc_1: 0.7786\n",
      "Epoch 430/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0472 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.3375 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 431/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0414 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1634 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 432/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0418 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.1828 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 433/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0350 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.9614 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 434/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0644 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.5763 - val_acc: 0.6667 - val_auc_1: 0.7286\n",
      "Epoch 435/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0586 - acc: 0.9783 - auc_1: 0.9981 - val_loss: 1.1535 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 436/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0465 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.3612 - val_acc: 0.6250 - val_auc_1: 0.8000\n",
      "Epoch 437/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1869 - acc: 0.9348 - auc_1: 0.9817 - val_loss: 1.4663 - val_acc: 0.6250 - val_auc_1: 0.7786\n",
      "Epoch 438/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1315 - acc: 0.9565 - auc_1: 0.9890 - val_loss: 1.3075 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 439/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0548 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.0598 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 440/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0451 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.2057 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 441/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0424 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1655 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 442/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0436 - acc: 0.9674 - auc_1: 0.9990 - val_loss: 1.0998 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 443/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0415 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.3002 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 444/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0440 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.1774 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 445/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0370 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.1874 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 446/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0378 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.0901 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 447/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0388 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0903 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 448/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0460 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.0849 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 449/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0459 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1423 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 450/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0454 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1116 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 451/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0512 - acc: 0.9891 - auc_1: 0.9986 - val_loss: 1.2171 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 452/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0328 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.1020 - val_acc: 0.7083 - val_auc_1: 0.7964\n",
      "Epoch 453/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0388 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3574 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 454/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0333 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.3674 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 455/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0582 - acc: 0.9674 - auc_1: 0.9986 - val_loss: 1.0588 - val_acc: 0.7083 - val_auc_1: 0.8214\n",
      "Epoch 456/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0374 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.2626 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 457/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0372 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4921 - val_acc: 0.6667 - val_auc_1: 0.7679\n",
      "Epoch 458/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0421 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.0672 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 459/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0386 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.1590 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 460/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0418 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.0826 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 461/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0306 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1114 - val_acc: 0.6667 - val_auc_1: 0.8357\n",
      "Epoch 462/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0349 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.2850 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 463/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0341 - acc: 0.9783 - auc_1: 1.0000 - val_loss: 1.0124 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 464/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0336 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.4587 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 465/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0456 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.2531 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 466/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1639 - acc: 0.9674 - auc_1: 0.9826 - val_loss: 0.8381 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 467/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2144 - acc: 0.9239 - auc_1: 0.9731 - val_loss: 1.2760 - val_acc: 0.6667 - val_auc_1: 0.81076    \n",
      "Epoch 468/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0410 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.2764 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 469/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0351 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.2790 - val_acc: 0.7083 - val_auc_1: 0.7857\n",
      "Epoch 470/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0338 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.2168 - val_acc: 0.7083 - val_auc_1: 0.8036\n",
      "Epoch 471/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0363 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3748 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 472/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0412 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2229 - val_acc: 0.7083 - val_auc_1: 0.8000\n",
      "Epoch 473/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0271 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4103 - val_acc: 0.6667 - val_auc_1: 0.8000\n",
      "Epoch 474/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0351 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.3124 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 475/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0485 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.6416 - val_acc: 0.6250 - val_auc_1: 0.7464\n",
      "Epoch 476/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0351 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0896 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 477/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0659 - acc: 0.9565 - auc_1: 0.9967 - val_loss: 1.2368 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 478/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0306 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0815 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 479/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0362 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.3667 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 480/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0321 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1155 - val_acc: 0.6667 - val_auc_1: 0.8143\n",
      "Epoch 481/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0417 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.4395 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 482/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0654 - acc: 0.9674 - auc_1: 0.9981 - val_loss: 1.4002 - val_acc: 0.6667 - val_auc_1: 0.7500\n",
      "Epoch 483/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0685 - acc: 0.9674 - auc_1: 0.9974 - val_loss: 1.4465 - val_acc: 0.6667 - val_auc_1: 0.7821\n",
      "Epoch 484/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0359 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.0940 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 485/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0265 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1929 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 486/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0304 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 0.9427 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 487/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0273 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.2672 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 488/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0261 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2166 - val_acc: 0.6667 - val_auc_1: 0.8214\n",
      "Epoch 489/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0294 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.1811 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 490/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0287 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1428 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 491/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0327 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0099 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 492/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2669 - acc: 0.9239 - auc_1: 0.9690 - val_loss: 1.4137 - val_acc: 0.6667 - val_auc_1: 0.7929\n",
      "Epoch 493/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0317 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3083 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 494/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0468 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.5789 - val_acc: 0.6667 - val_auc_1: 0.8036\n",
      "Epoch 495/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0420 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.2977 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 496/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0385 - acc: 0.9783 - auc_1: 0.9990 - val_loss: 1.1391 - val_acc: 0.6667 - val_auc_1: 0.8321\n",
      "Epoch 497/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0257 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0205 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 498/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0313 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2110 - val_acc: 0.6667 - val_auc_1: 0.8643\n",
      "Epoch 499/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0216 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1915 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 500/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0204 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0360 - val_acc: 0.6667 - val_auc_1: 0.8500\n",
      "Epoch 501/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0271 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9687 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 502/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0238 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1578 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 503/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0183 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1384 - val_acc: 0.6667 - val_auc_1: 0.8464\n",
      "Epoch 504/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0209 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1902 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 505/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0253 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0216 - val_acc: 0.6667 - val_auc_1: 0.8429\n",
      "Epoch 506/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0287 - acc: 0.9891 - auc_1: 0.9995 - val_loss: 1.0986 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 507/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0196 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1946 - val_acc: 0.6667 - val_auc_1: 0.8250\n",
      "Epoch 508/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0216 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1861 - val_acc: 0.6667 - val_auc_1: 0.8393\n",
      "Epoch 509/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0326 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1969 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 510/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1199 - acc: 0.9565 - auc_1: 0.9919 - val_loss: 1.2711 - val_acc: 0.6667 - val_auc_1: 0.7857\n",
      "Epoch 511/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0566 - acc: 0.9891 - auc_1: 0.9981 - val_loss: 1.2309 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 512/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0889 - acc: 0.9674 - auc_1: 0.9964 - val_loss: 1.0628 - val_acc: 0.7083 - val_auc_1: 0.8179\n",
      "Epoch 513/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0586 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.0020 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 514/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0268 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9907 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 515/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0277 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0521 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 516/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0236 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0989 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 517/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0179 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0623 - val_acc: 0.6667 - val_auc_1: 0.8607\n",
      "Epoch 518/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0171 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0107 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 519/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0144 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0572 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 520/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0192 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1889 - val_acc: 0.6667 - val_auc_1: 0.8571\n",
      "Epoch 521/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0226 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1835 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 522/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0269 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.1777 - val_acc: 0.6667 - val_auc_1: 0.8286\n",
      "Epoch 523/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0203 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0867 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 524/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0144 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0758 - val_acc: 0.7083 - val_auc_1: 0.8464\n",
      "Epoch 525/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0130 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1705 - val_acc: 0.7083 - val_auc_1: 0.8250\n",
      "Epoch 526/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0180 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0662 - val_acc: 0.7083 - val_auc_1: 0.8393\n",
      "Epoch 527/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0551 - acc: 0.9891 - auc_1: 0.9990 - val_loss: 1.0267 - val_acc: 0.7500 - val_auc_1: 0.8321\n",
      "Epoch 528/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1890 - acc: 0.9457 - auc_1: 0.9795 - val_loss: 1.1313 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 529/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0608 - acc: 0.9783 - auc_1: 0.9976 - val_loss: 1.0411 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 530/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0338 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2242 - val_acc: 0.7083 - val_auc_1: 0.8107\n",
      "Epoch 531/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1487 - acc: 0.9348 - auc_1: 0.9902 - val_loss: 1.3159 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 532/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0325 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0776 - val_acc: 0.6667 - val_auc_1: 0.8857\n",
      "Epoch 533/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0158 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0540 - val_acc: 0.6667 - val_auc_1: 0.8750\n",
      "Epoch 534/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0130 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1058 - val_acc: 0.6667 - val_auc_1: 0.8786\n",
      "Epoch 535/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0123 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0071 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 536/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0141 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0502 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 537/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0126 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0391 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 538/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0114 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0513 - val_acc: 0.7083 - val_auc_1: 0.8786\n",
      "Epoch 539/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0118 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0030 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 540/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0151 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0846 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 541/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0118 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1344 - val_acc: 0.7083 - val_auc_1: 0.8714\n",
      "Epoch 542/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0127 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0784 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 543/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0130 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0721 - val_acc: 0.7083 - val_auc_1: 0.8679\n",
      "Epoch 544/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0107 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0327 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 545/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0116 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1579 - val_acc: 0.7083 - val_auc_1: 0.8607\n",
      "Epoch 546/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0145 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0703 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 547/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0134 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1067 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 548/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0130 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1338 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 549/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0139 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9853 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 550/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0179 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1488 - val_acc: 0.6667 - val_auc_1: 0.8679\n",
      "Epoch 551/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0998 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 552/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0134 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0747 - val_acc: 0.7083 - val_auc_1: 0.8321\n",
      "Epoch 553/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0893 - acc: 0.9783 - auc_1: 0.9933 - val_loss: 1.5189 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 554/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0275 - acc: 0.9891 - auc_1: 1.0000 - val_loss: 1.0153 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 555/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0310 - acc: 0.9783 - auc_1: 0.9995 - val_loss: 1.2768 - val_acc: 0.6667 - val_auc_1: 0.8536\n",
      "Epoch 556/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1479 - val_acc: 0.7083 - val_auc_1: 0.8571\n",
      "Epoch 557/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0108 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1672 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 558/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0122 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1805 - val_acc: 0.7083 - val_auc_1: 0.8500\n",
      "Epoch 559/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0098 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0716 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 560/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0104 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2598 - val_acc: 0.7083 - val_auc_1: 0.8429\n",
      "Epoch 561/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0118 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1909 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 562/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0086 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1622 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 563/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1876 - val_acc: 0.7083 - val_auc_1: 0.8286\n",
      "Epoch 564/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2366 - val_acc: 0.6667 - val_auc_1: 0.8071\n",
      "Epoch 565/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0104 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2758 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 566/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3209 - val_acc: 0.6667 - val_auc_1: 0.8107\n",
      "Epoch 567/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0157 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1794 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 568/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0099 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1817 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 569/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0101 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1473 - val_acc: 0.7083 - val_auc_1: 0.8643\n",
      "Epoch 570/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0096 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2487 - val_acc: 0.7083 - val_auc_1: 0.8357\n",
      "Epoch 571/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2927 - val_acc: 0.7083 - val_auc_1: 0.8143\n",
      "Epoch 572/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0195 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0643 - val_acc: 0.7500 - val_auc_1: 0.8571\n",
      "Epoch 573/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.2934 - acc: 0.9239 - auc_1: 0.9636 - val_loss: 1.3193 - val_acc: 0.7083 - val_auc_1: 0.7250\n",
      "Epoch 574/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1244 - acc: 0.9783 - auc_1: 0.9862 - val_loss: 1.2163 - val_acc: 0.7917 - val_auc_1: 0.8143\n",
      "Epoch 575/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0922 - acc: 0.9783 - auc_1: 0.9950 - val_loss: 1.0118 - val_acc: 0.7083 - val_auc_1: 0.8536\n",
      "Epoch 576/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0172 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1536 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 577/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0124 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0954 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 578/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1360 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 579/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0084 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1211 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 580/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0080 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1387 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 581/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1418 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 582/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1918 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 583/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1512 - val_acc: 0.7500 - val_auc_1: 0.8536\n",
      "Epoch 584/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0070 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1701 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 585/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0069 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1461 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 586/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1275 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 587/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1842 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 588/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0074 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1926 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 589/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1615 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 590/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0065 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1789 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 591/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0064 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1979 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 592/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0063 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2363 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 593/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2205 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 594/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1551 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 595/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2085 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 596/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0058 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2126 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 597/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0067 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3144 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 598/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0108 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4048 - val_acc: 0.7500 - val_auc_1: 0.7821\n",
      "Epoch 599/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0082 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2021 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 600/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1937 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 601/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1904 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 602/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2008 - val_acc: 0.7500 - val_auc_1: 0.8143\n",
      "Epoch 603/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2222 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 604/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0059 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2553 - val_acc: 0.7500 - val_auc_1: 0.7786\n",
      "Epoch 605/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0071 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1738 - val_acc: 0.7500 - val_auc_1: 0.8107\n",
      "Epoch 606/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0091 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2048 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 607/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0282 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.4503 - val_acc: 0.6667 - val_auc_1: 0.7643\n",
      "Epoch 608/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6095 - acc: 0.8478 - auc_1: 0.9119 - val_loss: 0.9529 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 609/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1903 - acc: 0.9457 - auc_1: 0.9807 - val_loss: 1.0356 - val_acc: 0.7917 - val_auc_1: 0.8893\n",
      "Epoch 610/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0186 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0695 - val_acc: 0.7917 - val_auc_1: 0.8857\n",
      "Epoch 611/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0078 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1084 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 612/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1013 - val_acc: 0.7917 - val_auc_1: 0.8500\n",
      "Epoch 613/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1131 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 614/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0062 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1229 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 615/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1142 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 616/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0056 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1225 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 617/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0057 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1287 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 618/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1248 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 619/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1221 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 620/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0051 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1317 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 621/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0050 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1351 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 622/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1389 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 623/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1309 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 624/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1432 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 625/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1371 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 626/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1502 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 627/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1500 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 628/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1600 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 629/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1254 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 630/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1433 - val_acc: 0.7500 - val_auc_1: 0.8214\n",
      "Epoch 631/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1709 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 632/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1372 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 633/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1395 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 634/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1601 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 635/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1328 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 636/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1911 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 637/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1659 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 638/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1653 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 639/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1662 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 640/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1922 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 641/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1314 - val_acc: 0.7917 - val_auc_1: 0.8286\n",
      "Epoch 642/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1840 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 643/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2269 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 644/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1943 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 645/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2200 - val_acc: 0.7500 - val_auc_1: 0.8179\n",
      "Epoch 646/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1817 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 647/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1772 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 648/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0055 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1061 - val_acc: 0.7917 - val_auc_1: 0.8179\n",
      "Epoch 649/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1095 - acc: 0.9565 - auc_1: 0.9845 - val_loss: 1.3978 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 650/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1744 - acc: 0.9348 - auc_1: 0.9917 - val_loss: 1.0477 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 651/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0871 - acc: 0.9783 - auc_1: 0.9962 - val_loss: 1.1756 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 652/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0193 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9748 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 653/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0066 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2889 - val_acc: 0.7500 - val_auc_1: 0.8071\n",
      "Epoch 654/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0072 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2213 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 655/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1930 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 656/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1701 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 657/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0041 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1707 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 658/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2076 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 659/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1812 - val_acc: 0.7500 - val_auc_1: 0.8750\n",
      "Epoch 660/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1978 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 661/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0036 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2110 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 662/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2053 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 663/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2077 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 664/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1937 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 665/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2348 - val_acc: 0.7500 - val_auc_1: 0.8643\n",
      "Epoch 666/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1779 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 667/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2264 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 668/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1972 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 669/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2355 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 670/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0032 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2265 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 671/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2425 - val_acc: 0.7500 - val_auc_1: 0.8714\n",
      "Epoch 672/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0031 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2025 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 673/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2296 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 674/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1674 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 675/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2485 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 676/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2506 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 677/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2735 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 678/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0029 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2440 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 679/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2155 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 680/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0028 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2588 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 681/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2679 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 682/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0027 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2573 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 683/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.2734 - val_acc: 0.7500 - val_auc_1: 0.8286\n",
      "Epoch 684/700\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.3701 - val_acc: 0.7500 - val_auc_1: 0.7929\n",
      "Epoch 685/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.1759 - acc: 0.9783 - auc_1: 0.9840 - val_loss: 1.1956 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 686/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6829 - acc: 0.8587 - auc_1: 0.9255 - val_loss: 0.8536 - val_acc: 0.7917 - val_auc_1: 0.8643\n",
      "Epoch 687/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0496 - acc: 0.9783 - auc_1: 0.9986 - val_loss: 1.4040 - val_acc: 0.6667 - val_auc_1: 0.7964\n",
      "Epoch 688/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0141 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 0.9604 - val_acc: 0.7500 - val_auc_1: 0.8786\n",
      "Epoch 689/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0123 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0943 - val_acc: 0.7500 - val_auc_1: 0.8357\n",
      "Epoch 690/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0076 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0509 - val_acc: 0.7500 - val_auc_1: 0.8607\n",
      "Epoch 691/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0053 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0973 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 692/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1057 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 693/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0040 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0976 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 694/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0038 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0842 - val_acc: 0.7500 - val_auc_1: 0.8679\n",
      "Epoch 695/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0039 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1171 - val_acc: 0.7500 - val_auc_1: 0.8429\n",
      "Epoch 696/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1078 - val_acc: 0.7500 - val_auc_1: 0.8393\n",
      "Epoch 697/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1070 - val_acc: 0.7500 - val_auc_1: 0.8464\n",
      "Epoch 698/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0035 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0936 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 699/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.1036 - val_acc: 0.7500 - val_auc_1: 0.8500\n",
      "Epoch 700/700\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.0033 - acc: 1.0000 - auc_1: 1.0000 - val_loss: 1.0909 - val_acc: 0.7500 - val_auc_1: 0.8500\n"
     ]
    }
   ],
   "source": [
    "#training the model of neural network\n",
    "train_history = model.fit([X1, X2, X3, X4, X5], Y, validation_split=0.2, epochs = 700, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-4.0881070e-01,  1.7007966e+00,  6.9004856e-02, -1.1044264e+00,\n",
      "         5.3930092e-01, -5.2818257e-01, -4.4793886e-01,  4.9431887e-01,\n",
      "        -9.9468797e-01],\n",
      "       [ 1.1250957e-01, -1.4004050e+00, -1.4178330e-01, -1.8224800e+00,\n",
      "         9.7300464e-01,  3.0655795e-01,  1.7286868e+00, -2.1085439e+00,\n",
      "        -1.4521889e-01],\n",
      "       [ 4.3846667e-01, -5.0492465e-01,  1.1611291e+00,  7.9584777e-01,\n",
      "        -4.4810659e-01, -8.1534982e-01,  7.0983464e-01, -1.7379528e-01,\n",
      "        -2.7556652e-01],\n",
      "       [ 7.1722168e-01,  1.4188364e-01, -3.1795690e+00,  7.4569964e-01,\n",
      "        -1.6084092e+00,  3.4346044e+00,  3.0223820e-01, -7.8760052e-01,\n",
      "         2.2450368e+00],\n",
      "       [-1.8973413e+00,  1.5415464e-01, -6.0890192e-01, -4.2184412e-01,\n",
      "        -1.3627585e+00,  3.8761836e-01,  6.1264312e-01, -1.2506975e-03,\n",
      "         1.5441883e+00]], dtype=float32), array([-0.05279307,  0.37027958, -0.10518221,  0.16322547,  0.14424203,\n",
      "       -0.02659655, -0.5111968 ,  0.36118874, -0.18979488], dtype=float32), array([[ 1.4690429 , -1.2414513 ,  0.11271479, -1.7658539 ,  0.6170638 ,\n",
      "         0.21568377,  0.80369484,  0.14854458,  1.2706699 ],\n",
      "       [ 0.37016237, -0.32041007, -1.6398684 ,  1.4734865 , -1.0852649 ,\n",
      "         0.84089994, -0.43023401,  0.584815  , -0.59106517],\n",
      "       [-1.2406609 ,  0.44732574,  5.3923345 ,  1.2211416 , -1.5472319 ,\n",
      "        -0.70571494,  0.566365  ,  1.0836862 ,  1.9178593 ],\n",
      "       [-0.3735417 , -1.1313069 ,  1.2235234 , -0.8511309 ,  1.1665289 ,\n",
      "         0.66349894, -2.103634  ,  1.6004424 ,  0.31325558],\n",
      "       [ 1.5640631 ,  1.4235092 , -0.7737585 ,  0.64513874, -0.8601102 ,\n",
      "         0.36980546,  2.9969635 , -0.5484847 ,  0.9165777 ],\n",
      "       [ 0.51410836, -1.121616  , -4.9588966 , -2.8960984 ,  1.6798369 ,\n",
      "        -0.16454116, -0.15218924, -0.5564773 , -1.7995212 ],\n",
      "       [-1.7512591 , -0.89444655,  0.8195131 , -0.33358002, -0.08239124,\n",
      "        -4.0338664 ,  0.52797437, -1.5613621 ,  0.7933364 ],\n",
      "       [ 0.30117524,  0.31131008,  0.42090806,  1.5967411 , -0.0455221 ,\n",
      "         3.6673913 , -1.4218644 ,  1.550454  , -0.35987025],\n",
      "       [-2.5867875 , -1.3258055 , -1.8938853 , -2.1821187 ,  2.5087786 ,\n",
      "         0.35428056, -2.483771  , -0.8388616 , -1.9285374 ]],\n",
      "      dtype=float32), array([ 0.14901762,  0.81621957, -0.32802072, -0.22431867, -0.42153797,\n",
      "       -0.3282776 , -0.69433796,  0.20447598,  0.00646606], dtype=float32), array([[ 1.3203514 ,  1.2331765 ,  0.7090142 , -1.3806129 , -1.4296174 ,\n",
      "         0.07457475,  0.27480754, -1.1597643 , -0.75847375],\n",
      "       [-0.34878767,  3.1511235 , -0.1265775 , -2.5013156 , -0.6306948 ,\n",
      "         0.13389677,  1.123583  , -0.78270537,  0.52311695],\n",
      "       [-1.6226252 , -2.1375306 , -0.8633221 ,  0.5174641 , -1.2394778 ,\n",
      "        -0.7108624 , -0.2874096 , -1.1860979 ,  0.8624705 ],\n",
      "       [-1.0080202 ,  0.24131699, -1.2605888 ,  0.22845279, -0.47458234,\n",
      "        -1.5585533 , -1.5475409 , -0.3803534 ,  1.9220005 ],\n",
      "       [-0.04117176, -3.0364857 , -0.6583881 ,  2.9535358 ,  0.42996004,\n",
      "        -1.1143017 ,  0.9144509 ,  0.28401428,  0.49234843],\n",
      "       [ 0.58886075, -1.6833409 , -0.02022676,  2.6055949 , -3.3260417 ,\n",
      "         0.40761214, -0.15081535, -3.097654  , -0.02501595],\n",
      "       [-1.1269941 ,  1.7039051 , -0.9378996 , -1.415231  ,  1.5066689 ,\n",
      "        -0.86295354, -2.4931448 ,  1.4576681 ,  0.46091512],\n",
      "       [-0.4272351 , -0.2982555 ,  0.2736866 ,  1.0574472 , -4.456176  ,\n",
      "         0.91358113,  0.8103222 , -4.3327003 , -0.26140285],\n",
      "       [ 1.5080469 ,  1.3472486 ,  1.5405524 , -1.2775202 , -0.8909874 ,\n",
      "         0.61394006, -4.915071  , -0.5192552 , -1.473399  ]],\n",
      "      dtype=float32), array([ 0.16784714,  0.97094923,  0.16277488, -1.3892349 , -0.5433343 ,\n",
      "        0.5644972 ,  0.5184532 , -0.14647382, -0.12245607], dtype=float32), array([[-3.3548856],\n",
      "       [-3.6674745],\n",
      "       [-4.0246983],\n",
      "       [ 3.0695302],\n",
      "       [ 2.801277 ],\n",
      "       [-1.7429382],\n",
      "       [ 2.683729 ],\n",
      "       [ 2.8548899],\n",
      "       [ 3.121558 ]], dtype=float32), array([0.09257422], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#drawing the lines of losses and metrics\n",
    "def show_train_history(train_history, x1, x2):\n",
    "    plot.plot(train_history.history[x1])\n",
    "    plot.plot(train_history.history[x2])\n",
    "    plot.title('Train History')\n",
    "    plot.ylabel('train')\n",
    "    plot.xlabel('Epoch')\n",
    "    plot.legend([x1, x2], loc = 'upper right')\n",
    "    plot.show()\n",
    "\n",
    "show_train_history(train_history, 'auc_1', 'val_auc_1')\n",
    "\n",
    "#showing the weights in the model of neural network\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9310389e-02]\n",
      " [9.8879927e-01]\n",
      " [9.9929738e-01]\n",
      " [2.7341483e-05]\n",
      " [5.0833408e-04]\n",
      " [9.9992204e-01]\n",
      " [9.9458164e-01]\n",
      " [9.9992752e-01]\n",
      " [9.7049361e-01]\n",
      " [9.9018490e-01]\n",
      " [4.7183137e-05]\n",
      " [1.3327988e-02]\n",
      " [9.9998534e-01]\n",
      " [4.4209571e-03]\n",
      " [1.2239459e-02]\n",
      " [9.9978012e-01]\n",
      " [3.3006806e-02]\n",
      " [9.9965048e-01]\n",
      " [9.9737263e-01]\n",
      " [9.9903035e-01]\n",
      " [1.1760853e-05]\n",
      " [4.8743761e-05]\n",
      " [2.4933170e-03]\n",
      " [9.9922955e-01]\n",
      " [9.9994707e-01]\n",
      " [9.9961507e-01]\n",
      " [9.9947602e-01]\n",
      " [9.9862468e-01]\n",
      " [1.9240353e-04]\n",
      " [9.9999106e-01]\n",
      " [1.0080112e-03]\n",
      " [1.4260758e-05]\n",
      " [7.8939142e-05]\n",
      " [4.4414087e-04]\n",
      " [2.7840126e-06]\n",
      " [9.9971229e-01]\n",
      " [9.9961448e-01]\n",
      " [9.9467802e-01]\n",
      " [9.9991906e-01]\n",
      " [9.9925739e-01]\n",
      " [9.9999070e-01]\n",
      " [9.9971896e-01]\n",
      " [1.3014390e-03]\n",
      " [3.3589935e-05]\n",
      " [2.0616364e-05]\n",
      " [9.8119628e-01]\n",
      " [9.9641740e-01]\n",
      " [9.9999750e-01]\n",
      " [9.9926835e-01]\n",
      " [4.6918666e-04]\n",
      " [1.7505980e-06]\n",
      " [9.9622452e-01]\n",
      " [3.4641320e-07]\n",
      " [1.5224512e-04]\n",
      " [3.2267606e-05]\n",
      " [9.3765408e-07]\n",
      " [6.5301764e-03]\n",
      " [9.9999249e-01]\n",
      " [9.5630949e-06]\n",
      " [5.8265380e-03]\n",
      " [4.9349940e-03]\n",
      " [9.9865651e-01]\n",
      " [9.9750155e-01]\n",
      " [9.9999273e-01]\n",
      " [5.6234607e-05]\n",
      " [9.4983500e-04]\n",
      " [3.6921274e-06]\n",
      " [9.9946088e-01]\n",
      " [1.3085631e-07]\n",
      " [3.9862436e-03]\n",
      " [1.0412180e-02]\n",
      " [9.9945968e-01]\n",
      " [1.0000000e+00]\n",
      " [9.9995482e-01]\n",
      " [9.9996233e-01]\n",
      " [2.2906811e-06]\n",
      " [9.9867129e-01]\n",
      " [7.6313239e-07]\n",
      " [9.9194521e-01]\n",
      " [2.0340585e-06]\n",
      " [3.4923076e-03]\n",
      " [1.4649344e-06]\n",
      " [9.9691200e-01]\n",
      " [9.9934012e-01]\n",
      " [9.9482036e-01]\n",
      " [9.9649209e-01]\n",
      " [9.9109203e-01]\n",
      " [9.9981219e-01]\n",
      " [1.3973261e-02]\n",
      " [9.9999821e-01]\n",
      " [9.9911124e-01]\n",
      " [9.9978358e-01]\n",
      " [3.6919582e-07]\n",
      " [9.9935466e-01]\n",
      " [9.9965370e-01]\n",
      " [9.9638641e-01]\n",
      " [2.9988314e-07]\n",
      " [8.2371897e-01]\n",
      " [1.8229002e-05]\n",
      " [9.8653281e-01]\n",
      " [2.7777821e-01]\n",
      " [1.5464352e-06]\n",
      " [4.8682652e-03]\n",
      " [9.9981767e-01]\n",
      " [7.3602870e-02]\n",
      " [9.9982399e-01]\n",
      " [1.4060648e-06]\n",
      " [7.8985977e-05]\n",
      " [9.9980468e-01]\n",
      " [9.9044526e-01]\n",
      " [9.9404401e-01]\n",
      " [8.6780898e-03]\n",
      " [9.9999952e-01]\n",
      " [9.9996793e-01]\n",
      " [4.3137847e-03]\n",
      " [5.6879024e-04]]\n"
     ]
    }
   ],
   "source": [
    "#predicting the outputs of the model based on training data\n",
    "predictions = model.predict([X1, X2, X3, X4, X5])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
